Repo URL,Satd Comment Id,File Path Of First Occurence,File Path Of Last Occurence,renamed,Keyword,SATD Comment,context,bloc of first occurrence,bloc type of first occurrence,bloc of last occurrence,bloc type of last occurrence,SATD Comment Line Of First Occurence,SATD Comment Line Of Last Occurence,first Commit Hash,last Commit Hash,Link To The File Of First Occurence,Link To The File Of Last Occurence/When Adressed,Introduction Time,Last Occurence (even solved or not),number of commits,adressed ?,Computing Management Debt,IaC Code Debt,Dependency Management,Security Debt,Networking Debt,Environment-Based Configuration Debt,Monitoring and Logging Debt,Test Debt
https://github.com/rancherfederal/rke2-aws-tf,1,modules/server-nodepool/main.tf,data.tf,1,# todo,"# TODO: Ideally set this to `var.servers`, but currently blocked by: https://github.com/rancher/rke2/issues/349","# TODO: Ideally set this to `var.servers`, but currently blocked by: https://github.com/rancher/rke2/issues/349","module ""nodepool"" {
  source = ""../nodepool""

  name                   = var.name
  vpc_id                 = var.vpc_id
  subnets                = var.subnets
  instance_type          = var.instance_type
  ami                    = var.ami
  spot                   = var.spot
  iam_instance_profile   = var.iam_instance_profile == """" ? module.iam[0].iam_instance_profile : var.iam_instance_profile
  userdata               = data.template_cloudinit_config.this.rendered
  vpc_security_group_ids = concat([aws_security_group.this.id], [var.cluster_data.cluster_sg], var.extra_security_groups)
  asg                    = var.asg
  block_device_mappings  = var.block_device_mappings
  target_group_arns = [
    var.server_tg_arn,
    var.server_supervisor_tg_arn,
  ]

  # TODO: Ideally set this to `var.servers`, but currently blocked by: https://github.com/rancher/rke2/issues/349
  min_elb_capacity = 1

  tags = local.tags
}
",module,the block associated got renamed or deleted,,53,,6214e111668db69a992a72bd623ad7edf0a4bb21,6367365324003af74b9a259224515fbead095910,https://github.com/rancherfederal/rke2-aws-tf/blob/6214e111668db69a992a72bd623ad7edf0a4bb21/modules/server-nodepool/main.tf#L53,https://github.com/rancherfederal/rke2-aws-tf/blob/6367365324003af74b9a259224515fbead095910/data.tf,2020-10-16 17:18:14-06:00,2020-10-26 13:06:56-04:00,2,1,1,1,1,0,1,0,0,0
https://github.com/kubernetes/k8s.io,210,infra/gcp/terraform/kubernetes-public/k8s-kettle.tf,infra/gcp/terraform/kubernetes-public/k8s-kettle.tf,0,// todo,// TODO: remove when kettle migration is over,"// Service account dedicated for BigQuery Data Transfer from BQ dataset k8s-gubernator:builds 
 // TODO: remove when kettle migration is over","resource ""google_service_account"" ""bq_kettle_data_transfer_writer"" {
  account_id  = ""bq-data-transfer-kettle""
  description = ""Service Acccount BigQuery Data Transfer""
  project     = data.google_project.project.project_id
}
",resource,"resource ""google_service_account"" ""bq_kettle_data_transfer_writer"" {
  account_id  = ""bq-data-transfer-kettle""
  description = ""Service Acccount BigQuery Data Transfer""
  project     = data.google_project.project.project_id
}
",resource,69,77.0,decbde2d798942058e7c82462686bc21ce082996,5edb2a71296e70ec887d3827cb3eae428d0b9a3f,https://github.com/kubernetes/k8s.io/blob/decbde2d798942058e7c82462686bc21ce082996/infra/gcp/terraform/kubernetes-public/k8s-kettle.tf#L69,https://github.com/kubernetes/k8s.io/blob/5edb2a71296e70ec887d3827cb3eae428d0b9a3f/infra/gcp/terraform/kubernetes-public/k8s-kettle.tf#L77,2021-09-16 23:26:07+02:00,2024-04-15 09:31:30-04:00,6,0,0,1,0,1,0,0,0,0
https://github.com/uyuni-project/sumaform,118,libvirt_package_mirror/main.tf,modules/libvirt/package_mirror/main.tf,1,hack,// HACK: this output artificially depends on the domain id,"// HACK: this output artificially depends on the domain id 
 // any resource using this output will have to wait until domain is fully up","output ""hostname"" {
    // HACK: this output artificially depends on the domain id
    // any resource using this output will have to wait until domain is fully up
    value = ""${coalesce(""package-mirror.${var.domain}"", libvirt_domain.domain.id)}""
}
",output,the block associated got renamed or deleted,,64,,7b44a14d4d6a74a6e0387ceb7238c62df9765b92,0d3a83d22f57360dec522bcf1e5dd7adb3b9f9c3,https://github.com/uyuni-project/sumaform/blob/7b44a14d4d6a74a6e0387ceb7238c62df9765b92/libvirt_package_mirror/main.tf#L64,https://github.com/uyuni-project/sumaform/blob/0d3a83d22f57360dec522bcf1e5dd7adb3b9f9c3/modules/libvirt/package_mirror/main.tf,2016-09-05 14:18:52+02:00,2016-11-04 17:34:25+01:00,15,1,0,1,0,0,0,0,0,0
https://github.com/compiler-explorer/infra,268,terraform/ec2.tf,terraform/ec2.tf,0,todo,// TODO remove this,// TODO remove this,"resource ""aws_instance"" ""GPUNode"" {
  ami                         = local.gpu_image_id_old
  iam_instance_profile        = aws_iam_instance_profile.CompilerExplorerRole.name
  ebs_optimized               = false
  instance_type               = ""g4dn.xlarge""
  monitoring                  = false
  key_name                    = ""mattgodbolt""
  subnet_id                   = local.admin_subnet
  vpc_security_group_ids      = [aws_security_group.CompilerExplorer.id]
  associate_public_ip_address = true
  source_dest_check           = false
  user_data                   = ""gpu""

  lifecycle {
    ignore_changes = [
      // Seemingly needed to not replace stopped instances
      associate_public_ip_address
    ]
  }

  root_block_device {
    volume_type           = ""gp2""
    volume_size           = 24
    delete_on_termination = false
  }

  tags = {
    Site        = ""CompilerExplorer""
    Name        = ""GPUNode""
  }
}
",resource,the block associated got renamed or deleted,,134,,85295c876b56c7417ea7917c51c0a20ddb9b0a07,7e0840cb5b4fdc5b0c79ab82b68ed66fcd522e01,https://github.com/compiler-explorer/infra/blob/85295c876b56c7417ea7917c51c0a20ddb9b0a07/terraform/ec2.tf#L134,https://github.com/compiler-explorer/infra/blob/7e0840cb5b4fdc5b0c79ab82b68ed66fcd522e01/terraform/ec2.tf,2022-11-14 21:02:28-06:00,2022-11-15 07:39:11-06:00,2,1,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,467,examples/data-solutions/gcs-to-bq-with-dataflow/variables.tf,examples/data-solutions/gcs-to-bq-with-dataflow/variables.tf,0,fix,# FIXME(jccb): this is not used,"# FIXME(jccb): this is not used 
 # variable ""ssh_source_ranges"" { 
 #   description = ""IP CIDR ranges that will be allowed to connect via SSH to the onprem instance."" 
 #   type        = list(string) 
 #   default     = [""0.0.0.0/0""] 
 # } ","variable ""vpc_ip_cidr_range"" {
  description = ""Ip range used in the subnet deployef in the Service Project.""
  type        = string
  default     = ""10.0.0.0/20""
}
",variable,the block associated got renamed or deleted,,50,,90b0d18574a1b684aa8cb192f90ecf4494bd2688,970475de25d05a36a446a8cb7093d9bf511f6afa,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/90b0d18574a1b684aa8cb192f90ecf4494bd2688/examples/data-solutions/gcs-to-bq-with-dataflow/variables.tf#L50,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/970475de25d05a36a446a8cb7093d9bf511f6afa/examples/data-solutions/gcs-to-bq-with-dataflow/variables.tf,2022-01-13 18:30:55+01:00,2022-01-14 09:32:29+01:00,2,1,0,0,0,1,0,0,0,0
https://github.com/chanzuckerberg/cztack,170,databricks-cluster-policy/main.tf,databricks-cluster-policy/main.tf,0,implementation,## Messy implementation below - cannot set policy_family_id and/or policy_family_definiton_overrides,"## Messy implementation below - cannot set policy_family_id and/or policy_family_definiton_overrides 
 ## if definition is present, and setting them to null still triggers an error from the provider, so 
 ## we duplicate the setup and set a count on the var being present  
 ### if inherited cluster policy","resource ""databricks_cluster_policy"" ""inherited_cluster_policy"" {
  count = var.policy_family_id != null ? 1 : 0

  name                               = var.policy_name
  policy_family_definition_overrides = jsonencode(merge(local.default_policy, var.policy_overrides))
  policy_family_id                   = var.policy_family_id
}
",resource,"resource ""databricks_cluster_policy"" ""inherited_cluster_policy"" {
  count = var.policy_family_id != null ? 1 : 0

  name                               = var.policy_name
  policy_family_definition_overrides = jsonencode(merge(local.default_policy, var.policy_overrides))
  policy_family_id                   = var.policy_family_id
}
",resource,24,24.0,5f42e9bbb2eafdbde5a3afbc0d0fc1aa6d4093b9,0ab051aab7c11e550fcab20c4eaeef562c4d3e39,https://github.com/chanzuckerberg/cztack/blob/5f42e9bbb2eafdbde5a3afbc0d0fc1aa6d4093b9/databricks-cluster-policy/main.tf#L24,https://github.com/chanzuckerberg/cztack/blob/0ab051aab7c11e550fcab20c4eaeef562c4d3e39/databricks-cluster-policy/main.tf#L24,2023-10-31 13:13:06-07:00,2024-03-06 16:58:57-08:00,3,0,1,1,1,1,0,0,0,0
https://github.com/kbst/terraform-kubestack,48,quickstart/src/configurations/eks/eks_zero_cluster.tf,quickstart/src/configurations/eks/eks_zero_cluster.tf,0,fix,# FIXME: Use actual list when TF 0.12 finally supports heterogeneous maps,"# Comma-separated list of zone names to deploy worker nodes in 
 # EKS requires a min. of 2 zones 
 # Must match region set in provider 
 # e.g. cluster_availability_zones = ""eu-west-1a,eu-west-1b,eu-west-1c"" 
 # FIXME: Use actual list when TF 0.12 finally supports heterogeneous maps","module ""eks_zero"" {
  providers = {
    aws = aws.eks_zero
  }

  source = ""github.com/kbst/terraform-kubestack//aws/cluster?ref={{version}}""

  configuration = {
    # apps environment
    apps = {
      # Set name_prefix used to generate the cluster_name
      # [name_prefix]-[workspace]-[region]
      # e.g. name_prefix = kbst becomes: `kbst-apps-eu-west-1`
      # for small orgs the name works well
      # for bigger orgs consider department or team names
      name_prefix = """"

      # Set the base_domain used to generate the FQDN of the cluster
      # [cluster_name].[provider_name].[base_domain]
      # e.g. kbst-apps-eu-west-1.aws.infra.example.com
      base_domain = """"

      cluster_instance_type    = ""t3.small""
      cluster_desired_capacity = ""1""
      cluster_min_size         = ""1""
      cluster_max_size         = ""3""

      # Comma-separated list of zone names to deploy worker nodes in
      # EKS requires a min. of 2 zones
      # Must match region set in provider
      # e.g. cluster_availability_zones = ""eu-west-1a,eu-west-1b,eu-west-1c""
      # FIXME: Use actual list when TF 0.12 finally supports heterogeneous maps
      cluster_availability_zones = """"
    }

    # ops environment, inherits from apps
    ops = {}

    # loc environment, inherits from apps
    loc = {
      node_image = ""ghcr.io/kbst/kind-eks-d:v1.18.9-kbst.1""
    }
  }
}
",module,"module ""eks_zero"" {
  providers = {
    aws        = aws.eks_zero
    kubernetes = kubernetes.eks_zero
  }

  source = ""github.com/kbst/terraform-kubestack//aws/cluster?ref={{version}}""

  configuration = {
    # apps environment
    apps = {
      # Set name_prefix used to generate the cluster_name
      # [name_prefix]-[workspace]-[region]
      # e.g. name_prefix = kbst becomes: `kbst-apps-eu-west-1`
      # for small orgs the name works well
      # for bigger orgs consider department or team names
      name_prefix = """"

      # Set the base_domain used to generate the FQDN of the cluster
      # [cluster_name].[provider_name].[base_domain]
      # e.g. kbst-apps-eu-west-1.aws.infra.example.com
      base_domain = """"

      cluster_instance_type    = ""t3.small""
      cluster_desired_capacity = ""1""
      cluster_min_size         = ""1""
      cluster_max_size         = ""3""

      # Comma-separated list of zone names to deploy worker nodes in
      # EKS requires a min. of 2 zones
      # Must match region set in provider
      # e.g. cluster_availability_zones = ""eu-west-1a,eu-west-1b,eu-west-1c""
      # FIXME: Use actual list when TF 0.12 finally supports heterogeneous maps
      cluster_availability_zones = """"
    }

    # ops environment, inherits from apps
    ops = {}

    # loc environment, inherits from apps
    loc = {}
  }
}
",module,32,33.0,f767ed672b0f9d782e6b400522f7ba0bd651e33f,66873b2ae9f2c2dd667ee1818ec93d17ed0c9d83,https://github.com/kbst/terraform-kubestack/blob/f767ed672b0f9d782e6b400522f7ba0bd651e33f/quickstart/src/configurations/eks/eks_zero_cluster.tf#L32,https://github.com/kbst/terraform-kubestack/blob/66873b2ae9f2c2dd667ee1818ec93d17ed0c9d83/quickstart/src/configurations/eks/eks_zero_cluster.tf#L33,2021-06-04 18:37:18+02:00,2022-06-26 19:35:15+02:00,4,0,1,1,1,0,0,0,0,0
https://github.com/ministryofjustice/modernisation-platform,123,terraform/modules/iam_baseline/main.tf,terraform/modules/iam_baseline/main.tf,0,fix,"## Fix for DEFAULT KMS Key Error, Ref: https://github.com/hashicorp/terraform-provider-aws/issues/3450","## Fix for DEFAULT KMS Key Error, Ref: https://github.com/hashicorp/terraform-provider-aws/issues/3450","resource ""aws_iam_policy"" ""default_kms_key_policy"" {
  name        = ""cicd-member-kms-policy""
  description = ""IAM Policy for Default KMS Key, CICD member user""
  policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = [
          ""kms:DescribeKey""
        ]
        Effect   = ""Allow""
        Resource = ""arn:aws:kms:eu-west-2:771283872747:key/16234827-4f3c-479e-8000-7a3e75c6ed7e""
      },
    ]
  })
}
",resource,the block associated got renamed or deleted,,49,,89a681f139ebd642b075f0167ead77c7fdf991f4,c215a8bb6830b7f06eb7945a8eb92a7ff252a6bc,https://github.com/ministryofjustice/modernisation-platform/blob/89a681f139ebd642b075f0167ead77c7fdf991f4/terraform/modules/iam_baseline/main.tf#L49,https://github.com/ministryofjustice/modernisation-platform/blob/c215a8bb6830b7f06eb7945a8eb92a7ff252a6bc/terraform/modules/iam_baseline/main.tf,2022-09-29 21:15:15+01:00,2022-09-30 10:53:04+01:00,2,1,0,0,1,1,0,0,0,0
https://github.com/alphagov/govuk-aws,1305,terraform/projects/infra-public-wafs/backend_public_rule.tf,terraform/projects/infra-public-wafs/backend_public_rule.tf,0,# todo,# TODO: remove the above `count {}` statement and uncomment the below `block { ... }`,"# TODO: remove the above `count {}` statement and uncomment the below `block { ... }` 
 # statement once we're happy 
 # 
 # block { 
 #   custom_response { 
 #     response_code = 429  
 #     response_header { 
 #       name  = ""Retry-After"" 
 #       value = 30 
 #     }  
 #     response_header { 
 #       name  = ""Cache-Control"" 
 #       value = ""max-age=0, private"" 
 #     }  
 #     custom_response_body_key = ""backend-public-rule-429"" 
 #   } 
 # }","resource ""aws_wafv2_web_acl"" ""backend_public"" {
  name  = ""backend_public_web_acl""
  scope = ""REGIONAL""

  default_action {
    allow {}
  }

  # this rule matches any request that contains the header X-Always-Block: true
  # we use it as a simple sanity check / acceptance test from smokey to ensure that
  # the waf is enabled and processing requests
  rule {
    name     = ""x-always-block_web_acl_rule""
    priority = 1

    override_action {
      none {}
    }

    statement {
      rule_group_reference_statement {
        arn = aws_wafv2_rule_group.x_always_block.arn
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""x-always-block-rule-group""
      sampled_requests_enabled   = true
    }
  }

  # this rule matches any request from our NAT gateway IPs and allows it.
  rule {
    name     = ""allow-govuk-infra""
    priority = 2

    action {
      allow {}
    }

    statement {
      ip_set_reference_statement {
        arn = aws_wafv2_ip_set.govuk_requesting_ips.arn
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""govuk-infra-backend-requests""
      sampled_requests_enabled   = true
    }
  }

  # This rule is intended for monitoring only
  # set a base rate limit per IP looking back over the last 5 minutes
  # this is checked every 30s
  rule {
    name     = ""backend-public-base-rate-warning""
    priority = 9

    action {
      count {}
    }

    statement {
      rate_based_statement {
        limit              = var.backend_public_base_rate_warning
        aggregate_key_type = ""IP""
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""backend-public-base-rate-warning""
      sampled_requests_enabled   = true
    }
  }

  # set a base rate limit per IP looking back over the last 5 minutes
  # this is checked every 30s
  rule {
    name     = ""backend-public-base-rate-limit""
    priority = 10

    action {
      count {}
      # TODO: remove the above `count {}` statement and uncomment the below `block { ... }`
      # statement once we're happy
      #
      # block {
      #   custom_response {
      #     response_code = 429

      #     response_header {
      #       name  = ""Retry-After""
      #       value = 30
      #     }

      #     response_header {
      #       name  = ""Cache-Control""
      #       value = ""max-age=0, private""
      #     }

      #     custom_response_body_key = ""backend-public-rule-429""
      #   }
      # }
    }

    statement {
      rate_based_statement {
        limit              = var.backend_public_base_rate_limit
        aggregate_key_type = ""IP""
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""backend-public-base-rate-limit""
      sampled_requests_enabled   = true
    }
  }

  custom_response_body {
    key     = ""backend-public-rule-429""
    content = <<HTML
      <!DOCTYPE html>
      <html>
        <head>
          <title>Welcome to GOV.UK</title>
          <style>
            body { font-family: Arial, sans-serif; margin: 0; }
            header { background: black; }
            h1 { color: white; font-size: 29px; margin: 0 auto; padding: 10px; max-width: 990px; }
            p { color: black; margin: 30px auto; max-width: 990px; }
          </style>
        </head>
        <body>
          <header><h1>GOV.UK</h1></header>
          <p>Sorry, there have been too many attempts to access this page.</p>
          <p>Try again in a few minutes.</p>
        </body>
      </html>
      HTML

    content_type = ""TEXT_HTML""
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = ""backend-public-web-acl""
    sampled_requests_enabled   = true
  }
}
",resource,"resource ""aws_wafv2_web_acl"" ""backend_public"" {
  name  = ""backend_public_web_acl""
  scope = ""REGIONAL""

  default_action {
    allow {}
  }

  # this rule matches any request that contains the header X-Always-Block: true
  # we use it as a simple sanity check / acceptance test from smokey to ensure that
  # the waf is enabled and processing requests
  rule {
    name     = ""x-always-block_web_acl_rule""
    priority = 1

    override_action {
      none {}
    }

    statement {
      rule_group_reference_statement {
        arn = aws_wafv2_rule_group.x_always_block.arn
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""x-always-block-rule-group""
      sampled_requests_enabled   = true
    }
  }

  # this rule matches any request from our NAT gateway IPs and allows it.
  rule {
    name     = ""allow-govuk-infra""
    priority = 2

    action {
      allow {}
    }

    statement {
      ip_set_reference_statement {
        arn = aws_wafv2_ip_set.govuk_requesting_ips.arn
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""govuk-infra-backend-requests""
      sampled_requests_enabled   = true
    }
  }

  # This rule is intended for monitoring only
  # set a base rate limit per IP looking back over the last 5 minutes
  # this is checked every 30s
  rule {
    name     = ""backend-public-base-rate-warning""
    priority = 9

    action {
      count {}
    }

    statement {
      rate_based_statement {
        limit              = var.backend_public_base_rate_warning
        aggregate_key_type = ""IP""
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""backend-public-base-rate-warning""
      sampled_requests_enabled   = true
    }
  }

  # set a base rate limit per IP looking back over the last 5 minutes
  # this is checked every 30s
  rule {
    name     = ""backend-public-base-rate-limit""
    priority = 10

    action {
      block {
        custom_response {
          response_code = 429

          response_header {
            name  = ""Retry-After""
            value = 30
          }

          response_header {
            name  = ""Cache-Control""
            value = ""max-age=0, private""
          }

          custom_response_body_key = ""backend-public-rule-429""
        }
      }
    }

    statement {
      rate_based_statement {
        limit              = var.backend_public_base_rate_limit
        aggregate_key_type = ""IP""
      }
    }

    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""backend-public-base-rate-limit""
      sampled_requests_enabled   = true
    }
  }

  custom_response_body {
    key     = ""backend-public-rule-429""
    content = <<HTML
      <!DOCTYPE html>
      <html>
        <head>
          <title>Welcome to GOV.UK</title>
          <style>
            body { font-family: Arial, sans-serif; margin: 0; }
            header { background: black; }
            h1 { color: white; font-size: 29px; margin: 0 auto; padding: 10px; max-width: 990px; }
            p { color: black; margin: 30px auto; max-width: 990px; }
          </style>
        </head>
        <body>
          <header><h1>GOV.UK</h1></header>
          <p>Sorry, there have been too many attempts to access this page.</p>
          <p>Try again in a few minutes.</p>
        </body>
      </html>
      HTML

    content_type = ""TEXT_HTML""
  }

  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = ""backend-public-web-acl""
    sampled_requests_enabled   = true
  }
}
",resource,88,,a9e0334b2a80d6fc8771f71e8641d0c7fe914b96,3fdfd1b9c6c875b036403e4c686a8b6f6d6a111b,https://github.com/alphagov/govuk-aws/blob/a9e0334b2a80d6fc8771f71e8641d0c7fe914b96/terraform/projects/infra-public-wafs/backend_public_rule.tf#L88,https://github.com/alphagov/govuk-aws/blob/3fdfd1b9c6c875b036403e4c686a8b6f6d6a111b/terraform/projects/infra-public-wafs/backend_public_rule.tf,2023-01-05 13:47:47+00:00,2023-02-07 17:22:25+00:00,2,1,0,1,0,1,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,473,variables.tf,variables.tf,0,todo,"# TODO - at next breaking change, make 169.254.169.123/32 the default","# TODO - at next breaking change, make 169.254.169.123/32 the default","variable ""node_security_group_ntp_ipv4_cidr_block"" {
  description = ""IPv4 CIDR block to allow NTP egress. Default is public IP space, but [Amazon Time Sync Service](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html) can be used as well with `[\""169.254.169.123/32\""]`""
  type        = list(string)
  default     = [""0.0.0.0/0""]
}
",variable,the block associated got renamed or deleted,,325,,4543ab454bea80b64381b88a631d955a7cfae247,b2e97ca3dcbcd76063f1c932aa5199b4f49a2aa1,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/4543ab454bea80b64381b88a631d955a7cfae247/variables.tf#L325,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/b2e97ca3dcbcd76063f1c932aa5199b4f49a2aa1/variables.tf,2022-06-28 12:16:20-04:00,2022-12-05 16:26:23-05:00,5,1,1,1,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,6,foundations/business-units/main.tf,foundations/business-units/main.tf,0,# todo,# TODO(averbukh): simplify log-sink parameters once https://github.com/terraform-google-modules/terraform-google-log-export/issues/28 is done.,"# Copyright 2019 Google LLC 
 # 
 # Licensed under the Apache License, Version 2.0 (the ""License""); 
 # you may not use this file except in compliance with the License. 
 # You may obtain a copy of the License at 
 # 
 #     https://www.apache.org/licenses/LICENSE-2.0 
 # 
 # Unless required by applicable law or agreed to in writing, software 
 # distributed under the License is distributed on an ""AS IS"" BASIS, 
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 # See the License for the specific language governing permissions and 
 # limitations under the License.  
 # TODO(averbukh): simplify log-sink parameters once https://github.com/terraform-google-modules/terraform-google-log-export/issues/28 is done. ","locals {
  parent_numeric_id             = element(split(""/"", var.root_node), 1)
  log_sink_parent_resource_type = element(split(""/"", var.root_node), 0) == ""organizations"" ? ""organization"" : ""folder""
  log_sink_name                 = element(split(""/"", var.root_node), 0) == ""organizations"" ? ""logs-audit-org-${local.parent_numeric_id}"" : ""logs-audit-folder-${local.parent_numeric_id}""
}
",locals,the block associated got renamed or deleted,,15,,fd0704670d8ba2b663ee5e9ff19595e6d3ced5c3,c486bfc66f9814e33b410602cb557a5e4d532912,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/fd0704670d8ba2b663ee5e9ff19595e6d3ced5c3/foundations/business-units/main.tf#L15,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/c486bfc66f9814e33b410602cb557a5e4d532912/foundations/business-units/main.tf,2019-10-30 22:21:15+01:00,2020-04-03 14:06:48+02:00,5,1,0,1,1,0,0,0,1,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,206,variables-extensions.tf,variables-extensions.tf,0,todo,# TODO Update,"variable ""upgrade_nodepool"" { # TODO Update","variable ""upgrade_nodepool"" { # TODO Update
  default     = false
  description = ""Whether to upgrade the Kubernetes version of the node pools.""
  type        = bool
}
",variable,the block associated got renamed or deleted,,15,,6c867cd8e9cbf559742f56658989bcded0d1fd89,79845fb791998bdde1b58fa656b6c381f7d26510,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/6c867cd8e9cbf559742f56658989bcded0d1fd89/variables-extensions.tf#L15,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/79845fb791998bdde1b58fa656b6c381f7d26510/variables-extensions.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,3,1,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1753,fast/stages/0-bootstrap/organization.tf,fast/stages/0-bootstrap/organization.tf,0,# todo,# TODO: add a check block to ensure our custom roles exist in the factory files,# TODO: add a check block to ensure our custom roles exist in the factory files,"module ""organization"" {
  source          = ""../../../modules/organization""
  organization_id = ""organizations/${var.organization.id}""
  # human (groups) IAM bindings
  group_iam = {
    for k, v in local.group_iam :
    k => distinct(concat(v, lookup(var.group_iam, k, [])))
  }
  # machine (service accounts) IAM bindings
  iam = merge(
    {
      for k, v in local.iam : k => distinct(concat(v, lookup(var.iam, k, [])))
    },
    {
      for k, v in var.iam : k => v if lookup(local.iam, k, null) == null
    }
  )
  # additive bindings, used for roles co-managed by different stages
  iam_bindings_additive = merge(
    local.iam_bindings_additive,
    var.iam_bindings_additive
  )
  # delegated role grant for resource manager service account
  iam_bindings = {
    organization_iam_admin_conditional = {
      members = [module.automation-tf-resman-sa.iam_email]
      role    = module.organization.custom_role_id[""organization_iam_admin""]
      condition = {
        expression = format(
          ""api.getAttribute('iam.googleapis.com/modifiedGrantsByRole', []).hasOnly([%s])"",
          join("","", formatlist(""'%s'"", concat(
            [
              ""roles/accesscontextmanager.policyAdmin"",
              ""roles/compute.orgFirewallPolicyAdmin"",
              ""roles/compute.xpnAdmin"",
              ""roles/orgpolicy.policyAdmin"",
              ""roles/resourcemanager.organizationViewer"",
              module.organization.custom_role_id[""tenant_network_admin""]
            ],
            local.billing_mode == ""org"" ? [
              ""roles/billing.admin"",
              ""roles/billing.costsManager"",
              ""roles/billing.user"",
            ] : []
          )))
        )
        title       = ""automation_sa_delegated_grants""
        description = ""Automation service account delegated grants.""
      }
    }
  }
  custom_roles = var.custom_roles
  factories_config = {
    custom_roles = var.factories_config.custom_roles
    org_policies = (
      var.bootstrap_user != null ? null : var.factories_config.org_policy
    )
  }
  logging_sinks = {
    for name, attrs in var.log_sinks : name => {
      bq_partitioned_table = attrs.type == ""bigquery""
      destination          = local.log_sink_destinations[name].id
      filter               = attrs.filter
      type                 = attrs.type
    }
  }
  org_policies = var.bootstrap_user != null ? {} : {
    ""iam.allowedPolicyMemberDomains"" = {
      rules = [
        {
          allow = { values = local.drs_domains }
          condition = {
            expression = (
              ""!resource.matchTag('${local.drs_tag_name}', 'allowed-policy-member-domains-all')""
            )
          }
        },
        {
          allow = { all = true }
          condition = {
            expression = (
              ""resource.matchTag('${local.drs_tag_name}', 'allowed-policy-member-domains-all')""
            )
            title = ""allow-all""
          }
        },
      ]
    }
    # ""gcp.resourceLocations"" = {}
    # ""iam.workloadIdentityPoolProviders"" = {}
  }
  tags = {
    (var.org_policies_config.tag_name) = {
      description = ""Organization policy conditions.""
      iam         = {}
      values = merge(
        {
          allowed-policy-member-domains-all = {}
        },
        var.org_policies_config.tag_values
      )
    }
  }
}
",module,"import {
  for_each = (
    !var.org_policies_config.import_defaults || var.bootstrap_user != null
    ? toset([])
    : toset([
      # source: https://cloud.google.com/resource-manager/docs/secure-by-default-organizations#organization_policies_enforced_on_organization_resources
      # listed in the order as on page
      ""iam.disableServiceAccountKeyCreation"",
      ""iam.disableServiceAccountKeyUpload"",
      ""iam.automaticIamGrantsForDefaultServiceAccounts"",
      ""iam.allowedPolicyMemberDomains"",
      ""essentialcontacts.allowedContactDomains"",
      ""storage.uniformBucketLevelAccess"",
      # ""compute.setNewProjectDefaultToZonalDNSOnly"", # not confirmed, that this is already live
    ])
  )
  id = ""organizations/${var.organization.id}/policies/${each.key}""
  to = module.organization.google_org_policy_policy.default[each.key]
}
",import,80,99.0,9d6e61428b3c2d3279343e9357faa2cdd0c1e2bd,3368be51bd8e524a6ba6fc387d35936261af17db,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/9d6e61428b3c2d3279343e9357faa2cdd0c1e2bd/fast/stages/0-bootstrap/organization.tf#L80,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/3368be51bd8e524a6ba6fc387d35936261af17db/fast/stages/0-bootstrap/organization.tf#L99,2023-12-27 11:33:16+00:00,2024-05-21 11:27:57+02:00,13,0,0,1,0,1,0,0,0,1
https://github.com/pivotal-cf/terraforming-azure,2,security_group.tf,modules/infra/main.tf,1,# todo,# TODO: remove this rule once we have an internal mysql LB,# TODO: remove this rule once we have an internal mysql LB,"resource ""azurerm_network_security_group"" ""ops_manager_security_group"" {
  name                = ""${var.env_name}-ops-manager-security-group""
  location            = ""${var.location}""
  resource_group_name = ""${azurerm_resource_group.pcf_resource_group.name}""

  security_rule {
    name                       = ""internal-anything""
    priority                   = 100
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = ""*""
    source_address_prefix      = ""VirtualNetwork""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""ssh""
    priority                   = 200
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 22
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""bosh-agent""
    priority                   = 201
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 6868
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""bosh-director""
    priority                   = 202
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 25555
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""dns""
    priority                   = 203
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 53
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""http""
    priority                   = 204
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 80
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""https""
    priority                   = 205
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 443
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""loggregator""
    priority                   = 206
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 4443
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  # TODO: remove this rule once we have an internal mysql LB
  security_rule {
    name                       = ""mysql""
    priority                   = 207
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 3306
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  # TODO: remove this rule once we have an internal mysql LB
  security_rule {
    name                       = ""mysql-healthcheck""
    priority                   = 208
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 1936
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }
}
",resource,"resource ""azurerm_network_security_group"" ""ops_manager_security_group"" {
  name                = ""${var.env_name}-ops-manager-security-group""
  location            = ""${var.location}""
  resource_group_name = ""${azurerm_resource_group.pcf_resource_group.name}""

  security_rule {
    name                       = ""ssh""
    priority                   = 200
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""Tcp""
    source_port_range          = ""*""
    destination_port_range     = 22
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""http""
    priority                   = 204
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 80
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }

  security_rule {
    name                       = ""https""
    priority                   = 205
    direction                  = ""Inbound""
    access                     = ""Allow""
    protocol                   = ""*""
    source_port_range          = ""*""
    destination_port_range     = 443
    source_address_prefix      = ""Internet""
    destination_address_prefix = ""*""
  }
}
",resource,115,,d0626ac6159028a649606ae859f6ebd8d252a84c,bc53195163b46b90a13f5579ac82d3cf50490c18,https://github.com/pivotal-cf/terraforming-azure/blob/d0626ac6159028a649606ae859f6ebd8d252a84c/security_group.tf#L115,https://github.com/pivotal-cf/terraforming-azure/blob/bc53195163b46b90a13f5579ac82d3cf50490c18/modules/infra/main.tf,2016-10-07 11:24:38-07:00,2019-07-30 09:28:17-07:00,14,1,1,1,0,1,1,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,204,modules/iam/tagging.tf,modules/iam/tagging.tf,0,todo,// TODO Support reactivation of retired namespace w/ update,"state = ""ACTIVE"" // TODO Support reactivation of retired namespace w/ update","data ""oci_identity_tag_namespaces"" ""oke"" {
  provider       = oci.home
  compartment_id = var.compartment_id
  filter {
    name   = ""name""
    values = [var.tag_namespace]
  }
  state = ""ACTIVE"" // TODO Support reactivation of retired namespace w/ update
}
",data,"data ""oci_identity_tag_namespaces"" ""oke"" {
  count          = var.create_iam_resources ? 1 : 0
  provider       = oci.home
  compartment_id = var.compartment_id
  filter {
    name   = ""name""
    values = [var.tag_namespace]
  }

  state = ""ACTIVE"" // TODO Support reactivation of retired namespace w/ update
}
",data,11,13.0,6c867cd8e9cbf559742f56658989bcded0d1fd89,e2ac866a96bd7171c980727c46078cc438643225,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/6c867cd8e9cbf559742f56658989bcded0d1fd89/modules/iam/tagging.tf#L11,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/e2ac866a96bd7171c980727c46078cc438643225/modules/iam/tagging.tf#L13,2023-10-25 16:40:02+11:00,2024-03-28 20:16:45+11:00,8,0,0,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,485,modules/extensions/cilium.tf,modules/extensions/cilium.tf,0,todo,# TODO Support Flannel w/ generic-veth & tunnel disabled,# TODO Support Flannel w/ generic-veth & tunnel disabled,"locals {
  cilium_helm_crds_file       = join(""/"", [local.yaml_manifest_path, ""cilium.crds.yaml""])
  cilium_helm_manifest_file   = join(""/"", [local.yaml_manifest_path, ""cilium.manifest.yaml""])
  cilium_helm_values_file     = join(""/"", [local.yaml_manifest_path, ""cilium.values.yaml""])
  cilium_net_attach_def_file  = join(""/"", [local.yaml_manifest_path, ""cilium.net_attach_def.yaml""])
  cilium_veth_config_map_file = join(""/"", [local.yaml_manifest_path, ""cilium.cni_config_map.yaml""])

  cilium_helm_crds     = one(data.helm_template.cilium[*].crds)
  cilium_helm_manifest = one(data.helm_template.cilium[*].manifest)

  cilium_vxlan_cni = {
    install      = true
    chainingMode = ""none""
    exclusive    = true # !var.multus_install
  }

  # TODO Support Flannel w/ generic-veth & tunnel disabled
  cilium_tunnel = ""vxlan"" # var.cni_type == ""flannel"" ? ""disabled"" : ""vxlan""
  cilium_flannel_cni = {
    install      = true
    chainingMode = ""generic-veth""
    configMap    = ""cni-configuration""
    customConf   = var.cni_type == ""flannel""
    exclusive    = !var.multus_install
  }

  cilium_helm_values = {
    annotateK8sNode                 = true
    cluster                         = { name = ""oke-${var.state_id}"" }
    clustermesh                     = { useAPIServer = true }
    cni                             = local.cilium_vxlan_cni
    containerRuntime                = { integration = ""crio"" }
    installIptablesRules            = true
    installNoConntrackIptablesRules = false
    ipam                            = { mode = ""kubernetes"" }
    ipv4NativeRoutingCIDR           = element(var.vcn_cidrs, 0)
    kubeProxyReplacement            = ""disabled""
    pmtuDiscovery                   = { enabled = true }
    tunnel                          = local.cilium_tunnel

    hubble = {
      metrics = {
        dashboards = { enabled = var.prometheus_install }
        # serviceMonitor = { enabled = var.prometheus_enabled }
      }
      relay = { enabled = true }
      ui    = { enabled = true }
    }

    k8s = {
      requireIPv4PodCIDR   = true # wait for Kubernetes to provide the PodCIDR (ipam kubernetes)
      enableIPv4Masquerade = true # var.cni_type != ""flannel""  # masquerade IPv4 traffic leaving the node from endpoints
    }

    # Prometheus metrics
    metrics = {
      dashboards = { enabled = var.prometheus_install }
      #   # serviceMonitor = { enabled = var.prometheus_enabled }
    }

    prometheus = {
      enabled = var.prometheus_install
      # serviceMonitor = { enabled = var.prometheus_enabled }
    }

    operator = {
      prometheus = {
        enabled = var.prometheus_install
        # serviceMonitor = { enabled = var.prometheus_enabled }
      }
    }
  }

  cilium_net_attach_def_conf = {
    cniVersion = ""0.3.1""
    name       = ""cilium""
    plugins = [
      {
        cniVersion = ""0.3.1""
        name       = ""cilium""
        type       = ""cilium-cni""
      },
      {
        name = ""cilium-sbr""
        type = ""sbr""
      }
    ],
  }

  cilium_net_attach_def = {
    apiVersion = ""k8s.cni.cncf.io/v1""
    kind       = ""NetworkAttachmentDefinition""
    metadata   = { name = ""cilium"" }
    spec       = { config = jsonencode(local.cilium_net_attach_def_conf) }
  }

  cilium_veth_conf = {
    cniVersion = ""0.3.1""
    name       = ""cbr0""
    ""plugins"" = [
      {
        type = ""flannel""
        delegate = {
          hairpinMode      = true
          isDefaultGateway = true
        }
      },
      {
        type         = ""portmap""
        capabilities = { portMappings = true }
      },
      { type = ""cilium-cni"" },
    ]
  }

  cilium_veth_config_map = {
    apiVersion = ""v1""
    kind       = ""ConfigMap""
    metadata = {
      name      = ""cni-configuration""
      namespace = var.cilium_namespace
    }
    data = { ""cni-config"" = jsonencode(local.cilium_veth_conf) }
  }

  cilium_net_attach_def_yaml  = yamlencode(local.cilium_net_attach_def)
  cilium_veth_config_map_yaml = yamlencode(local.cilium_veth_config_map)
  cilium_helm_values_yaml     = yamlencode(local.cilium_helm_values)
}
",locals,"locals {
  cilium_helm_crds_file       = join(""/"", [local.yaml_manifest_path, ""cilium.crds.yaml""])
  cilium_helm_manifest_file   = join(""/"", [local.yaml_manifest_path, ""cilium.manifest.yaml""])
  cilium_helm_values_file     = join(""/"", [local.yaml_manifest_path, ""cilium.values.yaml""])
  cilium_net_attach_def_file  = join(""/"", [local.yaml_manifest_path, ""cilium.net_attach_def.yaml""])
  cilium_veth_config_map_file = join(""/"", [local.yaml_manifest_path, ""cilium.cni_config_map.yaml""])

  cilium_helm_crds     = one(data.helm_template.cilium[*].crds)
  cilium_helm_manifest = one(data.helm_template.cilium[*].manifest)

  cilium_vxlan_cni = {
    install      = true
    chainingMode = ""none""
    exclusive    = true # !var.multus_install
  }

  # TODO Support Flannel w/ generic-veth & tunnel disabled
  cilium_tunnel = ""vxlan"" # var.cni_type == ""flannel"" ? ""disabled"" : ""vxlan""
  cilium_flannel_cni = {
    install      = true
    chainingMode = ""generic-veth""
    configMap    = ""cni-configuration""
    customConf   = var.cni_type == ""flannel""
    exclusive    = !var.multus_install
  }

  cilium_helm_values = {
    annotateK8sNode                 = true
    cluster                         = { name = ""oke-${var.state_id}"" }
    clustermesh                     = { useAPIServer = true }
    cni                             = local.cilium_vxlan_cni
    containerRuntime                = { integration = ""crio"" }
    installIptablesRules            = true
    installNoConntrackIptablesRules = false
    ipam                            = { mode = ""kubernetes"" }
    ipv4NativeRoutingCIDR           = element(var.vcn_cidrs, 0)
    kubeProxyReplacement            = ""disabled""
    pmtuDiscovery                   = { enabled = true }
    tunnel                          = local.cilium_tunnel

    hubble = {
      metrics = {
        dashboards = { enabled = var.prometheus_install }
        # serviceMonitor = { enabled = var.prometheus_enabled }
      }
      relay = { enabled = true }
      ui    = { enabled = true }
    }

    k8s = {
      requireIPv4PodCIDR   = true # wait for Kubernetes to provide the PodCIDR (ipam kubernetes)
      enableIPv4Masquerade = true # var.cni_type != ""flannel""  # masquerade IPv4 traffic leaving the node from endpoints
    }

    # Prometheus metrics
    metrics = {
      dashboards = { enabled = var.prometheus_install }
      #   # serviceMonitor = { enabled = var.prometheus_enabled }
    }

    prometheus = {
      enabled = var.prometheus_install
      # serviceMonitor = { enabled = var.prometheus_enabled }
    }

    operator = {
      prometheus = {
        enabled = var.prometheus_install
        # serviceMonitor = { enabled = var.prometheus_enabled }
      }
    }
  }

  cilium_net_attach_def_conf = {
    cniVersion = ""0.3.1""
    name       = ""cilium""
    plugins = [
      {
        cniVersion = ""0.3.1""
        name       = ""cilium""
        type       = ""cilium-cni""
      },
      {
        name = ""cilium-sbr""
        type = ""sbr""
      }
    ],
  }

  cilium_net_attach_def = {
    apiVersion = ""k8s.cni.cncf.io/v1""
    kind       = ""NetworkAttachmentDefinition""
    metadata   = { name = ""cilium"" }
    spec       = { config = jsonencode(local.cilium_net_attach_def_conf) }
  }

  cilium_veth_conf = {
    cniVersion = ""0.3.1""
    name       = ""cbr0""
    ""plugins"" = [
      {
        type = ""flannel""
        delegate = {
          hairpinMode      = true
          isDefaultGateway = true
        }
      },
      {
        type         = ""portmap""
        capabilities = { portMappings = true }
      },
      { type = ""cilium-cni"" },
    ]
  }

  cilium_veth_config_map = {
    apiVersion = ""v1""
    kind       = ""ConfigMap""
    metadata = {
      name      = ""cni-configuration""
      namespace = var.cilium_namespace
    }
    data = { ""cni-config"" = jsonencode(local.cilium_veth_conf) }
  }

  cilium_net_attach_def_yaml  = yamlencode(local.cilium_net_attach_def)
  cilium_veth_config_map_yaml = yamlencode(local.cilium_veth_config_map)
  cilium_helm_values_yaml     = yamlencode(local.cilium_helm_values)
}
",locals,20,20.0,9b683d85bcd7aafb6cc0c0357ae46e28314942d5,9b683d85bcd7aafb6cc0c0357ae46e28314942d5,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/9b683d85bcd7aafb6cc0c0357ae46e28314942d5/modules/extensions/cilium.tf#L20,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/9b683d85bcd7aafb6cc0c0357ae46e28314942d5/modules/extensions/cilium.tf#L20,2023-11-29 10:56:56+11:00,2023-11-29 10:56:56+11:00,1,0,0,1,0,0,1,0,0,0
https://github.com/magma/magma,3,orc8r/cloud/deploy/terraform/orc8r-aws/variables.tf,orc8r/cloud/deploy/terraform/orc8r-aws/variables.tf,0,# todo,# TODO: support an existing VPC,"############################################################################## 
 # VPC configuration 
 ##############################################################################  
 # TODO: support an existing VPC ","variable ""vpc_name"" {
  description = ""Name for the VPC that will contain all the Orchestrator components.""
  type        = string
  default     = ""orc8r_vpc""
}
",variable,"variable ""vpc_name"" {
  description = ""Name for the VPC that will contain all the Orchestrator components.""
  type        = string
  default     = ""orc8r_vpc""
}
",variable,110,206.0,9ed394ba3baa1b2fb3f87da0634cd175e13b9639,b72801aa1cccc468273bbb99e5ec4fafa3c052c9,https://github.com/magma/magma/blob/9ed394ba3baa1b2fb3f87da0634cd175e13b9639/orc8r/cloud/deploy/terraform/orc8r-aws/variables.tf#L110,https://github.com/magma/magma/blob/b72801aa1cccc468273bbb99e5ec4fafa3c052c9/orc8r/cloud/deploy/terraform/orc8r-aws/variables.tf#L206,2020-03-03 14:15:32-08:00,2022-03-10 13:24:52+00:00,23,0,0,1,0,0,1,0,0,0
https://github.com/nasa/cumulus,127,tf-modules/cumulus_ecs_service/main.tf,tf-modules/cumulus_ecs_service/main.tf,0,todo,# TODO Re-enable tags once this warning is addressed:,"# TODO Re-enable tags once this warning is addressed: 
 #   The new ARN and resource ID format must be enabled to add tags to the 
 #   service. Opt in to the new format and try again. 
 # 
 # tags                               = var.tags","resource ""aws_ecs_service"" ""default"" {
  name                               = local.full_name
  cluster                            = var.cluster_arn
  desired_count                      = var.desired_count
  task_definition                    = aws_ecs_task_definition.default.arn
  deployment_maximum_percent         = 100
  deployment_minimum_healthy_percent = 0
  # TODO Re-enable tags once this warning is addressed:
  #   The new ARN and resource ID format must be enabled to add tags to the
  #   service. Opt in to the new format and try again.
  #
  # tags                               = var.tags
}
",resource,"resource ""aws_ecs_service"" ""default"" {
  name                               = local.full_name
  cluster                            = var.cluster_arn
  desired_count                      = var.desired_count
  task_definition                    = aws_ecs_task_definition.default.arn
  deployment_maximum_percent         = 100
  deployment_minimum_healthy_percent = 0
  # TODO Re-enable tags once this warning is addressed:
  #   The new ARN and resource ID format must be enabled to add tags to the
  #   service. Opt in to the new format and try again.
  #
  # tags                               = var.tags
}
",resource,63,75.0,a952912be21d15aca9ed51635d5bf9ef21eb2b65,a049cd2a95dda0e27182ed434f49c44116b708d0,https://github.com/nasa/cumulus/blob/a952912be21d15aca9ed51635d5bf9ef21eb2b65/tf-modules/cumulus_ecs_service/main.tf#L63,https://github.com/nasa/cumulus/blob/a049cd2a95dda0e27182ed434f49c44116b708d0/tf-modules/cumulus_ecs_service/main.tf#L75,2019-09-12 17:00:08-04:00,2023-08-08 16:33:19-06:00,17,0,1,1,0,0,0,0,0,0
https://github.com/CDCgov/prime-simplereport,1,ops/services/database/variables.tf,ops/services/database/variables.tf,0,fix,"// To fix, the postgres module could be refactored into the main terraform state","// Note: Rotating the master password has a race condition 
 // Terraform initializes the postgres module before it rotates the password 
 // Terraform will succeed on the plan phase, but fail during apply 
 // This is expected. Just run the deploy a second time and it will succeeed 
 // To fix, the postgres module could be refactored into the main terraform state","variable ""master_password_rotated"" {
  description = ""Changing this value will force the master database password to rotate. This can be any string, but a date is encourage to make tracking rotation easier.""
  type        = string
  default     = ""2020-11-23T00:00:00""
}
",variable,,,34,0.0,d4cbdde76ab0651a916fb6f36ae4973afb92beee,e68ecac5685fd77154663ddbdbf1a325ad00d808,https://github.com/CDCgov/prime-simplereport/blob/d4cbdde76ab0651a916fb6f36ae4973afb92beee/ops/services/database/variables.tf#L34,https://github.com/CDCgov/prime-simplereport/blob/e68ecac5685fd77154663ddbdbf1a325ad00d808/ops/services/database/variables.tf#L0,2020-11-24 09:45:34-05:00,2021-04-13 16:11:54-04:00,3,2,0,1,0,1,0,0,0,0
https://github.com/uyuni-project/sumaform,4,libvirt_package_mirror/main.tf,libvirt_package_mirror/main.tf,0,hack,//HACK: there's currently no better way to deploy a templated file,//HACK: there's currently no better way to deploy a templated file,"resource ""libvirt_domain"" ""domain"" {
  name = ""package-mirror""
  memory = 512
  vcpu = 1
  disk {
    volume_id = ""${libvirt_volume.main_disk.id}""
  }
  disk {
    volume_id = ""${libvirt_volume.data_disk.id}""
  }

  network_interface {
    wait_for_lease = true
    network = ""vagrant-libvirt""
  }

  connection {
    user = ""root""
    password = ""vagrant""
  }

  provisioner ""file"" {
    source = ""salt""
    destination = ""/root""
  }

  provisioner ""remote-exec"" {
    inline = [

//HACK: there's currently no better way to deploy a templated file
<<EOF

echo ""hostname: package-mirror
avahi-domain: ${var.avahi-domain}
role: package-mirror
"" >/etc/salt/grains

EOF
      ,
      ""salt-call --force-color --file-root /root/salt --local state.sls terraform-support"",
      ""salt-call --force-color --file-root /root/salt --local state.highstate""
    ]
  }
}
",resource,"resource ""libvirt_domain"" ""domain"" {
  name = ""package-mirror""
  memory = 512
  vcpu = 1

  disk {
    volume_id = ""${libvirt_volume.main_disk.id}""
  }
  disk {
    volume_id = ""${libvirt_volume.data_disk.id}""
  }

  network_interface {
    wait_for_lease = true
    network_name = ""vagrant-libvirt""
  }

  connection {
    user = ""root""
    password = ""linux""
  }

  provisioner ""file"" {
    source = ""salt""
    destination = ""/srv""
  }

  provisioner ""file"" {
    content = <<EOF

hostname: package-mirror
domain: ${var.domain}
role: package-mirror

EOF

    destination = ""/etc/salt/grains""
  }

  provisioner ""remote-exec"" {
    inline = [
      ""salt-call --local state.sls terraform-resource"",
      ""salt-call --local state.highstate""
    ]
  }
}
",resource,46,,aa4769cdd0f82673333e016331828c57635d961e,42c1ed331abd5ce0c41e605202cc4469acb8ac2b,https://github.com/uyuni-project/sumaform/blob/aa4769cdd0f82673333e016331828c57635d961e/libvirt_package_mirror/main.tf#L46,https://github.com/uyuni-project/sumaform/blob/42c1ed331abd5ce0c41e605202cc4469acb8ac2b/libvirt_package_mirror/main.tf,2016-06-30 07:59:00+02:00,2016-09-05 14:46:59+02:00,11,1,1,0,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1776,tests/fixtures/net-lb-app-int-cross-region.tf,tests/fixtures/net-lb-app-int-cross-region.tf,0,fix,# requires fixtures/fixtures/compute-mig.tf,"# Copyright 2024 Google LLC 
 # 
 # Licensed under the Apache License, Version 2.0 (the ""License""); 
 # you may not use this file except in compliance with the License. 
 # You may obtain a copy of the License at 
 # 
 #      http://www.apache.org/licenses/LICENSE-2.0 
 # 
 # Unless required by applicable law or agreed to in writing, software 
 # distributed under the License is distributed on an ""AS IS"" BASIS, 
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 # See the License for the specific language governing permissions and 
 # limitations under the License.  
 # requires fixtures/fixtures/compute-mig.tf ","module ""net-lb-app-int-cross-region"" {
  source     = ""./fabric/modules/net-lb-app-int-cross-region""
  name       = ""ilb-test""
  project_id = var.project_id
  backend_service_configs = {
    default = {
      backends = [{
        group = module.compute-mig.group_manager.instance_group
      }]
    }
  }
  vpc_config = {
    network = var.vpc.self_link
    subnetworks = {
      (var.region) = var.subnet.self_link
    }
  }
}",module,"module ""net-lb-app-int-cross-region"" {
  source     = ""./fabric/modules/net-lb-app-int-cross-region""
  name       = ""ilb-test""
  project_id = var.project_id
  backend_service_configs = {
    default = {
      backends = [{
        group = module.compute-mig.group_manager.instance_group
      }]
    }
  }
  vpc_config = {
    network = var.vpc.self_link
    subnetworks = {
      (var.region) = var.subnet.self_link
    }
  }
}",module,15,15.0,277777d1c700bb29e151a7877925fd0fb0aa761f,277777d1c700bb29e151a7877925fd0fb0aa761f,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/277777d1c700bb29e151a7877925fd0fb0aa761f/tests/fixtures/net-lb-app-int-cross-region.tf#L15,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/277777d1c700bb29e151a7877925fd0fb0aa761f/tests/fixtures/net-lb-app-int-cross-region.tf#L15,2024-01-23 16:34:45+01:00,2024-01-23 16:34:45+01:00,1,0,0,1,0,0,0,0,0,0
https://github.com/pingcap/tidb-operator,4,deploy/alicloud/ack/main.tf,deploy/aliyun/ack/main.tf,1,workaround,"// split and join: workaround for terraform's limitation of conditional list choice, similarly hereinafter","// split and join: workaround for terraform's limitation of conditional list choice, similarly hereinafter","resource ""alicloud_cs_managed_kubernetes"" ""k8s"" {
  name                  = ""${var.cluster_name}""
  // split and join: workaround for terraform's limitation of conditional list choice, similarly hereinafter
  vswitch_ids           = [""${element(split("","", var.vpc_id != """" && (length(data.alicloud_vswitches.default.vswitches) != 0) ? join("","", data.template_file.vswitch_id.*.rendered) : join("","", alicloud_vswitch.all.*.id)), 0)}""]
  key_name              = ""${alicloud_key_pair.default.key_name}""
  pod_cidr              = ""${var.k8s_pod_cidr}""
  service_cidr          = ""${var.k8s_service_cidr}""
  new_nat_gateway       = ""${var.create_nat_gateway}""
  cluster_network_type  = ""${var.cluster_network_type}""
  slb_internet_enabled  = ""${var.public_apiserver}""
  kube_config           = ""${var.kubeconfig_file != """" ? var.kubeconfig_file : format(""%s/kubeconfig"", path.module)}""
  worker_numbers        = [""${var.default_worker_count}""]
  worker_instance_types = [""${var.default_worker_type != """" ? var.default_worker_type : data.alicloud_instance_types.default.instance_types.0.id}""]

  # These varialbes are 'ForceNew' that will cause kubernetes cluster re-creation
  # on variable change, so we make all these variables immutable in favor of safety.
  lifecycle {
    ignore_changes = [
      ""vswitch_ids"",
      ""worker_instance_types"",
      ""key_name"",
      ""pod_cidr"",
      ""service_cidr"",
      ""cluster_network_type"",
    ]
  }

  depends_on = [""alicloud_vpc.vpc""]
}
",resource,,,59,0.0,eebd686956c0b2adf67a10e1a376659c95c571a3,042b1a97fbbdf342297002990564828e6644a3f0,https://github.com/pingcap/tidb-operator/blob/eebd686956c0b2adf67a10e1a376659c95c571a3/deploy/alicloud/ack/main.tf#L59,https://github.com/pingcap/tidb-operator/blob/042b1a97fbbdf342297002990564828e6644a3f0/deploy/aliyun/ack/main.tf#L0,2019-05-06 19:59:43+08:00,2019-07-23 19:44:58+08:00,3,2,1,1,1,0,0,0,0,0
https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd,57,modules/secure-cd/main.tf,modules/secure-cd/main.tf,0,# todo,"## TODO: we can't be sure that they will be using the default GCE SA, so how do we automate this permissioning?","## IAM bindings for GKE projects to access container images from GAR
## TODO: we can't be sure that they will be using the default GCE SA, so how do we automate this permissioning?","data ""google_project"" ""gke_projects"" {
  for_each = var.deploy_branch_clusters
  project_id = each.value.project_id
}
",data,"data ""google_project"" ""gke_projects"" {
  for_each   = var.deploy_branch_clusters
  project_id = each.value.project_id
}
",data,92,,b30d28bfe6d8cce68682b5e133d0a666d44d28a0,52077b54c7e19811bab2673ec1deb908487243dc,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/b30d28bfe6d8cce68682b5e133d0a666d44d28a0/modules/secure-cd/main.tf#L92,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/52077b54c7e19811bab2673ec1deb908487243dc/modules/secure-cd/main.tf,2021-10-28 16:34:02-05:00,2021-11-19 14:29:33-06:00,9,1,1,1,0,1,0,0,0,0
https://github.com/Worklytics/psoxy,946,infra/modules/aws-ssm-rules/main.tf,infra/modules/aws-ssm-rules/main.tf,0,implemented,"#  - less analogous to GCP; haven't implemented gcp yet, but we're using secret manager","# custom REST rules as SSM parameter  
 # as a module to get reusable 
 # - variable validation 
 # - length calculations  
 # pros: 
 #  - if small, human readable.  if large, can be gzipped 
 #  - can be reviewed/managed via AWS console 
 #  - rule changes readily visible in plan, not confused with source code changes 
 #  - bundle the same for all lambdas; speeds build/package, reduces disk/mem footprint needed for 
 #    deploy (concern if doing cloud shell) 
 # 
 # cons vs shipping with lambda's deployment as flat file: 
 #  - lambda won't see rule changes unless restarted 
 #  - another component to see/manage 
 #  - less analogous to GCP; haven't implemented gcp yet, but we're using secret manager 
 #  - need to worry about lambda's permissions to read the SSM param 
 #  - need to worry about terraforms permissions to write the SSM param (if we're not otherwise 
 #    writing SSMs, which as of Apr 2023 we are so not really concern)  ","locals {
  # size limits, in bytes
  ssm_advanced_size_limit = 8192
  ssm_standard_size_limit = 4096

  # read rules from file
  rules_plain      = file(var.file_path)

  # compress if necessary; but otherwise leave plain so human readable
  rules_compressed = base64gzip(local.rules_plain)
  use_compressed   = length(local.rules_plain) > local.ssm_advanced_size_limit
  param_value      = local.use_compressed ? local.rules_compressed : local.rules_plain
}
",locals,"locals {
  # size limits, in bytes
  ssm_advanced_size_limit = 8192
  ssm_standard_size_limit = 4096

  # read rules from file
  rules_plain = file(var.file_path)

  # compress if necessary; but otherwise leave plain so human readable
  use_compressed = length(local.rules_plain) > local.ssm_advanced_size_limit
  param_value    = local.use_compressed ? base64gzip(local.rules_plain) : local.rules_plain
}
",locals,17,17.0,926dbe102c0e9db551bf09109589d7c4f29bfa93,7b86e2c03b93770d5639033a6fba189daab5185c,https://github.com/Worklytics/psoxy/blob/926dbe102c0e9db551bf09109589d7c4f29bfa93/infra/modules/aws-ssm-rules/main.tf#L17,https://github.com/Worklytics/psoxy/blob/7b86e2c03b93770d5639033a6fba189daab5185c/infra/modules/aws-ssm-rules/main.tf#L17,2023-04-07 14:29:36-07:00,2023-05-03 16:37:52-07:00,5,0,1,0,1,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1580,modules/net-vpc-firewall-policy/net-global.tf,modules/net-firewall-policy/net-global.tf,1,barf,# Terraform's type system barfs in the condition if we use the locals map,# Terraform's type system barfs in the condition if we use the locals map,"resource ""google_compute_network_firewall_policy_rule"" ""net-global"" {
  # Terraform's type system barfs in the condition if we use the locals map
  for_each = toset(
    !local.use_hierarchical && !local.use_regional
    ? keys(local.rules)
    : []
  )
  project                 = var.parent_id
  firewall_policy         = google_compute_network_firewall_policy.net-global.0.name
  rule_name               = local.rules[each.key].name
  action                  = local.rules[each.key].action
  description             = local.rules[each.key].description
  direction               = local.rules[each.key].direction
  disabled                = local.rules[each.key].disabled
  enable_logging          = local.rules[each.key].enable_logging
  priority                = local.rules[each.key].priority
  target_service_accounts = local.rules[each.key].target_service_accounts
  match {
    dest_ip_ranges = local.rules[each.key].match.destination_ranges
    src_ip_ranges  = local.rules[each.key].match.source_ranges
    dest_address_groups = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.address_groups
      : null
    )
    dest_fqdns = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.fqdns
      : null
    )
    dest_region_codes = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.region_codes
      : null
    )
    dest_threat_intelligences = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.threat_intelligences
      : null
    )
    src_address_groups = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.address_groups
      : null
    )
    src_fqdns = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.fqdns
      : null
    )
    src_region_codes = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.region_codes
      : null
    )
    src_threat_intelligences = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.threat_intelligences
      : null
    )
    dynamic ""layer4_configs"" {
      for_each = local.rules[each.key].match.layer4_configs
      content {
        ip_protocol = layer4_configs.value.protocol
        ports       = layer4_configs.value.ports
      }
    }
    dynamic ""src_secure_tags"" {
      for_each = toset(coalesce(local.rules[each.key].match.source_tags, []))
      content {
        name = src_secure_tags.key
      }
    }
  }
  dynamic ""target_secure_tags"" {
    for_each = toset(
      local.rules[each.key].target_tags == null
      ? []
      : local.rules[each.key].target_tags
    )
    content {
      name = target_secure_tags.value
    }
  }
}
",resource,"resource ""google_compute_network_firewall_policy_rule"" ""net-global"" {
  # Terraform's type system barfs in the condition if we use the locals map
  for_each = toset(
    !local.use_hierarchical && !local.use_regional
    ? keys(local.rules)
    : []
  )
  project                 = var.parent_id
  firewall_policy         = google_compute_network_firewall_policy.net-global[0].name
  rule_name               = local.rules[each.key].name
  action                  = local.rules[each.key].action
  description             = local.rules[each.key].description
  direction               = local.rules[each.key].direction
  security_profile_group  = local.rules[each.key].security_profile_group
  disabled                = local.rules[each.key].disabled
  enable_logging          = local.rules[each.key].enable_logging
  priority                = local.rules[each.key].priority
  target_service_accounts = local.rules[each.key].target_service_accounts
  match {
    dest_ip_ranges = local.rules[each.key].match.destination_ranges
    src_ip_ranges  = local.rules[each.key].match.source_ranges
    dest_address_groups = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.address_groups
      : null
    )
    dest_fqdns = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.fqdns
      : null
    )
    dest_region_codes = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.region_codes
      : null
    )
    dest_threat_intelligences = (
      local.rules[each.key].direction == ""EGRESS""
      ? local.rules[each.key].match.threat_intelligences
      : null
    )
    src_address_groups = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.address_groups
      : null
    )
    src_fqdns = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.fqdns
      : null
    )
    src_region_codes = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.region_codes
      : null
    )
    src_threat_intelligences = (
      local.rules[each.key].direction == ""INGRESS""
      ? local.rules[each.key].match.threat_intelligences
      : null
    )
    dynamic ""layer4_configs"" {
      for_each = local.rules[each.key].match.layer4_configs
      content {
        ip_protocol = layer4_configs.value.protocol
        ports       = layer4_configs.value.ports
      }
    }
    dynamic ""src_secure_tags"" {
      for_each = toset(coalesce(local.rules[each.key].match.source_tags, []))
      content {
        name = src_secure_tags.key
      }
    }
  }
  dynamic ""target_secure_tags"" {
    for_each = toset(
      local.rules[each.key].target_tags == null
      ? []
      : local.rules[each.key].target_tags
    )
    content {
      name = target_secure_tags.value
    }
  }
}
",resource,35,35.0,80ada0e8ddfcad8425a138ae6a457b500873cfaf,79b36b614be77d1606d6f67a4de79e365df20729,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/80ada0e8ddfcad8425a138ae6a457b500873cfaf/modules/net-vpc-firewall-policy/net-global.tf#L35,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/79b36b614be77d1606d6f67a4de79e365df20729/modules/net-firewall-policy/net-global.tf#L35,2023-08-08 16:57:59+00:00,2024-05-21 04:38:43+00:00,3,0,0,1,1,0,1,0,0,0
https://github.com/Azure/sap-automation,32,deploy/terraform/terraform-units/modules/sap_system/hdb_node/infrastructure.tf,deploy/terraform/terraform-units/modules/sap_system/hdb_node/infrastructure.tf,0,# todo,# TODO:,"# TODO: 
 # Current behavior, it will try to add all VMs in the cluster into the backend pool, which would not work since we do not have availability sets created yet. 
 # In a scale-out scenario, we need to rewrite this code according to the scale-out + HA reference architecture.","resource ""azurerm_network_interface_backend_address_pool_association"" ""hdb"" {
  count                   = local.enable_db_lb_deployment ? var.database_server_count : 0
  network_interface_id    = azurerm_network_interface.nics_dbnodes_db[count.index].id
  ip_configuration_name   = azurerm_network_interface.nics_dbnodes_db[count.index].ip_configuration[0].name
  backend_address_pool_id = azurerm_lb_backend_address_pool.hdb[0].id
}
",resource,"resource ""azurerm_network_interface_backend_address_pool_association"" ""hdb"" {
  provider                             = azurerm.main
  count                                = local.enable_db_lb_deployment ? var.database_server_count : 0
  network_interface_id                 = azurerm_network_interface.nics_dbnodes_db[count.index].id
  ip_configuration_name                = azurerm_network_interface.nics_dbnodes_db[count.index].ip_configuration[0].name
  backend_address_pool_id              = azurerm_lb_backend_address_pool.hdb[0].id
}
",resource,62,109.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,db20ac2a47d9d00329385330cb4af6b3c726c400,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_system/hdb_node/infrastructure.tf#L62,https://github.com/Azure/sap-automation/blob/db20ac2a47d9d00329385330cb4af6b3c726c400/deploy/terraform/terraform-units/modules/sap_system/hdb_node/infrastructure.tf#L109,2021-11-17 19:29:07+02:00,2024-03-11 23:15:11+05:30,32,0,1,1,0,0,1,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-rds,4,modules/db_instance/main.tf,modules/db_instance/main.tf,0,todo,# TODO - remove coalesce() at next breaking change - adding existing name as fallback to maintain backwards compatibility,# TODO - remove coalesce() at next breaking change - adding existing name as fallback to maintain backwards compatibility,"resource ""aws_db_instance"" ""this_mssql"" {
  count = var.create && local.is_mssql ? 1 : 0

  identifier = var.identifier

  engine            = var.engine
  engine_version    = var.engine_version
  instance_class    = var.instance_class
  allocated_storage = var.allocated_storage
  storage_type      = var.storage_type
  storage_encrypted = var.storage_encrypted
  kms_key_id        = var.kms_key_id
  license_model     = var.license_model

  name                                = var.name
  username                            = var.username
  password                            = var.password
  port                                = var.port
  domain                              = var.domain
  domain_iam_role_name                = var.domain_iam_role_name
  iam_database_authentication_enabled = var.iam_database_authentication_enabled

  vpc_security_group_ids = var.vpc_security_group_ids
  db_subnet_group_name   = var.db_subnet_group_name
  parameter_group_name   = var.parameter_group_name
  option_group_name      = var.option_group_name

  availability_zone   = var.availability_zone
  multi_az            = var.multi_az
  iops                = var.iops
  publicly_accessible = var.publicly_accessible
  ca_cert_identifier  = var.ca_cert_identifier

  allow_major_version_upgrade = var.allow_major_version_upgrade
  auto_minor_version_upgrade  = var.auto_minor_version_upgrade
  apply_immediately           = var.apply_immediately
  maintenance_window          = var.maintenance_window

  snapshot_identifier   = var.snapshot_identifier
  copy_tags_to_snapshot = var.copy_tags_to_snapshot
  skip_final_snapshot   = var.skip_final_snapshot
  # TODO - remove coalesce() at next breaking change - adding existing name as fallback to maintain backwards compatibility
  final_snapshot_identifier = var.skip_final_snapshot ? null : coalesce(var.final_snapshot_identifier, ""${var.final_snapshot_identifier_prefix}-${var.identifier}-${random_id.snapshot_identifier[0].hex}"")

  performance_insights_enabled          = var.performance_insights_enabled
  performance_insights_retention_period = var.performance_insights_enabled ? var.performance_insights_retention_period : null
  performance_insights_kms_key_id       = var.performance_insights_enabled ? var.performance_insights_kms_key_id : null

  replicate_source_db     = var.replicate_source_db
  backup_retention_period = var.backup_retention_period
  backup_window           = var.backup_window
  max_allocated_storage   = var.max_allocated_storage
  monitoring_interval     = var.monitoring_interval
  monitoring_role_arn     = var.monitoring_interval > 0 ? coalesce(var.monitoring_role_arn, aws_iam_role.enhanced_monitoring.*.arn, null) : null

  character_set_name              = var.character_set_name
  timezone                        = var.timezone # MSSQL only
  enabled_cloudwatch_logs_exports = var.enabled_cloudwatch_logs_exports

  deletion_protection      = var.deletion_protection
  delete_automated_backups = var.delete_automated_backups

  tags = merge(
    var.tags,
    {
      ""Name"" = format(""%s"", var.identifier)
    },
  )

  timeouts {
    create = lookup(var.timeouts, ""create"", null)
    delete = lookup(var.timeouts, ""delete"", null)
    update = lookup(var.timeouts, ""update"", null)
  }
}
",resource,the block associated got renamed or deleted,,142,,2998de9699ae8a3bb3df8c14e93a4a688289063b,9149ec147327fbe5a7675ac48e9e641b5d7ec6e1,https://github.com/terraform-aws-modules/terraform-aws-rds/blob/2998de9699ae8a3bb3df8c14e93a4a688289063b/modules/db_instance/main.tf#L142,https://github.com/terraform-aws-modules/terraform-aws-rds/blob/9149ec147327fbe5a7675ac48e9e641b5d7ec6e1/modules/db_instance/main.tf,2021-03-14 21:31:12+01:00,2022-02-16 10:27:38+01:00,8,1,1,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,282,modules/iam/group-autoscaling.tf,modules/iam/group-autoscaling.tf,0,todo,"# ""tag.${var.tag_namespace}.state_id.value='${var.state_id}'"", # TODO optional use w/ config","# ""tag.${var.tag_namespace}.state_id.value='${var.state_id}'"", # TODO optional use w/ config","locals {
  autoscaler_group_name          = ""oke-autoscaler-${var.state_id}""
  autoscaler_compartments        = coalescelist(var.autoscaler_compartments, [var.compartment_id])
  autoscaler_compartment_matches = formatlist(""instance.compartment.id = '%s'"", local.autoscaler_compartments)
  autoscaler_compartment_rule    = format(""ANY {%s}"", join("", "", local.autoscaler_compartment_matches))

  autoscaler_group_rules = var.use_defined_tags ? format(""ALL {%s}"", join("", "", [
    ""tag.${var.tag_namespace}.role.value='worker'"",
    ""tag.${var.tag_namespace}.cluster_autoscaler.value='allowed'"",
    local.autoscaler_compartment_rule,
    # ""tag.${var.tag_namespace}.state_id.value='${var.state_id}'"", # TODO optional use w/ config
  ])) : local.autoscaler_compartment_rule

  autoscaler_templates = [
    ""Allow dynamic-group %s to manage cluster-node-pools in compartment id %s"",
    ""Allow dynamic-group %s to manage compute-management-family in compartment id %s"",
    ""Allow dynamic-group %s to manage instance-family in compartment id %s"",
    ""Allow dynamic-group %s to manage volume-family in compartment id %s"",
    ""Allow dynamic-group %s to use subnets in compartment id %s"",
    ""Allow dynamic-group %s to read virtual-network-family in compartment id %s"",
    ""Allow dynamic-group %s to use vnics in compartment id %s"",
    ""Allow dynamic-group %s to inspect compartments in compartment id %s"",
  ]

  autoscaler_policy_statements = var.create_iam_autoscaler_policy ? tolist([
    for statement in local.autoscaler_templates : formatlist(statement,
      local.autoscaler_group_name, local.worker_compartments,
    )
  ]) : []
}
",locals,"locals {
  autoscaler_group_name          = format(""oke-autoscaler-%v"", var.state_id)
  autoscaler_compartments        = coalescelist(var.autoscaler_compartments, [var.compartment_id])
  autoscaler_compartment_matches = formatlist(""instance.compartment.id = '%v'"", local.autoscaler_compartments)
  autoscaler_compartment_rule    = format(""ANY {%v}"", join("", "", local.autoscaler_compartment_matches))

  autoscaler_group_rules = var.use_defined_tags ? format(""ALL {%v}"", join("", "", [
    format(""tag.%v.role.value='worker'"", var.tag_namespace),
    format(""tag.%v.cluster_autoscaler.value='allowed'"", var.tag_namespace),
    local.autoscaler_compartment_rule,
    # ""tag.${var.tag_namespace}.state_id.value='${var.state_id}'"", # TODO optional use w/ config
  ])) : local.autoscaler_compartment_rule

  autoscaler_templates = [
    ""Allow dynamic-group %v to manage cluster-node-pools in compartment id %v"",
    ""Allow dynamic-group %v to manage compute-management-family in compartment id %v"",
    ""Allow dynamic-group %v to manage instance-family in compartment id %v"",
    ""Allow dynamic-group %v to manage volume-family in compartment id %v"",
    ""Allow dynamic-group %v to use subnets in compartment id %v"",
    ""Allow dynamic-group %v to read virtual-network-family in compartment id %v"",
    ""Allow dynamic-group %v to use vnics in compartment id %v"",
    ""Allow dynamic-group %v to inspect compartments in compartment id %v"",
  ]

  autoscaler_policy_statements = var.create_iam_autoscaler_policy ? tolist([
    for statement in local.autoscaler_templates : formatlist(statement,
      local.autoscaler_group_name, local.worker_compartments,
    )
  ]) : []
}
",locals,14,14.0,98efef8efee51511d39dcdd26b8c4442e2397316,5f4f0b39b2fe089d5a8d6641b9806135af54ed44,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/98efef8efee51511d39dcdd26b8c4442e2397316/modules/iam/group-autoscaling.tf#L14,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/5f4f0b39b2fe089d5a8d6641b9806135af54ed44/modules/iam/group-autoscaling.tf#L14,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,2,0,0,1,0,0,0,0,0,0
https://github.com/ministryofjustice/modernisation-platform,1,terraform/github/versions.tf,terraform/github/versions.tf,0,broken,# Pin to 3.0.0 as 3.1.0 is currently broken (https://github.com/terraform-providers/terraform-provider-github/issues/566#issuecomment-720150093),"version = ""3.0.0"" # Pin to 3.0.0 as 3.1.0 is currently broken (https://github.com/terraform-providers/terraform-provider-github/issues/566#issuecomment-720150093)","terraform {
  required_providers {
    github = {
      version = ""3.0.0"" # Pin to 3.0.0 as 3.1.0 is currently broken (https://github.com/terraform-providers/terraform-provider-github/issues/566#issuecomment-720150093)
      source  = ""hashicorp/github""
    }
  }
  required_version = "">= 0.13""
}
",terraform,"terraform {
  required_version = "">= 0.13""
  required_providers {
    github = {
      version = ""4.0.0""
      source  = ""hashicorp/github""
    }
  }
}
",terraform,4,,8312e176ff563134bcf4c1edbd13cf8d96cb5e6e,ed1cc1d6da1cb2d471f83b8e1d8eabf23b707c2e,https://github.com/ministryofjustice/modernisation-platform/blob/8312e176ff563134bcf4c1edbd13cf8d96cb5e6e/terraform/github/versions.tf#L4,https://github.com/ministryofjustice/modernisation-platform/blob/ed1cc1d6da1cb2d471f83b8e1d8eabf23b707c2e/terraform/github/versions.tf,2020-11-02 15:46:40+00:00,2020-11-12 10:40:21+00:00,4,1,0,1,1,0,0,0,0,0
https://github.com/Worklytics/psoxy,1827,infra/modules/psoxy-constants/main.tf,infra/modules/psoxy-constants/main.tf,0,# todo,"# TODO: add list of permissions, which customer could use to create custom role as alternative","# TODO: add list of permissions, which customer could use to create custom role as alternative ","locals {

  # AWS Managed polices
  # see: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#aws-managed-policies
  required_aws_roles_to_provision_host = {
    ""arn:aws:iam::aws:policy/IAMFullAccess""        = ""IAMFullAccess""
    ""arn:aws:iam::aws:policy/AmazonS3FullAccess""   = ""AmazonS3FullAccess""
    ""arn:aws:iam::aws:policy/CloudWatchFullAccess"" = ""CloudWatchFullAccess""
    ""arn:aws:iam::aws:policy/AmazonSSMFullAccess""  = ""AmazonSSMFullAccess""
    ""arn:aws:iam::aws:policy/AWSLambda_FullAccess"" = ""AWSLambda_FullAccess""
  }
  # TODO: create IAM policy document, which installer could use to create their own policy as
  # alternative to using AWS Managed policies

  required_gcp_roles_to_provision_host = {
    ""roles/storage.admin"" = {
      display_name    = ""Storage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#storage.admin""
    },
    ""roles/iam.roleAdmin"" = {
      display_name    = ""IAM Role Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.roleAdmin""
    },
    ""roles/secretmanager.admin"" = {
      display_name    = ""Secret Manager Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#secretmanager.admin""
    },
    ""roles/iam.serviceAccountAdmin"" = {
      display_name    = ""Service Account Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.serviceAccountAdmin""
    },
    ""roles/serviceusage.serviceUsageAdmin"" = {
      display_name    = ""Service Usage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin""
    },
    ""roles/cloudfunctions.admin"" = {
      display_name    = ""Cloud Functions Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#cloudfunctions.admin""
    },
  }  # TODO: add list of permissions, which customer could use to create custom role as alternative

  required_gcp_roles_to_provision_google_workspace_source = {
    ""roles/iam.serviceAccountAdmin"" = {
      display_name    = ""Service Account Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.serviceAccountAdmin""
    },
    ""roles/serviceusage.serviceUsageAdmin"" = {
      display_name    = ""Service Usage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin""
    }
  }
  # TODO: add list of permissions, which customer could use to create custom role as alternative

  required_azuread_roles_to_provision_msft_365_source = {
    ""7ab1d382-f21e-4acd-a863-ba3e13f7da61"" = ""Cloud Application Administrator"",
  }
}
",locals,"locals {

  # AWS Managed polices
  # see: https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_managed-vs-inline.html#aws-managed-policies
  required_aws_roles_to_provision_host = {
    ""arn:aws:iam::aws:policy/IAMFullAccess""        = ""IAMFullAccess""
    ""arn:aws:iam::aws:policy/AmazonS3FullAccess""   = ""AmazonS3FullAccess"" # only if using bulk sources, although 95% do
    ""arn:aws:iam::aws:policy/CloudWatchFullAccess"" = ""CloudWatchFullAccess""
    ""arn:aws:iam::aws:policy/AmazonSSMFullAccess""  = ""AmazonSSMFullAccess""
    ""arn:aws:iam::aws:policy/AWSLambda_FullAccess"" = ""AWSLambda_FullAccess""
  }
  # AWS managed policy required to consume Microsoft 365 data
  # (in addition to above)
  required_aws_managed_policies_to_consume_msft_365_source = {
    ""arn:aws:iam::aws:policy/AmazonCognitoPowerUser"" = ""AmazonCognitoPowerUser""
  }

  # subset of https://docs.aws.amazon.com/aws-managed-policy/latest/reference/SecretsManagerReadWrite.html
  # as that seems like overkill
  #  - if you're going to use KMS to encrypt the secrets, then you'll need to add the KMS permissions
  #    on the key you intend to use.
  #  - you can/should modify the Resource part of this to limit to a subset of secrets, if this
  #    is being deployed to an AWS account that's used for purposes beyond this proxy deployment
  required_aws_policy_to_use_secrets_manager = {
    ""Version"" : ""2012-10-17"",
    ""Statement"" : [
      {
        ""Effect"" : ""Allow"",
        ""Action"" : [
          ""secretsmanager:*"",
          ""tag:GetResources""
        ],
        ""Resource"" : ""*""
      }
    ]
  }


  # TODO: create IAM policy document, which installer could use to create their own policy as
  # alternative to using AWS Managed policies

  # initial GCP APIs that must be enabled in projects that will host the proxy.
  # (Terraform apply will enabled additional ones)
  required_gcp_apis_to_host = {
    # https://console.cloud.google.com/apis/library/iamcredentials.googleapis.com
    ""iamcredentials.googleapis.com"" = ""IAM Service Account Credentials API"",
    # https://console.cloud.google.com/apis/library/serviceusage.googleapis.com
    ""serviceusage.googleapis.com"" = ""Service Usage API"",
  }

  required_gcp_roles_to_provision_host = {
    ""roles/storage.admin"" = {
      display_name    = ""Storage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#storage.admin""
    },
    ""roles/iam.roleAdmin"" = {
      display_name    = ""IAM Role Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.roleAdmin""
    },
    ""roles/secretmanager.admin"" = {
      display_name    = ""Secret Manager Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#secretmanager.admin""
    },
    ""roles/iam.serviceAccountAdmin"" = {
      display_name    = ""Service Account Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.serviceAccountAdmin""
    },
    ""roles/serviceusage.serviceUsageAdmin"" = {
      display_name    = ""Service Usage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin""
    },
    ""roles/cloudfunctions.admin"" = {
      display_name    = ""Cloud Functions Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#cloudfunctions.admin""
    },
  }
  # TODO: add list of permissions, which customer could use to create custom role as alternative


  # TODO: confirm that this is indeed the same list (believe it is)
  required_gcp_apis_to_provision_google_workspace_source = local.required_gcp_apis_to_host

  required_gcp_roles_to_provision_google_workspace_source = {
    ""roles/iam.serviceAccountAdmin"" = {
      display_name    = ""Service Account Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#iam.serviceAccountAdmin""
    },
    ""roles/serviceusage.serviceUsageAdmin"" = {
      display_name    = ""Service Usage Admin"",
      description_url = ""https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin""
    }
  }
  # TODO: add list of permissions, which customer could use to create custom role as alternative

  required_azuread_roles_to_provision_msft_365_source = {
    ""7ab1d382-f21e-4acd-a863-ba3e13f7da61"" = ""Cloud Application Administrator"",
  }
}
",locals,52,93.0,afe4f8e792fc412e4d03b347a7e566d47a7fa0d2,005e1fed5f46b4310d81d41d29862bb1c4f360b0,https://github.com/Worklytics/psoxy/blob/afe4f8e792fc412e4d03b347a7e566d47a7fa0d2/infra/modules/psoxy-constants/main.tf#L52,https://github.com/Worklytics/psoxy/blob/005e1fed5f46b4310d81d41d29862bb1c4f360b0/infra/modules/psoxy-constants/main.tf#L93,2023-06-23 19:10:00+00:00,2024-02-06 19:07:07+00:00,5,0,0,1,0,1,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,165,modules/workergroup/instancepools.tf,modules/workers/instancepools.tf,1,todo,# TODO Accept full definition to create,"# Associate the instance pool with 0+ load balancers for ingress traffic 
 # TODO Accept full definition to create","resource ""oci_core_instance_pool"" ""instance_pools"" {
  # Create an OCI Instance Pool resource for each enabled entry of the worker_groups map with that mode.
  for_each                  = local.enabled_instance_pools
  compartment_id            = each.value.compartment_id
  display_name              = ""${each.value.label_prefix}-${each.key}""
  size                      = each.value.size
  instance_configuration_id = oci_core_instance_configuration.instance_configuration[each.key].id
  defined_tags              = merge(local.defined_tags, contains(keys(each.value), ""defined_tags"") ? each.value.defined_tags : {})
  freeform_tags             = merge(local.freeform_tags, contains(keys(each.value), ""freeform_tags"") ? each.value.freeform_tags : { worker_group = each.key })

  dynamic ""placement_configurations"" {
    # Define each configured availability domain for placement, with bounds on # available
    # Configured AD numbers e.g. [1,2,3] are converted into tenancy/compartment-specific names
    iterator = ad_number
    for_each = (contains(keys(each.value), ""placement_ads"")
      ? tolist(setintersection(each.value.placement_ads, local.ad_numbers))
      : local.ad_numbers
    )

    content {
      availability_domain = lookup(local.ad_number_to_name, ad_number.value, local.first_ad_name)
      primary_subnet_id   = each.value.subnet_id
    }
  }

  lifecycle {
    ignore_changes = [
      display_name, defined_tags, freeform_tags,
      placement_configurations,
    ]
  }

  dynamic ""load_balancers"" {
    # Associate the instance pool with 0+ load balancers for ingress traffic
    # TODO Accept full definition to create
    for_each = contains(keys(each.value), ""load_balancers"") ? each.value.load_balancers : {}

    content {
      # TODO From dynamic creation when no lb_id provided; introspected fields when present
      backend_set_name = lookup(lb, ""backend_set_name"", display_name)
      load_balancer_id = lookup(lb, ""lb_id"", lb_id)
      port             = lookup(lb, ""port"", 8080)

      // Possible values are ""PrimaryVnic"" or the displayName of
      // one of the secondary VNICs on the instance configuration
      // that is associated with the instance pool.
      vnic_selection = lookup(lb, ""vnic_selection"", ""PrimaryVnic"") # TODO Support w/ named secondary VNICs
    }
  }

  depends_on = [
    oci_core_instance_configuration.instance_configuration,
  ]
}",resource,the block associated got renamed or deleted,,39,,4d2b3f3d672a8f41655da3a7c58fded42c6858f3,f49f1da39d79cf260d80dcb10ee8e399828e6e1c,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/4d2b3f3d672a8f41655da3a7c58fded42c6858f3/modules/workergroup/instancepools.tf#L39,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/f49f1da39d79cf260d80dcb10ee8e399828e6e1c/modules/workers/instancepools.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,4,1,1,1,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,646,modules/project/service-accounts.tf,modules/project/service-accounts.tf,0,# todo,# TODO: deprecate gcf,# TODO: deprecate gcf,"locals {
  _service_accounts_cmek_service_dependencies = {
    ""composer"" : [
      ""composer"",
      ""artifactregistry"", ""container-engine"", ""compute"", ""pubsub"", ""storage""
    ]
    ""dataflow"" : [""dataflow"", ""compute""]
  }
  _service_accounts_robot_services = {
    artifactregistry  = ""service-%s@gcp-sa-artifactregistry""
    bq                = ""bq-%s@bigquery-encryption""
    cloudasset        = ""service-%s@gcp-sa-cloudasset""
    cloudbuild        = ""service-%s@gcp-sa-cloudbuild""
    cloudfunctions    = ""service-%s@gcf-admin-robot""
    cloudrun          = ""service-%s@serverless-robot-prod""
    composer          = ""service-%s@cloudcomposer-accounts""
    compute           = ""service-%s@compute-system""
    container-engine  = ""service-%s@container-engine-robot""
    containerregistry = ""service-%s@containerregistry""
    dataflow          = ""service-%s@dataflow-service-producer-prod""
    dataproc          = ""service-%s@dataproc-accounts""
    gae-flex          = ""service-%s@gae-api-prod""
    # TODO: deprecate gcf
    gcf           = ""service-%s@gcf-admin-robot""
    pubsub        = ""service-%s@gcp-sa-pubsub""
    secretmanager = ""service-%s@gcp-sa-secretmanager""
    storage       = ""service-%s@gs-project-accounts""
  }
  service_accounts_default = {
    compute = ""${local.project.number}-compute@developer.gserviceaccount.com""
    gae     = ""${local.project.project_id}@appspot.gserviceaccount.com""
  }
  service_account_cloud_services = (
    ""${local.project.number}@cloudservices.gserviceaccount.com""
  )
  service_accounts_robots = {
    for k, v in local._service_accounts_robot_services :
    k => ""${format(v, local.project.number)}.iam.gserviceaccount.com""
  }
  service_accounts_jit_services = [
    ""secretmanager.googleapis.com"",
    ""pubsub.googleapis.com"",
    ""cloudasset.googleapis.com""
  ]
  service_accounts_cmek_service_keys = distinct(flatten([
    for s in keys(var.service_encryption_key_ids) : [
      for ss in try(local._service_accounts_cmek_service_dependencies[s], [s]) : [
        for key in var.service_encryption_key_ids[s] : {
          service = ss
          key     = key
        } if key != null
      ]
    ]
  ]))
}
",locals,"locals {
  _service_accounts_cmek_service_dependencies = {
    ""composer"" : [
      ""composer"",
      ""artifactregistry"", ""container-engine"", ""compute"", ""pubsub"", ""storage""
    ]
    ""dataflow"" : [""dataflow"", ""compute""]
  }
  _service_agents_data = yamldecode(file(""${path.module}/service-agents.yaml""))
  service_accounts_default = {
    compute      = ""${local.project.number}-compute@developer.gserviceaccount.com""
    gae          = ""${local.project.project_id}@appspot.gserviceaccount.com""
    workstations = ""service-${local.project.number}@gcp-sa-workstationsvm.iam.gserviceaccount.com""
  }
  service_account_cloud_services = (
    ""${local.project.number}@cloudservices.gserviceaccount.com""
  )
  service_accounts_robots = merge(
    {
      for agent in local._service_agents_data :
      agent.name => format(agent.service_agent, local.project.number)
    },
    {
      for agent in local._service_agents_data :
      agent.alias => format(agent.service_agent, local.project.number)
      if lookup(agent, ""alias"", null) != null
    },
    {
      gke-mcs-importer = ""${local.project.project_id}.svc.id.goog[gke-mcs/gke-mcs-importer]""
    }
  )
  service_accounts_jit_services = [
    for agent in local._service_agents_data :
    ""${agent.name}.googleapis.com""
    if lookup(agent, ""jit"", false)
  ]
  service_accounts_cmek_service_keys = distinct(flatten([
    for s in keys(var.service_encryption_key_ids) : [
      for ss in try(local._service_accounts_cmek_service_dependencies[s], [s]) : [
        for key in var.service_encryption_key_ids[s] : {
          service = ss
          key     = key
        } if key != null
      ]
    ]
  ]))
}
",locals,41,,40cb46e1cc59c36cac9dd3198c841f32cee11733,b503bde544670d9acdd584a9798613dc84c0c0d5,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/40cb46e1cc59c36cac9dd3198c841f32cee11733/modules/project/service-accounts.tf#L41,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/b503bde544670d9acdd584a9798613dc84c0c0d5/modules/project/service-accounts.tf,2022-02-09 11:06:51+01:00,2023-03-30 09:36:14+03:00,25,1,0,0,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,1448,terraform/projects/app-elasticsearch6/main.tf,terraform/projects/app-elasticsearch6/main.tf,0,# todo,# TODO: enforce TLS once the last non-TLS clients are cleaned up.,# TODO: enforce TLS once the last non-TLS clients are cleaned up.,"resource ""aws_elasticsearch_domain"" ""elasticsearch6"" {
  domain_name           = ""${var.stackname}-elasticsearch6-domain""
  elasticsearch_version = ""6.7""

  cluster_config {
    instance_type            = var.elasticsearch6_instance_type
    instance_count           = var.elasticsearch6_instance_count
    dedicated_master_enabled = var.elasticsearch6_dedicated_master_enabled
    dedicated_master_type    = var.elasticsearch6_master_instance_type
    dedicated_master_count   = var.elasticsearch6_master_instance_count
    zone_awareness_enabled   = true
    zone_awareness_config { availability_zone_count = 3 }
  }

  domain_endpoint_options {
    custom_endpoint                 = ""elasticsearch6.${var.aws_environment}.govuk-internal.digital""
    custom_endpoint_certificate_arn = data.aws_acm_certificate.govuk_internal.arn
    custom_endpoint_enabled         = true
    # TODO: enforce TLS once the last non-TLS clients are cleaned up.
    enforce_https = false
  }

  ebs_options {
    ebs_enabled = true
    iops        = 3000
    volume_type = ""gp3""
    volume_size = var.elasticsearch6_ebs_size
  }

  vpc_options {
    subnet_ids = matchkeys(
      values(data.terraform_remote_state.infra_networking.outputs.private_subnet_elasticsearch_names_ids_map),
      keys(data.terraform_remote_state.infra_networking.outputs.private_subnet_elasticsearch_names_ids_map),
      var.elasticsearch_subnet_names
    )
    security_group_ids = [
      data.terraform_remote_state.infra_security_groups.outputs.sg_elasticsearch6_id,
      data.terraform_remote_state.infra_security_groups.outputs.sg_management_id,
    ]
  }

  snapshot_options {
    automated_snapshot_start_hour = var.elasticsearch6_snapshot_start_hour
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_application_log_group.arn
    log_type                 = ""ES_APPLICATION_LOGS""
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_search_log_group.arn
    log_type                 = ""SEARCH_SLOW_LOGS""
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_index_log_group.arn
    log_type                 = ""INDEX_SLOW_LOGS""
  }

  access_policies = jsonencode({
    Version = ""2012-10-17""
    Statement = [{
      Effect = ""Allow""
      Principal = {
        AWS = [""*""]
      }
      Action   = [""es:*""]
      Resource = ""arn:aws:es:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:domain/${var.stackname}-elasticsearch6-domain/*""
    }]
  })

  tags = {
    Name          = ""${var.stackname}-elasticsearch6""
    Project       = var.stackname
    aws_stackname = var.stackname
  }

  depends_on = [aws_iam_service_linked_role.role]
}
",resource,"resource ""aws_elasticsearch_domain"" ""elasticsearch6"" {
  depends_on = [aws_iam_service_linked_role.role]

  domain_name           = ""${var.stackname}-elasticsearch6-domain""
  elasticsearch_version = ""6.7""

  cluster_config {
    instance_type            = var.elasticsearch6_instance_type
    instance_count           = var.elasticsearch6_instance_count
    dedicated_master_enabled = var.elasticsearch6_dedicated_master_enabled
    dedicated_master_type    = var.elasticsearch6_master_instance_type
    dedicated_master_count   = var.elasticsearch6_master_instance_count
    zone_awareness_enabled   = true
    zone_awareness_config { availability_zone_count = 3 }
  }

  domain_endpoint_options {
    custom_endpoint                 = ""elasticsearch6.${var.aws_environment}.govuk-internal.digital""
    custom_endpoint_certificate_arn = data.aws_acm_certificate.govuk_internal.arn
    custom_endpoint_enabled         = true
    # TODO: enforce TLS once the last non-TLS clients are cleaned up.
    enforce_https = false
  }

  ebs_options {
    ebs_enabled = true
    iops        = 3000
    volume_type = ""gp3""
    volume_size = var.elasticsearch6_ebs_size
  }

  vpc_options {
    subnet_ids = matchkeys(
      values(data.terraform_remote_state.infra_networking.outputs.private_subnet_elasticsearch_names_ids_map),
      keys(data.terraform_remote_state.infra_networking.outputs.private_subnet_elasticsearch_names_ids_map),
      var.elasticsearch_subnet_names
    )
    security_group_ids = [
      data.terraform_remote_state.infra_security_groups.outputs.sg_elasticsearch6_id,
      data.terraform_remote_state.infra_security_groups.outputs.sg_management_id,
    ]
  }

  snapshot_options {
    automated_snapshot_start_hour = var.elasticsearch6_snapshot_start_hour
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_application_log_group.arn
    log_type                 = ""ES_APPLICATION_LOGS""
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_search_log_group.arn
    log_type                 = ""SEARCH_SLOW_LOGS""
  }

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.elasticsearch6_index_log_group.arn
    log_type                 = ""INDEX_SLOW_LOGS""
  }

  access_policies = data.aws_iam_policy_document.es_access.json

  tags = {
    Name          = ""${var.stackname}-elasticsearch6""
    Project       = var.stackname
    aws_stackname = var.stackname
  }
}
",resource,105,107.0,4357f2d981e7f59c9ba3dc7858196714b4851628,43daf872ea009b7fbcb5765b726cf1f5ec7f0953,https://github.com/alphagov/govuk-aws/blob/4357f2d981e7f59c9ba3dc7858196714b4851628/terraform/projects/app-elasticsearch6/main.tf#L105,https://github.com/alphagov/govuk-aws/blob/43daf872ea009b7fbcb5765b726cf1f5ec7f0953/terraform/projects/app-elasticsearch6/main.tf#L107,2023-08-08 15:01:01+01:00,2023-08-08 15:01:01+01:00,3,0,1,1,0,1,1,0,0,0
https://github.com/terraform-google-modules/terraform-google-bigquery,2,main.tf,main.tf,0,#todo,#TODO: format this ne excluded by default but can optionally be defined if the user wishes,#TODO: format this ne excluded by default but can optionally be defined if the user wishes,"resource ""google_bigquery_dataset"" ""default"" {
  dataset_id                  = ""${var.dataset_id}""
  friendly_name               = ""${var.dataset_name}""
  description                 = ""${var.description}""
  #TODO: add if condition to validate if neither US or EU are supplied
  location                    = ""${var.region}""
  #TODO: format this ne excluded by default but can optionally be defined if the user wishes
  default_table_expiration_ms = ""${var.expiration}""
  project                     = ""${var.project_id}""

  #TODO: Need to find a way to dynamically assign a dict object(s)
  labels {
    env = ""default""
    foo = ""bar""
    tonyd = ""tonyd""
  }

  //TODO: array of users or groups needs to be added to have access. Need to figure out the best method of customers to allocate users or groups.
  # access {
  #   role   = ""READER""
  #   domain = ""adigangi.com""
  # }
  #
  # access {
  #   role           = ""WRITER""
  #   user_by_email = ""adigangi@adigangi.com""
  # }
  #
  # access {
  #   role           = ""OWNER""
  #   special_group  = ""projectOwners""
  # }
}
",resource,the block associated got renamed or deleted,,28,,d56aa2c9a80343d60eed3e1a7d24962be31ee0b6,7f922f7e9df197df38c9b09dfa6e3614d71f19f5,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/d56aa2c9a80343d60eed3e1a7d24962be31ee0b6/main.tf#L28,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/7f922f7e9df197df38c9b09dfa6e3614d71f19f5/main.tf,2018-11-20 10:30:15-05:00,2019-01-16 18:10:54-05:00,3,1,1,1,0,0,0,0,0,0
https://github.com/Worklytics/psoxy,305,infra/modules/gcp-psoxy-bulk/main.tf,infra/modules/gcp-psoxy-bulk/main.tf,0,# todo,# TODO: revisit if custom role is a good idea this triggers security events for some orgs,# TODO: revisit if custom role is a good idea this triggers security events for some orgs,"resource ""google_project_iam_custom_role"" ""bucket-write"" {
  project     = var.project_id
  role_id     = ""writeAccess""
  title       = ""Access for writing and update objects in bucket""
  description = ""Write and update support, because storage.objectCreator role only support creation -not update""
  permissions = [""storage.objects.create"", ""storage.objects.delete""]
}
",resource,the block associated got renamed or deleted,,54,,8759718756a55e8e9b5aedfe6089959fb890ffcd,eb9e250b49ea08479a679b4e54110da683d611bd,https://github.com/Worklytics/psoxy/blob/8759718756a55e8e9b5aedfe6089959fb890ffcd/infra/modules/gcp-psoxy-bulk/main.tf#L54,https://github.com/Worklytics/psoxy/blob/eb9e250b49ea08479a679b4e54110da683d611bd/infra/modules/gcp-psoxy-bulk/main.tf,2022-08-01 11:02:03-07:00,2022-08-31 16:13:44-07:00,6,1,0,1,0,1,0,0,0,0
https://github.com/aws-ia/terraform-aws-eks-blueprints,177,modules/kubernetes-addons/main.tf,modules/kubernetes-addons/main.tf,0,#todo,"#TODO once source is updated and aligned with addon_context changes, pass addon_context and remove eks_cluster_id & tags","#TODO once source is updated and aligned with addon_context changes, pass addon_context and remove eks_cluster_id & tags","module ""kube_state_metrics"" {
  count                     = var.enable_kube_state_metrics ? 1 : 0
  source                    = ""askulkarni2/kube-state-metrics-addon/eksblueprints""
  version                   = ""0.0.2""
  eks_cluster_id            = var.eks_cluster_id
  helm_config               = var.kube_state_metrics_helm_config
  irsa_policies             = var.kube_state_metrics_irsa_policies
  irsa_permissions_boundary = var.kube_state_metrics_irsa_permissions_boundary
  tags                      = var.tags
  manage_via_gitops         = var.argocd_manage_add_ons
}
",module,the block associated got renamed or deleted,,228,,24efa030eccfd775a885381e65f5327796448d66,0ad2138f70605f8b562c5f65ff9a4674041a9152,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/24efa030eccfd775a885381e65f5327796448d66/modules/kubernetes-addons/main.tf#L228,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/0ad2138f70605f8b562c5f65ff9a4674041a9152/modules/kubernetes-addons/main.tf,2022-03-03 11:17:04-06:00,2022-03-07 10:58:36-08:00,9,1,1,1,0,0,0,0,1,0
https://github.com/Worklytics/psoxy,534,infra/modules/google-workspace-dwd-connection/main.tf,infra/modules/google-workspace-dwd-connection/main.tf,0,hack,# but in a sense that's a little hackier as is exploiting implementation details of Google's OAuth scope format,"# alternatively, could test if prefix of ANY needed scope starts with 'https://www.googleapis.com/auth/admin', 
 # but in a sense that's a little hackier as is exploiting implementation details of Google's OAuth scope format  
 # additionally, each of these OAuth scopes would seem tp imply *specific* permissions for the role 
 # that the service account needs; so we could formally define the subset","locals {
  # alternatively, could test if prefix of ANY needed scope starts with 'https://www.googleapis.com/auth/admin',
  # but in a sense that's a little hackier as is exploiting implementation details of Google's OAuth scope format

  # additionally, each of these OAuth scopes would seem tp imply *specific* permissions for the role
  # that the service account needs; so we could formally define the subset
  scopes_requiring_admin_account = [
    ""https://www.googleapis.com/auth/admin.directory.user.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.user.alias.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.domain.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.group.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.group.member.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.orgunit.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.rolemanagement.readonly"",
    ""https://www.googleapis.com/auth/admin.reports.audit.readonly"",
  ]
  google_workspace_admin_account_required = (length(setintersection(local.scopes_requiring_admin_account, var.oauth_scopes_needed)) > 0)
  google_workspace_service_account_setup  = <<EOT
  5. Create an account to act as a 'Service Account' for the connection in your Google Workspace
     Directory. This is not to be confused with a GCP Service Account. Rather, this is a regular
     Google Workspace user account, but intended to be assigned to a service rather than a human
     user. Your proxy instance will impersonate this user when accessing the [Google Admin Directory](https://developers.google.com/admin-sdk/directory/v1/guides)
     and [Reports](https://developers.google.com/admin-sdk/reports/v1/guides) APIs. (Google requires
     that these be accessed via impersonation of a Google user account, rather than directly using
     a GCP service account).

     We recommend naming the account `svc-worklytics@{your-domain.com}`.

     If you have already created a sufficiently privelleged service account user for a different
     Google Workspace connection, you can re-use that one.

  6. Assign the account a sufficiently privileged role. At minimum, the role must have the following
     permissions:
       * Admin API
       * Domain Settings
       * Groups
       * Organizational Units
       * Reports (required only if you are connecting to the Audit Logs, used for Google Chat, Meet, etc)
       * Users
     You may use a predefined role, or define a [Custom Role](https://support.google.com/a/answer/2406043?fl=1).

(NOTE: Steps 5/6 are optional, but highly recommended. You could use the account of a sufficiently
privileged human user, but then should you ever remove that user or revoke privleges, your
connection to will fail)

  7. Send the email address of the account you created to the administrator who will create the
     connection in the Worklytics portal. They will need to provide it as the value of the 'Google
     Account to Use for Connection' setting when they create the connection.
  8. Optionally, you may also set the email address of the account you created the value of
     `google_workspace_example_user` in your `terraform.tfvars` file. This will cause the example
     API invocations generated by the terraform modules to prefill this value as the account to
     impersonate on those requests. This will allow you to validate the permissions of the account,
     as well as the ability of the proxy connection to impersonate it.
EOT

}
",locals,"locals {
  # alternatively, could test if prefix of ANY needed scope starts with 'https://www.googleapis.com/auth/admin',
  # but in a sense that's a little hackier as is exploiting implementation details of Google's OAuth scope format

  # additionally, each of these OAuth scopes would seem tp imply *specific* permissions for the role
  # that the service account needs; so we could formally define the subset
  scopes_requiring_admin_account = [
    ""https://www.googleapis.com/auth/admin.directory.user.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.user.alias.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.domain.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.group.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.group.member.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.orgunit.readonly"",
    ""https://www.googleapis.com/auth/admin.directory.rolemanagement.readonly"",
    ""https://www.googleapis.com/auth/admin.reports.audit.readonly"",
  ]
  google_workspace_admin_account_required = (length(setintersection(local.scopes_requiring_admin_account, var.oauth_scopes_needed)) > 0)
  google_workspace_service_account_setup  = <<EOT
  5. Create an account to act as a 'Service Account' for the connection in your Google Workspace
     Directory. This is not to be confused with a GCP Service Account. Rather, this is a regular
     Google Workspace user account, but intended to be assigned to a service rather than a human
     user. Your proxy instance will impersonate this user when accessing the [Google Admin Directory](https://developers.google.com/admin-sdk/directory/v1/guides)
     and [Reports](https://developers.google.com/admin-sdk/reports/v1/guides) APIs. (Google requires
     that these be accessed via impersonation of a Google user account, rather than directly using
     a GCP service account).

     We recommend naming the account `svc-worklytics@{your-domain.com}`.

     If you have already created a sufficiently privileged service account user for a different
     Google Workspace connection, you can re-use that one.

  6. Assign the account a sufficiently privileged role. At minimum, the role must have permission
     to READ the following [Administrator Setting Privileges](https://support.google.com/a/answer/1219251):
       * Admin API
       * Domain Settings
       * Groups
       * Organizational Units
       * Reports (required only if you are connecting to the Audit Logs, used for Google Chat, Meet, etc)
       * Users
     You may use a predefined role, or define a [Custom Role](https://support.google.com/a/answer/2406043?fl=1).

(NOTE: Steps 5/6 are optional, but highly recommended. You could use the account of a sufficiently
privileged human user, but then should you ever remove that user or revoke privileges, your
connection to will fail)

  7. Send the email address of the account you created to the administrator who will create the
     connection in the Worklytics portal. They will need to provide it as the value of the 'Google
     Account to Use for Connection' setting when they create the connection.

  8. Optionally, you may also set the email address of the account you created the value of
     `google_workspace_example_user` in your `terraform.tfvars` file. This will cause the example
     API invocations generated by the terraform modules to prefill this value as the account to
     impersonate on those requests. This will allow you to validate the permissions of the account,
     as well as the ability of the proxy connection to impersonate it.
EOT

  todo_content = <<EOT
Complete the following steps via the Google Workspace Admin console:
  1. Visit https://admin.google.com/ and navigate to ""Security"" --> ""Access and Data Control"" -->
     ""API Controls"", then find ""Manage Domain Wide Delegation"". Click ""Add new"".

  2. Copy and paste client ID `${google_service_account.connector_sa.unique_id}` into the
     ""Client ID"" input in the popup. (this is the unique ID of the GCP service account with
     email `${google_service_account.connector_sa.email}`; you can (and should) verify its identity
     via the GCP console, with the project `${google_service_account.connector_sa.project}`, under:

     [""IAM & Admin"" --> ""Service Accounts""](https://console.cloud.google.com/iam-admin/serviceaccounts?project=${google_service_account.connector_sa.project}&supportedpurview=project)

     This ensures you are granting domain-wide delegation to the correct service account, and
     mitigates the risk that these instructions were forged by a malicious actor.

     Via the GCP console, you can also verify all extant keys for the service account, to ensure
     that there is exactly one, which should be held by the proxy.  GCP provides log of key usage,
     creation, revocation, etc, which you can monitor to ensure that the key is being used only by
     the proxy, only for the data access you expect. If you ever suspect compromise, you may revoke
     the key from the GCP console at any time (NOTE: that proxy connection will be broken until your
     Terraform configuration is re-applied, to provision a new key).

  3. Copy and paste the following OAuth 2.0 scope string into the ""Scopes"" input:
```
${join("","", var.oauth_scopes_needed)}
```

   4. Authorize it. With this, your psoxy instance should be able to authenticate with Google as
      the GCP Service Account `${google_service_account.connector_sa.email}` and request data from
      Google as authorized by the OAuth scopes you granted.
${local.google_workspace_admin_account_required ? local.google_workspace_service_account_setup : """"}
EOT
}
",locals,25,43.0,fc966f9714e332add194d2aacc9c7e328b714c1c,419ab7426298f38d950186bd64303ef628cc2fc5,https://github.com/Worklytics/psoxy/blob/fc966f9714e332add194d2aacc9c7e328b714c1c/infra/modules/google-workspace-dwd-connection/main.tf#L25,https://github.com/Worklytics/psoxy/blob/419ab7426298f38d950186bd64303ef628cc2fc5/infra/modules/google-workspace-dwd-connection/main.tf#L43,2022-12-21 09:04:05-08:00,2023-12-20 09:36:51-08:00,17,0,0,0,0,1,0,0,0,1
https://github.com/alphagov/govuk-aws,131,terraform/projects/infra-security-groups/publishing-api.tf,terraform/projects/infra-security-groups/publishing-api.tf,0,# todo,# TODO: replace this with ingress from the publishing-api LBs when we build them.,# TODO: replace this with ingress from the publishing-api LBs when we build them.,"resource ""aws_security_group_rule"" ""allow_management_to_publishing-api_elb"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  security_group_id        = ""${aws_security_group.publishing-api_elb.id}""
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,47,,e24ab6cf75591ebb9e307097e5eddcf47015e8fb,983522b0b260af5bc85ae8728f09499a79baf7ac,https://github.com/alphagov/govuk-aws/blob/e24ab6cf75591ebb9e307097e5eddcf47015e8fb/terraform/projects/infra-security-groups/publishing-api.tf#L47,https://github.com/alphagov/govuk-aws/blob/983522b0b260af5bc85ae8728f09499a79baf7ac/terraform/projects/infra-security-groups/publishing-api.tf,2017-07-20 12:58:19+01:00,2017-08-17 13:01:36+01:00,3,1,0,1,0,1,1,0,0,0
https://github.com/pingcap/tidb-operator,9,deploy/alicloud/main.tf,deploy/aliyun/main.tf,1,workaround,"# Workaround: Terraform cannot specify provider dependency, so we take over kubernetes and helm stuffs,","# Workaround: Terraform cannot specify provider dependency, so we take over kubernetes and helm stuffs, 
 # But we cannot ouput kubernetes and helm resources in this way. 
 # TODO: use helm and kubernetes provider when upstream get this fixed","resource ""null_resource"" ""deploy-tidb-cluster"" {
  depends_on = [""null_resource.setup-env"", ""local_file.tidb-cluster-values""]

  triggers {
    values = ""${data.template_file.tidb-cluster-values.rendered}""
  }

  provisioner ""local-exec"" {
    command = <<EOS
helm upgrade --install tidb-cluster ${path.module}/charts/tidb-cluster --namespace=tidb -f ${local.tidb_cluster_values_path}
echo ""TiDB cluster setup complete!""
EOS

    environment = {
      KUBECONFIG = ""${local.kubeconfig}""
    }
  }
}
",resource,the block associated got renamed or deleted,,119,,eebd686956c0b2adf67a10e1a376659c95c571a3,042b1a97fbbdf342297002990564828e6644a3f0,https://github.com/pingcap/tidb-operator/blob/eebd686956c0b2adf67a10e1a376659c95c571a3/deploy/alicloud/main.tf#L119,https://github.com/pingcap/tidb-operator/blob/042b1a97fbbdf342297002990564828e6644a3f0/deploy/aliyun/main.tf,2019-05-06 19:59:43+08:00,2019-07-23 19:44:58+08:00,4,1,0,1,1,0,0,1,0,0
https://github.com/Worklytics/psoxy,623,infra/modules/worklytics-psoxy-connection-generic/variables.tf,infra/modules/worklytics-psoxy-connection-generic/variables.tf,0,# todo,# TODO: rename to `host_platform_id` in future versions avoid coupling to brand name,# TODO: rename to `host_platform_id` in future versions avoid coupling to brand name,"variable ""psoxy_host_platform_id"" {
  type        = string
  description = ""Psoxy host platform id (AWS, GCP, etc""
  default     = ""GCP""

  validation {
    condition     = contains([""AWS"", ""GCP""], var.psoxy_host_platform_id)
    error_message = ""`psoxy_host_platform_id` must be one of AWS or GCP.""
  }
}
",variable,"variable ""psoxy_host_platform_id"" {
  type        = string
  description = ""Psoxy host platform id (AWS, GCP, etc""
  default     = ""GCP""

  validation {
    condition     = contains([""AWS"", ""GCP""], var.psoxy_host_platform_id)
    error_message = ""`psoxy_host_platform_id` must be one of AWS or GCP.""
  }
}
",variable,14,14.0,df24acebb5a0d8049e753a7084cbf84c34e773b3,5937e6a45055a94ff2b493f96f21863d91699825,https://github.com/Worklytics/psoxy/blob/df24acebb5a0d8049e753a7084cbf84c34e773b3/infra/modules/worklytics-psoxy-connection-generic/variables.tf#L14,https://github.com/Worklytics/psoxy/blob/5937e6a45055a94ff2b493f96f21863d91699825/infra/modules/worklytics-psoxy-connection-generic/variables.tf#L14,2023-01-16 09:59:11-08:00,2024-03-06 18:11:21+00:00,3,0,0,1,0,0,0,0,0,0
https://github.com/RhinoSecurityLabs/cloudgoat,1,scenarios/ecs_efs_attack/terraform/lambda.tf,scenarios/ecs_efs_attack/terraform/lambda.tf,0,fix,# get added to the efs. The old code will remain below until the timing bug is found and fixed.,"# Setup cloudwatch to trigger lambda every three minutes.filename 
 # This method was used over aws_lambda_invocation due to a timing bug. When aws_lambda_invocation would run it would fail to mount 
 # the efs. This was used as a work around. Idealy this function should only be called once but this method reduces the chance the file does not 
 # get added to the efs. The old code will remain below until the timing bug is found and fixed. ","resource ""aws_cloudwatch_event_rule"" ""cg_insert_file_every_three_minutes"" {
  name                = ""cg_every_three_minutes_${var.cgid}""
  description         = ""Fires every_three_minutes""
  schedule_expression = ""rate(3 minutes)""
}
",resource,"resource ""aws_cloudwatch_event_rule"" ""cg_insert_file_every_three_minutes"" {
  name                = ""cg_every_three_minutes_${var.cgid}""
  description         = ""Fires every_three_minutes""
  schedule_expression = ""rate(3 minutes)""

  tags = local.default_tags
}
",resource,51,36.0,a24a719704b95b7b309e0535b756dc5ca4498768,6e1b8a98b303cb108508d6ebcc74bf2342b44dee,https://github.com/RhinoSecurityLabs/cloudgoat/blob/a24a719704b95b7b309e0535b756dc5ca4498768/scenarios/ecs_efs_attack/terraform/lambda.tf#L51,https://github.com/RhinoSecurityLabs/cloudgoat/blob/6e1b8a98b303cb108508d6ebcc74bf2342b44dee/scenarios/ecs_efs_attack/terraform/lambda.tf#L36,2020-11-11 09:53:46-08:00,2024-01-05 15:09:47-07:00,2,0,0,1,0,0,0,0,1,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,4,infrastructure/shared-vpc/test-resources.tf,infrastructure/shared-vpc/test-resources.tf,0,# todo,# TODO(ludomagno): add a location output to the keyring module,# TODO(ludomagno): add a location output to the keyring module,"module ""container-vm_cos-mysql"" {
  source         = ""terraform-google-modules/container-vm/google//modules/cos-mysql""
  version        = ""1.0.4""
  project_id     = lookup(local.service_projects, module.project-service-gce.project_id, """")
  region         = ""${lookup(local.net_subnet_regions, ""gce"", """")}""
  zone           = ""${lookup(local.net_subnet_regions, ""gce"", """")}-b""
  network        = module.net-vpc-host.network_self_link
  subnetwork     = lookup(local.net_subnet_links, ""gke"", """")
  instance_count = ""1""
  data_disk_size = ""10""
  vm_tags        = [""ssh"", ""mysql""]
  password       = null_resource.mysql_password.triggers.ciphertext
  # TODO(ludomagno): add a location output to the keyring module
  kms_data = {
    key        = ""mysql""
    keyring    = module.host-kms.keyring_name
    location   = var.kms_keyring_location
    project_id = module.project-svpc-host.project_id
  }
}
",module,,,124,0.0,ddb8c70f793f7a2c24682a051dbf2af7bea06de5,c486bfc66f9814e33b410602cb557a5e4d532912,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/ddb8c70f793f7a2c24682a051dbf2af7bea06de5/infrastructure/shared-vpc/test-resources.tf#L124,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/c486bfc66f9814e33b410602cb557a5e4d532912/infrastructure/shared-vpc/test-resources.tf#L0,2019-10-20 08:17:32+02:00,2020-04-03 14:06:48+02:00,2,2,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1597,fast/stages-multitenant/0-bootstrap-tenant/automation-sas.tf,fast/stages-multitenant/0-bootstrap-tenant/automation-sas.tf,0,# todo,# TODO: move to new iam_bindings_additive in the organization module,"# assign org policy admin with a tag-based condition to stage 2 and 3 SAs 
 # TODO: move to new iam_bindings_additive in the organization module ","resource ""google_organization_iam_member"" ""org_policy_admin_stage2_3"" {
  for_each = {
    for k, v in module.automation-tf-resman-sa-stage2-3 : k => v.iam_email
  }
  org_id = var.organization.id
  role   = ""roles/orgpolicy.policyAdmin""
  member = each.value
  condition {
    title = ""org_policy_tag_${var.tenant_config.short_name}_${each.key}_scoped""
    description = join("""", [
      ""Org policy tag scoped grant for tenant ${var.tenant_config.short_name} "",
      local.branch_sas[each.key].description
    ])
    expression = join("" && "", [
      local.iam_tenant_condition, local.branch_sas[each.key].condition
    ])
  }
}
",resource,,,109,0.0,819894d2bab4b440f1b52b1ac8035912fb107004,7a5dd4e6db197daa52da8a8d877ce86b5c93182e,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/819894d2bab4b440f1b52b1ac8035912fb107004/fast/stages-multitenant/0-bootstrap-tenant/automation-sas.tf#L109,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/7a5dd4e6db197daa52da8a8d877ce86b5c93182e/fast/stages-multitenant/0-bootstrap-tenant/automation-sas.tf#L0,2023-08-20 09:44:20+02:00,2024-05-15 09:17:13+00:00,2,2,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-kubernetes-engine,3,test/fixtures/networks/main.tf,test/fixtures/networks/main.tf,0,todo,// TODO clean up CIDRs,// TODO clean up CIDRs,"resource ""google_compute_subnetwork"" ""example-deploy_service"" {
  name = ""cft-gke-test-deploy-service-${random_string.suffix.result}""
  ip_cidr_range = ""10.0.32.0/20""
  region = ""${var.region}""
  network = ""${google_compute_network.main.self_link}""
  secondary_ip_range {
    range_name = ""cft-gke-test-deploy-service-pods-${random_string.suffix.result}""
    ip_cidr_range = ""192.168.32.0/22""
  }
  secondary_ip_range {
    range_name = ""cft-gke-test-deploy-service-services-${random_string.suffix.result}""
    ip_cidr_range = ""192.168.36.0/22""
  }
}
",resource,,,21,0.0,98eb6d1205eb0916666a108b85ad3770deb6d9de,d3d4436db18854d4a653ceca9e10a629e4fca8ab,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/98eb6d1205eb0916666a108b85ad3770deb6d9de/test/fixtures/networks/main.tf#L21,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/d3d4436db18854d4a653ceca9e10a629e4fca8ab/test/fixtures/networks/main.tf#L0,2018-12-19 13:12:41-05:00,2018-12-19 13:13:26-05:00,3,2,0,1,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1865,fast/stages/2-networking-e-nva-bgp/nva.tf,fast/stages/2-networking-e-nva-bgp/nva.tf,0,# todo,# TODO: use address module,# TODO: use address module,"resource ""google_compute_address"" ""nva_static_ip_landing"" {
  for_each     = local.nva_configs
  name         = ""nva-ip-landing-${each.value.shortname}-${each.value.zone}""
  project      = module.landing-project.project_id
  subnetwork   = module.landing-vpc.subnet_self_links[""${each.value.region}/landing-default""]
  address_type = ""INTERNAL""
  address      = each.value.ip_landing
  region       = each.value.region
}
",resource,"resource ""google_compute_address"" ""nva_static_ip_landing"" {
  for_each     = local.nva_configs
  name         = ""nva-ip-landing-${each.value.shortname}-${each.value.zone}""
  project      = module.landing-project.project_id
  subnetwork   = module.landing-vpc.subnet_self_links[""${each.value.region}/landing-default""]
  address_type = ""INTERNAL""
  address      = each.value.ip_landing
  region       = each.value.region
}
",resource,137,137.0,3972eb6df4b2f5f3a133afa72a253568cc3cf1df,3af7e257d21f889ffaf7b32a3bab974fdbfda6e4,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/3972eb6df4b2f5f3a133afa72a253568cc3cf1df/fast/stages/2-networking-e-nva-bgp/nva.tf#L137,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/3af7e257d21f889ffaf7b32a3bab974fdbfda6e4/fast/stages/2-networking-e-nva-bgp/nva.tf#L137,2024-02-29 07:45:19+01:00,2024-04-17 10:23:48+02:00,2,0,0,1,0,0,1,0,0,0
https://github.com/awslabs/data-on-eks,12,ai-ml/jupyterhub/addons.tf,ai-ml/jupyterhub/addons.tf,0,# todo,# TODO: Define just the right permission for Jupyter Notebooks,"policy = ""arn:aws:iam::aws:policy/AdministratorAccess"" # TODO: Define just the right permission for Jupyter Notebooks","module ""jupyterhub_single_user_irsa"" {
  source = ""terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks""

  role_name = ""${module.eks.cluster_name}-jupyterhub-single-user-sa""

  role_policy_arns = {
    policy = ""arn:aws:iam::aws:policy/AdministratorAccess"" # TODO: Define just the right permission for Jupyter Notebooks
  }


  oidc_providers = {
    main = {
      provider_arn               = module.eks.oidc_provider_arn
      namespace_service_accounts = [""${kubernetes_namespace.jupyterhub.metadata[0].name}:jupyterhub-single-user""]
    }
  }
}
",module,"module ""jupyterhub_single_user_irsa"" {
  source = ""terraform-aws-modules/iam/aws//modules/iam-role-for-service-accounts-eks""

  role_name = ""${module.eks.cluster_name}-jupyterhub-single-user-sa""

  role_policy_arns = {
    policy = ""arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"" # Policy needs to be defined based in what you need to give access to your notebook instances.
  }


  oidc_providers = {
    main = {
      provider_arn               = module.eks.oidc_provider_arn
      namespace_service_accounts = [""${kubernetes_namespace.jupyterhub.metadata[0].name}:jupyterhub-single-user""]
    }
  }
}
",module,174,,64fadc52b6f9eec59bf827c8fcdc5ae076734b07,211817445b59d484337a5506a03f3077e7960cec,https://github.com/awslabs/data-on-eks/blob/64fadc52b6f9eec59bf827c8fcdc5ae076734b07/ai-ml/jupyterhub/addons.tf#L174,https://github.com/awslabs/data-on-eks/blob/211817445b59d484337a5506a03f3077e7960cec/ai-ml/jupyterhub/addons.tf,2023-07-31 20:33:08-05:00,2023-08-02 11:36:36-05:00,4,1,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-bigquery,5,main.tf,main.tf,0,#todo,#TODO: is this required?,#TODO: is this required?,"resource ""google_bigquery_table"" ""default"" {
  dataset_id = ""${google_bigquery_dataset.default.dataset_id}""
  table_id   = ""${var.table_id}""
  project    = ""${var.project_id}""

  #TODO: is this required?
  time_partitioning {
    type = ""${var.time_partitioning}""
  }

  labels {
    env = ""default""
  }

  schema = ""${file(""${var.schema_file}"")}""
}
",resource,the block associated got renamed or deleted,,61,,d56aa2c9a80343d60eed3e1a7d24962be31ee0b6,7f922f7e9df197df38c9b09dfa6e3614d71f19f5,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/d56aa2c9a80343d60eed3e1a7d24962be31ee0b6/main.tf#L61,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/7f922f7e9df197df38c9b09dfa6e3614d71f19f5/main.tf,2018-11-20 10:30:15-05:00,2019-01-16 18:10:54-05:00,3,1,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/hpc-toolkit,17,community/modules/remote-desktop-linux/main.tf,community/modules/remote-desktop-linux/main.tf,0,todo,# todo change this to driver install script,# todo change this to driver install script,"locals {
  resource_prefix = var.name_prefix != null ? var.name_prefix : ""${var.deployment_name}-chrome-remote-desktop""

  /*
  #
  # if a machine type is a2-*-?g it will automatically fill in the guest_accelerator structure.
  #
  is_a2_vm = length(regexall(""a2-[a-z]+-\\d+g"", var.machine_type)) > 0
  accelerator_types = {
    ""highgpu""  = ""nvidia-tesla-a100""
    ""megagpu""  = ""nvidia-tesla-a100""
    ""ultragpu"" = ""nvidia-a100-80gb""
  }
  guest_accelerator = var.guest_accelerator == null && local.is_a2_vm ? [{
    type  = lookup(local.accelerator_types, regex(""a2-([A-Za-z]+)-"", var.machine_type)[0], """"),
    count = one(regex(""a2-[A-Za-z]+-(\\d+)"", var.machine_type)),
  }] : var.guest_accelerator

  gpu_count = length(local.guest_accelerator) > 0 ? 0 : local.guest_accelerator[0].count

*/
  user_startup_script_runners = var.startup_script == null ? [] : [
    {
      type        = ""shell""
      content     = var.startup_script
      destination = ""user_startup_script.sh""
    }
  ]

  ssh_args = join("""", [
    ""-e host_name_prefix=${local.resource_prefix}""
  ])

  configure_ssh_runners = [
    {
      type        = ""data""
      source      = ""${path.module}/scripts/setup-ssh-keys.sh""
      destination = ""/usr/local/ghpc/setup-ssh-keys.sh""
    },
    {
      type        = ""data""
      source      = ""${path.module}/scripts/setup-ssh-keys.yml""
      destination = ""/usr/local/ghpc/setup-ssh-keys.yml""
    },
    {
      type        = ""ansible-local""
      content     = file(""${path.module}/scripts/configure-ssh.yml"")
      destination = ""configure-ssh.yml""
      args        = local.ssh_args
    }
  ]
  # todo change this to driver install script
  configure_nvidia_driver_runners = var.install_nvidia_driver == false ? [] : [
    {
      type        = ""shell""
      content     = file(""${path.module}/scripts/configure-grid-drivers.sh"")
      destination = ""/usr/local/ghpc/configure-grid-drivers.yml""
    }
  ]
  # todo change this to chrome install script & merge with xfce install script
  configure_chrome_remote_desktop_runners = var.configure_chrome_remote_desktop == false ? [] : [
    {
      type        = ""shell""
      content     = file(""${path.module}/scripts/configure-chrome-desktop.sh"")
      destination = ""/usr/local/ghpc/configure-chrome-desktop.yml""
    }
  ]

  driver     = { install-nvidia-driver = var.install_nvidia_driver }
  logging    = var.enable_google_logging ? { google-logging-enable = 1 } : { google-logging-enable = 0 }
  monitoring = var.enable_google_monitoring ? { google-monitoring-enable = 1 } : { google-monitoring-enable = 0 }
  shutdown   = { shutdown-script = ""/opt/deeplearning/bin/shutdown_script.sh"" }
  metadata   = merge(local.driver, local.logging, local.monitoring, local.shutdown, var.metadata)
}
",locals,,,69,0.0,cb06601fe71434d7539ea073a9e1c3c03981e641,1fe9b4674767a89081bf6aa27b34e9e4338e8111,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/cb06601fe71434d7539ea073a9e1c3c03981e641/community/modules/remote-desktop-linux/main.tf#L69,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/1fe9b4674767a89081bf6aa27b34e9e4338e8111/community/modules/remote-desktop-linux/main.tf#L0,2023-01-11 06:57:26+00:00,2023-01-18 12:58:23+11:00,2,2,0,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd,3,modules/secure-cd/main.tf,modules/secure-cd/main.tf,0,//todo,//TODO,require_attestations_by = [google_binary_authorization_attestor.attestor.name] //TODO,"resource ""google_binary_authorization_policy"" ""deployment_policy"" {
  admission_whitelist_patterns {
    name_pattern = ""gcr.io/google_containers/*""
  }

  default_admission_rule {
    evaluation_mode  = ""ALWAYS_DENY""
    enforcement_mode = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
  }

  global_policy_evaluation_mode = ""ENABLE""

  // Prod Cluster Policy
  cluster_admission_rules {
    cluster                 = ""${var.primary_location}.${var.prod_cluster_name}""
    evaluation_mode         = ""REQUIRE_ATTESTATION""
    enforcement_mode        = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
    require_attestations_by = [google_binary_authorization_attestor.attestor.name] //TODO
  }

  // QA Cluster Policy
  cluster_admission_rules {
    cluster                 = ""${var.primary_location}.${var.qa_cluster_name}""
    evaluation_mode         = ""REQUIRE_ATTESTATION""
    enforcement_mode        = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
    require_attestations_by = [google_binary_authorization_attestor.attestor.name] //TODO
  }

  // Dev Cluster Policy
  cluster_admission_rules {
    cluster                 = ""${var.primary_location}.${var.dev_cluster_name}""
    evaluation_mode         = ""REQUIRE_ATTESTATION""
    enforcement_mode        = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
    require_attestations_by = [google_binary_authorization_attestor.attestor.name] //TODO
  }
}",resource,"resource ""google_binary_authorization_policy"" ""deployment_policy"" {
  for_each = var.deploy_branch_clusters
  project  = each.value.project_id
  
  admission_whitelist_patterns {
    name_pattern = ""gcr.io/google_containers/*""
  }

  default_admission_rule {
    evaluation_mode  = ""ALWAYS_DENY""
    enforcement_mode = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
  }

  global_policy_evaluation_mode = ""ENABLE""

  cluster_admission_rules {
    cluster                 = ""${each.value.location}.${each.value.cluster}"" // TODO: customer config
    evaluation_mode         = ""REQUIRE_ATTESTATION""
    enforcement_mode        = ""ENFORCED_BLOCK_AND_AUDIT_LOG""
    require_attestations_by = each.value.attestations //TODO?
  }
}
",resource,79,,33dc63e0d09516388c2b1d1d9d0bedaf1face074,6249c4ca90692e593bc0c7bc6d603580150ff255,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/33dc63e0d09516388c2b1d1d9d0bedaf1face074/modules/secure-cd/main.tf#L79,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/6249c4ca90692e593bc0c7bc6d603580150ff255/modules/secure-cd/main.tf,2021-10-14 11:53:32-05:00,2021-10-26 17:18:47-05:00,6,1,1,1,0,1,0,0,0,0
https://github.com/chanzuckerberg/cztack,25,aws-ecs-service/iam.tf,aws-ecs-service/iam.tf,0,# todo,# TODO: Add support for giving permissions to ECR ARNs and possibly cloudwatch log group,"# TODO: Add support for giving permissions to ECR ARNs and possibly cloudwatch log group 
 # Or provide ability to pass in own execution role ARN","resource ""aws_iam_role_policy_attachment"" ""task_execution_role"" {
  count      = var.registry_secretsmanager_arn != null ? 1 : 0
  role       = aws_iam_role.task_execution_role[0].name
  policy_arn = ""arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy""
}
",resource,"resource ""aws_iam_role_policy_attachment"" ""task_execution_role"" {
  count      = var.registry_secretsmanager_arn != null ? 1 : 0
  role       = aws_iam_role.task_execution_role[0].name
  policy_arn = ""arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy""
}
",resource,18,19.0,6918848f1dab99c67e49d21bdc839d907ff8b647,133cb5c3ab7a3671f4212fe1e28476e675247247,https://github.com/chanzuckerberg/cztack/blob/6918848f1dab99c67e49d21bdc839d907ff8b647/aws-ecs-service/iam.tf#L18,https://github.com/chanzuckerberg/cztack/blob/133cb5c3ab7a3671f4212fe1e28476e675247247/aws-ecs-service/iam.tf#L19,2019-09-25 09:47:44-07:00,2019-10-09 10:54:43-07:00,3,0,0,1,0,1,0,0,1,0
https://github.com/Azure/az-hop,43,tf/network_security_group.tf,tf/network_security_group.tf,0,todo,# TODO : Need to understand which ports needs to be open when refreshing the OOD webpage,# TODO : Need to understand which ports needs to be open when refreshing the OOD webpage,"resource ""azurerm_network_security_group"" ""admin"" {
  count                = local.create_vnet ? 1 : 0
  name                = ""nsg-${local.create_vnet ? azurerm_subnet.admin[0].name : data.azurerm_subnet.admin[0].name}""
  location            = azurerm_resource_group.rg[0].location
  resource_group_name = azurerm_resource_group.rg[0].name

  #
  #         INBOUND
  #
  security_rule {
        name                       = ""AllowSshIn""
        priority                   = ""100""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Ssh""]
        source_application_security_group_ids  = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ssh""].id]
  }

  security_rule {
        name                       = ""AllowRdpIn""
        priority                   = ""110""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Rdp""]
        source_application_security_group_ids  = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInTcp""
        priority                   = ""120""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInComputeTcp""
        priority                   = ""130""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInNetAppTcp""
        priority                   = ""140""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_address_prefixes    = azurerm_subnet.netapp[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInUdp""
        priority                   = ""150""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInComputeUdp""
        priority                   = ""160""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInNetAppUdp""
        priority                   = ""170""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_address_prefixes    = azurerm_subnet.netapp[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafIn""
        priority                   = ""180""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-telegraf""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafComputeIn""
        priority                   = ""190""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowGrafanaIn""
        priority                   = ""200""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Grafana""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowCycleWebIn""
        priority                   = ""210""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Web""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientIn""
        priority                   = ""220""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientComputeIn""
        priority                   = ""230""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowPbsIn""
        priority                   = ""240""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowPbsComputeIn""
        priority                   = ""250""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowLustreIn""
        priority                   = ""260""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowLustreComputeIn""
        priority                   = ""270""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowRobinhoodIn""
        priority                   = ""280""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Web""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-robinhood""].id]
  }

  security_rule {
        name                       = ""AllowSocksIn""
        priority                   = ""290""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Socks""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  # TODO : Need to understand which ports needs to be open when refreshing the OOD webpage
  security_rule {
        name                       = ""AllowOnDemandToAd""
        priority                   = ""300""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""DenyVnetInbound""
        priority                   = ""3100""
        direction                  = ""Inbound""
        access                     = ""Deny""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }

  #
  #         OUTBOUND
  #
  security_rule {
        name                       = ""AllowAdServerOutTcp""
        priority                   = ""100""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad-client""].id]
  }

  security_rule {
        name                       = ""AllowAdClientOutTcp""
        priority                   = ""110""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerComputeOutTcp""
        priority                   = ""120""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowAdServerOutUdp""
        priority                   = ""130""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad-client""].id]
  }

  security_rule {
        name                       = ""AllowAdClientOutUdp""
        priority                   = ""140""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerComputeOutUdp""
        priority                   = ""150""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowDnsOut""
        priority                   = ""160""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Dns""]
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }

  security_rule {
        name                       = ""AllowCycleServerOut""
        priority                   = ""170""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientOut""
        priority                   = ""180""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientComputeOut""
        priority                   = ""190""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowPbsOut""
        priority                   = ""200""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
  }

  security_rule {
        name                       = ""AllowPbsClientOut""
        priority                   = ""210""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowPbsComputeOut""
        priority                   = ""220""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowLustreOut""
        priority                   = ""230""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
  }

  security_rule {
        name                       = ""AllowLustreClientOut""
        priority                   = ""240""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowLustreComputeOut""
        priority                   = ""250""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowNFSOut""
        priority                   = ""260""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Nfs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-nfs-client""].id]
        destination_address_prefixes = azurerm_subnet.netapp[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowChronyOut""
        priority                   = ""270""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Chrony""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-chrony""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ondemand""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafOut""
        priority                   = ""280""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-telegraf""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowInternetOutBound""
        priority                   = ""3000""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""*""
        destination_address_prefix = ""Internet""
  }

  security_rule {
        name                       = ""DenyVnetOutBound""
        priority                   = ""3100""
        direction                  = ""Outbound""
        access                     = ""Deny""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }
}
",resource,"resource ""azurerm_network_security_group"" ""admin"" {
  count                = local.create_vnet ? 1 : 0
  name                = ""nsg-${local.create_vnet ? azurerm_subnet.admin[0].name : data.azurerm_subnet.admin[0].name}""
  location            = azurerm_resource_group.rg[0].location
  resource_group_name = azurerm_resource_group.rg[0].name

  #
  #         INBOUND
  #
  security_rule {
        name                       = ""AllowSshIn""
        priority                   = ""100""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Ssh""]
        source_application_security_group_ids  = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ssh""].id]
  }

  security_rule {
        name                       = ""AllowRdpIn""
        priority                   = ""110""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Rdp""]
        source_application_security_group_ids  = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInTcp""
        priority                   = ""120""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInComputeTcp""
        priority                   = ""130""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInNetAppTcp""
        priority                   = ""140""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_address_prefixes    = azurerm_subnet.netapp[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInUdp""
        priority                   = ""150""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInComputeUdp""
        priority                   = ""160""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerInNetAppUdp""
        priority                   = ""170""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_address_prefixes    = azurerm_subnet.netapp[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafIn""
        priority                   = ""180""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-telegraf""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafComputeIn""
        priority                   = ""190""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowGrafanaIn""
        priority                   = ""200""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Grafana""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowCycleWebIn""
        priority                   = ""210""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Web""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientIn""
        priority                   = ""220""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientComputeIn""
        priority                   = ""230""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowPbsIn""
        priority                   = ""240""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowPbsComputeIn""
        priority                   = ""250""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowLustreIn""
        priority                   = ""260""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowLustreComputeIn""
        priority                   = ""270""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowRobinhoodIn""
        priority                   = ""280""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Web""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-robinhood""].id]
  }

  security_rule {
        name                       = ""AllowSocksIn""
        priority                   = ""290""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Socks""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-jumpbox""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowOnDemandToAd""
        priority                   = ""300""
        direction                  = ""Inbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ondemand""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""DenyVnetInbound""
        priority                   = ""3100""
        direction                  = ""Inbound""
        access                     = ""Deny""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }

  #
  #         OUTBOUND
  #
  security_rule {
        name                       = ""AllowAdServerOutTcp""
        priority                   = ""100""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad-client""].id]
  }

  security_rule {
        name                       = ""AllowAdClientOutTcp""
        priority                   = ""110""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerComputeOutTcp""
        priority                   = ""120""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerTcp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowAdServerOutUdp""
        priority                   = ""130""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad-client""].id]
  }

  security_rule {
        name                       = ""AllowAdClientOutUdp""
        priority                   = ""140""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ad""].id]
  }

  security_rule {
        name                       = ""AllowAdServerComputeOutUdp""
        priority                   = ""150""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""udp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""DomainControlerUdp""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-ad""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowDnsOut""
        priority                   = ""160""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Dns""]
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }

  security_rule {
        name                       = ""AllowCycleServerOut""
        priority                   = ""170""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientOut""
        priority                   = ""180""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
  }

  security_rule {
        name                       = ""AllowCycleClientComputeOut""
        priority                   = ""190""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""CycleCloud""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-cyclecloud""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowPbsOut""
        priority                   = ""200""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
  }

  security_rule {
        name                       = ""AllowPbsClientOut""
        priority                   = ""210""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-pbs""].id]
  }

  security_rule {
        name                       = ""AllowPbsComputeOut""
        priority                   = ""220""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Pbs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-pbs""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowLustreOut""
        priority                   = ""230""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
  }

  security_rule {
        name                       = ""AllowLustreClientOut""
        priority                   = ""240""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre-client""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-lustre""].id]
  }

  security_rule {
        name                       = ""AllowLustreComputeOut""
        priority                   = ""250""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Lustre""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-lustre""].id]
        destination_address_prefixes    = azurerm_subnet.compute[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowNFSOut""
        priority                   = ""260""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Nfs""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-nfs-client""].id]
        destination_address_prefixes = azurerm_subnet.netapp[0].address_prefixes
  }

  security_rule {
        name                       = ""AllowChronyOut""
        priority                   = ""270""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Chrony""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-chrony""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-ondemand""].id]
  }

  security_rule {
        name                       = ""AllowTelegrafOut""
        priority                   = ""280""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""tcp""
        source_port_range          = ""*""
        destination_port_ranges    = local.nsg_destination_ports[""Telegraf""]
        source_application_security_group_ids      = [azurerm_application_security_group.asg[""asg-telegraf""].id]
        destination_application_security_group_ids = [azurerm_application_security_group.asg[""asg-grafana""].id]
  }

  security_rule {
        name                       = ""AllowInternetOutBound""
        priority                   = ""3000""
        direction                  = ""Outbound""
        access                     = ""Allow""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""*""
        destination_address_prefix = ""Internet""
  }

  security_rule {
        name                       = ""DenyVnetOutBound""
        priority                   = ""3100""
        direction                  = ""Outbound""
        access                     = ""Deny""
        protocol                   = ""*""
        source_port_range          = ""*""
        destination_port_range     = ""*""
        source_address_prefix      = ""VirtualNetwork""
        destination_address_prefix = ""VirtualNetwork""
  }
}
",resource,616,,c95834ec17f0ddf8fd2d57b342b94c1247e54eae,dd5a5d163a07fe7a9d84803747d6a9382c015f38,https://github.com/Azure/az-hop/blob/c95834ec17f0ddf8fd2d57b342b94c1247e54eae/tf/network_security_group.tf#L616,https://github.com/Azure/az-hop/blob/dd5a5d163a07fe7a9d84803747d6a9382c015f38/tf/network_security_group.tf,2021-09-07 11:12:18+00:00,2021-09-07 15:03:17+00:00,2,1,0,1,0,1,1,0,0,0
https://github.com/ministryofjustice/modernisation-platform,281,terraform/environments/core-shared-services/ad-fixngo.tf,terraform/environments/core-shared-services/ad-fixngo.tf,0,fix,# NOTE: Fixed IPs for IP allow listing and to avoid AD DNS updates,"# NOTE: Fixed IPs for IP allow listing and to avoid AD DNS updates 
 # NOTE: Naming convention (for tags.Name and EC2 hostname) 
 # ad           = active directory 
 # azure/hmpp   = netbios domain name 
 # dc           = domain controller 
 # rdlic        = remote desktop licensing server 
 # a/b/c suffix = availability zone  
 # ad-hmpp-dc-a = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2a"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role"" 
 #   instance_type             = ""t3.large"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-a""] 
 #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[0] 
 #   vpc_security_group_name   = ""ad_hmpp_dc_sg"" 
 #   tags = { 
 #     server-type = ""DomainController"" 
 #     domain-name = ""azure.hmpp.root"" 
 #     description = ""domain controller for FixNGo azure.hmpp.root domain"" 
 #   } 
 # } 
 # ad-hmpp-dc-b = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2b"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role"" 
 #   instance_type             = ""t3.large"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-b""] 
 #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[1] 
 #   vpc_security_group_name   = ""ad_hmpp_dc_sg"" 
 #   tags = { 
 #     server-type = ""DomainController"" 
 #     domain-name = ""azure.hmpp.root"" 
 #     description = ""domain controller for FixNGo azure.hmpp.root domain"" 
 #   } 
 # } 
 # ad-hmpp-rdlic = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2c"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role"" 
 #   instance_type             = ""t3.medium"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-rdlic""] 
 #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[2] 
 #   vpc_security_group_name   = ""ad_hmpp_rdlic_sg"" 
 #   tags = { 
 #     server-type = ""RDLicensing"" 
 #     domain-name = ""azure.hmpp.root"" 
 #     description = ""remote desktop licensing server for FixNGo azure.hmpp.root domain"" 
 #   } 
 # }  
 # ad-azure-dc-a = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2a"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role"" 
 #   instance_type             = ""t3.large"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-a""] 
 #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[0] 
 #   vpc_security_group_name   = ""ad_azure_dc_sg"" 
 #   tags = { 
 #     server-type = ""DomainController"" 
 #     domain-name = ""azure.noms.root"" 
 #     description = ""domain controller for FixNGo azure.noms.root domain"" 
 #   } 
 # } 
 # ad-azure-dc-b = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2b"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role"" 
 #   instance_type             = ""t3.large"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-b""] 
 #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[1] 
 #   vpc_security_group_name   = ""ad_azure_dc_sg"" 
 #   tags = { 
 #     server-type = ""DomainController"" 
 #     domain-name = ""azure.noms.root"" 
 #     description = ""domain controller for FixNGo azure.noms.root domain"" 
 #   } 
 # } 
 # ad-azure-rdlic = { 
 #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z"" 
 #   availability_zone         = ""eu-west-2c"" 
 #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role"" 
 #   instance_type             = ""t3.medium"" 
 #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-rdlic""] 
 #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[2] 
 #   vpc_security_group_name   = ""ad_azure_rdlic_sg"" 
 #   tags = { 
 #     server-type = ""RDLicensing"" 
 #     domain-name = ""azure.noms.root"" 
 #     description = ""remote desktop licensing server for FixNGo azure.noms.root domain"" 
 #   } 
 # }","locals {

  ad_fixngo = {

    aws_instances = {

      # NOTE: Fixed IPs for IP allow listing and to avoid AD DNS updates
      # NOTE: Naming convention (for tags.Name and EC2 hostname)
      # ad           = active directory
      # azure/hmpp   = netbios domain name
      # dc           = domain controller
      # rdlic        = remote desktop licensing server
      # a/b/c suffix = availability zone

      # ad-hmpp-dc-a = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2a""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.large""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-a""]
      #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[0]
      #   vpc_security_group_name   = ""ad_hmpp_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""domain controller for FixNGo azure.hmpp.root domain""
      #   }
      # }
      # ad-hmpp-dc-b = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2b""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.large""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-b""]
      #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[1]
      #   vpc_security_group_name   = ""ad_hmpp_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""domain controller for FixNGo azure.hmpp.root domain""
      #   }
      # }
      # ad-hmpp-rdlic = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2c""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.medium""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-rdlic""]
      #   subnet_id                 = module.vpc[""live_data""].non_tgw_subnet_ids_map.private[2]
      #   vpc_security_group_name   = ""ad_hmpp_rdlic_sg""
      #   tags = {
      #     server-type = ""RDLicensing""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""remote desktop licensing server for FixNGo azure.hmpp.root domain""
      #   }
      # }

      # ad-azure-dc-a = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2a""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
      #   instance_type             = ""t3.large""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-a""]
      #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[0]
      #   vpc_security_group_name   = ""ad_azure_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.noms.root""
      #     description = ""domain controller for FixNGo azure.noms.root domain""
      #   }
      # }
      # ad-azure-dc-b = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2b""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
      #   instance_type             = ""t3.large""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-b""]
      #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[1]
      #   vpc_security_group_name   = ""ad_azure_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.noms.root""
      #     description = ""domain controller for FixNGo azure.noms.root domain""
      #   }
      # }
      # ad-azure-rdlic = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2c""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
      #   instance_type             = ""t3.medium""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-rdlic""]
      #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[2]
      #   vpc_security_group_name   = ""ad_azure_rdlic_sg""
      #   tags = {
      #     server-type = ""RDLicensing""
      #     domain-name = ""azure.noms.root""
      #     description = ""remote desktop licensing server for FixNGo azure.noms.root domain""
      #   }
      # }
    }

    ec2_iam_roles = {
      # NOTE: roles will be granted access to relevant domain secrets in hmpps-domain-services accounts
      ad-fixngo-ec2-nonlive-role = {
        managed_policy_arns = [
          ""arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"",
          ""ad-fixngo-ec2-policy"",
          ""ad-fixngo-nonlive-secrets-policy"",
        ]
      }
      ad-fixngo-ec2-live-role = {
        managed_policy_arns = [
          ""arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"",
          ""ad-fixngo-ec2-policy"",
          ""ad-fixngo-live-secrets-policy"",
        ]
      }
    }
    ec2_iam_policies = {
      ad-fixngo-ec2-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles""
        path        = ""/""
        statements = [
          {
            sid    = ""BusinessUnitKmsCmk""
            effect = ""Allow""
            actions = [
              ""kms:Encrypt"",
              ""kms:Decrypt"",
              ""kms:ReEncrypt*"",
              ""kms:GenerateDataKey*"",
              ""kms:DescribeKey"",
              ""kms:CreateGrant"",
              ""kms:ListGrants"",
              ""kms:RevokeGrant""
            ]
            resources = [
              module.kms[""hmpps""].key_arns[""ebs""].arn,
              module.kms[""hmpps""].key_arns[""general""].arn,
            ]
          },
          {
            sid    = ""Ec2SelfProvision""
            effect = ""Allow""
            actions = [
              ""ec2:DescribeVolumes"",
              ""ec2:DescribeTags"",
              ""ec2:DescribeInstances"",
            ]
            resources = [""*""]
          },
        ]
      }
      ad-fixngo-nonlive-secrets-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles to access azure.noms.root secrets""
        path        = ""/""
        statements = [
          {
            sid    = ""HmppsDomainSecretsDevTest""
            effect = ""Allow""
            actions = [
              ""secretsmanager:GetSecretValue"",
            ]
            resources = [
              ""arn:aws:secretsmanager:*:${local.environment_management.account_ids.hmpps-domain-services-test}:secret:/microsoft/AD/*/shared-*"",
            ]
          },
        ]
      }
      ad-fixngo-live-secrets-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles to access azure.hmpp.root secrets""
        path        = ""/""
        statements = [
          {
            sid    = ""HmppsDomainSecretsProd""
            effect = ""Allow""
            actions = [
              ""secretsmanager:GetSecretValue"",
            ]
            resources = [
              ""arn:aws:secretsmanager:*:${local.environment_management.account_ids.hmpps-domain-services-production}:secret:/microsoft/AD/*/shared-*"",
            ]
          },
        ]
      }
    }

    security_groups = {
      ad_hmpp_dc_sg = {
        description = ""Security group for azure.hmpp.root DCs""
        vpc_id      = module.vpc[""live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          dns-udp-53 = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-tcp-53 = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-88 = {
            port        = 88
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-88 = {
            port        = 88
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ntp-udp-123 = {
            port        = 123
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-135 = {
            port        = 135
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          netbios-tcp-139 = {
            port        = 139
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-udp-389 = {
            port        = 389
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-tcp-389 = {
            port        = 389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          smb-tcp-445 = {
            port        = 445
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-464 = {
            port        = 464
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-464 = {
            port        = 464
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-636 = {
            port        = 636
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-global-catalog-tcp-3268 = {
            from_port   = 3268
            to_port     = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-3269 = {
            port        = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          adws-tcp-9389 = {
            port        = 9389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-dynamic2 = {
            from_port   = 49152
            to_port     = 65535
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_hmpp_rdlic_sg = {
        # requires RPC
        description = ""security group for azure.hmpp.root remote desktop licensing server""
        vpc_id      = module.vpc[""live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          rpc-tcp-135 = {
            port     = 135
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          netbios-tcp-139 = {
            port     = 139
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_hmpp_domain_controllers,
            ])
          }
          netbios-tcp-445 = {
            port     = 445
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_hmpp_domain_controllers,
            ])
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          rpc-tcp-dynamic2 = {
            from_port = 49152
            to_port   = 65535
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_azure_dc_sg = {
        description = ""Security group for azure.noms.root DCs""
        vpc_id      = module.vpc[""non_live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          dns-udp-53 = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-tcp-53 = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-88 = {
            port        = 88
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-88 = {
            port        = 88
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ntp-udp-123 = {
            port        = 123
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-135 = {
            port        = 135
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          netbios-tcp-139 = {
            port        = 139
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-udp-389 = {
            port        = 389
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-tcp-389 = {
            port        = 389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          smb-tcp-445 = {
            port        = 445
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-464 = {
            port        = 464
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-464 = {
            port        = 464
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-636 = {
            port        = 636
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-global-catalog-tcp-3268 = {
            from_port   = 3268
            to_port     = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-3269 = {
            port        = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          adws-tcp-9389 = {
            port        = 9389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-dynamic2 = {
            from_port   = 49152
            to_port     = 65535
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_azure_rdlic_sg = {
        description = ""security group for azure.noms.root remote desktop licensing server""
        vpc_id      = module.vpc[""non_live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          rpc-tcp-135 = {
            port     = 135
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          netbios-tcp-139 = {
            port     = 139
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_azure_domain_controllers,
            ])
          }
          netbios-tcp-445 = {
            port     = 445
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_azure_domain_controllers,
            ])
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          rpc-tcp-dynamic2 = {
            from_port = 49152
            to_port   = 65535
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }
    }

    tags = merge(local.tags, {
      source-code            = ""https://github.com/ministryofjustice/modernisation-platform""
      infrastructure-support = ""DSO:digital-studio-operations-team@digital.justice.gov.uk""
    })
  }
}
",locals,"locals {

  ad_fixngo = {

    aws_key_pairs = {
      # See https://dsdmoj.atlassian.net/wiki/x/3oCKGAE
      ad-fixngo-ec2-live    = ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQC4XM7YBLA/DY3w4oMS4PEYyfYLcK2OuidwRRUKTFyS3lnzoucuPg4fuv3yMbLJxxoUT8QjfHDWUzQRsQorkj6ig8TB68rAz0/BBx3wuA76dNoDXAXSM/sOP1ZA1gXL3BR21hbe8QIvmqP881BLgKvB5WGN7iSPIepNtxea8g6/Eg91ISLnDvVKkqjej+wJbeBKcnGCdv6LJ082HZRMxIBfAuN9snoNyjymXYU/nMeXgwZhfSzLHU9KYOAzuYxOHgVz0k1NOPYCJflSqcYyqNbuvmLmUJVSb3u/8kpOwcTR9UP0awIzuH7PXZf87g1wyfesyAkNPMa4uUoEMIIah2tp+rAp9AUDnzn5MIv84lSkerqp2+0L/dLf+FCjNpIUePpmJiC8JCqD7oemwvrEuPpsvFalmRuRNlg2s+DKg7FVdhUWH7HiIKoiSB7dBtb02AjeY5Hi8c9urFBas4LmtngEbH8mf65VZTA82S2mLjOw8DdGRGPTc/o4MilYqR7cqDcNIw3+eEw1PqYkJUykJP5saKjLZuUxe6U0dog1iY9pimPdRKiYouF95tt43+b7/7zVTajq096r/BY2XkklVmbQ/a1HBO/Q/cfQWxhaaIaQwwnAwGQdMtEZsXaJ0OR650NJYeqtKh9ZKeMF/M+HLddiC7+1ncu78NFLlB98zD8cTw==""
      ad-fixngo-ec2-nonlive = ""ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDZ7Q515wcJIdw68vUuf2v0BFow0GmqFjapC7qJ+x6eiFqfP3Cq7jT/HYS51nzJgiXUUvyXPhQcKJgQ1O0VlTX/AjctUdm9YUbArI+S74BgNFLLbDd9EsMxhm6SKjYqbhrL9S4YxA6C0hgz4+NiEJk8XKEg5laHrOCt7kmtRE8FDvyzTLZLQ7HomHkd43tDLtvTKzKkeV2iOlnYG+l0XAFLC58ufOS3ujtK9jD2vZwyarfLTiyyE/gXTtFpb+ktUnwvJpgNXDdaGHVOOjAdJh7jEmqtl438aXxfDoroX7BQmn+8nrY0lkSY+eUis58exHDqWWtUsSyHqaSUeKvyJvC0dnCUQEVulsCljFVRWeof+xcCpeHGrS4tfDop5Kckoadpwa0LILiun8NeQTLTt8jnPAU3auZZTb4u+vQeWYsE0DSWMsTMEoAh+pKBSfnAFZNYgIIp0jQKJJwL8ndTC/XPm0Wu3eorwFGnMgyNVZbkOA6yjtaknUqNVDb/9MOINZYi12NJSguLJg0tN04F0W4X6nCm2v5I72Uv5BLX/c0YpgKjHMCZdSzjS+EWD2a/WRtSUqSmg/ObHimOinPGhdM3JoIlXXUTXHCLkPADLYJ+b8e2sdEqhHFuGvLgXe302ZYftTqfZANMngkrd9tTM3uIoCxRCibicB/jJJ1u8YBqJQ==""
    }

    aws_instances = {

      # NOTE: Fixed IPs for IP allow listing and to avoid AD DNS updates
      # NOTE: Naming convention (for tags.Name and EC2 hostname)
      # ad           = active directory
      # azure/hmpp   = netbios domain name
      # dc           = domain controller
      # rdlic        = remote desktop licensing server
      # a/b/c suffix = availability zone

      # ad-hmpp-dc-a = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2a""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.large""
      #   key_name                  = ""ad-fixngo-ec2-live""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-a""]
      #   subnet_id                 = aws_subnet.live-data-additional[""eu-west-2a""].id
      #   vpc_security_group_name   = ""ad_hmpp_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""domain controller for FixNGo azure.hmpp.root domain""
      #   }
      # }
      # ad-hmpp-dc-b = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2b""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.large""
      #   key_name                  = ""ad-fixngo-ec2-live""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-dc-b""]
      #   subnet_id                 = aws_subnet.live-data-additional[""eu-west-2b""].id
      #   vpc_security_group_name   = ""ad_hmpp_dc_sg""
      #   tags = {
      #     server-type = ""DomainController""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""domain controller for FixNGo azure.hmpp.root domain""
      #   }
      # }
      # ad-hmpp-rdlic = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2c""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-live-role""
      #   instance_type             = ""t3.medium""
      #   key_name                  = ""ad-fixngo-ec2-live""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-hmpp-rdlic""]
      #   subnet_id                 = aws_subnet.live-data-additional[""eu-west-2c""].id
      #   vpc_security_group_name   = ""ad_hmpp_rdlic_sg""
      #   tags = {
      #     server-type = ""RDLicensing""
      #     domain-name = ""azure.hmpp.root""
      #     description = ""remote desktop licensing server for FixNGo azure.hmpp.root domain""
      #   }
      # }

      ad-azure-dc-a = {
        ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
        availability_zone         = ""eu-west-2a""
        iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
        instance_type             = ""t3.large""
        key_name                  = ""ad-fixngo-ec2-nonlive""
        private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-a""]
        subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[0]
        vpc_security_group_name   = ""ad_azure_dc_sg""
        tags = {
          server-type = ""DomainController""
          domain-name = ""azure.noms.root""
          description = ""domain controller for FixNGo azure.noms.root domain""
        }
      }
      ad-azure-dc-b = {
        ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
        availability_zone         = ""eu-west-2b""
        iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
        instance_type             = ""t3.large""
        key_name                  = ""ad-fixngo-ec2-nonlive""
        private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-dc-b""]
        subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[1]
        vpc_security_group_name   = ""ad_azure_dc_sg""
        tags = {
          server-type = ""DomainController""
          domain-name = ""azure.noms.root""
          description = ""domain controller for FixNGo azure.noms.root domain""
        }
      }
      # ad-azure-rdlic = {
      #   ami_name                  = ""hmpps_windows_server_2022_release_2024-02-02T00-00-04.569Z""
      #   availability_zone         = ""eu-west-2c""
      #   iam_instance_profile_role = ""ad-fixngo-ec2-nonlive-role""
      #   instance_type             = ""t3.medium""
      #   key_name                  = ""ad-fixngo-ec2-nonlive""
      #   private_ip                = module.ad_fixngo_ip_addresses.mp_ip[""ad-azure-rdlic""]
      #   subnet_id                 = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private[2]
      #   vpc_security_group_name   = ""ad_azure_rdlic_sg""
      #   tags = {
      #     server-type = ""RDLicensing""
      #     domain-name = ""azure.noms.root""
      #     description = ""remote desktop licensing server for FixNGo azure.noms.root domain""
      #   }
      # }
    }

    ec2_iam_roles = {
      # NOTE: roles will be granted access to relevant domain secrets in hmpps-domain-services accounts
      ad-fixngo-ec2-nonlive-role = {
        description = ""AD FixNGo EC2 instance role for SSM and accessing non-live Secrets""
        assume_role_policy = jsonencode({
          ""Version"" : ""2012-10-17"",
          ""Statement"" : [{
            ""Effect"" : ""Allow"",
            ""Principal"" : {
              ""Service"" : ""ec2.amazonaws.com""
            }
            ""Action"" : ""sts:AssumeRole"",
            ""Condition"" : {}
          }]
        })
        managed_policy_arns = [
          ""arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"",
          ""ad-fixngo-ec2-policy"",
          ""ad-fixngo-nonlive-secrets-policy"",
        ]
      }
      ad-fixngo-ec2-live-role = {
        description = ""AD FixNGo EC2 instance role for SSM and accessing live Secrets""
        assume_role_policy = jsonencode({
          ""Version"" : ""2012-10-17"",
          ""Statement"" : [{
            ""Effect"" : ""Allow"",
            ""Principal"" : {
              ""Service"" : ""ec2.amazonaws.com""
            }
            ""Action"" : ""sts:AssumeRole"",
            ""Condition"" : {}
          }]
        })
        managed_policy_arns = [
          ""arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore"",
          ""ad-fixngo-ec2-policy"",
          ""ad-fixngo-live-secrets-policy"",
        ]
      }
      ad-fixngo-ec2-access = {
        description = ""AD FixNGo role for FleetManager EC2 console access""
        assume_role_policy = jsonencode({
          ""Version"" : ""2012-10-17"",
          ""Statement"" : [{
            ""Effect"" : ""Allow"",
            ""Principal"" : {
              ""AWS"" : ""*""
            },
            ""Action"" : ""sts:AssumeRole"",
            ""Condition"" : {
              ""ForAnyValue:StringLike"" : {
                ""aws:PrincipalOrgPaths"" : [""${data.aws_organizations_organization.root_account.id}/*/${local.environment_management.modernisation_platform_organisation_unit_id}/*""]
              }
            }
          }]
        })
        managed_policy_arns = [
          ""arn:aws:iam::aws:policy/AmazonEC2ReadOnlyAccess"",
          ""arn:aws:iam::aws:policy/AmazonSSMReadOnlyAccess"",
          ""ad-fixngo-fleetmanager-access-policy"",
        ]
      }
    }
    ec2_iam_policies = {
      ad-fixngo-ec2-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles""
        path        = ""/""
        statements = [
          {
            sid    = ""BusinessUnitKmsCmk""
            effect = ""Allow""
            actions = [
              ""kms:Encrypt"",
              ""kms:Decrypt"",
              ""kms:ReEncrypt*"",
              ""kms:GenerateDataKey*"",
              ""kms:DescribeKey"",
              ""kms:CreateGrant"",
              ""kms:ListGrants"",
              ""kms:RevokeGrant""
            ]
            resources = [
              module.kms[""hmpps""].key_arns[""ebs""],
              module.kms[""hmpps""].key_arns[""general""],
            ]
          },
          {
            sid    = ""Ec2SelfProvision""
            effect = ""Allow""
            actions = [
              ""ec2:DescribeVolumes"",
              ""ec2:DescribeTags"",
              ""ec2:DescribeInstances"",
            ]
            resources = [""*""]
          },
        ]
      }
      ad-fixngo-nonlive-secrets-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles to access azure.noms.root secrets""
        path        = ""/""
        statements = [
          {
            sid    = ""HmppsDomainSecretsDevTest""
            effect = ""Allow""
            actions = [
              ""secretsmanager:GetSecretValue"",
            ]
            resources = [
              ""arn:aws:secretsmanager:*:${local.environment_management.account_ids.hmpps-domain-services-test}:secret:/microsoft/AD/*/shared-*"",
            ]
          },
        ]
      }
      ad-fixngo-live-secrets-policy = {
        description = ""Policy used by AD FixNGo EC2 instance roles to access azure.hmpp.root secrets""
        path        = ""/""
        statements = [
          {
            sid    = ""HmppsDomainSecretsProd""
            effect = ""Allow""
            actions = [
              ""secretsmanager:GetSecretValue"",
            ]
            resources = [
              ""arn:aws:secretsmanager:*:${local.environment_management.account_ids.hmpps-domain-services-production}:secret:/microsoft/AD/*/shared-*"",
            ]
          },
        ]
      }
      ad-fixngo-fleetmanager-access-policy = {
        description = ""Policy to allow FleetManager access via console""
        path        = ""/""
        statements = [
          {
            sid    = ""EC2"",
            effect = ""Allow"",
            actions = [
              ""ec2:GetPasswordData"",
            ],
            resources = [""*""]
          },
          {
            sid    = ""SSMStartSession"",
            effect = ""Allow"",
            actions = [
              ""ssm:StartSession""
            ],
            resources = [
              ""arn:aws:ec2:*:*:instance/*"",
              ""arn:aws:ssm:*:*:document/AWS-StartPortForwardingSession""
            ]
          },
          {
            sid    = ""GuiConnect"",
            effect = ""Allow"",
            actions = [
              ""ssm-guiconnect:CancelConnection"",
              ""ssm-guiconnect:GetConnection"",
              ""ssm-guiconnect:StartConnection""
            ],
            resources = [""*""]
          }
        ]
      }
    }

    route53_resolver_endpoints = {
      ad-fixngo-live-data = {
        direction           = ""OUTBOUND""
        security_group_name = ""ad_hmpp_route53_resolver_sg""
        subnet_ids          = module.vpc[""live_data""].non_tgw_subnet_ids_map.private
      }
      ad-fixngo-non-live-data = {
        direction           = ""OUTBOUND""
        security_group_name = ""ad_azure_route53_resolver_sg""
        subnet_ids          = module.vpc[""non_live_data""].non_tgw_subnet_ids_map.private
      }
    }

    route53_resolver_rules = {
      ad-fixngo-azure-noms-root = {
        domain_name            = ""azure.noms.root""
        target_ips             = module.ad_fixngo_ip_addresses.azure_fixngo_ips.devtest.domain_controllers
        resolver_endpoint_name = ""ad-fixngo-non-live-data""
        rule_type              = ""FORWARD""
        vpc_id                 = module.vpc[""non_live_data""].vpc_id
      }
      ad-fixngo-azure-hmpp-root = {
        domain_name            = ""azure.hmpp.root""
        target_ips             = module.ad_fixngo_ip_addresses.azure_fixngo_ips.prod.domain_controllers
        resolver_endpoint_name = ""ad-fixngo-live-data""
        rule_type              = ""FORWARD""
        vpc_id                 = module.vpc[""live_data""].vpc_id
      }
      # resolve infra.int hosts via HMPP DCs as they have forest trust
      ad-fixngo-infra-int = {
        domain_name            = ""infra.int""
        target_ips             = module.ad_fixngo_ip_addresses.azure_fixngo_ips.prod.domain_controllers
        resolver_endpoint_name = ""ad-fixngo-live-data""
        rule_type              = ""FORWARD""
        vpc_id                 = module.vpc[""live_data""].vpc_id
      }
    }

    security_groups = {
      ad_hmpp_route53_resolver_sg = {
        description = ""Security group for azure.hmpp.root Route53 Resolver""
        vpc_id      = module.vpc[""live_data""].vpc_id
        ingress     = {}
        egress = {
          dns-tcp = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-udp = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
      }
      ad_hmpp_dc_sg = {
        description = ""Security group for azure.hmpp.root DCs""
        vpc_id      = module.vpc[""live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          dns-udp-53 = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-tcp-53 = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-88 = {
            port        = 88
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-88 = {
            port        = 88
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ntp-udp-123 = {
            port        = 123
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-135 = {
            port        = 135
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          netbios-tcp-139 = {
            port        = 139
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-udp-389 = {
            port        = 389
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-tcp-389 = {
            port        = 389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          smb-tcp-445 = {
            port        = 445
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-464 = {
            port        = 464
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-464 = {
            port        = 464
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-636 = {
            port        = 636
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-global-catalog-tcp-3268 = {
            from_port   = 3268
            to_port     = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-3269 = {
            port        = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          adws-tcp-9389 = {
            port        = 9389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-dynamic2 = {
            from_port   = 49152
            to_port     = 65535
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_hmpp_rdlic_sg = {
        # requires RPC
        description = ""security group for azure.hmpp.root remote desktop licensing server""
        vpc_id      = module.vpc[""live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          rpc-tcp-135 = {
            port     = 135
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          netbios-tcp-139 = {
            port     = 139
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_hmpp_domain_controllers,
            ])
          }
          netbios-tcp-445 = {
            port     = 445
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_hmpp_domain_controllers,
            ])
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
          rpc-tcp-dynamic2 = {
            from_port = 49152
            to_port   = 65535
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.prod,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-preproduction,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-production,
            ])
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_azure_route53_resolver_sg = {
        description = ""Security group for azure.noms.root Route53 Resolver""
        vpc_id      = module.vpc[""non_live_data""].vpc_id
        ingress     = {}
        egress = {
          dns-tcp = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-udp = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
      }
      ad_azure_dc_sg = {
        description = ""Security group for azure.noms.root DCs""
        vpc_id      = module.vpc[""non_live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          dns-udp-53 = {
            port        = 53
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          dns-tcp-53 = {
            port        = 53
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-88 = {
            port        = 88
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-88 = {
            port        = 88
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ntp-udp-123 = {
            port        = 123
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-135 = {
            port        = 135
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          netbios-tcp-139 = {
            port        = 139
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-udp-389 = {
            port        = 389
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-tcp-389 = {
            port        = 389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          smb-tcp-445 = {
            port        = 445
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-udp-464 = {
            port        = 464
            protocol    = ""UDP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          kerberos-tcp-464 = {
            port        = 464
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-636 = {
            port        = 636
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldap-global-catalog-tcp-3268 = {
            from_port   = 3268
            to_port     = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          ldaps-tcp-3269 = {
            port        = 3269
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          adws-tcp-9389 = {
            port        = 9389
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
          rpc-tcp-dynamic2 = {
            from_port   = 49152
            to_port     = 65535
            protocol    = ""TCP""
            cidr_blocks = [""10.0.0.0/8""]
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }

      ad_azure_rdlic_sg = {
        description = ""security group for azure.noms.root remote desktop licensing server""
        vpc_id      = module.vpc[""non_live_data""].vpc_id
        ingress = {
          all-from-self = {
            port     = 0
            protocol = -1
            self     = true
          }
          rpc-tcp-135 = {
            port     = 135
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          netbios-tcp-139 = {
            port     = 139
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_azure_domain_controllers,
            ])
          }
          netbios-tcp-445 = {
            port     = 445
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest_domain_controllers,
              module.ad_fixngo_ip_addresses.mp_cidrs.ad_fixngo_azure_domain_controllers,
            ])
          }
          rdp-tcp-3389 = {
            port     = 3389
            protocol = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          winrm-tcp-5985-5986 = {
            from_port = 5985
            to_port   = 5986
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
          rpc-tcp-dynamic2 = {
            from_port = 49152
            to_port   = 65535
            protocol  = ""TCP""
            cidr_blocks = flatten([
              module.ad_fixngo_ip_addresses.azure_fixngo_cidrs.devtest,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-development,
              module.ad_fixngo_ip_addresses.mp_cidr.hmpps-test,
            ])
          }
        }
        egress = {
          all = {
            port        = 0
            protocol    = -1
            cidr_blocks = [""0.0.0.0/0""]
          }
        }
      }
    }

    ssm_parameters = {
      ""/ad-fixngo/account_ids"" = {
        description = ""Account IDs used when provisioning the AD FixNGo EC2s""
        value = jsonencode({
          for key, value in local.environment_management.account_ids :
          key => value if contains([""hmpps-domain-services-test"", ""hmpps-domain-services-production""], key)
        })
      }
    }

    tags = merge(local.tags, {
      environment-name       = terraform.workspace
      infrastructure-support = ""DSO:digital-studio-operations-team@digital.justice.gov.uk""
      source-code            = ""https://github.com/ministryofjustice/modernisation-platform""
    })
  }
}
",locals,17,28.0,4a4a151027aba403b4c260dd6716d7aadf3411a8,6fc3d7f041e9c3fe4f83d7367d41009d98b3d9a3,https://github.com/ministryofjustice/modernisation-platform/blob/4a4a151027aba403b4c260dd6716d7aadf3411a8/terraform/environments/core-shared-services/ad-fixngo.tf#L17,https://github.com/ministryofjustice/modernisation-platform/blob/6fc3d7f041e9c3fe4f83d7367d41009d98b3d9a3/terraform/environments/core-shared-services/ad-fixngo.tf#L28,2024-02-15 09:40:10+00:00,2024-05-23 11:38:09+01:00,26,0,0,0,0,0,1,0,0,0
https://github.com/ministryofjustice/cloud-platform-infrastructure,209,terraform/aws-accounts/cloud-platform-aws/vpc/eks/components/k8s-resources.tf,terraform/aws-accounts/cloud-platform-aws/vpc/eks/components/k8s-resources.tf,0,hack,# mini-hack to remove the default from GP2 because otherwise terraform tries (and fails) to create the storageclass again,# mini-hack to remove the default from GP2 because otherwise terraform tries (and fails) to create the storageclass again,"resource ""kubectl_manifest"" ""change_sc_default"" {
  depends_on = [kubernetes_storage_class.storageclass_gp3]
  yaml_body  = <<YAML
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: ""false""
  name: gp2
parameters:
  fsType: ext4
  type: gp2
provisioner: kubernetes.io/aws-ebs
volumeBindingMode: WaitForFirstConsumer
YAML
}
",resource,"resource ""kubectl_manifest"" ""change_sc_default"" {
  depends_on = [kubernetes_storage_class.storageclass_gp3]
  yaml_body  = <<YAML
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  annotations:
    storageclass.kubernetes.io/is-default-class: ""true""
  name: gp2
parameters:
  fsType: ext4
  type: gp2
provisioner: kubernetes.io/aws-ebs
volumeBindingMode: WaitForFirstConsumer
YAML
}
",resource,40,,b4d5253f8850b7989ac7a75c49d956e6d811ff79,cb1e9798c7c5f85e9febb33315ce780446998c5a,https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/b4d5253f8850b7989ac7a75c49d956e6d811ff79/terraform/aws-accounts/cloud-platform-aws/vpc/eks/components/k8s-resources.tf#L40,https://github.com/ministryofjustice/cloud-platform-infrastructure/blob/cb1e9798c7c5f85e9febb33315ce780446998c5a/terraform/aws-accounts/cloud-platform-aws/vpc/eks/components/k8s-resources.tf,2021-07-15 14:17:12+01:00,2021-07-30 12:20:35+01:00,2,1,1,1,1,0,0,0,0,0
https://github.com/Worklytics/psoxy,4,infra/modules/gcp-secret-to-cloud-function/main.tf,infra/modules/gcp-secret-to-cloud-function/main.tf,0,todo,"# todo needed bc as of Sept 2021, no way to expose secret via Cloud Function Maven plugin or","# todo needed bc as of Sept 2021, no way to expose secret via Cloud Function Maven plugin or 
 # terraform","resource ""local_file"" ""todo"" {
  filename = ""TODO - expose secret to ${var.function_name}.md""
  content  = <<EOT
expose the secret to the cloud function
```shell
  gcloud beta functions deploy ${var.function_name} \
--project ${var.project_id} \
--runtime java11 \
--update-secrets 'SERVICE_ACCOUNT_KEY=${var.secret_name}:${local.secret_version_number}'
```
EOT
}
",resource,"resource ""local_file"" ""todo"" {
  filename = ""TODO ${var.function_name} - deploy ${local.slugified_secret_name}.md""
  content  = <<EOT

gcloud functions deploy ${var.function_name} \
    --entry-point=co.worklytics.psoxy.Route \
    --runtime=java11 \
    --trigger-http \
    --source=target/deployment \
    --project=${var.project_id} \
    --service-account=${var.service_account_email} \
    --env-vars-file=config.yaml \
    --update-secrets 'SERVICE_ACCOUNT_KEY=${var.secret_name}:${local.secret_version_number}'
```
EOT
}
",resource,13,,1259c535e4d315fea708946a07b95f255b249721,cbbf5ad8ce95ac33bb704a4bcbab2eda61880dac,https://github.com/Worklytics/psoxy/blob/1259c535e4d315fea708946a07b95f255b249721/infra/modules/gcp-secret-to-cloud-function/main.tf#L13,https://github.com/Worklytics/psoxy/blob/cbbf5ad8ce95ac33bb704a4bcbab2eda61880dac/infra/modules/gcp-secret-to-cloud-function/main.tf,2021-10-06 09:58:36-07:00,2021-10-15 13:16:30-07:00,3,1,1,0,0,1,0,0,0,0
https://github.com/kubernetes/k8s.io,149,infra/gcp/clusters/projects/k8s-infra-prow-build-trusted/prow-build-trusted/main.tf,infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf,1,// todo,// TODO: consider making this a real module to reduce copy-pasta,"// TODO: consider making this a real module to reduce copy-pasta 
 // 
 // The ""workload_identity_service_account"" comment denotes a pseudo-module of 
 // copy-pasted resources, similar to ""ensure_workload_identity_serviceaccount"" 
 // in ensure-main-project.sh. 
 // 
 // It is a shorthand for making a Kubernetes Service Account bound to a GCP 
 // Service Account of the same name, and optionally assigning it IAM roles. 
 // Some of the roles are assigned in bash or other terraform modules, so as 
 // to keep the permissions necessary to run this terraform module scoped to 
 // ""roles/owner"" for local.project_id  
 // workload_identity_service_account: prow-build-trusted 
 // description: intended as default service account for pods in this cluster","resource ""google_service_account"" ""prow_build_cluster_sa"" {
  project      = local.project_id
  account_id   = local.cluster_sa_name
  display_name = ""Used by pods in '${local.cluster_name}' GKE cluster""
}
",resource,the block associated got renamed or deleted,,56,,30cb355a58992da9dc7d3ae8d3ee14bf778dde2f,e7225f5825a089b4cc3e27beb4f430306d09103d,https://github.com/kubernetes/k8s.io/blob/30cb355a58992da9dc7d3ae8d3ee14bf778dde2f/infra/gcp/clusters/projects/k8s-infra-prow-build-trusted/prow-build-trusted/main.tf#L56,https://github.com/kubernetes/k8s.io/blob/e7225f5825a089b4cc3e27beb4f430306d09103d/infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf,2021-08-03 11:51:23-07:00,2021-08-30 11:00:11-04:00,6,1,0,1,0,1,0,0,0,0
https://github.com/apache/beam,8,playground/terraform/infrastructure/artifact_registry/main.tf,playground/terraform/infrastructure/artifact_registry/main.tf,0,// todo,// TODO: remove when generally available,// TODO: remove when generally available,"resource ""google_artifact_registry_repository"" ""playground_repo"" {
  // TODO: remove when generally available
  provider = google-beta

  project       = var.project_id
  location      = var.location
  repository_id = var.id
  description   = ""Playground docker repository""
  format        = ""DOCKER""
}
",resource,"resource ""google_artifact_registry_repository"" ""playground_repo"" {
  // TODO: remove when generally available
  provider = google-beta

  project       = var.project_id
  location      = var.location
  repository_id = var.id
  description   = ""Playground docker repository""
  format        = ""DOCKER""
}
",resource,21,21.0,ad21d8353c856152346408f1d5029c9af05957c8,ad21d8353c856152346408f1d5029c9af05957c8,https://github.com/apache/beam/blob/ad21d8353c856152346408f1d5029c9af05957c8/playground/terraform/infrastructure/artifact_registry/main.tf#L21,https://github.com/apache/beam/blob/ad21d8353c856152346408f1d5029c9af05957c8/playground/terraform/infrastructure/artifact_registry/main.tf#L21,2022-03-16 14:13:22-07:00,2022-03-16 14:13:22-07:00,1,0,1,1,0,0,0,0,0,0
https://github.com/compiler-explorer/infra,158,terraform/asg.tf,terraform/asg.tf,0,// todo,// TODO: reduce this,"// Worst case it takes ~8m to get through all the compilers at startup. 
 // See https://github.com/compiler-explorer/compiler-explorer/issues/2977 
 // TODO: reduce this","locals {
  subnets      = local.all_subnet_ids
  // Worst case it takes ~8m to get through all the compilers at startup.
  // See https://github.com/compiler-explorer/compiler-explorer/issues/2977
  // TODO: reduce this
  grace_period = 600
  cooldown     = 180
}
",locals,"locals {
  subnets      = local.all_subnet_ids
  // A startup I measured on Oct 31st 2021 took 3m to become ready.
  grace_period = 220
  cooldown     = 180
}
",locals,5,,b2137e7929197380d05c2011ad5d6ef0e53e679d,2caa355db18b9008a4218966836b353bbc97e671,https://github.com/compiler-explorer/infra/blob/b2137e7929197380d05c2011ad5d6ef0e53e679d/terraform/asg.tf#L5,https://github.com/compiler-explorer/infra/blob/2caa355db18b9008a4218966836b353bbc97e671/terraform/asg.tf,2021-09-30 22:56:19-05:00,2021-10-31 15:41:01-05:00,2,1,0,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,974,fast/stages/01-resman/outputs.tf,fast/stages/01-resman/outputs.tf,0,# todo,# TODO(jccb): add gke here,# TODO(jccb): add gke here,"locals {
  _tpl_providers = ""${path.module}/templates/providers.tf.tpl""
  cicd_workflow_attrs = {
    data_platform_dev = {
      service_account   = try(module.branch-dp-dev-sa-cicd.0.email, null)
      tf_providers_file = ""03-data-platform-dev-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    data_platform_prod = {
      service_account   = try(module.branch-dp-prod-sa-cicd.0.email, null)
      tf_providers_file = ""03-data-platform-prod-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    # TODO(jccb): add gke here
    networking = {
      service_account   = try(module.branch-network-sa-cicd.0.email, null)
      tf_providers_file = ""02-networking-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_2
    }
    project_factory_dev = {
      service_account   = try(module.branch-pf-dev-sa-cicd.0.email, null)
      tf_providers_file = ""03-project-factory-dev-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    project_factory_prod = {
      service_account   = try(module.branch-pf-prod-sa-cicd.0.email, null)
      tf_providers_file = ""03-project-factory-prod-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    security = {
      service_account   = try(module.branch-security-sa-cicd.0.email, null)
      tf_providers_file = ""02-security-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_2
    }
  }
  cicd_workflows = {
    for k, v in local.cicd_repositories : k => templatefile(
      ""${path.module}/templates/workflow-${v.type}.yaml"",
      merge(local.cicd_workflow_attrs[k], {
        identity_provider = try(
          local.identity_providers[v.identity_provider].name, null
        )
        outputs_bucket = var.automation.outputs_bucket
        stage_name     = k
      })
    )
  }
  folder_ids = merge(
    {
      data-platform-dev  = try(module.branch-dp-dev-folder.0.id, null)
      data-platform-prod = try(module.branch-dp-prod-folder.0.id, null)
      gke-dev            = try(module.branch-gke-dev-folder.0.id, null)
      gke-prod           = try(module.branch-gke-prod-folder.0.id, null)
      networking         = module.branch-network-folder.id
      networking-dev     = module.branch-network-dev-folder.id
      networking-prod    = module.branch-network-prod-folder.id
      sandbox            = try(module.branch-sandbox-folder.0.id, null)
      security           = module.branch-security-folder.id
      teams              = try(module.branch-teams-folder.0.id, null)
    },
    {
      for k, v in module.branch-teams-team-folder :
      ""team-${k}"" => v.id
    },
    {
      for k, v in module.branch-teams-team-dev-folder :
      ""team-${k}-dev"" => v.id
    },
    {
      for k, v in module.branch-teams-team-prod-folder :
      ""team-${k}-prod"" => v.id
    }
  )
  providers = merge(
    {
      ""02-networking"" = templatefile(local._tpl_providers, {
        bucket = module.branch-network-gcs.name
        name   = ""networking""
        sa     = module.branch-network-sa.email
      })
      ""02-security"" = templatefile(local._tpl_providers, {
        bucket = module.branch-security-gcs.name
        name   = ""security""
        sa     = module.branch-security-sa.email
      })
    },
    !var.fast_features.data_platform ? {} : {
      ""03-data-platform-dev"" = templatefile(local._tpl_providers, {
        bucket = module.branch-dp-dev-gcs.0.name
        name   = ""dp-dev""
        sa     = module.branch-dp-dev-sa.0.email
      })
      ""03-data-platform-prod"" = templatefile(local._tpl_providers, {
        bucket = module.branch-dp-prod-gcs.0.name
        name   = ""dp-prod""
        sa     = module.branch-dp-prod-sa.0.email
      })
    },
    !var.fast_features.gke ? {} : {
      ""03-gke-dev"" = templatefile(local._tpl_providers, {
        bucket = module.branch-gke-dev-gcs.0.name
        name   = ""gke-dev""
        sa     = module.branch-gke-dev-sa.0.email
      })
      ""03-gke-prod"" = templatefile(local._tpl_providers, {
        bucket = module.branch-gke-prod-gcs.0.name
        name   = ""gke-prod""
        sa     = module.branch-gke-prod-sa.0.email
      })
    },
    !var.fast_features.project_factory ? {} : {
      ""03-project-factory-dev"" = templatefile(local._tpl_providers, {
        bucket = module.branch-pf-dev-gcs.0.name
        name   = ""team-dev""
        sa     = module.branch-pf-dev-sa.0.email
      })
      ""03-project-factory-prod"" = templatefile(local._tpl_providers, {
        bucket = module.branch-pf-prod-gcs.0.name
        name   = ""team-prod""
        sa     = module.branch-pf-prod-sa.0.email
      })
    },
    !var.fast_features.sandbox ? {} : {
      ""99-sandbox"" = templatefile(local._tpl_providers, {
        bucket = module.branch-sandbox-gcs.0.name
        name   = ""sandbox""
        sa     = module.branch-sandbox-sa.0.email
      })
    }
  )
  service_accounts = merge(
    {
      data-platform-dev    = try(module.branch-dp-dev-sa.0.email, null)
      data-platform-prod   = try(module.branch-dp-prod-sa.0.email, null)
      gke-dev              = try(module.branch-gke-dev-sa.0.email, null)
      gke-prod             = try(module.branch-gke-prod-sa.0.email, null)
      networking           = module.branch-network-sa.email
      project-factory-dev  = try(module.branch-pf-dev-sa.0.email, null)
      project-factory-prod = try(module.branch-pf-prod-sa.0.email, null)
      sandbox              = try(module.branch-sandbox-sa.0.email, null)
      security             = module.branch-security-sa.email
      teams                = try(module.branch-teams-prod-sa.0.email, null)
    },
    {
      for k, v in module.branch-teams-team-sa : ""team-${k}"" => v.email
    },
  )
  tfvars = {
    folder_ids       = local.folder_ids
    service_accounts = local.service_accounts
    tag_names        = var.tag_names
  }
}
",locals,"locals {
  _tpl_providers = ""${path.module}/templates/providers.tf.tpl""
  cicd_workflow_attrs = {
    data_platform_dev = {
      service_account   = try(module.branch-dp-dev-sa-cicd.0.email, null)
      tf_providers_file = ""03-data-platform-dev-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    data_platform_prod = {
      service_account   = try(module.branch-dp-prod-sa-cicd.0.email, null)
      tf_providers_file = ""03-data-platform-prod-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    networking = {
      service_account   = try(module.branch-network-sa-cicd.0.email, null)
      tf_providers_file = ""02-networking-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_2
    }
    project_factory_dev = {
      service_account   = try(module.branch-pf-dev-sa-cicd.0.email, null)
      tf_providers_file = ""03-project-factory-dev-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    project_factory_prod = {
      service_account   = try(module.branch-pf-prod-sa-cicd.0.email, null)
      tf_providers_file = ""03-project-factory-prod-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_3
    }
    security = {
      service_account   = try(module.branch-security-sa-cicd.0.email, null)
      tf_providers_file = ""02-security-providers.tf""
      tf_var_files      = local.cicd_workflow_var_files.stage_2
    }
  }
  cicd_workflows = {
    for k, v in local.cicd_repositories : k => templatefile(
      ""${path.module}/templates/workflow-${v.type}.yaml"",
      merge(local.cicd_workflow_attrs[k], {
        identity_provider = try(
          local.identity_providers[v.identity_provider].name, null
        )
        outputs_bucket = var.automation.outputs_bucket
        stage_name     = k
      })
    )
  }
  folder_ids = merge(
    {
      data-platform-dev  = try(module.branch-dp-dev-folder.0.id, null)
      data-platform-prod = try(module.branch-dp-prod-folder.0.id, null)
      networking         = module.branch-network-folder.id
      networking-dev     = module.branch-network-dev-folder.id
      networking-prod    = module.branch-network-prod-folder.id
      sandbox            = try(module.branch-sandbox-folder.0.id, null)
      security           = module.branch-security-folder.id
      teams              = try(module.branch-teams-folder.0.id, null)
    },
    {
      for k, v in module.branch-teams-team-folder :
      ""team-${k}"" => v.id
    },
    {
      for k, v in module.branch-teams-team-dev-folder :
      ""team-${k}-dev"" => v.id
    },
    {
      for k, v in module.branch-teams-team-prod-folder :
      ""team-${k}-prod"" => v.id
    }
  )
  providers = merge(
    {
      ""02-networking"" = templatefile(local._tpl_providers, {
        bucket = module.branch-network-gcs.name
        name   = ""networking""
        sa     = module.branch-network-sa.email
      })
      ""02-security"" = templatefile(local._tpl_providers, {
        bucket = module.branch-security-gcs.name
        name   = ""security""
        sa     = module.branch-security-sa.email
      })
    },
    !var.fast_features.data_platform ? {} : {
      ""03-data-platform-dev"" = templatefile(local._tpl_providers, {
        bucket = module.branch-dp-dev-gcs.0.name
        name   = ""dp-dev""
        sa     = module.branch-dp-dev-sa.0.email
      })
      ""03-data-platform-prod"" = templatefile(local._tpl_providers, {
        bucket = module.branch-dp-prod-gcs.0.name
        name   = ""dp-prod""
        sa     = module.branch-dp-prod-sa.0.email
      })
    },
    !var.fast_features.project_factory ? {} : {
      ""03-project-factory-dev"" = templatefile(local._tpl_providers, {
        bucket = module.branch-pf-dev-gcs.0.name
        name   = ""team-dev""
        sa     = module.branch-pf-dev-sa.0.email
      })
      ""03-project-factory-prod"" = templatefile(local._tpl_providers, {
        bucket = module.branch-pf-prod-gcs.0.name
        name   = ""team-prod""
        sa     = module.branch-pf-prod-sa.0.email
      })
    },
    !var.fast_features.sandbox ? {} : {
      ""99-sandbox"" = templatefile(local._tpl_providers, {
        bucket = module.branch-sandbox-gcs.0.name
        name   = ""sandbox""
        sa     = module.branch-sandbox-sa.0.email
      })
    },
    !var.fast_features.teams ? {} : merge(
      {
        ""03-teams"" = templatefile(local._tpl_providers, {
          bucket = module.branch-teams-gcs.0.name
          name   = ""teams""
          sa     = module.branch-teams-sa.0.email
        })
      },
      {
        for k, v in module.branch-teams-team-sa :
        ""03-teams-${k}"" => templatefile(local._tpl_providers, {
          bucket = module.branch-teams-team-gcs[k].name
          name   = ""teams""
          sa     = v.email
        })
      }
    )
  )
  service_accounts = merge(
    {
      data-platform-dev    = try(module.branch-dp-dev-sa.0.email, null)
      data-platform-prod   = try(module.branch-dp-prod-sa.0.email, null)
      networking           = module.branch-network-sa.email
      project-factory-dev  = try(module.branch-pf-dev-sa.0.email, null)
      project-factory-prod = try(module.branch-pf-prod-sa.0.email, null)
      sandbox              = try(module.branch-sandbox-sa.0.email, null)
      security             = module.branch-security-sa.email
      teams                = try(module.branch-teams-sa.0.email, null)
    },
    {
      for k, v in module.branch-teams-team-sa : ""team-${k}"" => v.email
    },
  )
  tfvars = {
    folder_ids       = local.folder_ids
    service_accounts = local.service_accounts
    tag_names        = var.tag_names
  }
}
",locals,30,,e7bc11e6b9160e51358d897bbce171ef4e98f253,bfefaf627e6ac699851ce6255c6f16c8923e3ca0,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/e7bc11e6b9160e51358d897bbce171ef4e98f253/fast/stages/01-resman/outputs.tf#L30,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/bfefaf627e6ac699851ce6255c6f16c8923e3ca0/fast/stages/01-resman/outputs.tf,2022-07-12 12:10:39+02:00,2022-08-03 16:34:09+02:00,2,1,1,1,0,0,0,0,0,0
https://github.com/camptocamp/devops-stack,173,examples/sks/main.tf,examples/sks/main.tf,0,todo,# TODO Create an external database as PoC,# TODO Create an external database as PoC,"module ""keycloak"" {
  source = ""git::https://github.com/camptocamp/devops-stack-module-keycloak?ref=v2.0.1""

  cluster_name     = module.sks.cluster_name
  base_domain      = module.sks.base_domain
  cluster_issuer   = local.cluster_issuer
  argocd_namespace = module.argocd_bootstrap.argocd_namespace

  app_autosync = local.app_autosync

  dependency_ids = {
    argocd       = module.argocd_bootstrap.id
    traefik      = module.traefik.id
    cert-manager = module.cert-manager.id
  }
}
",module,"module ""keycloak"" {
  source = ""git::https://github.com/camptocamp/devops-stack-module-keycloak.git?ref=v3.1.1""

  cluster_name   = module.sks.cluster_name
  base_domain    = module.sks.base_domain
  subdomain      = local.subdomain
  cluster_issuer = local.cluster_issuer
  argocd_project = module.sks.cluster_name

  app_autosync = local.app_autosync

  dependency_ids = {
    argocd       = module.argocd_bootstrap.id
    traefik      = module.traefik.id
    cert-manager = module.cert-manager.id
  }
}
",module,59,67.0,5d660c5717536a4d579ec105b22843f55fd1567a,2632a7f360da457a904270f71617e0850ecd23f4,https://github.com/camptocamp/devops-stack/blob/5d660c5717536a4d579ec105b22843f55fd1567a/examples/sks/main.tf#L59,https://github.com/camptocamp/devops-stack/blob/2632a7f360da457a904270f71617e0850ecd23f4/examples/sks/main.tf#L67,2023-08-18 14:48:32+02:00,2024-04-24 09:03:27+02:00,26,0,1,1,0,1,0,0,0,0
https://github.com/Azure/sap-automation,2,deploy/terraform/bootstrap/sap_library/module.tf,deploy/terraform/bootstrap/sap_library/module.tf,0,fix,# commenting out for fixing issues,"# commenting out for fixing issues 
 #  providers = { 
 #    azurerm.main     = azurerm 
 #    azurerm.deployer = azurerm.deployer 
 #  }","module ""sap_library"" {
  source = ""../../terraform-units/modules/sap_library""
  # commenting out for fixing issues
  #  providers = {
  #    azurerm.main     = azurerm
  #    azurerm.deployer = azurerm.deployer
  #  }
  infrastructure          = local.infrastructure
  storage_account_sapbits = local.storage_account_sapbits
  storage_account_tfstate = local.storage_account_tfstate
  software                = var.software
  deployer                = local.deployer
  key_vault               = local.key_vault
  service_principal       = var.use_deployer ? local.service_principal : local.account
  deployer_tfstate        = try(data.terraform_remote_state.deployer[0].outputs, [])
  naming                  = module.sap_namegenerator.naming
  dns_label               = var.dns_label
  use_private_endpoint    = var.use_private_endpoint
}
",module,"module ""sap_library"" {
  source = ""../../terraform-units/modules/sap_library""
   providers = {
     azurerm.main     = azurerm
     azurerm.deployer = azurerm.deployer
   }
  infrastructure          = local.infrastructure
  storage_account_sapbits = local.storage_account_sapbits
  storage_account_tfstate = local.storage_account_tfstate
  software                = var.software
  deployer                = local.deployer
  key_vault               = local.key_vault
  service_principal       = var.use_deployer ? local.service_principal : local.account
  deployer_tfstate        = try(data.terraform_remote_state.deployer[0].outputs, [])
  naming                  = length(var.name_override_file) > 0 ? local.custom_names : module.sap_namegenerator.naming
  dns_label               = var.dns_label
  use_private_endpoint    = var.use_private_endpoint
}
",module,7,,6ff0b891114c36d3aeccb850d830b698cd1fe52a,21eea3fa8fc368e0456ea18538764e8e600200b0,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/bootstrap/sap_library/module.tf#L7,https://github.com/Azure/sap-automation/blob/21eea3fa8fc368e0456ea18538764e8e600200b0/deploy/terraform/bootstrap/sap_library/module.tf,2021-11-17 19:29:07+02:00,2022-04-19 09:55:53+03:00,2,1,0,1,1,0,0,0,0,0
https://github.com/ministryofjustice/modernisation-platform,7,terraform/github/locals.tf,terraform/github/locals.tf,0,get rid of this,# Hopefully we can get rid of this if this issue is resolved - https://github.com/ministryofjustice/operations-engineering/issues/139,"# Modernisation platform application teams (need to give access to environments repo as needed for github environments) 
 # Hopefully we can get rid of this if this issue is resolved - https://github.com/ministryofjustice/operations-engineering/issues/139 
 # But if not we will need to automate the updating of this list based on slugs in the environment json files.","locals {
  # GitHub usernames for the Modernisation Platform team maintainers
  # NB: Terraform shows a perputal difference in roles if someone is an organisation owner
  # and will attempt to change them from `maintainer` to `member`, so owners should go in here.
  maintainers = [
    ""ewastempel"",
    ""jakemulley"",
    ""philhorrocks"",
    ""SteveMarshall""
  ]

  # GitHub usernames for CI users
  ci_users = [
    ""modernisation-platform-ci""
  ]

  # All GitHub team maintainers
  all_maintainers = concat(local.maintainers, local.ci_users)

  # GitHub usernames for team members who don't need full AWS access
  general_members = [
    ""ewastempel"",
    ""kcbotsh"",
    ""nishamoj"",
    ""seanprivett"",
    ""SimonPPledger"",
    ""SteveMarshall"",
    ""christine-elliott"",
  ]

  # GitHub usernames for engineers who need full AWS access
  engineers = [
    ""davidkelliott"",
    ""donmasters"",
    ""ezman"", # Fasih
    ""jackstockley89"",
    ""jakemulley"",
    ""philhorrocks"",
    ""zuriguardiola"",
    ""stevelinden""
  ]

  # All members
  all_members = concat(local.general_members, local.engineers)

  # Everyone
  everyone = concat(local.all_maintainers, local.all_members)

  # Modernisation platform application teams (need to give access to environments repo as needed for github environments)
  # Hopefully we can get rid of this if this issue is resolved - https://github.com/ministryofjustice/operations-engineering/issues/139
  # But if not we will need to automate the updating of this list based on slugs in the environment json files.
  application_teams = [
    ""all-org-members"",
    ""operations-engineering"",
    ""performance-hub-developers""
  ]
}
",locals,"locals {
  environment_management = jsondecode(data.aws_secretsmanager_secret_version.environment_management.secret_string)

  # GitHub usernames for the Modernisation Platform team maintainers
  # NB: Terraform shows a perputal difference in roles if someone is an organisation owner
  # and will attempt to change them from `maintainer` to `member`, so owners should go in here.
  maintainers = [
    ""ewastempel"",
    ""jakemulley"",
    ""SteveMarshall"",
    ""davidkelliott""
  ]

  # GitHub usernames for CI users
  ci_users = [
    ""modernisation-platform-ci""
  ]

  # All GitHub team maintainers
  all_maintainers = concat(local.maintainers, local.ci_users)

  # GitHub usernames for team members who don't need full AWS access
  general_members = [
    ""kcbotsh"",
    ""seanprivett"",
    ""SteveMarshall"",
    ""ScottSeaward""
  ]

  # GitHub usernames for engineers who need full AWS access
  engineers = [
    ""davidkelliott"",
    ""jakemulley"",
    ""stevelinden"",
    ""markgov"",
    ""dms1981"", # David Sibley
    ""ep-93"",   # Edward Proctor
    ""julialawrence"",
    ""ewastempel""
  ]

  # All members
  all_members = concat(local.general_members, local.engineers)

  # Everyone
  everyone = concat(local.all_maintainers, local.all_members)

  environments_json = [
    for file in fileset(""../../environments/"", ""*.json"") : merge({
      name = replace(file, "".json"", """")
    }, jsondecode(file(""../../environments/${file}"")))
  ]

  application_github_slugs = concat(
    [""all-org-members""],
    distinct(flatten([
      for application in local.environments_json : [
        for environment in application.environments : [
          for access in environment.access :
          access.github_slug
          if application.account-type == ""member"" && !contains([""modernisation-platform"", ""modernisation-platform-engineers""], access.github_slug)
        ]
      ]
    ]))
  )

  # Create a list of repositories that we want our customers to be able to contribute to
  modernisation_platform_repositories = [
    for s in data.github_repositories.modernisation-platform-repositories.names : s if startswith(s, ""modernisation-platform-"")
  ]
}
",locals,50,,b8f0805c02104b615aba54601bef993f9c069e52,8ba8e0b97b75be96f43ff9ea8ca61dc7cb60ec7d,https://github.com/ministryofjustice/modernisation-platform/blob/b8f0805c02104b615aba54601bef993f9c069e52/terraform/github/locals.tf#L50,https://github.com/ministryofjustice/modernisation-platform/blob/8ba8e0b97b75be96f43ff9ea8ca61dc7cb60ec7d/terraform/github/locals.tf,2021-06-14 12:50:27+01:00,2022-12-14 21:42:26+00:00,55,1,0,1,1,1,0,0,0,0
https://github.com/returntocorp/semgrep-rules,1,terraform/aws/best-practice/aws-s3-bucket-versioning-not-enabled.tf,terraform/aws/best-practice/aws-s3-bucket-versioning-not-enabled.tf,0,# todo,# todoruleid: aws-s3-bucket-versioning-not-enabled,# todoruleid: aws-s3-bucket-versioning-not-enabled,"resource ""aws_s3_bucket"" ""this"" {
  bucket = var.bucket
  acl    = ""private""
  versioning {
    enabled = var.enabled
  }
}
",resource,"resource ""aws_s3_bucket"" ""this"" {
  bucket = var.bucket
  acl    = ""private""
  versioning {
    enabled = var.enabled
  }
}
",resource,97,97.0,eefcc40d66ea97ca14eb496031ad9a84388214e2,eefcc40d66ea97ca14eb496031ad9a84388214e2,https://github.com/returntocorp/semgrep-rules/blob/eefcc40d66ea97ca14eb496031ad9a84388214e2/terraform/aws/best-practice/aws-s3-bucket-versioning-not-enabled.tf#L97,https://github.com/returntocorp/semgrep-rules/blob/eefcc40d66ea97ca14eb496031ad9a84388214e2/terraform/aws/best-practice/aws-s3-bucket-versioning-not-enabled.tf#L97,2022-02-02 16:53:31-06:00,2022-02-02 16:53:31-06:00,1,0,1,0,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,326,node_groups.tf,node_groups.tf,0,todo,# TODO - hopefully AWS releases a managed policy which can replace this,"################################################################################ 
 # EKS IPV6 CNI Policy 
 # TODO - hopefully AWS releases a managed policy which can replace this 
 # https://docs.aws.amazon.com/eks/latest/userguide/cni-iam-role.html#cni-iam-role-create-ipv6-policy 
 ################################################################################ ","data ""aws_iam_policy_document"" ""cni_ipv6_policy"" {
  count = var.create && var.create_cni_ipv6_iam_policy ? 1 : 0

  statement {
    sid = ""AssignDescribe""
    actions = [
      ""ec2:AssignIpv6Addresses"",
      ""ec2:DescribeInstances"",
      ""ec2:DescribeTags"",
      ""ec2:DescribeNetworkInterfaces"",
      ""ec2:DescribeInstanceTypes""
    ]
    resources = [""*""]
  }

  statement {
    sid       = ""CreateTags""
    actions   = [""ec2:CreateTags""]
    resources = [""arn:aws:ec2:*:*:network-interface/*""]
  }
}
",data,"data ""aws_iam_policy_document"" ""cni_ipv6_policy"" {
  count = var.create && var.create_cni_ipv6_iam_policy ? 1 : 0

  statement {
    sid = ""AssignDescribe""
    actions = [
      ""ec2:AssignIpv6Addresses"",
      ""ec2:DescribeInstances"",
      ""ec2:DescribeTags"",
      ""ec2:DescribeNetworkInterfaces"",
      ""ec2:DescribeInstanceTypes""
    ]
    resources = [""*""]
  }

  statement {
    sid       = ""CreateTags""
    actions   = [""ec2:CreateTags""]
    resources = [""arn:${local.partition}:ec2:*:*:network-interface/*""]
  }
}
",data,11,,314192e2ebc5faaf5f027a7d868cd36c4844aee1,6b40bdbb1d283d9259f43b03d24dca99cc1eceff,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/314192e2ebc5faaf5f027a7d868cd36c4844aee1/node_groups.tf#L11,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/6b40bdbb1d283d9259f43b03d24dca99cc1eceff/node_groups.tf,2022-01-14 21:17:03+01:00,2024-02-02 09:36:25-05:00,32,1,0,0,1,1,1,0,0,0
https://github.com/aws-ia/terraform-aws-eks-blueprints,175,modules/kubernetes-addons/ingress-nginx/locals.tf,modules/kubernetes-addons/ingress-nginx/locals.tf,0,# todo,"# todo: Create policies, add names here","irsa_iam_policies                 = [] # todo: Create policies, add names here","locals {
  name                 = ""ingress-nginx""
  service_account_name = ""${local.name}-sa""
  default_helm_config = {
    name                       = local.name
    chart                      = local.name
    repository                 = ""https://kubernetes.github.io/ingress-nginx""
    version                    = ""4.0.6""
    namespace                  = ""kube-system""
    timeout                    = ""1200""
    create_namespace           = false
    values                     = local.default_helm_values
    set                        = []
    set_sensitive              = null
    lint                       = false
    verify                     = false
    keyring                    = """"
    repository_key_file        = """"
    repository_cert_file       = """"
    repository_ca_file         = """"
    repository_username        = """"
    repository_password        = """"
    disable_webhooks           = false
    reuse_values               = false
    reset_values               = false
    force_update               = false
    recreate_pods              = false
    cleanup_on_fail            = false
    max_history                = 0
    atomic                     = false
    skip_crds                  = false
    render_subchart_notes      = true
    disable_openapi_validation = false
    wait                       = true
    wait_for_jobs              = false
    dependency_update          = false
    replace                    = false
    description                = ""The NGINX HelmChart Ingress Controller deployment configuration""
    postrender                 = """"
  }

  default_helm_values = [templatefile(""${path.module}/values.yaml"", { sa-name = local.service_account_name })]

  helm_config = merge(
    local.default_helm_config,
    var.helm_config
  )

  set_values = [
    {
      name  = ""serviceAccount.name""
      value = local.service_account_name
    },
    {
      name  = ""serviceAccount.create""
      value = false
    }
  ]

  irsa_config = {
    kubernetes_namespace              = ""kube-system""
    kubernetes_service_account        = local.service_account_name
    create_kubernetes_namespace       = false
    create_kubernetes_service_account = true
    iam_role_path                     = ""/""
    eks_cluster_id                    = var.eks_cluster_id
    irsa_iam_policies                 = [] # todo: Create policies, add names here
    tags                              = var.tags
  }

  argocd_gitops_config = {
    enable             = true
    serviceAccountName = local.service_account_name
  }
}
",locals,"locals {
  name                 = ""ingress-nginx""
  service_account_name = ""${local.name}-sa""
  default_helm_config = {
    name                       = local.name
    chart                      = local.name
    repository                 = ""https://kubernetes.github.io/ingress-nginx""
    version                    = ""4.0.6""
    namespace                  = ""kube-system""
    timeout                    = ""1200""
    create_namespace           = false
    values                     = local.default_helm_values
    set                        = []
    set_sensitive              = null
    lint                       = false
    verify                     = false
    keyring                    = """"
    repository_key_file        = """"
    repository_cert_file       = """"
    repository_ca_file         = """"
    repository_username        = """"
    repository_password        = """"
    disable_webhooks           = false
    reuse_values               = false
    reset_values               = false
    force_update               = false
    recreate_pods              = false
    cleanup_on_fail            = false
    max_history                = 0
    atomic                     = false
    skip_crds                  = false
    render_subchart_notes      = true
    disable_openapi_validation = false
    wait                       = true
    wait_for_jobs              = false
    dependency_update          = false
    replace                    = false
    description                = ""The NGINX HelmChart Ingress Controller deployment configuration""
    postrender                 = """"
  }

  default_helm_values = [templatefile(""${path.module}/values.yaml"", { sa-name = local.service_account_name })]

  helm_config = merge(
    local.default_helm_config,
    var.helm_config
  )

  set_values = [
    {
      name  = ""serviceAccount.name""
      value = local.service_account_name
    },
    {
      name  = ""serviceAccount.create""
      value = false
    }
  ]

  irsa_config = {
    kubernetes_namespace              = ""kube-system""
    kubernetes_service_account        = local.service_account_name
    create_kubernetes_namespace       = false
    create_kubernetes_service_account = true
    iam_role_path                     = ""/""
    eks_cluster_id                    = var.eks_cluster_id
    irsa_iam_policies                 = [aws_iam_policy.this.arn]
    tags                              = var.tags
  }

  argocd_gitops_config = {
    enable             = true
    serviceAccountName = local.service_account_name
  }
}
",locals,68,,474e9a84867085167c0bac9883bbf18c1c65eeee,59cb42bf58d2e3974001b4b7f3d8d76129e178fa,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/474e9a84867085167c0bac9883bbf18c1c65eeee/modules/kubernetes-addons/ingress-nginx/locals.tf#L68,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/59cb42bf58d2e3974001b4b7f3d8d76129e178fa/modules/kubernetes-addons/ingress-nginx/locals.tf,2022-02-02 16:33:01-05:00,2022-02-08 17:00:03-05:00,2,1,1,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,805,fast/stages/00-bootstrap/variables.tf,fast/stages/00-bootstrap/variables.tf,0,# todo,# TODO: edit description once we add support for Cloud Build (null provider),# TODO: edit description once we add support for Cloud Build (null provider),"variable ""cicd_repositories"" {
  # TODO: edit description once we add support for Cloud Build (null provider)
  description = ""CI/CD repository configuration. Identity providers reference keys in the `federated_identity_providers` variable. Set to null to disable, or set individual repositories to null if not needed.""
  type = object({
    bootstrap = object({
      branch            = string
      identity_provider = string
      name              = string
      type              = string
    })
    resman = object({
      branch            = string
      identity_provider = string
      name              = string
      type              = string
    })
  })
  default = null
  validation {
    condition = alltrue([
      for k, v in coalesce(var.cicd_repositories, {}) :
      v == null || (
        try(v.name, null) != null
        &&
        try(v.identity_provider, null) != null
      )
    ])
    error_message = ""Non-null repositories need non-null name and providers.""
  }
  validation {
    condition = alltrue([
      for k, v in coalesce(var.cicd_repositories, {}) :
      v == null || (
        contains([""github""], coalesce(try(v.type, null), ""null""))
      )
    ])
    error_message = ""Invalid repository type, supported types: 'github'.""
  }
}
",variable,"variable ""cicd_repositories"" {
  description = ""CI/CD repository configuration. Identity providers reference keys in the `federated_identity_providers` variable. Set to null to disable, or set individual repositories to null if not needed.""
  type = object({
    bootstrap = object({
      branch            = string
      identity_provider = string
      name              = string
      type              = string
    })
    resman = object({
      branch            = string
      identity_provider = string
      name              = string
      type              = string
    })
  })
  default = null
  validation {
    condition = alltrue([
      for k, v in coalesce(var.cicd_repositories, {}) :
      v == null || try(v.name, null) != null
    ])
    error_message = ""Non-null repositories need a non-null name.""
  }
  validation {
    condition = alltrue([
      for k, v in coalesce(var.cicd_repositories, {}) :
      v == null || (
        try(v.identity_provider, null) != null
        ||
        try(v.type, null) == ""sourcerepo""
      )
    ])
    error_message = ""Non-null repositories need a non-null provider unless type is 'sourcerepo'.""
  }
  validation {
    condition = alltrue([
      for k, v in coalesce(var.cicd_repositories, {}) :
      v == null || (
        contains([""github"", ""gitlab"", ""sourcerepo""], coalesce(try(v.type, null), ""null""))
      )
    ])
    error_message = ""Invalid repository type, supported types: 'github' 'gitlab' or 'sourcerepo'.""
  }
}
",variable,32,,725f7effce7bdb69522b8ad004b78cda31dcb7ce,44ae2671b0d1e8bbf8aca6ca815c68b56080a8cb,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/725f7effce7bdb69522b8ad004b78cda31dcb7ce/fast/stages/00-bootstrap/variables.tf#L32,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/44ae2671b0d1e8bbf8aca6ca815c68b56080a8cb/fast/stages/00-bootstrap/variables.tf,2022-04-12 08:17:27+02:00,2022-06-08 11:34:08+02:00,5,1,0,1,0,0,0,1,0,0
https://github.com/compiler-explorer/infra,220,terraform/cloudfront.tf,terraform/cloudfront.tf,0,todo,# TODO all these?,"  scope = ""REGIONAL"" # TODO all these?","resource ""aws_wafv2_web_acl"" ""banned-ips"" {
  name  = ""deny-banned-ips""
  scope = ""REGIONAL"" # TODO all these?
  default_action {
    allow {}
  }

  rule {
    name     = ""deny-ipv4""
    priority = 0
    action {
      block {}
    }
    statement {
      ip_set_reference_statement {
        arn = aws_wafv2_ip_set.banned-ipv4.arn
        ip_set_forwarded_ip_config {
          fallback_behavior = ""MATCH""
          header_name       = ""X-Forwarded-For""
          position          = ""ANY""
        }
      }
    }
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""deny-ipv4""
      sampled_requests_enabled   = true
    }
  }
  rule {
    name     = ""deny-ipv6""
    priority = 1
    action {
      block {}
    }
    statement {
      ip_set_reference_statement {
        arn = aws_wafv2_ip_set.banned-ipv6.arn
        ip_set_forwarded_ip_config {
          fallback_behavior = ""MATCH""
          header_name       = ""X-Forwarded-For""
          position          = ""ANY""
        }
      }
    }
    visibility_config {
      cloudwatch_metrics_enabled = true
      metric_name                = ""deny-ipv6""
      sampled_requests_enabled   = true
    }
  }
  visibility_config {
    cloudwatch_metrics_enabled = true
    metric_name                = ""deny-banned-ips"" # todo change
    sampled_requests_enabled   = true
  }
}
",resource,the block associated got renamed or deleted,,566,,bae9867971b4d1a63f896071dd267f6a8bbe9637,5984967d8fe56d0296be70c38a7c15dd8e16615d,https://github.com/compiler-explorer/infra/blob/bae9867971b4d1a63f896071dd267f6a8bbe9637/terraform/cloudfront.tf#L566,https://github.com/compiler-explorer/infra/blob/5984967d8fe56d0296be70c38a7c15dd8e16615d/terraform/cloudfront.tf,2022-10-06 18:18:22-05:00,2022-10-06 19:03:41-05:00,2,1,0,1,0,0,0,0,0,0
https://github.com/nasa/cumulus,51,tf-modules/ingest/iam.tf,tf-modules/ingest/iam.tf,0,todo,# TODO Where is this being created?,# TODO Where is this being created?,"data ""aws_iam_policy_document"" ""step_policy"" {
  statement {
    actions = [
      ""lambda:InvokeFunction"",
      ""ecr:*"",
      ""cloudtrail:LookupEvents"",
      ""ecs:RunTask"",
      ""ecs:StopTask"",
      ""ecs:DescribeTasks"",
      ""autoscaling:Describe*"",
      ""cloudwatch:*"",
      ""logs:*"",
      ""sns:*"",
      ""iam:GetPolicy"",
      ""iam:GetPolicyVersion"",
      ""iam:GetRole"",
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""events:DescribeRule"",
      ""events:PutRule"",
      ""events:PutTargets""
    ]
    # TODO Where is this being created?
    resources = [""arn:aws:events:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:rule/StepFunctionsGetEventsForECSTaskRule""]
  }
}
",data,"data ""aws_iam_policy_document"" ""step_policy"" {
  statement {
    actions = [
      ""lambda:InvokeFunction"",
      ""ecr:*"",
      ""cloudtrail:LookupEvents"",
      ""ecs:RunTask"",
      ""ecs:StopTask"",
      ""ecs:DescribeTasks"",
      ""autoscaling:Describe*"",
      ""cloudwatch:*"",
      ""logs:*"",
      ""sns:*"",
      ""iam:GetPolicy"",
      ""iam:GetPolicyVersion"",
      ""iam:GetRole"",
    ]
    resources = [""*""]
  }
}
",data,86,,59283cd10c3891258816b76160848a494ffc35b7,595b9b87702be8c093242aa4453ff55b3d242663,https://github.com/nasa/cumulus/blob/59283cd10c3891258816b76160848a494ffc35b7/tf-modules/ingest/iam.tf#L86,https://github.com/nasa/cumulus/blob/595b9b87702be8c093242aa4453ff55b3d242663/tf-modules/ingest/iam.tf,2019-08-16 13:47:55-04:00,2019-09-09 14:10:40-05:00,3,1,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-iam,12,modules/helper/main.tf,modules/helper/main.tf,0,# todo,# TODO: Refactor this to force the order somehow.,"# TODO: Refactor this to force the order somehow. 
 #       If you are to change the algo of generating `keys_additive` 
 #       or `bindings_by_member`, you have to make sure that the order 
 #       of the elements inside them matches.","locals {
  authoritative = var.mode == ""authoritative""
  additive      = var.mode == ""additive""

  # When there is only one entity, consider that the entity passed
  # might be dynamic. In this case the `for_each` will not use
  # entity name when constructing the unique ID.
  #
  # Other rules regrading the dynamic nature of resources:
  # 1. The roles might never be dynamic.
  # 2. Members might only be dynamic in `authoritative` mode.
  singular = length(var.entities) == 1

  # In singular mode, replace entity name with a constant ""default"". This
  # will prevent the potentially dynamic resource name usage in the `for_each`
  aliased_entities = local.singular ? [""default""] : var.entities

  bindings_by_role = distinct(flatten([
    for name in var.entities
    : [
      for role, members in var.bindings
      : { name = name, role = role, members = members }
    ]
  ]))

  bindings_by_member = distinct(flatten([
    for binding in local.bindings_by_role
    : [
      for member in binding[""members""]
      : { name = binding[""name""], role = binding[""role""], member = member }
    ]
  ]))

  keys_authoritative = distinct(flatten([
    for alias in local.aliased_entities
    : [
      for role in keys(var.bindings)
      : ""${alias}--${role}""
    ]
  ]))

  keys_additive = distinct(flatten([
    for alias in local.aliased_entities
    : [
      for role, members in var.bindings
      : [
        for member in members
        : ""${alias}--${role}--${member}""
      ]
    ]
  ]))

  # TODO: Refactor this to force the order somehow.
  #       If you are to change the algo of generating `keys_authoritative`
  #       or `bindings_by_role`, you have to make sure that the order
  #       of the elements inside them matches.
  bindings_authoritative = (
    local.authoritative
    ? zipmap(local.keys_authoritative, local.bindings_by_role)
    : {}
  )

  # TODO: Refactor this to force the order somehow.
  #       If you are to change the algo of generating `keys_additive`
  #       or `bindings_by_member`, you have to make sure that the order
  #       of the elements inside them matches.
  bindings_additive = (
    local.additive
    ? zipmap(local.keys_additive, local.bindings_by_member)
    : {}
  )

  # It is important to provide a set for the `for_each` instead of
  # the map, since we have to guarantee that the `for_each`
  # expression is resolved synchonously.
  set_authoritative = (
    local.authoritative
    ? toset(local.keys_authoritative)
    : []
  )

  set_additive = (
    local.additive
    ? toset(local.keys_additive)
    : []
  )
}
",locals,"locals {
  authoritative = var.mode == ""authoritative""
  additive      = var.mode == ""additive""

  # When there is only one entity, consider that the entity passed
  # might be dynamic. In this case the `for_each` will not use
  # entity name when constructing the unique ID.
  #
  # Other rules regrading the dynamic nature of resources:
  # 1. The roles might never be dynamic.
  # 2. Members might only be dynamic in `authoritative` mode.
  singular = length(var.entities) == 1

  # In singular mode, replace entity name with a constant ""default"". This
  # will prevent the potentially dynamic resource name usage in the `for_each`
  aliased_entities = local.singular ? [""default""] : var.entities

  bindings_by_role = distinct(flatten([
    for name in var.entities
    : [
      for role, members in var.bindings
      : { name = name, role = role, members = members }
    ]
  ]))

  bindings_by_member = distinct(flatten([
    for binding in local.bindings_by_role
    : [
      for member in binding[""members""]
      : { name = binding[""name""], role = binding[""role""], member = member }
    ]
  ]))

  keys_authoritative = distinct(flatten([
    for alias in local.aliased_entities
    : [
      for role in keys(var.bindings)
      : ""${alias}--${role}""
    ]
  ]))

  keys_additive = distinct(flatten([
    for alias in local.aliased_entities
    : [
      for role, members in var.bindings
      : [
        for member in members
        : ""${alias}--${role}--${member}""
      ]
    ]
  ]))

  bindings_authoritative = (
    local.authoritative
    ? zipmap(local.keys_authoritative, local.bindings_by_role)
    : {}
  )

  bindings_additive = (
    local.additive
    ? zipmap(local.keys_additive, local.bindings_by_member)
    : {}
  )

  # It is important to provide a set for the `for_each` instead of
  # the map, since we have to guarantee that the `for_each`
  # expression is resolved synchonously.
  set_authoritative = (
    local.authoritative
    ? toset(local.keys_authoritative)
    : []
  )

  set_additive = (
    local.additive
    ? toset(local.keys_additive)
    : []
  )
}
",locals,79,,665a160dd97a99c80a325250d7fea70fa9f4fac5,2529fe6173f7540994a346066d5ab141144861e9,https://github.com/terraform-google-modules/terraform-google-iam/blob/665a160dd97a99c80a325250d7fea70fa9f4fac5/modules/helper/main.tf#L79,https://github.com/terraform-google-modules/terraform-google-iam/blob/2529fe6173f7540994a346066d5ab141144861e9/modules/helper/main.tf,2019-10-14 19:29:14+03:00,2019-10-23 19:31:30+03:00,2,1,0,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,1055,terraform/projects/app-postgresql/main.tf,terraform/projects/app-postgresql/main.tf,0,# todo,"# TODO: confirm that the standby instance is unused and if so, decommission it.","# TODO: confirm that the standby instance is unused and if so, decommission it.","variable ""standby_instance_type"" {
  type        = ""string""
  description = ""Instance type used for standby RDS""
  default     = ""db.m5.4xlarge""
}
",variable,,,70,0.0,5da7363c4f3f20dcecd2bb839f3d85e33c299601,611c48ae6f4b956b25ea7e57869ea89832ead830,https://github.com/alphagov/govuk-aws/blob/5da7363c4f3f20dcecd2bb839f3d85e33c299601/terraform/projects/app-postgresql/main.tf#L70,https://github.com/alphagov/govuk-aws/blob/611c48ae6f4b956b25ea7e57869ea89832ead830/terraform/projects/app-postgresql/main.tf#L0,2020-03-17 18:42:18+00:00,2022-01-21 16:44:13+00:00,7,2,1,1,0,0,0,0,0,0
https://github.com/chanzuckerberg/cztack,22,aws-ecs-job/outputs.tf,aws-ecs-job/outputs.tf,0,hack,# Awful hack modified from https://github.com/hashicorp/terraform/issues/16726,"# Awful hack modified from https://github.com/hashicorp/terraform/issues/16726 
 # Since we know exactly one of the following has count > 0, we just concatenate all the mostly empty lists, and return the first element.","output ""ecs_service_arn"" {
  description = ""ARN for the ECS service.""

  # Awful hack modified from https://github.com/hashicorp/terraform/issues/16726
  # Since we know exactly one of the following has count > 0, we just concatenate all the mostly empty lists, and return the first element.
  value = concat(aws_ecs_service.unmanaged-job.*.id, aws_ecs_service.job.*.id)[0]
}
",output,"output ""ecs_service_arn"" {
  description = ""ARN for the ECS service.""

  # Awful hack modified from https://github.com/hashicorp/terraform/issues/16726
  # Since we know exactly one of the following has count > 0, we just concatenate all the mostly empty lists, and return the first element.
  value = concat(aws_ecs_service.unmanaged-job.*.id, aws_ecs_service.job.*.id)[0]
}
",output,4,4.0,6918848f1dab99c67e49d21bdc839d907ff8b647,6918848f1dab99c67e49d21bdc839d907ff8b647,https://github.com/chanzuckerberg/cztack/blob/6918848f1dab99c67e49d21bdc839d907ff8b647/aws-ecs-job/outputs.tf#L4,https://github.com/chanzuckerberg/cztack/blob/6918848f1dab99c67e49d21bdc839d907ff8b647/aws-ecs-job/outputs.tf#L4,2019-09-25 09:47:44-07:00,2019-09-25 09:47:44-07:00,1,0,0,0,1,0,0,0,0,0
https://github.com/Azure/sap-automation,28,deploy/terraform/terraform-units/modules/sap_system/app_tier/infrastructure.tf,deploy/terraform/terraform-units/modules/sap_system/app_tier/infrastructure.tf,0,//todo,//TODO: azurerm_lb_probe,"//TODO: azurerm_lb_probe  
 # Create the Web dispatcher Load Balancer Rules","resource ""azurerm_lb_rule"" ""web"" {
  provider                       = azurerm.main
  count                          = local.enable_web_lb_deployment ? 1 : 0
  resource_group_name            = var.resource_group[0].name
  loadbalancer_id                = azurerm_lb.web[0].id
  name                           = format(""%s%s%s"", local.prefix, var.naming.separator, local.resource_suffixes.web_alb_inrule)
  protocol                       = ""All""
  frontend_port                  = 0
  backend_port                   = 0
  frontend_ip_configuration_name = azurerm_lb.web[0].frontend_ip_configuration[0].name
  backend_address_pool_ids       = [azurerm_lb_backend_address_pool.web[0].id]
  enable_floating_ip             = true
}
",resource,"resource ""azurerm_lb_rule"" ""web"" {
  provider                       = azurerm.main
  count                          = local.enable_web_lb_deployment ? 1 : 0
  resource_group_name            = var.resource_group[0].name
  loadbalancer_id                = azurerm_lb.web[0].id
  name                           = format(""%s%s%s"", local.prefix, var.naming.separator, local.resource_suffixes.web_alb_inrule)
  protocol                       = ""All""
  frontend_port                  = 0
  backend_port                   = 0
  frontend_ip_configuration_name = azurerm_lb.web[0].frontend_ip_configuration[0].name
  backend_address_pool_ids       = [azurerm_lb_backend_address_pool.web[0].id]
  enable_floating_ip             = true
  probe_id                       = azurerm_lb_probe.web[0].id
}
",resource,237,,6ff0b891114c36d3aeccb850d830b698cd1fe52a,93f0e410055c0d8adb0db7009f72d4bf2d0e11ad,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_system/app_tier/infrastructure.tf#L237,https://github.com/Azure/sap-automation/blob/93f0e410055c0d8adb0db7009f72d4bf2d0e11ad/deploy/terraform/terraform-units/modules/sap_system/app_tier/infrastructure.tf,2021-11-17 19:29:07+02:00,2022-02-24 22:36:47+02:00,3,1,0,1,0,0,1,0,0,0
https://github.com/kubernetes/k8s.io,321,infra/gcp/terraform/k8s-infra-porche-prod/porche.tf,infra/gcp/terraform/k8s-infra-porche-prod/porche.tf,0,# todo,# TODO(justinsb): Replace with prod image once we have promoted one,# TODO(justinsb): Replace with prod image once we have promoted one,"locals {

  # TODO(justinsb): Replace with prod image once we have promoted one
  image = ""gcr.io/k8s-staging-infra-tools/redirectserver:${var.tag}""

  external_ips = {
    address-v4 = {
      name = ""k8s-infra-porche-v4"",
    },
    address-v6 = {
      name = ""k8s-infra-porche-v6"",
      ipv6 = true
    },
  }
}
",locals,"locals {

  # TODO(justinsb): Replace with prod image once we have promoted one
  image = ""gcr.io/k8s-staging-infra-tools/redirectserver:${var.tag}""

  external_ips = {
    address-v4 = {
      name = ""k8s-infra-porche-v4"",
    },
    address-v6 = {
      name = ""k8s-infra-porche-v6"",
      ipv6 = true
    },
  }
}
",locals,19,19.0,94fdf8b21a21764b5667c13368c21d767864d521,94fdf8b21a21764b5667c13368c21d767864d521,https://github.com/kubernetes/k8s.io/blob/94fdf8b21a21764b5667c13368c21d767864d521/infra/gcp/terraform/k8s-infra-porche-prod/porche.tf#L19,https://github.com/kubernetes/k8s.io/blob/94fdf8b21a21764b5667c13368c21d767864d521/infra/gcp/terraform/k8s-infra-porche-prod/porche.tf#L19,2023-02-08 09:59:38-05:00,2023-02-08 09:59:38-05:00,1,0,1,1,0,0,0,1,0,0
https://github.com/compiler-explorer/infra,115,terraform/ec2.tf,terraform/ec2.tf,0,todo,// TODO bring into the fold,// TODO bring into the fold,"resource ""aws_instance"" ""BuilderNode"" {
  ami                         = local.builder_image_id
  // TODO bring into the fold
  iam_instance_profile        = ""GccBuilder""
  ebs_optimized               = true
  // TODO make 4xlarge or similar
  instance_type               = ""c5d.large""
  monitoring                  = false
  key_name                    = ""mattgodbolt""
  subnet_id                   = aws_subnet.ce-1a.id
  // TODO reconsider, make an SG specifically for builder
  vpc_security_group_ids      = [aws_security_group.AdminNode.id]
  associate_public_ip_address = true
  source_dest_check           = false

  root_block_device {
    volume_type           = ""gp2""
    volume_size           = 24
    delete_on_termination = true
  }

  tags = {
    Name = ""Builder-New""
  }
}
",resource,"resource ""aws_instance"" ""BuilderNode"" {
  ami                         = local.builder_image_id
  iam_instance_profile        = aws_iam_instance_profile.Builder.name
  ebs_optimized               = true
  instance_type               = ""c5d.4xlarge""
  monitoring                  = false
  key_name                    = ""mattgodbolt""
  subnet_id                   = aws_subnet.ce-1a.id
  // TODO reconsider, make an SG specifically for builder
  vpc_security_group_ids      = [aws_security_group.AdminNode.id]
  associate_public_ip_address = true
  source_dest_check           = false

  root_block_device {
    volume_type           = ""gp2""
    volume_size           = 24
    delete_on_termination = true
  }

  lifecycle {
    ignore_changes = [
      // Seemingly needed to not replace stopped instances
      associate_public_ip_address
    ]
  }

  tags = {
    Name = ""Builder""
  }
}
",resource,71,,b419a94ffc423c637e8722d79fb4f42770acf05e,2eaefccbb0f3e28949710984dfe0f9c6067a61be,https://github.com/compiler-explorer/infra/blob/b419a94ffc423c637e8722d79fb4f42770acf05e/terraform/ec2.tf#L71,https://github.com/compiler-explorer/infra/blob/2eaefccbb0f3e28949710984dfe0f9c6067a61be/terraform/ec2.tf,2021-08-30 22:47:49-05:00,2021-09-02 08:22:34-05:00,4,1,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1144,fast/stages/02-networking-nva/nva.tf,fast/stages/02-networking-nva/nva.tf,0,fix,# FIXME: cycle,"# FIXME: cycle 
 # auto_healing_policies = { 
 #   health_check      = module.nva-mig[each.key].health_check.self_link 
 #   initial_delay_sec = 30 
 # }","module ""nva-mig"" {
  for_each    = local.nva_locality
  source      = ""../../../modules/compute-mig""
  project_id  = module.landing-project.project_id
  regional    = true
  location    = each.value.region
  name        = ""nva-cos-${each.value.trigram}-${each.value.zone}""
  target_size = 1
  # FIXME: cycle
  # auto_healing_policies = {
  #   health_check      = module.nva-mig[each.key].health_check.self_link
  #   initial_delay_sec = 30
  # }
  health_check_config = {
    type    = ""tcp""
    check   = { port = 22 }
    config  = {}
    logging = true
  }
  default_version = {
    instance_template = module.nva-template[each.key].template.self_link
    name              = ""default""
  }
}
",module,"module ""nva-mig"" {
  for_each          = local.nva_locality
  source            = ""../../../modules/compute-mig""
  project_id        = module.landing-project.project_id
  location          = each.value.region
  name              = ""nva-cos-${each.value.trigram}-${each.value.zone}""
  instance_template = module.nva-template[each.key].template.self_link
  target_size       = 1
  auto_healing_policies = {
    initial_delay_sec = 30
  }
  health_check_config = {
    enable_logging = true
    tcp = {
      port = 22
    }
  }
}
",module,104,,674deb1c4fe36b322e7c706fc5069f2a2df79767,a30c186f1fcc21e9cd2e6016485b6d797af176e8,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/674deb1c4fe36b322e7c706fc5069f2a2df79767/fast/stages/02-networking-nva/nva.tf#L104,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/a30c186f1fcc21e9cd2e6016485b6d797af176e8/fast/stages/02-networking-nva/nva.tf,2022-10-10 09:16:28+02:00,2022-11-01 09:38:59+01:00,2,1,1,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1762,modules/net-lb-app-ext-regional/backend-service.tf,modules/net-lb-app-ext-regional/backend-service.tf,0,#todo,#TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL,#TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL,"resource ""google_compute_region_backend_service"" ""default"" {
  provider = google-beta
  for_each = var.backend_service_configs
  project = (
    each.value.project_id == null
    ? var.project_id
    : each.value.project_id
  )
  name                            = ""${var.name}-${each.key}""
  region                          = var.region
  description                     = var.description
  affinity_cookie_ttl_sec         = each.value.affinity_cookie_ttl_sec
  connection_draining_timeout_sec = each.value.connection_draining_timeout_sec
  enable_cdn                      = each.value.enable_cdn
  health_checks = length(each.value.health_checks) == 0 ? null : [
    for k in each.value.health_checks : lookup(local.hc_ids, k, k)
  ]
  # external regional load balancer is always EXTERNAL_MANAGER.
  # TODO(jccb): double check if this is true
  load_balancing_scheme = ""EXTERNAL_MANAGED""
  #TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL
  port_name = (
    each.value.port_name == null
    ? lower(each.value.protocol == null ? var.protocol : each.value.protocol)
    : each.value.port_name
  )
  protocol = (
    each.value.protocol == null ? var.protocol : each.value.protocol
  )
  session_affinity = each.value.session_affinity
  timeout_sec      = each.value.timeout_sec

  dynamic ""backend"" {
    for_each = { for b in coalesce(each.value.backends, []) : b.backend => b }
    content {
      group           = lookup(local.group_ids, backend.key, backend.key)
      balancing_mode  = backend.value.balancing_mode # UTILIZATION, RATE
      capacity_scaler = backend.value.capacity_scaler
      description     = backend.value.description
      max_connections = try(
        backend.value.max_connections.per_group, null
      )
      max_connections_per_endpoint = try(
        backend.value.max_connections.per_endpoint, null
      )
      max_connections_per_instance = try(
        backend.value.max_connections.per_instance, null
      )
      max_rate = try(
        backend.value.max_rate.per_group, null
      )
      max_rate_per_endpoint = try(
        backend.value.max_rate.per_endpoint, null
      )
      max_rate_per_instance = try(
        backend.value.max_rate.per_instance, null
      )
      max_utilization = backend.value.max_utilization
    }
  }

  dynamic ""cdn_policy"" {
    for_each = (
      each.value.cdn_policy == null ? [] : [each.value.cdn_policy]
    )
    iterator = cdn
    content {
      cache_mode                   = cdn.value.cache_mode
      client_ttl                   = cdn.value.client_ttl
      default_ttl                  = cdn.value.default_ttl
      max_ttl                      = cdn.value.max_ttl
      negative_caching             = cdn.value.negative_caching
      serve_while_stale            = cdn.value.serve_while_stale
      signed_url_cache_max_age_sec = cdn.value.signed_url_cache_max_age_sec
      dynamic ""cache_key_policy"" {
        for_each = (
          cdn.value.cache_key_policy == null
          ? []
          : [cdn.value.cache_key_policy]
        )
        iterator = ck
        content {
          include_host           = ck.value.include_host
          include_named_cookies  = ck.value.include_named_cookies
          include_protocol       = ck.value.include_protocol
          include_query_string   = ck.value.include_query_string
          query_string_blacklist = ck.value.query_string_blacklist
          query_string_whitelist = ck.value.query_string_whitelist
        }
      }
      dynamic ""negative_caching_policy"" {
        for_each = (
          cdn.value.negative_caching_policy == null
          ? []
          : [cdn.value.negative_caching_policy]
        )
        iterator = nc
        content {
          code = nc.value.code
          ttl  = nc.value.ttl
        }
      }
    }
  }

  dynamic ""circuit_breakers"" {
    for_each = (
      each.value.circuit_breakers == null ? [] : [each.value.circuit_breakers]
    )
    iterator = cb
    content {
      max_connections             = cb.value.max_connections
      max_pending_requests        = cb.value.max_pending_requests
      max_requests                = cb.value.max_requests
      max_requests_per_connection = cb.value.max_requests_per_connection
      max_retries                 = cb.value.max_retries
      dynamic ""connect_timeout"" {
        for_each = (
          cb.value.connect_timeout == null ? [] : [cb.value.connect_timeout]
        )
        content {
          seconds = connect_timeout.value.seconds
          nanos   = connect_timeout.value.nanos
        }
      }
    }
  }

  dynamic ""consistent_hash"" {
    for_each = (
      each.value.consistent_hash == null ? [] : [each.value.consistent_hash]
    )
    iterator = ch
    content {
      http_header_name  = ch.value.http_header_name
      minimum_ring_size = ch.value.minimum_ring_size
      dynamic ""http_cookie"" {
        for_each = ch.value.http_cookie == null ? [] : [ch.value.http_cookie]
        content {
          name = http_cookie.value.name
          path = http_cookie.value.path
          dynamic ""ttl"" {
            for_each = (
              http_cookie.value.ttl == null ? [] : [http_cookie.value.ttl]
            )
            content {
              seconds = ttl.value.seconds
              nanos   = ttl.value.nanos
            }
          }
        }
      }
    }
  }

  dynamic ""iap"" {
    for_each = each.value.iap_config == null ? [] : [each.value.iap_config]
    content {
      oauth2_client_id            = iap.value.oauth2_client_id
      oauth2_client_secret        = iap.value.oauth2_client_secret
      oauth2_client_secret_sha256 = iap.value.oauth2_client_secret_sha256
    }
  }

  dynamic ""log_config"" {
    for_each = each.value.log_sample_rate == null ? [] : [""""]
    content {
      enable      = true
      sample_rate = each.value.log_sample_rate
    }
  }

  dynamic ""outlier_detection"" {
    for_each = (
      each.value.outlier_detection == null ? [] : [each.value.outlier_detection]
    )
    iterator = od
    content {
      consecutive_errors                    = od.value.consecutive_errors
      consecutive_gateway_failure           = od.value.consecutive_gateway_failure
      enforcing_consecutive_errors          = od.value.enforcing_consecutive_errors
      enforcing_consecutive_gateway_failure = od.value.enforcing_consecutive_gateway_failure
      enforcing_success_rate                = od.value.enforcing_success_rate
      max_ejection_percent                  = od.value.max_ejection_percent
      success_rate_minimum_hosts            = od.value.success_rate_minimum_hosts
      success_rate_request_volume           = od.value.success_rate_request_volume
      success_rate_stdev_factor             = od.value.success_rate_stdev_factor
      dynamic ""base_ejection_time"" {
        for_each = (
          od.value.base_ejection_time == null ? [] : [od.value.base_ejection_time]
        )
        content {
          seconds = base_ejection_time.value.seconds
          nanos   = base_ejection_time.value.nanos
        }
      }
      dynamic ""interval"" {
        for_each = (
          od.value.interval == null ? [] : [od.value.interval]
        )
        content {
          seconds = interval.value.seconds
          nanos   = interval.value.nanos
        }
      }
    }
  }
}
",resource,"resource ""google_compute_region_backend_service"" ""default"" {
  provider = google-beta
  for_each = var.backend_service_configs
  project = (
    each.value.project_id == null
    ? var.project_id
    : each.value.project_id
  )
  name                            = ""${var.name}-${each.key}""
  region                          = var.region
  description                     = var.description
  affinity_cookie_ttl_sec         = each.value.affinity_cookie_ttl_sec
  connection_draining_timeout_sec = each.value.connection_draining_timeout_sec
  enable_cdn                      = each.value.enable_cdn
  health_checks = length(each.value.health_checks) == 0 ? null : [
    for k in each.value.health_checks : lookup(local.hc_ids, k, k)
  ]
  # external regional load balancer is always EXTERNAL_MANAGER.
  # TODO(jccb): double check if this is true
  load_balancing_scheme = ""EXTERNAL_MANAGED""
  #TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL
  port_name = (
    each.value.port_name == null
    ? lower(each.value.protocol == null ? var.protocol : each.value.protocol)
    : each.value.port_name
  )
  protocol = (
    each.value.protocol == null ? var.protocol : each.value.protocol
  )
  session_affinity = each.value.session_affinity
  timeout_sec      = each.value.timeout_sec

  dynamic ""backend"" {
    for_each = { for b in coalesce(each.value.backends, []) : b.backend => b }
    content {
      group           = lookup(local.group_ids, backend.key, backend.key)
      balancing_mode  = backend.value.balancing_mode # UTILIZATION, RATE
      capacity_scaler = backend.value.capacity_scaler
      description     = backend.value.description
      max_connections = try(
        backend.value.max_connections.per_group, null
      )
      max_connections_per_endpoint = try(
        backend.value.max_connections.per_endpoint, null
      )
      max_connections_per_instance = try(
        backend.value.max_connections.per_instance, null
      )
      max_rate = try(
        backend.value.max_rate.per_group, null
      )
      max_rate_per_endpoint = try(
        backend.value.max_rate.per_endpoint, null
      )
      max_rate_per_instance = try(
        backend.value.max_rate.per_instance, null
      )
      max_utilization = backend.value.max_utilization
    }
  }

  dynamic ""cdn_policy"" {
    for_each = (
      each.value.cdn_policy == null ? [] : [each.value.cdn_policy]
    )
    iterator = cdn
    content {
      cache_mode                   = cdn.value.cache_mode
      client_ttl                   = cdn.value.client_ttl
      default_ttl                  = cdn.value.default_ttl
      max_ttl                      = cdn.value.max_ttl
      negative_caching             = cdn.value.negative_caching
      serve_while_stale            = cdn.value.serve_while_stale
      signed_url_cache_max_age_sec = cdn.value.signed_url_cache_max_age_sec
      dynamic ""cache_key_policy"" {
        for_each = (
          cdn.value.cache_key_policy == null
          ? []
          : [cdn.value.cache_key_policy]
        )
        iterator = ck
        content {
          include_host           = ck.value.include_host
          include_named_cookies  = ck.value.include_named_cookies
          include_protocol       = ck.value.include_protocol
          include_query_string   = ck.value.include_query_string
          query_string_blacklist = ck.value.query_string_blacklist
          query_string_whitelist = ck.value.query_string_whitelist
        }
      }
      dynamic ""negative_caching_policy"" {
        for_each = (
          cdn.value.negative_caching_policy == null
          ? []
          : [cdn.value.negative_caching_policy]
        )
        iterator = nc
        content {
          code = nc.value.code
          ttl  = nc.value.ttl
        }
      }
    }
  }

  dynamic ""circuit_breakers"" {
    for_each = (
      each.value.circuit_breakers == null ? [] : [each.value.circuit_breakers]
    )
    iterator = cb
    content {
      max_connections             = cb.value.max_connections
      max_pending_requests        = cb.value.max_pending_requests
      max_requests                = cb.value.max_requests
      max_requests_per_connection = cb.value.max_requests_per_connection
      max_retries                 = cb.value.max_retries
      dynamic ""connect_timeout"" {
        for_each = (
          cb.value.connect_timeout == null ? [] : [cb.value.connect_timeout]
        )
        content {
          seconds = connect_timeout.value.seconds
          nanos   = connect_timeout.value.nanos
        }
      }
    }
  }

  dynamic ""consistent_hash"" {
    for_each = (
      each.value.consistent_hash == null ? [] : [each.value.consistent_hash]
    )
    iterator = ch
    content {
      http_header_name  = ch.value.http_header_name
      minimum_ring_size = ch.value.minimum_ring_size
      dynamic ""http_cookie"" {
        for_each = ch.value.http_cookie == null ? [] : [ch.value.http_cookie]
        content {
          name = http_cookie.value.name
          path = http_cookie.value.path
          dynamic ""ttl"" {
            for_each = (
              http_cookie.value.ttl == null ? [] : [http_cookie.value.ttl]
            )
            content {
              seconds = ttl.value.seconds
              nanos   = ttl.value.nanos
            }
          }
        }
      }
    }
  }

  dynamic ""iap"" {
    for_each = each.value.iap_config == null ? [] : [each.value.iap_config]
    content {
      oauth2_client_id            = iap.value.oauth2_client_id
      oauth2_client_secret        = iap.value.oauth2_client_secret
      oauth2_client_secret_sha256 = iap.value.oauth2_client_secret_sha256
    }
  }

  dynamic ""log_config"" {
    for_each = each.value.log_sample_rate == null ? [] : [""""]
    content {
      enable      = true
      sample_rate = each.value.log_sample_rate
    }
  }

  dynamic ""outlier_detection"" {
    for_each = (
      each.value.outlier_detection == null ? [] : [each.value.outlier_detection]
    )
    iterator = od
    content {
      consecutive_errors                    = od.value.consecutive_errors
      consecutive_gateway_failure           = od.value.consecutive_gateway_failure
      enforcing_consecutive_errors          = od.value.enforcing_consecutive_errors
      enforcing_consecutive_gateway_failure = od.value.enforcing_consecutive_gateway_failure
      enforcing_success_rate                = od.value.enforcing_success_rate
      max_ejection_percent                  = od.value.max_ejection_percent
      success_rate_minimum_hosts            = od.value.success_rate_minimum_hosts
      success_rate_request_volume           = od.value.success_rate_request_volume
      success_rate_stdev_factor             = od.value.success_rate_stdev_factor
      dynamic ""base_ejection_time"" {
        for_each = (
          od.value.base_ejection_time == null ? [] : [od.value.base_ejection_time]
        )
        content {
          seconds = base_ejection_time.value.seconds
          nanos   = base_ejection_time.value.nanos
        }
      }
      dynamic ""interval"" {
        for_each = (
          od.value.interval == null ? [] : [od.value.interval]
        )
        content {
          seconds = interval.value.seconds
          nanos   = interval.value.nanos
        }
      }
    }
  }
}
",resource,62,62.0,8beb621e070226b7f11a82807a706170ae7040ea,8beb621e070226b7f11a82807a706170ae7040ea,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/8beb621e070226b7f11a82807a706170ae7040ea/modules/net-lb-app-ext-regional/backend-service.tf#L62,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/8beb621e070226b7f11a82807a706170ae7040ea/modules/net-lb-app-ext-regional/backend-service.tf#L62,2024-01-05 16:59:27+01:00,2024-01-05 16:59:27+01:00,1,0,0,1,0,1,0,0,0,0
https://github.com/uyuni-project/sumaform,1195,modules/libvirt/suse_manager/main.tf,modules/libvirt/suse_manager/main.tf,0,hack,// HACK: Terraform 0.11 ternary operator is not short-circuiting,"// HACK: Terraform 0.11 ternary operator is not short-circuiting 
 // https://github.com/hashicorp/terraform/issues/11566 
 // example by https://github.com/coreos/tectonic-installer/commit/0f209b31b169ce129ba457096b23792f6601d66e#diff-17708827fa84c637698cd840c01710c9R16","module ""suse_manager"" {
  source = ""../host""

  base_configuration = ""${var.base_configuration}""
  name = ""${var.name}""
  count = 1
  use_os_released_updates = ""${var.use_os_released_updates}""
  use_os_unreleased_updates = ""${var.use_os_unreleased_updates}""
  additional_repos = ""${var.additional_repos}""
  additional_repos_only = ""${var.additional_repos_only}""
  additional_certs = ""${var.additional_certs}""
  additional_packages = ""${var.additional_packages}""
  swap_file_size = ""${var.swap_file_size}""
  ssh_key_path = ""${var.ssh_key_path}""
  gpg_keys = ""${var.gpg_keys}""
  ipv6 = ""${var.ipv6}""
  connect_to_base_network = true
  connect_to_additional_network = false
  # HACK: work around ""conditional operator cannot be used with list values""
  roles = ""${split("","", var.register_to_server == ""null"" ? ""suse_manager_server"" : ""suse_manager_server,minion"")}""
  grains = <<EOF

product_version: ${var.product_version}
cc_username: ${var.base_configuration[""cc_username""]}
cc_password: ${var.base_configuration[""cc_password""]}
channels: [${join("","", var.channels)}]
cloned_channels: ${var.cloned_channels}
mirror: ${var.base_configuration[""mirror""]}
iss_master: ${var.iss_master}
iss_slave: ${var.iss_slave}
server: ${var.register_to_server}
auto_connect_to_master: ${var.auto_register}
susemanager:
  activation_key: ${var.activation_key}
smt: ${var.smt}
server_username: ${var.server_username}
server_password: ${var.server_password}
disable_firewall: ${var.disable_firewall}
allow_postgres_connections: ${var.allow_postgres_connections}
unsafe_postgres: ${var.unsafe_postgres}
java_debugging: ${var.java_debugging}
skip_changelog_import: ${var.skip_changelog_import}
browser_side_less: ${var.browser_side_less}
create_first_user: ${var.create_first_user}
mgr_sync_autologin: ${var.mgr_sync_autologin}
create_sample_channel: ${var.create_sample_channel}
create_sample_activation_key: ${var.create_sample_activation_key}
create_sample_bootstrap_script: ${var.create_sample_bootstrap_script}
publish_private_ssl_key: ${var.publish_private_ssl_key}
disable_download_tokens: ${var.disable_download_tokens}
auto_accept: ${var.auto_accept}
monitored: ${var.monitored}
pts: ${var.pts}
pts_minion: ${var.pts_minion}
pts_locust: ${var.pts_locust}
pts_system_count: ${var.pts_system_count}
pts_system_prefix: ${var.pts_system_prefix}
apparmor: ${var.apparmor}
from_email: ${var.from_email}
traceback_email: ${var.traceback_email}
saltapi_tcpdump: ${var.saltapi_tcpdump}
repository_disk_size: ${var.repository_disk_size}

EOF

  // Provider-specific variables
  image = ""${var.image == ""default"" ? lookup(var.images, var.product_version) : var.image}""
  memory = ""${var.memory}""
  vcpu = ""${var.vcpu}""
  running = ""${var.running}""
  mac = ""${var.mac}""

  // HACK: Terraform 0.11 ternary operator is not short-circuiting
  // https://github.com/hashicorp/terraform/issues/11566
  // example by https://github.com/coreos/tectonic-installer/commit/0f209b31b169ce129ba457096b23792f6601d66e#diff-17708827fa84c637698cd840c01710c9R16
  additional_disk = ""${slice(
    list(map(""volume_id"", join("""",libvirt_volume.server_data_disk.*.id))),
    0,
    var.repository_disk_size > 0 ? 1 : 0
  )}""
}
",module,"module ""suse_manager"" {
  source = ""../host""

  base_configuration            = var.base_configuration
  name                          = var.name
  use_os_released_updates       = var.use_os_released_updates
  use_os_unreleased_updates     = var.use_os_unreleased_updates
  additional_repos              = var.additional_repos
  additional_repos_only         = var.additional_repos_only
  additional_certs              = var.additional_certs
  additional_packages           = var.additional_packages
  swap_file_size                = var.swap_file_size
  ssh_key_path                  = var.ssh_key_path
  gpg_keys                      = var.gpg_keys
  ipv6                          = var.ipv6
  connect_to_base_network       = true
  connect_to_additional_network = false

  # HACK: work around ""conditional operator cannot be used with list values""
  roles = split(
    "","",
    var.register_to_server == ""null"" ? ""suse_manager_server"" : ""suse_manager_server,minion"",
  )
  grains = <<EOF

product_version: ${var.product_version}
cc_username: ${var.base_configuration[""cc_username""]}
cc_password: ${var.base_configuration[""cc_password""]}
channels: [${join("","", var.channels)}]
cloned_channels: ${var.cloned_channels}
mirror: ${var.base_configuration[""mirror""]}
iss_master: ${var.iss_master}
iss_slave: ${var.iss_slave}
server: ${var.register_to_server}
auto_connect_to_master: ${var.auto_register}
susemanager:
  activation_key: ${var.activation_key}
smt: ${var.smt}
server_username: ${var.server_username}
server_password: ${var.server_password}
disable_firewall: ${var.disable_firewall}
allow_postgres_connections: ${var.allow_postgres_connections}
unsafe_postgres: ${var.unsafe_postgres}
java_debugging: ${var.java_debugging}
skip_changelog_import: ${var.skip_changelog_import}
browser_side_less: ${var.browser_side_less}
create_first_user: ${var.create_first_user}
mgr_sync_autologin: ${var.mgr_sync_autologin}
create_sample_channel: ${var.create_sample_channel}
create_sample_activation_key: ${var.create_sample_activation_key}
create_sample_bootstrap_script: ${var.create_sample_bootstrap_script}
publish_private_ssl_key: ${var.publish_private_ssl_key}
disable_download_tokens: ${var.disable_download_tokens}
auto_accept: ${var.auto_accept}
monitored: ${var.monitored}
pts: ${var.pts}
pts_minion: ${var.pts_minion}
pts_locust: ${var.pts_locust}
pts_system_count: ${var.pts_system_count}
pts_system_prefix: ${var.pts_system_prefix}
apparmor: ${var.apparmor}
from_email: ${var.from_email}
traceback_email: ${var.traceback_email}
saltapi_tcpdump: ${var.saltapi_tcpdump}
repository_disk_size: ${var.repository_disk_size}
repository_disk_device: vdb

EOF


  // Provider-specific variables
  image           = var.image == ""default"" ? var.images[var.product_version] : var.image
  memory          = var.memory
  vcpu            = var.vcpu
  running         = var.running
  mac             = var.mac
  additional_disk = var.repository_disk_size > 0 ? [{ volume_id = libvirt_volume.server_data_disk[0].id }] : []
}
",module,93,,6539acf5ba321598716c3360ff27eef5297bbcc0,b6b58a650bc084486e92a74c5c12c855b53895ec,https://github.com/uyuni-project/sumaform/blob/6539acf5ba321598716c3360ff27eef5297bbcc0/modules/libvirt/suse_manager/main.tf#L93,https://github.com/uyuni-project/sumaform/blob/b6b58a650bc084486e92a74c5c12c855b53895ec/modules/libvirt/suse_manager/main.tf,2019-11-12 11:49:58+01:00,2019-11-19 17:08:35+01:00,6,1,0,1,1,0,0,0,0,0
https://github.com/ministryofjustice/modernisation-platform,195,terraform/environments/data-platform-apps-and-tools/eks-cluster.tf,terraform/environments/data-platform-apps-and-tools/eks-cluster.tf,0,fix,#tfsec:ignore:aws-ec2-no-public-egress-sgr - We are going to have a wider discussion and if needed we will fix this,"#tfsec:ignore:aws-eks-no-public-cluster-access - k8s API is secured with AWS STS 
 #tfsec:ignore:aws-eks-no-public-cluster-access-to-cidr - "" "" 
 #tfsec:ignore:aws-ec2-no-public-egress-sgr - We are going to have a wider discussion and if needed we will fix this","module ""eks"" {
  #checkov:skip=CKV_TF_1:Module is from Terraform registry

  source  = ""terraform-aws-modules/eks/aws""
  version = ""19.16.0""

  cluster_name    = local.environment_configuration.eks_cluster_name
  cluster_version = local.environment_configuration.eks_versions.cluster

  cluster_endpoint_private_access = true
  cluster_endpoint_public_access  = true

  vpc_id                   = module.vpc.vpc_id
  control_plane_subnet_ids = module.vpc.private_subnets
  subnet_ids               = module.vpc.private_subnets

  cluster_enabled_log_types = [""api"", ""audit"", ""authenticator"", ""controllerManager"", ""scheduler""]

  cluster_addons = {
    coredns = {
      addon_version = local.environment_configuration.eks_versions.addon_coredns
    }
    kube-proxy = {
      addon_version = local.environment_configuration.eks_versions.addon_kube_proxy
    }
    vpc-cni = {
      addon_version = local.environment_configuration.eks_versions.addon_vpc_cni
    }
    aws-guardduty-agent = {
      addon_version = local.environment_configuration.eks_versions.addon_aws_guardduty_agent
    }
  }

  eks_managed_node_group_defaults = {
    ami_release_version = local.environment_configuration.eks_versions.ami_release
    ami_type            = ""BOTTLEROCKET_x86_64""
    platform            = ""bottlerocket""
    metadata_options = {
      http_endpoint               = ""enabled""
      http_put_response_hop_limit = 2
      http_tokens                 = ""required""
      instance_metadata_tags      = ""enabled""
    }

    block_device_mappings = {
      xvda = {
        device_name = ""/dev/xvda""
        ebs = {
          volume_size = 100
        }
      }
    }

    iam_role_additional_policies = {
      AmazonSSMManagedInstanceCore = ""arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore""
      CloudWatchAgentServerPolicy  = ""arn:aws:iam::aws:policy/CloudWatchAgentServerPolicy""
    }
  }

  // TODO: Review these settings
  eks_managed_node_groups = {
    general = {
      min_size       = 3
      max_size       = 10
      desired_size   = 5
      instance_types = [""t3.xlarge""]
    }
  }

  manage_aws_auth_configmap = true

  aws_auth_roles = [
    {
      rolearn  = ""arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/${one(data.aws_iam_roles.eks_sso_access_role.names)}""
      groups   = [""system:masters""]
      username = ""administrator""
    },
    {
      // rolearn cannot consume module.airflow_execution_role.arn because that role consumes module.eks.cluster_arn, but we can construct the ARN manually
      rolearn  = ""arn:aws:iam::${data.aws_caller_identity.current.account_id}:role/${local.environment_configuration.airflow_execution_role_name}""
      groups   = [""airflow""]
      username = ""airflow""
    }
  ]

  tags = local.tags
}
",module,,,3,0.0,90002b7667baf7c1eb23d0e49dcfa9d9eaee7567,951ffdb805c4255e3bb6d0a5febe5f1bb21407c9,https://github.com/ministryofjustice/modernisation-platform/blob/90002b7667baf7c1eb23d0e49dcfa9d9eaee7567/terraform/environments/data-platform-apps-and-tools/eks-cluster.tf#L3,https://github.com/ministryofjustice/modernisation-platform/blob/951ffdb805c4255e3bb6d0a5febe5f1bb21407c9/terraform/environments/data-platform-apps-and-tools/eks-cluster.tf#L0,2023-10-18 15:43:32+01:00,2023-12-19 15:49:47+00:00,9,2,1,1,0,0,0,0,0,1
https://github.com/Worklytics/psoxy,1911,infra/modules/gcp-host/main.tf,infra/modules/gcp-host/main.tf,0,# todo,"# TODO: in v0.5, the prefix with the instance_id can be removed","# TODO: in v0.5, the prefix with the instance_id can be removed","locals {
  secrets_to_provision = {
    for k, v in var.api_connectors :
    k => {
      for var_def in v.secured_variables :
      # TODO: in v0.5, the prefix with the instance_id can be removed
      ""${replace(upper(var_def.name), ""-"", ""_"")}"" =>
      merge({
        instance_id        = k
        instance_secret_id = ""${replace(upper(k), ""-"", ""_"")}_${replace(upper(var_def.name), ""-"", ""_"")}""
        value              = ""TODO: fill me""
        description        = """"
        },
      var_def)
    }
  }
  lockable_secrets = flatten([
    for instance_id, secrets in local.secrets_to_provision :
    [for secret_id, secret in values(secrets) : secret if secret.lockable]
  ])
}
",locals,"locals {
  secrets_to_provision = {
    for k, v in var.api_connectors :
    k => {
      for var_def in v.secured_variables :
      # TODO: in v0.5, the prefix with the instance_id can be removed
      ""${replace(upper(var_def.name), ""-"", ""_"")}"" =>
      merge({
        instance_id        = k
        instance_secret_id = ""${replace(upper(k), ""-"", ""_"")}_${replace(upper(var_def.name), ""-"", ""_"")}""
        value              = ""TODO: fill me""
        description        = """"
        },
      var_def)
    }
  }

  secrets_writable_by_instance = flatten([
    for instance_id, secrets in local.secrets_to_provision :
    [for secret_id, secret in values(secrets) : secret if secret.lockable || secret.writable]
  ])

  secrets_bound_as_env_vars = {
    for instance_id, secrets in local.secrets_to_provision :
    instance_id => {
      for secret_name, secret in secrets :
      secret_name => module.secrets[instance_id].secret_bindings[secret_name] if secret.value_managed_by_tf && !secret.lockable && !secret.writable
    }
  }

  # eg, neither writable, nor suitable to bind as env var (as GCP cloud function won't start if can't
  # read a value for something that's bound as an env var)
  secrets_access_only_but_not_managed_by_terraform = flatten([
    for instance_id, secrets in local.secrets_to_provision :
    [for secret_id, secret in values(secrets) : secret if !secret.value_managed_by_tf && !secret.lockable && !secret.writable]
  ])
}
",locals,38,51.0,10e60e9a53aa6a95dc6be6a2c50a167972aa7831,0db6077bf0549cf79dc2e0cb57563d5ac2453feb,https://github.com/Worklytics/psoxy/blob/10e60e9a53aa6a95dc6be6a2c50a167972aa7831/infra/modules/gcp-host/main.tf#L38,https://github.com/Worklytics/psoxy/blob/0db6077bf0549cf79dc2e0cb57563d5ac2453feb/infra/modules/gcp-host/main.tf#L51,2023-06-29 15:45:43-07:00,2024-04-03 10:54:59-07:00,25,0,0,1,0,0,0,0,0,0
https://github.com/aws-ia/terraform-aws-eks-blueprints,1,eks.tf,eks.tf,0,todo,# TODO handle this in aws-ia TF EKS module,"#############################END OF EKS CLUSTER MODULE #############################################################  
 # TODO handle this in aws-ia TF EKS module 
 //  map_roles    = local.common_roles 
 //  map_users    = var.map_users 
 //  map_accounts = var.map_accounts  
 # TODO Create a new Self-Managed Node group and remove worker_create_cluster_primary_security_group_rules and worker_groups_launch_template 
 #---------------------------------------------------------------------------------- 
 #   Self-managed node group (worker group) 
 #---------------------------------------------------------------------------------- 
 # Conditionally allow Worker nodes <-> primary cluster SG traffic 
 # See https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/faq.md#im-using-both-aws-managed-node-groups-and-self-managed-worker-groups-and-pods-scheduled-on-a-aws-managed-node-groups-are-unable-resolve-dns-even-communication-between-pods","module ""eks"" {
  create_eks      = var.create_eks
  manage_aws_auth = false
  source          = ""terraform-aws-modules/eks/aws""
  version         = ""17.1.0""
  cluster_name    = module.eks-label.id
  cluster_version = var.kubernetes_version

  vpc_id = var.create_vpc == false ? var.vpc_id : module.vpc.vpc_id

  subnets                         = var.create_vpc == false ? var.private_subnet_ids : module.vpc.private_subnets
  cluster_endpoint_private_access = var.endpoint_private_access
  cluster_endpoint_public_access  = var.endpoint_public_access
  enable_irsa                     = var.enable_irsa
  kubeconfig_output_path          = ""./kubeconfig/""

  tags = module.eks-label.tags

  cluster_enabled_log_types = var.enabled_cluster_log_types

  cluster_encryption_config = [
    {
      provider_key_arn = aws_kms_key.eks.arn
      resources = [
      ""secrets""]
    }
  ]

  #############################END OF EKS CLUSTER MODULE #############################################################

  # TODO handle this in aws-ia TF EKS module
  //  map_roles    = local.common_roles
  //  map_users    = var.map_users
  //  map_accounts = var.map_accounts

  # TODO Create a new Self-Managed Node group and remove worker_create_cluster_primary_security_group_rules and worker_groups_launch_template
  #----------------------------------------------------------------------------------
  #   Self-managed node group (worker group)
  #----------------------------------------------------------------------------------
  # Conditionally allow Worker nodes <-> primary cluster SG traffic
  # See https://github.com/terraform-aws-modules/terraform-aws-eks/blob/master/docs/faq.md#im-using-both-aws-managed-node-groups-and-self-managed-worker-groups-and-pods-scheduled-on-a-aws-managed-node-groups-are-unable-resolve-dns-even-communication-between-pods
  worker_create_cluster_primary_security_group_rules = var.enable_self_managed_nodegroups

  # Conditionally create a self-managed node group (worker group) - either Windows or Linux
  worker_groups_launch_template = var.enable_self_managed_nodegroups ? [{
    name     = var.self_managed_nodegroup_name
    platform = local.self_managed_node_platform

    # Use custom AMI, user data script template, and its parameters, if provided in input. 
    # Otherwise, use default EKS-optimized AMI, user data script for Windows / Linux.
    ami_id                       = var.self_managed_node_ami_id != """" ? var.self_managed_node_ami_id : var.enable_windows_support ? data.aws_ami.windows2019core.id : data.aws_ami.amazonlinux2eks.id
    userdata_template_file       = var.self_managed_node_userdata_template_file != """" ? var.self_managed_node_userdata_template_file : var.enable_windows_support ? ""./templates/userdata-windows.tpl"" : ""./templates/userdata-amazonlinux2eks.tpl""
    userdata_template_extra_args = var.self_managed_node_userdata_template_extra_params

    override_instance_types = var.self_managed_node_instance_types
    root_encrypted          = true
    root_volume_size        = var.self_managed_node_volume_size

    iam_instance_profile_name = var.enable_windows_support ? module.windows_support_iam[0].windows_instance_profile.name : null
    asg_desired_capacity      = var.self_managed_node_desired_size
    asg_min_size              = var.self_managed_node_min_size
    asg_max_size              = var.self_managed_node_max_size

    kubelet_extra_args = ""--node-labels=Environment=${var.environment},Zone=${var.zone},WorkerType=SELF_MANAGED_${upper(local.self_managed_node_platform)}""

    # Extra tags, needed for cluster autoscaler autodiscovery
    tags = var.cluster_autoscaler_enable ? [{
      key                 = ""k8s.io/cluster-autoscaler/enabled"",
      value               = true,
      propagate_at_launch = true
      }, {
      key                 = ""k8s.io/cluster-autoscaler/${module.eks-label.id}"",
      value               = ""owned"",
      propagate_at_launch = true
    }] : []
  }] : []

}
",module,"module ""eks"" {
  create_eks      = var.create_eks
  manage_aws_auth = false # Replaced by the auth.tf file

  #TODO Refer to internal AWS-IA module
  source  = ""terraform-aws-modules/eks/aws""
  version = ""17.1.0""

  cluster_name    = module.eks-label.id
  cluster_version = var.kubernetes_version

  # NETWORK CONFIG
  vpc_id  = var.create_vpc == false ? var.vpc_id : module.vpc.vpc_id
  subnets = var.create_vpc == false ? var.private_subnet_ids : module.vpc.private_subnets

  cluster_endpoint_private_access = var.endpoint_private_access
  cluster_endpoint_public_access  = var.endpoint_public_access

  # IRSA
  enable_irsa            = var.enable_irsa
  kubeconfig_output_path = ""./kubeconfig/""

  # TAGS
  tags = module.eks-label.tags

  # CLUSTER LOGGING
  cluster_enabled_log_types = var.enabled_cluster_log_types

  # CLUSTER ENCRYPTION
  cluster_encryption_config = [
    {
      provider_key_arn = aws_kms_key.eks.arn
      resources = [
      ""secrets""]
    }
  ]
}
",module,81,,50f6e2c2dcd3479177d5c5001732c013be2fe6de,125390ed86df57dc9d8064df92b36e14cc8eb3e2,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/50f6e2c2dcd3479177d5c5001732c013be2fe6de/eks.tf#L81,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/125390ed86df57dc9d8064df92b36e14cc8eb3e2/eks.tf,2021-08-27 00:35:58+01:00,2021-09-13 14:12:34+01:00,4,1,1,1,0,0,0,0,0,0
https://github.com/kubernetes/k8s.io,284,infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf,infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf,0,hack,// since this cloud run service is handled by https://github.com/kubernetes-sigs/oci-proxy/blob/main/hack/make-rules/deploy.sh,"// Ignore changes done on the container specification 
 // since this cloud run service is handled by https://github.com/kubernetes-sigs/oci-proxy/blob/main/hack/make-rules/deploy.sh","resource ""google_cloud_run_service"" ""regions"" {
  project  = google_project.project.project_id
  for_each = toset(var.cloud_run_regions)
  name     = ""${local.project_id}-${each.key}""
  location = each.key

  template {
    metadata {
      annotations = {
        ""autoscaling.knative.dev/maxScale"" = ""3"" // Control costs.
        ""run.googleapis.com/launch-stage""  = ""BETA""
      }
    }
    spec {
      service_account_name = google_service_account.oci-proxy.email
      containers {
        image = local.image
      }
      container_concurrency = 5
      // 30 seconds less than cloud scheduler maximum.
      timeout_seconds = 570
    }
  }

  traffic {
    percent         = 100
    latest_revision = true
  }

  depends_on = [
    google_project_service.project[""run.googleapis.com""]
  ]

  lifecycle {
    ignore_changes = [
      // This gets added by the Cloud Run API post deploy and causes diffs, can be ignored...
      template[0].metadata[0].annotations[""client.knative.dev/user-image""],
      template[0].metadata[0].annotations[""run.googleapis.com/sandbox""],
      template[0].metadata[0].annotations[""run.googleapis.com/client-name""],
      template[0].metadata[0].annotations[""run.googleapis.com/client-version""],
      // Ignore changes done on the container specification
      // since this cloud run service is handled by https://github.com/kubernetes-sigs/oci-proxy/blob/main/hack/make-rules/deploy.sh
      template[0].spec[0].containers[0],
    ]
  }
}
",resource,,,157,0.0,8219f980d204345cc624987ba6022780fefb4db5,585608eaa86847071620860d476b7fb781794e33,https://github.com/kubernetes/k8s.io/blob/8219f980d204345cc624987ba6022780fefb4db5/infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf#L157,https://github.com/kubernetes/k8s.io/blob/585608eaa86847071620860d476b7fb781794e33/infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf#L0,2022-08-05 22:03:15+02:00,2023-04-04 15:39:35-07:00,6,2,1,1,1,0,0,0,0,0
https://github.com/Azure/az-hop,51,tf/variables_local.tf,tf/variables_local.tf,0,todo,# TODO : Add mapping for names,"# VM name to list of ASGs associations 
 # TODO : Add mapping for names","locals {
    # azure environment
    azure_environment = var.AzureEnvironment
    key_vault_suffix = var.KeyVaultSuffix
    blob_storage_suffix = var.BlobStorageSuffix

    # azurerm_client_config contains empty values for Managed Identity so use variables instead
    tenant_id = var.tenant_id
    logged_user_objectId = var.logged_user_objectId

    # config files and directories
    packer_root_dir = ""${path.cwd}/packer""
    playbook_root_dir = ""${path.cwd}/playbooks""
    playbooks_template_dir = ""${path.root}/templates""
    configuration_file=""${path.cwd}/config.yml""
    configuration_yml=yamldecode(file(local.configuration_file))
    
    # Load parameters from the configuration file
    location = local.configuration_yml[""location""]
    resource_group = local.configuration_yml[""resource_group""]
    extra_tags = try(local.configuration_yml[""tags""], null)
    common_tags = {
        CreatedBy = var.CreatedBy
        CreatedOn = timestamp()
    }

    # Use a linux custom image reference if the linux_base_image is defined and contains "":""
    use_linux_image_reference = try(length(split("":"", local.configuration_yml[""linux_base_image""])[1])>0, false)
    #use_linux_image_reference = false
    # Use a linux custom image reference if the linux_base_image is defined and contains "":""
    use_windows_image_reference = try(length(split("":"", local.configuration_yml[""windows_base_image""])[1])>0, false)

    linux_base_image_reference = {
        publisher = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[0] : ""OpenLogic""
        offer     = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[1] : ""CentOS""
        sku       = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[2] : ""7_9-gen2""
        version   = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[3] : ""latest""
    }
    windows_base_image_reference = {
        publisher = local.use_linux_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[0] : ""MicrosoftWindowsServer""
        offer     = local.use_linux_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[1] : ""WindowsServer""
        sku       = local.use_linux_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[2] : ""2016-Datacenter-smalldisk""
        version   = local.use_linux_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[3] : ""latest""
    }

    # Use a linux custom image id if the linux_base_image is defined and contains ""/""
    use_linux_image_id = try(length(split(""/"", local.configuration_yml[""linux_base_image""])[1])>0, false)
    linux_image_id = local.use_linux_image_id ? local.configuration_yml[""linux_base_image""] : null

    # Use a windows custom image id if the windows_base_image is defined and contains ""/""
    use_windows_image_id = try(length(split(""/"", local.configuration_yml[""windows_base_image""])[1])>0, false)
    windows_image_id = local.use_windows_image_id ? local.configuration_yml[""windows_base_image""] : null

    _linux_base_image_plan = {}
    # _cis_image_reference = {
    #     publisher = ""center-for-internet-security-inc""
    #     offer     = ""cis-centos-7-v2-1-1-l1""
    #     sku       = ""cis-centos7-l1""
    #     version   = ""3.1.5""
    # }
    # _cis_image_plan = {
    #     name      = ""cis-centos7-l1""
    #     publisher = ""center-for-internet-security-inc""
    #     product   = ""cis-centos-7-v2-1-1-l1""
    # }

    base_image_plan = {}
    #linux_base_image_reference = local.use_linux_image_reference ? local._cis_image_reference : local._linux_base_image_reference
    #base_image_plan = local.enable_cis ? local._cis_image_plan : local._linux_base_image_plan

    # Create the RG if not using an existing RG and (creating a VNET or when reusing a VNET in another resource group)
    use_existing_rg = try(local.configuration_yml[""use_existing_rg""], false)
    create_rg = (!local.use_existing_rg) && (local.create_vnet || try(split(""/"", local.vnet_id)[4], local.resource_group) != local.resource_group)

    # ANF
    create_anf = try(local.configuration_yml[""anf""][""homefs_size_tb""] > 0, false) || try(local.configuration_yml[""homefs_size_tb""] > 0, false)

    homefs_size_tb = try(local.configuration_yml[""anf""][""homefs_size_tb""], try(local.configuration_yml[""homefs_size_tb""], 4))
    homefs_service_level = try(local.configuration_yml[""anf""][""homefs_service_level""], try(local.configuration_yml[""homefs_service_level""], ""Standard""))
    anf_dual_protocol = try(local.configuration_yml[""anf""][""dual_protocol""], try(local.configuration_yml[""dual_protocol""], false))

    homedir_mountpoint = try(local.configuration_yml[""mounts""][""home""][""mountpoint""], try(local.configuration_yml[""homedir_mountpoint""], ""/anfhome""))

    admin_username = local.configuration_yml[""admin_user""]
    key_vault_readers = try(local.configuration_yml[""key_vault_readers""], null)

    # Lustre
    lustre_archive_account = try(local.configuration_yml[""lustre""][""hsm""][""storage_account""], null)
    lustre_rbh_sku = try(local.configuration_yml[""lustre""][""rbh_sku""], ""Standard_D8d_v4"")
    lustre_mds_sku = try(local.configuration_yml[""lustre""][""mds_sku""], ""Standard_D8d_v4"")
    lustre_oss_sku = try(local.configuration_yml[""lustre""][""oss_sku""], ""Standard_D32d_v4"")
    lustre_oss_count = try(local.configuration_yml[""lustre""][""oss_count""], 2)

    # Enable Windows Remote Visualization scenarios
    enable_remote_winviz = try(local.configuration_yml[""enable_remote_winviz""], false)

    # Slurm Accounting Database
    slurm_accounting = local.enable_remote_winviz || try(local.configuration_yml[""slurm""].accounting_enabled, false)
    slurm_accounting_admin_user = ""sqladmin""
    
    # VNET
    create_vnet = try(length(local.vnet_id) > 0 ? false : true, true)
    vnet_id = try(local.configuration_yml[""network""][""vnet""][""id""], null)

    # VNET Peering
    vnet_peering = try(tolist(local.configuration_yml[""network""][""peering""]), [])

    # Lockdown scenario
    locked_down_network = try(local.configuration_yml[""locked_down_network""][""enforce""], false)
    grant_access_from   = try(local.configuration_yml[""locked_down_network""][""grant_access_from""], [])
    allow_public_ip     = try(local.configuration_yml[""locked_down_network""][""public_ip""], true)
    jumpbox_ssh_port    = try(local.configuration_yml[""jumpbox""][""ssh_port""], ""22"")
    # subnets
    _subnets = {
        ad = ""ad"",
        frontend = ""frontend"",
        admin = ""admin"",
        netapp = ""netapp"",
        compute = ""compute""
    }

    # Create subnet if required. If not specified create only if vnet is created
    create_frontend_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""frontend""][""create""], local.create_vnet )
    create_admin_subnet    = try(local.configuration_yml[""network""][""vnet""][""subnets""][""admin""][""create""], local.create_vnet )
    create_netapp_subnet   = try(local.configuration_yml[""network""][""vnet""][""subnets""][""netapp""][""create""], local.create_vnet )
    create_ad_subnet       = try(local.configuration_yml[""network""][""vnet""][""subnets""][""ad""][""create""], local.create_vnet )
    create_compute_subnet  = try(local.configuration_yml[""network""][""vnet""][""subnets""][""compute""][""create""], local.create_vnet )

    bastion_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""bastion""], null)
    no_bastion_subnet = try(length(local.bastion_subnet) > 0 ? false : true, true )
    create_bastion_subnet  = try(local.bastion_subnet[""create""], local.create_vnet )

    gateway_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""gateway""], null)
    no_gateway_subnet = try(length(local.gateway_subnet) > 0 ? false : true, true )
    create_gateway_subnet  = try(local.gateway_subnet[""create""], local.create_vnet )

    subnets = merge(local._subnets, 
                    local.no_bastion_subnet ? {} : {bastion = ""AzureBastionSubnet""},
                    local.no_gateway_subnet ? {} : {gateway = ""GatewaySubnet""}
                    )

    # Application Security Groups
    create_nsg = try(local.configuration_yml[""network""][""create_nsg""], local.create_vnet )
    # If create NSG then use the local resource group otherwise use the configured one. Default to local resource group
    asg_resource_group = local.create_nsg ? local.resource_group : try(length(local.configuration_yml[""network""][""asg""][""resource_group""]) > 0 ? local.configuration_yml[""network""][""asg""][""resource_group""] : local.resource_group, local.resource_group )

    _default_asgs = {
        asg-ssh = ""asg-ssh""
        asg-rdp = ""asg-rdp""
        asg-jumpbox = ""asg-jumpbox""
        asg-ad = ""asg-ad""
        asg-ad-client = ""asg-ad-client""
        asg-lustre = ""asg-lustre""
        asg-lustre-client = ""asg-lustre-client""
        asg-pbs = ""asg-pbs""
        asg-pbs-client = ""asg-pbs-client""
        asg-cyclecloud = ""asg-cyclecloud""
        asg-cyclecloud-client = ""asg-cyclecloud-client""
        asg-nfs-client = ""asg-nfs-client""
        asg-telegraf = ""asg-telegraf""
        asg-grafana = ""asg-grafana""
        asg-robinhood = ""asg-robinhood""
        asg-ondemand = ""asg-ondemand""
        asg-deployer = ""asg-deployer""
        asg-guacamole = ""asg-guacamole""
    }
    #asgs = local.create_nsg ? local._default_asgs :  try(local.configuration_yml[""network""][""asg""][""names""], local._default_asgs)
    asgs = try(local.configuration_yml[""network""][""asg""][""names""], local._default_asgs)
    #asgs = { for v in local.default_asgs : v => v }
    empty_array = []
    empty_map = { for v in local.empty_array : v => v }

    # VM name to list of ASGs associations
    # TODO : Add mapping for names
    asg_associations = {
        ad        = [""asg-ad"", ""asg-rdp""]
        ccportal  = [""asg-ssh"", ""asg-cyclecloud"", ""asg-telegraf"", ""asg-ad-client""]
        grafana   = [""asg-ssh"", ""asg-grafana"", ""asg-ad-client"", ""asg-telegraf"", ""asg-nfs-client""]
        jumpbox   = [""asg-ssh"", ""asg-jumpbox"", ""asg-ad-client"", ""asg-telegraf"", ""asg-nfs-client""]
        lustre    = [""asg-ssh"", ""asg-lustre"", ""asg-lustre-client"", ""asg-telegraf""]
        ondemand  = [""asg-ssh"", ""asg-ondemand"", ""asg-ad-client"", ""asg-nfs-client"", ""asg-pbs-client"", ""asg-lustre-client"", ""asg-telegraf"", ""asg-guacamole"", ""asg-cyclecloud-client""]
        robinhood = [""asg-ssh"", ""asg-robinhood"", ""asg-lustre-client"", ""asg-telegraf""]
        scheduler = [""asg-ssh"", ""asg-pbs"", ""asg-ad-client"", ""asg-cyclecloud-client"", ""asg-nfs-client"", ""asg-telegraf""]
        guacamole = [""asg-ssh"", ""asg-ad-client"", ""asg-telegraf"", ""asg-nfs-client"", ""asg-cyclecloud-client""]
    }

    # Open ports for NSG TCP rules
    # ANF and SMB https://docs.microsoft.com/en-us/azure/azure-netapp-files/create-active-directory-connections
    nsg_destination_ports = {
        All = [""0-65535""]
        Bastion = [""22"", ""3389""]
        Web = [""443"", ""80""]
        Ssh    = [""22""]
        Public_Ssh = [local.jumpbox_ssh_port]
        Socks = [""5985""]
        # DNS, Kerberos, RpcMapper, Ldap, Smb, KerberosPass, LdapSsl, LdapGc, LdapGcSsl, AD Web Services, RpcSam
        DomainControlerTcp = [""53"", ""88"", ""135"", ""389"", ""445"", ""464"", ""686"", ""3268"", ""3269"", ""9389"", ""49152-65535""]
        # DNS, Kerberos, W32Time, NetBIOS, Ldap, KerberosPass, LdapSsl
        DomainControlerUdp = [""53"", ""88"", ""123"", ""138"", ""389"", ""464"", ""686""]
        # Web, NoVNC, WebSockify
        NoVnc = [""80"", ""443"", ""5900-5910"", ""61001-61010""]
        Dns = [""53""]
        Rdp = [""3389""]
        Pbs = [""6200"", ""15001-15009"", ""17001"", ""32768-61000"", ""6817-6819""]
        Slurmd = [""6818""]
        Lustre = [""635"", ""988""]
        Nfs = [""111"", ""635"", ""2049"", ""4045"", ""4046""]
        Telegraf = [""8086""]
        Grafana = [""3000""]
        # HTTPS, AMQP
        CycleCloud = [""9443"", ""5672""],
        # MySQL
        MySQL = [""3306"", ""33060""],
        # Guacamole
        Guacamole = [""8080""]
    }

    # Array of NSG rules to be applied on the common NSG
    # NsgRuleName = [priority, direction, access, protocol, destination_port_range, source, destination]
    #   - priority               : integer value from 100 to 4096
    #   - direction              : Inbound, Outbound
    #   - access                 : Allow, Deny
    #   - protocol               : Tcp, Udp, *
    #   - destination_port_range : name of one of the nsg_destination_ports defined above
    #   - source                 : asg/<asg-name>, subnet/<subnet-name>, tag/<tag-name>. tag-name = any Azure tags like Internet, VirtualNetwork, AzureLoadBalancer, ...
    #   - destination            : same as source
    _nsg_rules = {
        # ================================================================================================================================================================
        #                          ###
        #                           #     #    #  #####    ####   #    #  #    #  #####
        #                           #     ##   #  #    #  #    #  #    #  ##   #  #    #
        #                           #     # #  #  #####   #    #  #    #  # #  #  #    #
        #                           #     #  # #  #    #  #    #  #    #  #  # #  #    #
        #                           #     #   ##  #    #  #    #  #    #  #   ##  #    #
        #                          ###    #    #  #####    ####    ####   #    #  #####
        # ================================================================================================================================================================
        # AD communication
        AllowAdServerTcpIn          = [""220"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad"",        ""asg/asg-ad-client""],
        AllowAdServerUdpIn          = [""230"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad"",        ""asg/asg-ad-client""],
        AllowAdClientTcpIn          = [""240"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad-client"", ""asg/asg-ad""],
        AllowAdClientUdpIn          = [""250"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad-client"", ""asg/asg-ad""],
        AllowAdServerComputeTcpIn   = [""260"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad"",        ""subnet/compute""],
        AllowAdServerComputeUdpIn   = [""270"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad"",        ""subnet/compute""],
        AllowAdClientComputeTcpIn   = [""280"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/compute"",    ""asg/asg-ad""],
        AllowAdClientComputeUdpIn   = [""290"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/compute"",    ""asg/asg-ad""],
        AllowAdServerNetappTcpIn    = [""300"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/netapp"",      ""asg/asg-ad""],
        AllowAdServerNetappUdpIn    = [""310"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/netapp"",      ""asg/asg-ad""],

        # SSH internal rules
        AllowSshFromJumpboxIn       = [""320"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-jumpbox"",   ""asg/asg-ssh""],
        AllowSshFromComputeIn       = [""330"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",    ""asg/asg-ssh""],
        AllowSshFromDeployerIn      = [""340"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",  ""asg/asg-ssh""], # Only in a deployer VM scenario
        AllowDeployerToPackerSshIn  = [""350"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",  ""subnet/admin""], # Only in a deployer VM scenario
        AllowSshToComputeIn         = [""360"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-ssh"",       ""subnet/compute""],
        AllowSshComputeComputeIn    = [""365"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",    ""subnet/compute""],

        # PBS
        AllowPbsIn                  = [""369"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs"",        ""asg/asg-pbs-client""],
        AllowPbsClientIn            = [""370"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs-client"", ""asg/asg-pbs""],
        AllowPbsComputeIn           = [""380"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs"",        ""subnet/compute""],
        AllowComputePbsClientIn     = [""390"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""asg/asg-pbs-client""],
        AllowComputePbsIn           = [""400"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""asg/asg-pbs""],
        AllowComputeComputePbsIn    = [""401"", ""Inbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""subnet/compute""],

        # SLURM
        AllowComputeSlurmIn         = [""405"", ""Inbound"", ""Allow"", ""*"",   ""Slurmd"",             ""asg/asg-ondemand"",    ""subnet/compute""],

        # Lustre
        AllowLustreIn               = [""409"", ""Inbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre"",        ""asg/asg-lustre-client""],
        AllowLustreClientIn         = [""410"", ""Inbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre-client"", ""asg/asg-lustre""],
        AllowLustreClientComputeIn  = [""420"", ""Inbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""subnet/compute"",        ""asg/asg-lustre""],
        AllowRobinhoodIn            = [""430"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",      ""asg/asg-robinhood""],

        # CycleCloud
        AllowCycleWebIn             = [""440"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",          ""asg/asg-cyclecloud""],
        AllowCycleClientIn          = [""450"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud-client"", ""asg/asg-cyclecloud""],
        AllowCycleClientComputeIn   = [""460"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""subnet/compute"",            ""asg/asg-cyclecloud""],
        AllowCycleServerIn          = [""465"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud"",        ""asg/asg-cyclecloud-client""],

        # OnDemand NoVNC
        AllowComputeNoVncIn         = [""470"", ""Inbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""subnet/compute"",            ""asg/asg-ondemand""],
        AllowNoVncComputeIn         = [""480"", ""Inbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""asg/asg-ondemand"",          ""subnet/compute""],

        # Telegraf / Grafana
        AllowTelegrafIn             = [""490"", ""Inbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""asg/asg-telegraf"",          ""asg/asg-grafana""],
        AllowComputeTelegrafIn      = [""500"", ""Inbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""subnet/compute"",            ""asg/asg-grafana""],
        AllowGrafanaIn              = [""510"", ""Inbound"", ""Allow"", ""Tcp"", ""Grafana"",            ""asg/asg-ondemand"",          ""asg/asg-grafana""],

        # Admin and Deployment
        AllowSocksIn                = [""520"", ""Inbound"", ""Allow"", ""Tcp"", ""Socks"",              ""asg/asg-jumpbox"",          ""asg/asg-rdp""],
        AllowRdpIn                  = [""550"", ""Inbound"", ""Allow"", ""Tcp"", ""Rdp"",                ""asg/asg-jumpbox"",          ""asg/asg-rdp""],

        # Guacamole
#        AllowGuacamoleWebIn         = [""600"", ""Inbound"", ""Allow"", ""Tcp"", ""Guacamole"",           ""asg/asg-ondemand"",          ""asg/asg-guacamole""],
        AllowGuacamoleRdpIn         = [""610"", ""Inbound"", ""Allow"", ""Tcp"", ""Rdp"",                 ""asg/asg-guacamole"",         ""subnet/compute""],

        # Deny all remaining traffic
        DenyVnetInbound             = [""3100"", ""Inbound"", ""Deny"", ""*"", ""All"",                  ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],

        # ================================================================================================================================================================
        #                            #######
        #                            #     #  #    #   #####  #####    ####   #    #  #    #  #####
        #                            #     #  #    #     #    #    #  #    #  #    #  ##   #  #    #
        #                            #     #  #    #     #    #####   #    #  #    #  # #  #  #    #
        #                            #     #  #    #     #    #    #  #    #  #    #  #  # #  #    #
        #                            #     #  #    #     #    #    #  #    #  #    #  #   ##  #    #
        #                            #######   ####      #    #####    ####    ####   #    #  #####
        # ================================================================================================================================================================
        # AD communication
        AllowAdClientTcpOut         = [""200"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad-client"", ""asg/asg-ad""],
        AllowAdClientUdpOut         = [""210"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad-client"", ""asg/asg-ad""],
        AllowAdClientComputeTcpOut  = [""220"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/compute"",    ""asg/asg-ad""],
        AllowAdClientComputeUdpOut  = [""230"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/compute"",    ""asg/asg-ad""],
        AllowAdServerTcpOut         = [""240"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad"",        ""asg/asg-ad-client""],
        AllowAdServerUdpOut         = [""250"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad"",        ""asg/asg-ad-client""],
        AllowAdServerComputeTcpOut  = [""260"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad"",        ""subnet/compute""],
        AllowAdServerComputeUdpOut  = [""270"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad"",        ""subnet/compute""],
        AllowAdServerNetappTcpOut   = [""280"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad"",        ""subnet/netapp""],
        AllowAdServerNetappUdpOut   = [""290"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad"",        ""subnet/netapp""],

        # CycleCloud
        AllowCycleServerOut         = [""300"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud"",        ""asg/asg-cyclecloud-client""],
        AllowCycleClientOut         = [""310"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud-client"", ""asg/asg-cyclecloud""],
        AllowComputeCycleClientIn   = [""320"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""subnet/compute"",            ""asg/asg-cyclecloud""],
        AllowCycleWebOut            = [""330"", ""Outbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",          ""asg/asg-cyclecloud""],

        # PBS
        AllowPbsOut                 = [""340"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs"",        ""asg/asg-pbs-client""],
        AllowPbsClientOut           = [""350"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs-client"", ""asg/asg-pbs""],
        AllowPbsComputeOut          = [""360"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""asg/asg-pbs"",        ""subnet/compute""],
        AllowPbsClientComputeOut    = [""370"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""asg/asg-pbs""],
        AllowComputePbsClientOut    = [""380"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""asg/asg-pbs-client""],
        AllowComputeComputePbsOut   = [""381"", ""Outbound"", ""Allow"", ""*"",   ""Pbs"",                ""subnet/compute"",     ""subnet/compute""],

        # SLURM
        AllowSlurmComputeOut        = [""385"", ""Outbound"", ""Allow"", ""*"",   ""Slurmd"",             ""asg/asg-ondemand"",        ""subnet/compute""],

        # Lustre
        AllowLustreOut              = [""390"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre"",           ""asg/asg-lustre-client""],
        AllowLustreClientOut        = [""400"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre-client"",    ""asg/asg-lustre""],
#        AllowLustreComputeOut       = [""410"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre"",           ""subnet/compute""],
        AllowLustreClientComputeOut = [""420"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""subnet/compute"",           ""asg/asg-lustre""],
        AllowRobinhoodOut           = [""430"", ""Outbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",         ""asg/asg-robinhood""],

        # NFS
        AllowNfsOut                 = [""440"", ""Outbound"", ""Allow"", ""*"",   ""Nfs"",                ""asg/asg-nfs-client"",       ""subnet/netapp""],
        AllowNfsComputeOut          = [""450"", ""Outbound"", ""Allow"", ""*"",   ""Nfs"",                ""subnet/compute"",           ""subnet/netapp""],

        # Telegraf / Grafana
        AllowTelegrafOut            = [""460"", ""Outbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""asg/asg-telegraf"",          ""asg/asg-grafana""],
        AllowComputeTelegrafOut     = [""470"", ""Outbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""subnet/compute"",            ""asg/asg-grafana""],
        AllowGrafanaOut             = [""480"", ""Outbound"", ""Allow"", ""Tcp"", ""Grafana"",            ""asg/asg-ondemand"",          ""asg/asg-grafana""],

        # SSH internal rules
        AllowSshFromJumpboxOut      = [""490"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-jumpbox"",          ""asg/asg-ssh""],
        AllowSshComputeOut          = [""500"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-ssh"",              ""subnet/compute""],
        AllowSshDeployerOut         = [""510"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",         ""asg/asg-ssh""],
        AllowSshDeployerPackerOut   = [""520"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",         ""subnet/admin""],
        AllowSshFromComputeOut      = [""530"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",           ""asg/asg-ssh""],
        AllowSshComputeComputeOut   = [""540"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",           ""subnet/compute""],

        # OnDemand NoVNC
        AllowComputeNoVncOut        = [""550"", ""Outbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""subnet/compute"",            ""asg/asg-ondemand""],
        AllowNoVncComputeOut        = [""560"", ""Outbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""asg/asg-ondemand"",          ""subnet/compute""],

        # Admin and Deployment
        AllowRdpOut                 = [""570"", ""Outbound"", ""Allow"", ""Tcp"", ""Rdp"",                ""asg/asg-jumpbox"",          ""asg/asg-rdp""],
        AllowSocksOut               = [""580"", ""Outbound"", ""Allow"", ""Tcp"", ""Socks"",              ""asg/asg-jumpbox"",          ""asg/asg-rdp""],
        AllowDnsOut                 = [""590"", ""Outbound"", ""Allow"", ""*"",   ""Dns"",                ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],

        # Guacamole
#        AllowGuacamoleWebOut        = [""600"", ""Outbound"", ""Allow"", ""Tcp"", ""Guacamole"",           ""asg/asg-ondemand"",         ""asg/asg-guacamole""],
        AllowGuacamoleRdpOut        = [""610"", ""Outbound"", ""Allow"", ""Tcp"", ""Rdp"",                 ""asg/asg-guacamole"",         ""subnet/compute""],

        # Deny all remaining traffic and allow Internet access
        AllowInternetOutBound       = [""3000"", ""Outbound"", ""Allow"", ""Tcp"", ""All"",               ""tag/VirtualNetwork"",       ""tag/Internet""],
        DenyVnetOutbound            = [""3100"", ""Outbound"", ""Deny"",  ""*"",   ""All"",               ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],
    }

    internet_nsg_rules = {
        AllowInternetSshIn          = [""200"", ""Inbound"", ""Allow"", ""Tcp"", ""Public_Ssh"",         ""tag/Internet"", ""asg/asg-jumpbox""], # Only when using a PIP
        AllowInternetHttpIn         = [""210"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""tag/Internet"", ""asg/asg-ondemand""], # Only when using a PIP
    }

    hub_nsg_rules = {
        AllowHubSshIn          = [""200"", ""Inbound"", ""Allow"", ""Tcp"", ""Public_Ssh"",               ""tag/VirtualNetwork"", ""asg/asg-jumpbox""],
        AllowHubHttpIn         = [""210"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                      ""tag/VirtualNetwork"", ""asg/asg-ondemand""],
    }

    bastion_nsg_rules = {
        AllowBastionIn              = [""530"", ""Inbound"", ""Allow"", ""Tcp"", ""Bastion"",            ""subnet/bastion"",           ""tag/VirtualNetwork""],
    }

    gateway_nsg_rules = {
        AllowInternalWebUsersIn     = [""540"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""subnet/gateway"",           ""asg/asg-ondemand""],
    }

    nsg_rules = merge(  local._nsg_rules, 
                        local.no_bastion_subnet ? {} : local.bastion_nsg_rules, 
                        local.no_gateway_subnet ? {} : local.gateway_nsg_rules,
                        local.allow_public_ip ? local.internet_nsg_rules : local.hub_nsg_rules)

}
",locals,"locals {
    # azure environment
    public_cloud_endpoints = {
        KeyVaultSuffix =  ""vault.azure.net""
        BlobStorageSuffix = ""blob.core.windows.net""
        FileStorageSuffix = ""file.core.windows.net""
        MariaDBPrivateLink = ""privatelink.mariadb.database.azure.com""
    }
    usgov_cloud_endpoints = {
        KeyVaultSuffix =  ""vault.usgovcloudapi.net""
        BlobStorageSuffix = ""blob.core.usgovcloudapi.net""
        FileStorageSuffix = ""file.core.usgovcloudapi.net""
        MariaDBPrivateLink = ""privatelink.mariadb.database.usgovcloudapi.net""
    }
    azure_endpoints = {
        AZUREPUBLICCLOUD = local.public_cloud_endpoints
        AZUREUSGOVERNMENTCLOUD = local.usgov_cloud_endpoints
    }
    azure_environment = var.AzureEnvironment
    key_vault_suffix = local.azure_endpoints[local.azure_environment].KeyVaultSuffix #var.KeyVaultSuffix
    blob_storage_suffix = local.azure_endpoints[local.azure_environment].BlobStorageSuffix #var.BlobStorageSuffix

    # azurerm_client_config contains empty values for Managed Identity so use variables instead
    tenant_id = var.tenant_id
    logged_user_objectId = var.logged_user_objectId

    # config files and directories
    packer_root_dir = ""${path.cwd}/packer""
    playbook_root_dir = ""${path.cwd}/playbooks""
    playbooks_template_dir = ""${path.root}/templates""
    configuration_file=""${path.cwd}/config.yml""
    configuration_yml=yamldecode(file(local.configuration_file))
    
    # Load parameters from the configuration file
    location = local.configuration_yml[""location""]
    resource_group = local.configuration_yml[""resource_group""]
    extra_tags = try(local.configuration_yml[""tags""], null)
    common_tags = {
        CreatedBy = var.CreatedBy
        CreatedOn = timestamp()
    }

    # the PUID for telemetry is meant to be unique and identifies azhop, so it should not be changed
    telem_azhop_puid  = ""58d16d1a-5b7c-11ed-8042-00155d5d7a47""

    # local to determine if the user chose to disable telemetry of azhop
    optout_telemetry = try(local.configuration_yml[""optout_telemetry""], false)

    telem_azhop_name = substr(
        format(
            ""pid-%s"",
            local.telem_azhop_puid
        ),
        0,
        64
    )

    # empty arm template to create the telemetry resource
    telem_arm_subscription_template_content = <<TEMPLATE
    {
        ""$schema"": ""https://schema.management.azure.com/schemas/2018-05-01/subscriptionDeploymentTemplate.json#"",
        ""contentVersion"": ""1.0.0.0"",
        ""parameters"": {},
        ""variables"": {},
        ""resources"": [],
        ""outputs"": {
            ""telemetry"": {
                ""type"": ""String"",
                ""value"": ""For more information, see https://azure.github.io/az-hop/deploy/telemetry.html""
            }
        }
    }
    TEMPLATE

    # Log Analytics
    create_log_analytics_workspace = try(local.configuration_yml[""log_analytics""][""create""], false)
    log_analytics_name = try(local.configuration_yml[""log_analytics""][""name""], null)
    log_analytics_resource_group = try(local.configuration_yml[""log_analytics""][""resource_group""], null)
    log_analytics_subscription_id = try(local.configuration_yml[""log_analytics""][""subscription_id""], data.azurerm_subscription.primary.subscription_id)
    log_analytics_workspace_id = try(""/subscriptions/${local.log_analytics_subscription_id}/resourceGroups/${local.log_analytics_resource_group}/providers/Microsoft.OperationalInsights/workspaces/${local.log_analytics_name}"", null)
    use_existing_ws = ( !local.create_log_analytics_workspace && local.log_analytics_workspace_id != null )  ? true : false
     
    monitor = ( local.create_log_analytics_workspace || local.use_existing_ws ) ? true : false
    ama_install = try(local.configuration_yml[""monitoring""][""azure_monitor_agent""], true) && local.monitor ? true : false
    create_grafana = try(local.configuration_yml[""monitoring""][""grafana""], true)
    create_ondemand = try(length(local.configuration_yml[""ondemand""]) > 0, false)

    alert_email = try(local.configuration_yml[""alerting""][""admin_email""], ""admin.mail@contoso.com"")

    #For alerting to be enabled - the analytics workspace needs to be created since log alerts are leveraged. 
    #We also need to ensure that we have an email to send alerts to.  
    create_alerts = local.monitor && local.alert_email != ""admin.mail@contoso.com"" && try(local.configuration_yml[""alerting""][""enabled""], false) ? true : false
    anf_vol_threshold = try(local.configuration_yml[""anf""][""alert_threshold""], 80)  # default to 80% if not specified 

    # will be used with a KQL query that checks the free space percentage of local volumes
    # if the user wants to create an alert when local volumes are 80% full, then the free space percentage should be 20%
    local_vol_threshold = 100 - try(local.configuration_yml[""alerting""][""local_volume_threshold""], 20) 

    mounts = try(local.configuration_yml[""mounts""], {})
    mountpoints =  [ for mount in local.mounts : mount.mountpoint ]
    mountpoints_str = ""[ ${join("","", [for mp in local.mountpoints : format(""%q"", mp)])} ]"" //necessary to build generic KQL query on local volumes

    # Active Directory values
    # Updates the assumptions to the possibility that DNS may not point to Active Directory when using the customer provided AD.
    create_ad             = !try(local.configuration_yml[""domain""].use_existing_dc, false) && (try(local.configuration_yml[""authentication""].user_auth, ""ad"") == ""ad"")
    use_existing_ad       = try(local.configuration_yml[""domain""].use_existing_dc, false)
    create_dns_records    = local.create_ad || local.use_existing_ad
    domain_name           = local.use_existing_ad ? local.configuration_yml[""domain""].name : ""hpc.azure""
    domain_join_user      = local.use_existing_ad ? local.configuration_yml[""domain""].domain_join_user.username : local.admin_username
    domain_join_password  = local.use_existing_ad ? data.azurerm_key_vault_secret.domain_join_password[0].value : random_password.password.result
    domain_join_ou        = local.use_existing_ad ? local.configuration_yml[""domain""].domain_join_ou : ""CN=Computers""
    ad_ha                 = try(local.configuration_yml[""ad""].high_availability, false)
    domain_controlers     = local.use_existing_ad ? zipmap(local.configuration_yml[""domain""].existing_dc_details.domain_controller_names, local.configuration_yml[""domain""].existing_dc_details.domain_controller_names) : (local.ad_ha ? {ad=local.ad_name, ad2=local.ad2_name} : {ad=local.ad_name})
    ldap_server           = local.use_existing_ad ? local.configuration_yml[""domain""].existing_dc_details.domain_controller_names[0]     : local.ad_name
    private_dns_servers   = local.use_existing_ad ? local.configuration_yml[""domain""].existing_dc_details.private_dns_servers            : (local.create_ad ? (local.ad_ha ? [azurerm_network_interface.ad-nic[0].private_ip_address, azurerm_network_interface.ad2-nic[0].private_ip_address] : [azurerm_network_interface.ad-nic[0].private_ip_address]) : [])
    domain_controller_ips = local.use_existing_ad ? local.configuration_yml[""domain""].existing_dc_details.domain_controller_ip_addresses : (local.create_ad ? (local.ad_ha ? [azurerm_network_interface.ad-nic[0].private_ip_address, azurerm_network_interface.ad2-nic[0].private_ip_address] : [azurerm_network_interface.ad-nic[0].private_ip_address]) : [])

    # private DNS 
    create_private_dns = try(local.configuration_yml[""private_dns""].create, false)
    private_dns_zone_name = try(local.configuration_yml[""private_dns""].name, ""hpc.azure"")
    private_dns_registration_enabled = try(local.configuration_yml[""private_dns""].registration_enabled, false)

    # Use a linux custom image reference if the linux_base_image is defined and contains "":""
    use_linux_image_reference = try(length(split("":"", local.configuration_yml[""linux_base_image""])[1])>0, false)
    # Use a linux custom image reference if the linux_base_image is defined and contains "":""
    use_windows_image_reference = try(length(split("":"", local.configuration_yml[""windows_base_image""])[1])>0, false)
    # Use a linux custom image reference if the linux_base_image is defined and contains "":""
    use_cyclecloud_image_reference = try(length(split("":"", local.configuration_yml[""cyclecloud""][""image""])[1])>0, false)

    linux_base_image_reference = {
        publisher = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[0] : ""OpenLogic""
        offer     = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[1] : ""CentOS""
        sku       = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[2] : ""7_9-gen2""
        version   = local.use_linux_image_reference ? split("":"", local.configuration_yml[""linux_base_image""])[3] : ""latest""
    }
    windows_base_image_reference = {
        publisher = local.use_windows_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[0] : ""MicrosoftWindowsServer""
        offer     = local.use_windows_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[1] : ""WindowsServer""
        sku       = local.use_windows_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[2] : ""2019-Datacenter-smalldisk""
        version   = local.use_windows_image_reference ? split("":"", local.configuration_yml[""windows_base_image""])[3] : ""latest""
    }
    cyclecloud_image_reference = {
        publisher = local.use_cyclecloud_image_reference ? split("":"", local.configuration_yml[""cyclecloud""][""image""])[0] : local.linux_base_image_reference.publisher
        offer     = local.use_cyclecloud_image_reference ? split("":"", local.configuration_yml[""cyclecloud""][""image""])[1] : local.linux_base_image_reference.offer
        sku       = local.use_cyclecloud_image_reference ? split("":"", local.configuration_yml[""cyclecloud""][""image""])[2] : local.linux_base_image_reference.sku
        version   = local.use_cyclecloud_image_reference ? split("":"", local.configuration_yml[""cyclecloud""][""image""])[3] : local.linux_base_image_reference.version
    }

    # Use a linux custom image id if the linux_base_image is defined and contains ""/""
    use_linux_image_id = try(length(split(""/"", local.configuration_yml[""linux_base_image""])[1])>0, false)
    linux_image_id = local.use_linux_image_id ? local.configuration_yml[""linux_base_image""] : null

    # Use a windows custom image id if the windows_base_image is defined and contains ""/""
    use_windows_image_id = try(length(split(""/"", local.configuration_yml[""windows_base_image""])[1])>0, false)
    windows_image_id = local.use_windows_image_id ? local.configuration_yml[""windows_base_image""] : null

    # Use a cyclecloud custom image id if the cyclecloud_base_image is defined and contains ""/""
    use_cyclecloud_image_id = try(length(split(""/"", local.configuration_yml[""cyclecloud""][""image""])[1])>0, false)
    cyclecloud_image_id = local.use_cyclecloud_image_id ? local.configuration_yml[""cyclecloud""][""image""] : null

    _empty_image_plan = {}
    _linux_base_image_plan = {
        publisher = try(split("":"", local.configuration_yml[""linux_base_plan""])[0], """")
        product   = try(split("":"", local.configuration_yml[""linux_base_plan""])[1], """")
        name      = try(split("":"", local.configuration_yml[""linux_base_plan""])[2], """")
    }
    linux_image_plan = try( length(local._linux_base_image_plan.publisher) > 0 ? local._linux_base_image_plan : local._empty_image_plan, local._empty_image_plan)

    _cyclecloud_image_plan = {
        publisher = try(split("":"", local.configuration_yml[""cyclecloud""][""plan""])[0], """")
        product   = try(split("":"", local.configuration_yml[""cyclecloud""][""plan""])[1], """")
        name      = try(split("":"", local.configuration_yml[""cyclecloud""][""plan""])[2], """")
    }
    cyclecloud_image_plan = try( length(local._cyclecloud_image_plan.publisher) > 0 ? local._cyclecloud_image_plan : local._empty_image_plan, local._empty_image_plan)


    # Create the RG if not using an existing RG and (creating a VNET or when reusing a VNET in another resource group)
    use_existing_rg = try(local.configuration_yml[""use_existing_rg""], false)
    create_rg = (!local.use_existing_rg) && (local.create_vnet || try(split(""/"", local.vnet_id)[4], local.resource_group) != local.resource_group)

    # ANF
    create_anf = try(local.configuration_yml[""anf""][""create""], false)
    anf_size=try(local.configuration_yml[""anf""][""homefs_size_tb""], 4)
    anf_service_level = try(local.configuration_yml[""anf""][""homefs_service_level""], ""Standard"")
    anf_dual_protocol = try(local.configuration_yml[""anf""][""dual_protocol""], false)

    #Azure Files
    create_nfsfiles = try(local.configuration_yml[""azurefiles""][""create""], false)
    azure_files_size= try(local.configuration_yml[""azurefiles""][""size_gb""], 1024)

    # Home Directory
    homedir_type = try(local.configuration_yml[""mounts""][""home""][""type""], ""existing"")
    config_nfs_home_ip = local.configuration_yml[""mounts""][""home""][""server""]
    config_nfs_home_path = local.configuration_yml[""mounts""][""home""][""export""]
    config_nfs_home_opts = local.configuration_yml[""mounts""][""home""][""options""]

    homedir_mountpoint = try(local.configuration_yml[""mounts""][""home""][""mountpoint""], ""/anfhome"")

    admin_username = local.configuration_yml[""admin_user""]
    key_vault_readers = try(local.configuration_yml[""key_vault_readers""], null)

    # Resource names
    scheduler_name = try(local.configuration_yml[""scheduler""][""name""], ""scheduler"")
    ccportal_name = try(local.configuration_yml[""cyclecloud""][""name""], ""ccportal"")
    ondemand_name = try(local.configuration_yml[""ondemand""][""name""], ""ondemand"")
    grafana_name = try(local.configuration_yml[""grafana""][""name""], ""grafana"")
    jumpbox_name = try(local.configuration_yml[""jumpbox""][""name""], ""jumpbox"")
    ad_name = try(local.configuration_yml[""ad""][""name""], ""ad"")
    ad2_name = try(local.configuration_yml[""ad""][""ha_name""], ""ad2"")

    key_vault_name = try(local.configuration_yml[""azure_key_vault""][""name""], format(""%s%s"", ""kv"", random_string.resource_postfix.result))
    storage_account_name = try(local.configuration_yml[""azure_storage_account""][""name""], ""azhop${random_string.resource_postfix.result}"")
    mariadb_name = try(local.configuration_yml[""database""][""name""], ""azhop-${random_string.resource_postfix.result}"")

    # Lustre - AMLFS not implemented for TF
    lustre_enabled = false

    # Use a jumpbox when defined
    jumpbox_enabled = try(length(local.configuration_yml[""jumpbox""]) > 0, false)

    # Queue manager
    queue_manager = try(local.configuration_yml[""queue_manager""], ""openpbs"")

    # Create Database
    create_database  = ( try(local.configuration_yml[""slurm""].accounting_enabled, false) ) && (! local.use_existing_database)
    use_existing_database = try(length(local.configuration_yml[""database""].fqdn) > 0 ? true : false, false)
    database_user = local.create_database ? ""sqladmin"" : (local.use_existing_database ? try(local.configuration_yml[""database""].user, """") : """")
    mariadb_private_dns_zone = local.azure_endpoints[local.azure_environment].MariaDBPrivateLink

    create_sig = try(local.configuration_yml[""image_gallery""][""create""], false)
    
    # VNET
    create_vnet = try(length(local.vnet_id) > 0 ? false : true, true)
    vnet_id = try(local.configuration_yml[""network""][""vnet""][""id""], null)

    # VNET Peering
    vnet_peering = try(tolist(local.configuration_yml[""network""][""peering""]), [])

    # Lockdown scenario
    locked_down_network = try(local.configuration_yml[""locked_down_network""][""enforce""], false)
    grant_access_from   = try(local.configuration_yml[""locked_down_network""][""grant_access_from""], [])
    allow_public_ip     = try(local.configuration_yml[""locked_down_network""][""public_ip""], true)
    jumpbox_ssh_port    = try(local.configuration_yml[""jumpbox""][""ssh_port""], ""22"")

    # NAT Gateway
    create_nat_gateway = try(local.configuration_yml[""nat_gateway""][""create""], false)
    nat_gateway_name = try(local.configuration_yml[""nat_gateway""][""name""], ""natgw-${random_string.resource_postfix.result}"")

    # subnets
    _subnets = {
        frontend = ""frontend"",
        admin = ""admin"",
        netapp = ""netapp"",
        compute = ""compute"",
        ad = ""ad""
    }

    # Create subnet if required. If not specified create only if vnet is created
    create_frontend_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""frontend""][""create""], local.create_vnet )
    create_admin_subnet    = try(local.configuration_yml[""network""][""vnet""][""subnets""][""admin""][""create""], local.create_vnet )
    create_netapp_subnet   = try(local.configuration_yml[""network""][""vnet""][""subnets""][""netapp""][""create""], local.create_vnet )
    create_compute_subnet  = try(local.configuration_yml[""network""][""vnet""][""subnets""][""compute""][""create""], local.create_vnet )

    ad_subnet        = try(local.configuration_yml[""network""][""vnet""][""subnets""][""ad""], null)
    no_ad_subnet     = try(length(local.ad_subnet) > 0 ? false : true, true)
    create_ad_subnet = try(local.ad_subnet[""create""], (local.create_ad ? local.create_vnet : false))

    bastion_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""bastion""], null)
    no_bastion_subnet = try(length(local.bastion_subnet) > 0 ? false : true, true )
    create_bastion_subnet  = try(local.bastion_subnet[""create""], local.create_vnet )

    gateway_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""gateway""], null)
    no_gateway_subnet = try(length(local.gateway_subnet) > 0 ? false : true, true )
    create_gateway_subnet  = try(local.gateway_subnet[""create""], local.create_vnet )

    outbounddns_subnet = try(local.configuration_yml[""network""][""vnet""][""subnets""][""outbounddns""], null)
    no_outbounddns_subnet = try(length(local.outbounddns_subnet) > 0 ? false : true, true )
    create_outbounddns_subnet  = try(local.outbounddns_subnet[""create""], local.create_vnet ? (local.no_outbounddns_subnet ? false : true) : false )

    dns_forwarders = try(local.configuration_yml[""dns""][""forwarders""], [])
    create_dnsfw_rules = length(local.dns_forwarders) > 0 ? true : false

    subnets = merge(local._subnets, 
                    local.no_bastion_subnet ? {} : {bastion = ""AzureBastionSubnet""},
                    local.no_gateway_subnet ? {} : {gateway = ""GatewaySubnet""},
                    local.no_outbounddns_subnet ? {} : {outbounddns = ""outbounddns""}
                    )

    # Application Security Groups
    create_nsg = try(local.configuration_yml[""network""][""create_nsg""], local.create_vnet )
    # If create NSG then use the local resource group otherwise use the configured one. Default to local resource group
    asg_resource_group = local.create_nsg ? local.resource_group : try(length(local.configuration_yml[""network""][""asg""][""resource_group""]) > 0 ? local.configuration_yml[""network""][""asg""][""resource_group""] : local.resource_group, local.resource_group )

    _asg_ad = {
        asg-ad = ""asg-ad""
        asg-ad-client = ""asg-ad-client""
        asg-rdp = ""asg-rdp""
     }

    _asg_grafana = {
        asg-telegraf = ""asg-telegraf""
        asg-grafana = ""asg-grafana""
    }

    _asg_ondemand = {
        asg-ondemand = ""asg-ondemand""
    }

    _asg_lustre = {
        asg-lustre-client = ""asg-lustre-client""
    }

    _asg_mariadb = {
        asg-mariadb-client = ""asg-mariadb-client""
    }

    _default_asgs = merge ({
            asg-ssh = ""asg-ssh""
            asg-jumpbox = ""asg-jumpbox""
            asg-sched = ""asg-sched""
            asg-cyclecloud = ""asg-cyclecloud""
            asg-cyclecloud-client = ""asg-cyclecloud-client""
            asg-nfs-client = ""asg-nfs-client""
            asg-deployer = ""asg-deployer""
        },
        local.create_ad || local.use_existing_ad ? local._asg_ad : {},
        local.create_grafana ? local._asg_grafana : {},
        local.create_ondemand ? local._asg_ondemand : {},
        local.lustre_enabled ? local._asg_lustre : {},
        local.create_database || local.use_existing_database ? local._asg_mariadb : {}
    )

    #asgs = local.create_nsg ? local._default_asgs :  try(local.configuration_yml[""network""][""asg""][""names""], local._default_asgs)
    asgs = try(local.configuration_yml[""network""][""asg""][""names""], local._default_asgs)
    #asgs = { for v in local.default_asgs : v => v }
    empty_array = []
    empty_map = { for v in local.empty_array : v => v }

    # VM name to list of ASGs associations
    asg_asso_ad = [""asg-ad"", ""asg-rdp"", ""asg-ad-client""] # asg-ad-client will allow the secondary DC scenario
    asg_asso_ccportal = concat([""asg-ssh"", ""asg-cyclecloud""], 
                            local.create_grafana ? [""asg-telegraf""] : [], 
                            local.create_ad || local.use_existing_ad ? [""asg-ad-client""] : [])
    asg_asso_grafana = concat([""asg-ssh"", ""asg-grafana"", ""asg-telegraf"", ""asg-nfs-client""], 
                            local.create_ad || local.use_existing_ad ? [""asg-ad-client""] : [])
    asg_asso_jumpbox = concat([""asg-ssh"", ""asg-jumpbox"" ],
                                local.create_grafana ? [""asg-telegraf""] : [])
    asg_asso_ondemand = concat([""asg-ssh"", ""asg-ondemand"", ""asg-nfs-client"", ""asg-sched"", ""asg-cyclecloud-client"" ],
                            local.create_grafana ? [""asg-telegraf""] : [],
                            local.lustre_enabled ? [""asg-lustre-client""] : [],
                            local.create_ad || local.use_existing_ad ? [""asg-ad-client""] : [])
    asg_asso_scheduler = concat([""asg-ssh"", ""asg-sched"", ""asg-cyclecloud-client"", ""asg-nfs-client""],
                            local.create_grafana ? [""asg-telegraf""] : [], 
                            local.create_ad || local.use_existing_ad ? [""asg-ad-client""] : [],
                            local.create_database || local.use_existing_database ? [""asg-mariadb-client""] : [])

    asg_associations = {
        ad        = local.asg_asso_ad 
        ccportal  = local.asg_asso_ccportal
        grafana   = local.asg_asso_grafana
        jumpbox   = local.asg_asso_jumpbox
        ondemand  = local.asg_asso_ondemand
        scheduler = local.asg_asso_scheduler
    }

    # Open ports for NSG TCP rules
    # ANF and SMB https://docs.microsoft.com/en-us/azure/azure-netapp-files/create-active-directory-connections
    nsg_destination_ports = {
        All = [""0-65535""]
        Bastion = [""22"", ""3389""]
        Web = [""443"", ""80""]
        Ssh    = [""22""]
        Public_Ssh = [local.jumpbox_ssh_port]
        # DNS, Kerberos, RpcMapper, Ldap, Smb, KerberosPass, LdapSsl, LdapGc, LdapGcSsl, AD Web Services, RpcSam
        DomainControlerTcp = [""53"", ""88"", ""135"", ""389"", ""445"", ""464"", ""636"", ""3268"", ""3269"", ""9389"", ""49152-65535""]
        # DNS, Kerberos, W32Time, NetBIOS, Ldap, KerberosPass, LdapSsl
        DomainControlerUdp = [""53"", ""88"", ""123"", ""138"", ""389"", ""464"", ""636""]
        # Web, NoVNC, WebSockify
        NoVnc = [""80"", ""443"", ""5900-5910"", ""61001-61010""]
        Dns = [""53""]
        Rdp = [""3389""]
        #Pbs = [""6200"", ""15001-15009"", ""17001"", ""32768-61000""]
        #Slurmd = [""6817-6819""]
        Sched = (local.queue_manager == ""slurm"") ? [""6817-6819""] : [""6200"", ""15001-15009"", ""17001"", ""32768-61000""]
        Lustre = [""635"", ""988""]
        Nfs = [""111"", ""635"", ""2049"", ""4045"", ""4046""]
        SMB = [""445""]
        Telegraf = [""8086""]
        Grafana = [""3000""]
        # HTTPS, AMQP
        CycleCloud = [""9443"", ""5672""],
        # MariaDB
        MariaDB = [""3306"", ""33060""],
        # WinRM
        WinRM = [""5985"", ""5986""]
    }

    #Replace the AD ASG with domain controller IP addresses when customer is bringing their own AD
    #use an indexing concept since we can't substitute a list for a string
    ad_nsg_index = local.use_existing_ad ? ""ips/dc_ips"" : ""asg/asg-ad""
    ips = {
        dc_ips = local.domain_controller_ips
    }

    # Array of NSG rules to be applied on the common NSG
    # NsgRuleName = [priority, direction, access, protocol, destination_port_range, source, destination]
    #   - priority               : integer value from 100 to 4096
    #   - direction              : Inbound, Outbound
    #   - access                 : Allow, Deny
    #   - protocol               : Tcp, Udp, *
    #   - destination_port_range : name of one of the nsg_destination_ports defined above
    #   - source                 : asg/<asg-name>, subnet/<subnet-name>, tag/<tag-name>. tag-name = any Azure tags like Internet, VirtualNetwork, AzureLoadBalancer, ...
    #   - destination            : same as source
    _nsg_rules = {
        # ================================================================================================================================================================
        #                          ###
        #                           #     #    #  #####    ####   #    #  #    #  #####
        #                           #     ##   #  #    #  #    #  #    #  ##   #  #    #
        #                           #     # #  #  #####   #    #  #    #  # #  #  #    #
        #                           #     #  # #  #    #  #    #  #    #  #  # #  #    #
        #                           #     #   ##  #    #  #    #  #    #  #   ##  #    #
        #                          ###    #    #  #####    ####    ####   #    #  #####
        # ================================================================================================================================================================

        # SSH internal rules
        AllowSshFromJumpboxIn       = [""320"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-jumpbox"",   ""asg/asg-ssh""],
        AllowSshFromComputeIn       = [""330"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",    ""asg/asg-ssh""],
        AllowSshFromDeployerIn      = [""340"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",  ""asg/asg-ssh""], # Only in a deployer VM scenario
        AllowDeployerToPackerSshIn  = [""350"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",  ""subnet/admin""], # Only in a deployer VM scenario
        AllowSshToComputeIn         = [""360"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-ssh"",       ""subnet/compute""],
        AllowSshComputeComputeIn    = [""365"", ""Inbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",    ""subnet/compute""],

        # Scheduler
        AllowSchedIn                = [""369"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-sched"",      ""asg/asg-sched""],
        #AllowPbsClientIn            = [""370"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-pbs-client"", ""asg/asg-pbs""],
        AllowSchedComputeIn         = [""380"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-sched"",      ""subnet/compute""],
        #AllowComputePbsClientIn     = [""390"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""asg/asg-pbs-client""],
        AllowComputeSchedIn         = [""400"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""asg/asg-sched""],
        AllowComputeComputeSchedIn  = [""401"", ""Inbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""subnet/compute""],

        # NFS
        AllowNfsIn                  = [""430"", ""Inbound"", ""Allow"", ""*"",   ""Nfs"",                ""asg/asg-nfs-client"",       ""subnet/netapp""],
        AllowNfsComputeIn           = [""435"", ""Inbound"", ""Allow"", ""*"",   ""Nfs"",                ""subnet/compute"",           ""subnet/netapp""],

        # CycleCloud
        AllowCycleClientIn          = [""450"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud-client"", ""asg/asg-cyclecloud""],
        AllowCycleClientComputeIn   = [""460"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""subnet/compute"",            ""asg/asg-cyclecloud""],
        AllowCycleServerIn          = [""465"", ""Inbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud"",        ""asg/asg-cyclecloud-client""],

        # Deny all remaining traffic
        DenyVnetInbound             = [""3100"", ""Inbound"", ""Deny"", ""*"", ""All"",                  ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],

        # ================================================================================================================================================================
        #                            #######
        #                            #     #  #    #   #####  #####    ####   #    #  #    #  #####
        #                            #     #  #    #     #    #    #  #    #  #    #  ##   #  #    #
        #                            #     #  #    #     #    #####   #    #  #    #  # #  #  #    #
        #                            #     #  #    #     #    #    #  #    #  #    #  #  # #  #    #
        #                            #     #  #    #     #    #    #  #    #  #    #  #   ##  #    #
        #                            #######   ####      #    #####    ####    ####   #    #  #####
        # ================================================================================================================================================================

        # CycleCloud
        AllowCycleServerOut         = [""300"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud"",        ""asg/asg-cyclecloud-client""],
        AllowCycleClientOut         = [""310"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""asg/asg-cyclecloud-client"", ""asg/asg-cyclecloud""],
        AllowComputeCycleClientIn   = [""320"", ""Outbound"", ""Allow"", ""Tcp"", ""CycleCloud"",         ""subnet/compute"",            ""asg/asg-cyclecloud""],

        # Scheduler
        AllowSchedOut               = [""340"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-sched"",      ""asg/asg-sched""],
        #AllowPbsClientOut           = [""350"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-pbs-client"", ""asg/asg-pbs""],
        AllowSchedComputeOut        = [""360"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""asg/asg-sched"",      ""subnet/compute""],
        AllowComputeSchedOut        = [""370"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""asg/asg-sched""],
        #AllowComputePbsClientOut    = [""380"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""asg/asg-pbs-client""],
        AllowComputeComputeSchedOut = [""381"", ""Outbound"", ""Allow"", ""*"",   ""Sched"",                ""subnet/compute"",     ""subnet/compute""],

        # NFS
        AllowNfsOut                 = [""440"", ""Outbound"", ""Allow"", ""*"",   ""Nfs"",                ""asg/asg-nfs-client"",       ""subnet/netapp""],
        AllowNfsComputeOut          = [""450"", ""Outbound"", ""Allow"", ""*"",   ""Nfs"",                ""subnet/compute"",           ""subnet/netapp""],

        # SMB
        AllowSMBComputeOut          = [""455"", ""Outbound"", ""Allow"", ""*"",   ""SMB"",                ""subnet/compute"",            ""subnet/netapp""],

        # SSH internal rules
        AllowSshFromJumpboxOut      = [""490"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-jumpbox"",          ""asg/asg-ssh""],
        AllowSshComputeOut          = [""500"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-ssh"",              ""subnet/compute""],
        AllowSshDeployerOut         = [""510"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",         ""asg/asg-ssh""],
        AllowSshDeployerPackerOut   = [""520"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""asg/asg-deployer"",         ""subnet/admin""],
        AllowSshFromComputeOut      = [""530"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",           ""asg/asg-ssh""],
        AllowSshComputeComputeOut   = [""540"", ""Outbound"", ""Allow"", ""Tcp"", ""Ssh"",                ""subnet/compute"",           ""subnet/compute""],

        # Admin and Deployment
        AllowDnsOut                 = [""590"", ""Outbound"", ""Allow"", ""*"",   ""Dns"",                ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],

        # Deny all remaining traffic and allow Internet access
        AllowInternetOutBound       = [""3000"", ""Outbound"", ""Allow"", ""Tcp"", ""All"",               ""tag/VirtualNetwork"",       ""tag/Internet""],
        DenyVnetOutbound            = [""3100"", ""Outbound"", ""Deny"",  ""*"",   ""All"",               ""tag/VirtualNetwork"",       ""tag/VirtualNetwork""],
    }

    internet_nsg_rules = {
        AllowInternetSshIn          = [""200"", ""Inbound"", ""Allow"", ""Tcp"", ""Public_Ssh"",         ""tag/Internet"", ""asg/asg-jumpbox""], # Only when using a PIP
        AllowInternetHttpIn         = [""210"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""tag/Internet"", ""subnet/frontend""], # Only when using a PIP
    }

    hub_nsg_rules = {
        AllowHubSshIn          = [""200"", ""Inbound"", ""Allow"", ""Tcp"", ""Public_Ssh"",               ""tag/VirtualNetwork"", ""tag/VirtualNetwork""],
        AllowHubHttpIn         = [""210"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                      ""tag/VirtualNetwork"", ""tag/VirtualNetwork""],
    }

    ad_nsg_rules = {
        # Inbound
        AllowAdServerTcpIn        = [""220"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", local.ad_nsg_index, ""asg/asg-ad-client""],
        AllowAdServerUdpIn        = [""230"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", local.ad_nsg_index, ""asg/asg-ad-client""],
        AllowAdClientTcpIn        = [""240"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad-client"", local.ad_nsg_index],
        AllowAdClientUdpIn        = [""250"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad-client"", local.ad_nsg_index],
        AllowAdServerComputeTcpIn = [""260"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", local.ad_nsg_index, ""subnet/compute""],
        AllowAdServerComputeUdpIn = [""270"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", local.ad_nsg_index, ""subnet/compute""],
        AllowAdClientComputeTcpIn = [""280"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/compute"", local.ad_nsg_index],
        AllowAdClientComputeUdpIn = [""290"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/compute"", local.ad_nsg_index],
        AllowAdServerNetappTcpIn  = [""300"", ""Inbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/netapp"", local.ad_nsg_index],
        AllowAdServerNetappUdpIn  = [""310"", ""Inbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/netapp"", local.ad_nsg_index],
        AllowWinRMIn              = [""520"", ""Inbound"", ""Allow"", ""Tcp"", ""WinRM"",              ""asg/asg-jumpbox"", ""asg/asg-rdp""],
        AllowRdpIn                = [""550"", ""Inbound"", ""Allow"", ""Tcp"", ""Rdp"",                ""asg/asg-jumpbox"", ""asg/asg-rdp""],
        AllowPackerWinRMIn        = [""560"", ""Inbound"", ""Allow"", ""Tcp"", ""WinRM"",              ""tag/VirtualNetwork"", ""subnet/compute""],

        # Outbound
        AllowAdClientTcpOut        = [""200"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""asg/asg-ad-client"", local.ad_nsg_index],
        AllowAdClientUdpOut        = [""210"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""asg/asg-ad-client"", local.ad_nsg_index],
        AllowAdClientComputeTcpOut = [""220"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", ""subnet/compute"", local.ad_nsg_index],
        AllowAdClientComputeUdpOut = [""230"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", ""subnet/compute"", local.ad_nsg_index],
        AllowAdServerTcpOut        = [""240"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", local.ad_nsg_index, ""asg/asg-ad-client""],
        AllowAdServerUdpOut        = [""250"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", local.ad_nsg_index, ""asg/asg-ad-client""],
        AllowAdServerComputeTcpOut = [""260"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", local.ad_nsg_index, ""subnet/compute""],
        AllowAdServerComputeUdpOut = [""270"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", local.ad_nsg_index, ""subnet/compute""],
        AllowAdServerNetappTcpOut  = [""280"", ""Outbound"", ""Allow"", ""Tcp"", ""DomainControlerTcp"", local.ad_nsg_index, ""subnet/netapp""],
        AllowAdServerNetappUdpOut  = [""290"", ""Outbound"", ""Allow"", ""Udp"", ""DomainControlerUdp"", local.ad_nsg_index, ""subnet/netapp""],
        AllowRdpOut                = [""570"", ""Outbound"", ""Allow"", ""Tcp"", ""Rdp"", ""asg/asg-jumpbox"", ""asg/asg-rdp""],
        AllowWinRMOut              = [""580"", ""Outbound"", ""Allow"", ""Tcp"", ""WinRM"", ""asg/asg-jumpbox"", ""asg/asg-rdp""],
    }

    bastion_nsg_rules = {
        AllowBastionIn              = [""530"", ""Inbound"", ""Allow"", ""Tcp"", ""Bastion"",            ""subnet/bastion"",           ""tag/VirtualNetwork""],
    }

    gateway_nsg_rules = {
        AllowInternalWebUsersIn     = [""540"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""subnet/gateway"",           ""asg/asg-ondemand""],
    }

    ondemand_nsg_rules = {
        # Inbound
#        AllowComputeSlurmIn         = [""405"", ""Inbound"", ""Allow"", ""*"",   ""Slurmd"",             ""asg/asg-ondemand"",    ""subnet/compute""],
        AllowCycleWebIn             = [""440"", ""Inbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",          ""asg/asg-cyclecloud""],
        AllowComputeNoVncIn         = [""470"", ""Inbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""subnet/compute"",            ""asg/asg-ondemand""],
        AllowNoVncComputeIn         = [""480"", ""Inbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""asg/asg-ondemand"",          ""subnet/compute""],
        # Outbound
        AllowCycleWebOut            = [""330"", ""Outbound"", ""Allow"", ""Tcp"", ""Web"",                ""asg/asg-ondemand"",          ""asg/asg-cyclecloud""],
#        AllowSlurmComputeOut        = [""385"", ""Outbound"", ""Allow"", ""*"",   ""Slurmd"",             ""asg/asg-ondemand"",        ""subnet/compute""],
        AllowComputeNoVncOut        = [""550"", ""Outbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""subnet/compute"",            ""asg/asg-ondemand""],
        AllowNoVncComputeOut        = [""560"", ""Outbound"", ""Allow"", ""Tcp"", ""NoVnc"",              ""asg/asg-ondemand"",          ""subnet/compute""],

    }
    grafana_nsg_rules = {
        # Telegraf / Grafana
        AllowTelegrafIn             = [""490"", ""Inbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""asg/asg-telegraf"",          ""asg/asg-grafana""],
        AllowComputeTelegrafIn      = [""500"", ""Inbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""subnet/compute"",            ""asg/asg-grafana""],
        AllowGrafanaIn              = [""510"", ""Inbound"", ""Allow"", ""Tcp"", ""Grafana"",            ""asg/asg-ondemand"",          ""asg/asg-grafana""],

        # Telegraf / Grafana
        AllowTelegrafOut            = [""460"", ""Outbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""asg/asg-telegraf"",          ""asg/asg-grafana""],
        AllowComputeTelegrafOut     = [""470"", ""Outbound"", ""Allow"", ""Tcp"", ""Telegraf"",           ""subnet/compute"",            ""asg/asg-grafana""],
        AllowGrafanaOut             = [""480"", ""Outbound"", ""Allow"", ""Tcp"", ""Grafana"",            ""asg/asg-ondemand"",          ""asg/asg-grafana""],
    }

    mariadb_nsg_rules = {
        # Inbound
        AllowMariaDBIn              = [""700"", ""Inbound"", ""Allow"", ""Tcp"", ""MariaDB"",             ""asg/asg-mariadb-client"",    ""subnet/admin""],
        # Outbound
        AllowMariaDBOut             = [""700"", ""Outbound"", ""Allow"", ""Tcp"", ""MariaDB"",             ""asg/asg-mariadb-client"",    ""subnet/admin""],
    }

    lustre_nsg_rules = {
        # Inbound
        AllowLustreClientIn         = [""410"", ""Inbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre-client"", ""subnet/admin""],
        AllowLustreClientComputeIn  = [""420"", ""Inbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""subnet/compute"",        ""subnet/admin""],
        # Outbound
        AllowLustreClientOut        = [""400"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""asg/asg-lustre-client"",    ""subnet/admin""],
        AllowLustreClientComputeOut = [""420"", ""Outbound"", ""Allow"", ""Tcp"", ""Lustre"",             ""subnet/compute"",           ""subnet/admin""],

    }
    nsg_rules = merge(  local._nsg_rules, 
                        local.create_ad || local.use_existing_ad ? local.ad_nsg_rules : {},
                        local.no_bastion_subnet ? {} : local.bastion_nsg_rules, 
                        local.no_gateway_subnet ? {} : local.gateway_nsg_rules,
                        local.allow_public_ip ? local.internet_nsg_rules : local.hub_nsg_rules,
                        local.create_grafana ? local.grafana_nsg_rules : {},
                        local.create_database || local.use_existing_database ? local.mariadb_nsg_rules : {},
                        local.create_ondemand ? local.ondemand_nsg_rules : {},
                        local.lustre_enabled ? local.lustre_nsg_rules : {}
                    )

}
",locals,174,,bfcf4909e4cbc62b1432c80a5aeafaf0c03519ad,964901a7b7f4cf3c3fcfc7b44d1c6df5a91f4f91,https://github.com/Azure/az-hop/blob/bfcf4909e4cbc62b1432c80a5aeafaf0c03519ad/tf/variables_local.tf#L174,https://github.com/Azure/az-hop/blob/964901a7b7f4cf3c3fcfc7b44d1c6df5a91f4f91/tf/variables_local.tf,2022-06-15 16:52:43+02:00,2024-02-12 17:40:00+01:00,66,1,0,1,0,1,0,0,0,0
https://github.com/aws-observability/terraform-aws-observability-accelerator,34,examples/existing-cluster-with-base-and-infra/main.tf,examples/existing-cluster-with-base-and-infra/main.tf,0,# todo,# TODO: manage with Secrets manager,# TODO: manage with Secrets manager,"module ""workloads_infra"" {
  source = ""../../workloads/infra""
  # source = ""aws-ia/terrarom-aws-observability-accelerator/workloads/infra""

  eks_cluster_id = module.eks_observability_accelerator.eks_cluster_id

  dashboards_folder_id            = module.eks_observability_accelerator.grafana_dashboards_folder_id
  managed_prometheus_workspace_id = module.eks_observability_accelerator.managed_prometheus_workspace_id

  # TODO remove when Kevin's PR is live
  managed_prometheus_workspace_endpoint = module.eks_observability_accelerator.managed_prometheus_workspace_endpoint
  managed_prometheus_workspace_region   = module.eks_observability_accelerator.managed_prometheus_workspace_region


  managed_grafana_workspace_endpoint = module.eks_observability_accelerator.managed_grafana_workspace_endpoint

  # TODO: manage with Secrets manager
  grafana_api_key = var.grafana_api_key

  # module custom configuration, check module Documentation
  # config               = {}

  # depends_on = [
  #   module.eks_observability_accelerator
  # ]
}
",module,"module ""workloads_infra"" {
  source = ""../../modules/workloads/infra""
  # source = ""aws-observability/terrarom-aws-observability-accelerator/workloads/infra""

  eks_cluster_id = module.eks_observability_accelerator.eks_cluster_id

  dashboards_folder_id            = module.eks_observability_accelerator.grafana_dashboards_folder_id
  managed_prometheus_workspace_id = module.eks_observability_accelerator.managed_prometheus_workspace_id

  managed_prometheus_workspace_endpoint = module.eks_observability_accelerator.managed_prometheus_workspace_endpoint
  managed_prometheus_workspace_region   = module.eks_observability_accelerator.managed_prometheus_workspace_region

  enable_alerting_rules = false

  tags = local.tags

  depends_on = [
    module.eks_observability_accelerator
  ]
}
",module,97,,6dca51b135de9dae7aa62a61e7eebc9895c27412,05511992e9cc5b9fdd5c3ba59e30704d78fadda3,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/6dca51b135de9dae7aa62a61e7eebc9895c27412/examples/existing-cluster-with-base-and-infra/main.tf#L97,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/05511992e9cc5b9fdd5c3ba59e30704d78fadda3/examples/existing-cluster-with-base-and-infra/main.tf,2022-08-26 17:30:03+02:00,2022-08-30 19:59:34+02:00,7,1,0,1,0,1,0,0,1,0
https://github.com/Azure/Avere,21,src/terraform/modules/hammerspace/anvil/main.tf,src/terraform/modules/hammerspace/anvil/main.tf,0,todo,"// TODO - need ""loadBalancerBackendAddressPools"": ""[if(variables('highAvailability'), variables('lbPools'), json('null'))]""","// TODO - need ""loadBalancerBackendAddressPools"": ""[if(variables('highAvailability'), variables('lbPools'), json('null'))]""","resource ""azurerm_network_interface"" ""anvildata"" {
  count               = local.anvil_node_count
  name                = ""${local.anvil_host_names[count.index]}-datanic""
  location            = var.location
  resource_group_name = var.resource_group_name

  ip_configuration {
    name                          = ""${var.unique_name}-ipconfig""
    primary                       = true
    private_ip_address_allocation = local.is_high_availability || local.anvil_dynamic_cluster_ip ? ""Dynamic"" : ""Static""
    private_ip_address            = local.is_high_availability || local.anvil_dynamic_cluster_ip ? null : var.anvil_data_cluster_ip
    subnet_id                     = data.azurerm_subnet.data_subnet.id
    // TODO - need ""loadBalancerBackendAddressPools"": ""[if(variables('highAvailability'), variables('lbPools'), json('null'))]""
  }
}
",resource,"resource ""azurerm_network_interface"" ""anvildata"" {
  count               = local.anvil_node_count
  name                = ""${local.anvil_host_names[count.index]}-datanic""
  location            = var.location
  resource_group_name = var.resource_group_name

  ip_configuration {
    name                          = ""${var.unique_name}-ipconfig""
    primary                       = true
    private_ip_address_allocation = local.is_high_availability || local.anvil_dynamic_cluster_ip ? ""Dynamic"" : ""Static""
    private_ip_address            = local.is_high_availability || local.anvil_dynamic_cluster_ip ? null : var.anvil_data_cluster_ip
    subnet_id                     = data.azurerm_subnet.data_subnet.id
  }
}
",resource,167,,47847b35c4a7b8d24584e2c9690ea7a41d5bc3f1,a64c98d189a8f44b087f399cfa0864ecef7b3eeb,https://github.com/Azure/Avere/blob/47847b35c4a7b8d24584e2c9690ea7a41d5bc3f1/src/terraform/modules/hammerspace/anvil/main.tf#L167,https://github.com/Azure/Avere/blob/a64c98d189a8f44b087f399cfa0864ecef7b3eeb/src/terraform/modules/hammerspace/anvil/main.tf,2021-03-02 06:48:40-05:00,2021-05-02 10:11:01-04:00,7,1,0,1,0,0,1,0,0,0
https://github.com/deckhouse/deckhouse,8,candi/cloud-providers/aws/terraform-modules/static-node/main.tf,candi/cloud-providers/aws/terraform-modules/static-node/main.tf,0,#todo,#TODO: remove ignore after we enable automatic converge for master nodes,#TODO: remove ignore after we enable automatic converge for master nodes,"resource ""aws_instance"" ""node"" {
  ami             = var.node_group.instanceClass.ami
  instance_type   = var.node_group.instanceClass.instanceType
  key_name        = var.prefix
  subnet_id       = local.zone_to_subnet_id_map[local.zone]
  vpc_security_group_ids = concat([data.aws_security_group.node.id], var.additional_security_groups)
  source_dest_check = false
  associate_public_ip_address = var.associate_public_ip_address
  user_data = var.cloud_config == """" ? """" : base64decode(var.cloud_config)
  iam_instance_profile = ""${var.prefix}-node""

  root_block_device {
    volume_size = var.root_volume_size
    volume_type = var.root_volume_type
  }

  tags = merge(var.tags, {
    Name = ""${var.prefix}-${var.node_group.name}-${var.node_index}""
    ""kubernetes.io/cluster/${var.cluster_uuid}"" = ""shared""
    ""kubernetes.io/cluster/${var.prefix}"" = ""shared""
  })

  lifecycle {
    ignore_changes = [
      user_data,
      ebs_optimized,
      #TODO: remove ignore after we enable automatic converge for master nodes
      volume_tags
    ]
  }
}
",resource,"resource ""aws_instance"" ""node"" {
  ami             = var.node_group.instanceClass.ami
  instance_type   = var.node_group.instanceClass.instanceType
  key_name        = var.prefix
  subnet_id       = local.zone_to_subnet_id_map[local.zone]
  vpc_security_group_ids = concat([data.aws_security_group.node.id], var.additional_security_groups)
  source_dest_check = false
  associate_public_ip_address = var.associate_public_ip_address
  user_data = var.cloud_config == """" ? """" : base64decode(var.cloud_config)
  iam_instance_profile = ""${var.prefix}-node""

  root_block_device {
    volume_size = var.root_volume_size
    volume_type = var.root_volume_type
    tags        = var.tags
  }

  tags = merge(var.tags, {
    Name = ""${var.prefix}-${var.node_group.name}-${var.node_index}""
    ""kubernetes.io/cluster/${var.cluster_uuid}"" = ""shared""
    ""kubernetes.io/cluster/${var.prefix}"" = ""shared""
  })

  lifecycle {
    ignore_changes = [
      # user_data in our case is node bootstrap.sh template, which depends on kubernetes version, registry, etc. If we do not suppress
      # user_data, the state of the terraform will change when we change the cluster parameters.
      # how aws calculates user_data:
      # root@kube-master-1:~# curl 169.254.169.254/latest/user-data 2>/dev/null | shasum
      # 3539ff5cb43fb326f4faa6fa5d5aeb9dec1ea141
      user_data,
      # https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance#user_data_replace_on_change
      # When used in combination with user_data or user_data_base64 will trigger a destroy and recreate when set to true. Defaults to false if not set.
      # In older versions of terraform-provider-aws this parameter was absent, so now terraform tries to add them.
      # we ignore user_data_replace_on_change to avoid manual converge.
      user_data_replace_on_change,
      ebs_optimized,
      #TODO: remove ignore after we enable automatic converge for master nodes
      volume_tags
    ]
  }
}
",resource,64,75.0,7c8069ef5a8cae87abcc96f543bda7020574bf94,5b2588e32e8e305e7ad57826fc61ab3aaa7f71a1,https://github.com/deckhouse/deckhouse/blob/7c8069ef5a8cae87abcc96f543bda7020574bf94/candi/cloud-providers/aws/terraform-modules/static-node/main.tf#L64,https://github.com/deckhouse/deckhouse/blob/5b2588e32e8e305e7ad57826fc61ab3aaa7f71a1/candi/cloud-providers/aws/terraform-modules/static-node/main.tf#L75,2021-10-07 23:56:05+03:00,2023-08-29 11:21:50+03:00,3,0,1,1,0,0,0,0,0,0
https://github.com/Azure/sap-automation,7,deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf,deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf,0,// todo,// TODO: Example Documentation block follows:,"/* 
 Description: 
  
 Define infrastructure resources for deployer(s). 
 */  
 // TODO: Example Documentation block follows:   
 /*--------------------------------------+---------------------------------------* 
 *                                                                               * 
 *                                RESOURCE GROUPS                                * 
 *                                                                               * 
 *---------------------------------------4---------------------------------------8 
 Function: 
 Creates a Resorce Group. 
  
 Description: 
 Resorce Group in which to group all the Resources that are deployed for the 
 Deployer in this unit of execution. 
  
 Usage: 
  
 local.enable_deployers 
 Variable                  : local.enable_deployers [true|false] derived from local.deployer_input based on legnth greater than zero 
 Variable                  : local.deployer_input is a copy of var.defaults 
 Variable                  : var.defaults defined empty 
 Module Caller             : Pass var.deployers object into module 
 Input                     : Any overrides are inserted (JSON or TFVARS) 
 Main                      : Defines empty var.deployers object [{}] 
  
  
 local.rg_name 
 Variable                  : local.rg_name derived from default format(""%s%s"", local.prefix, local.resource_suffixes.deployer_rg) or overridden with var.infrastructure.resource_group.name 
 Override) 
 Variable              : var.infrastructure.resource_group.name is contained in var.infrastructure.resource_group 
 Variable              : var.infrastructure.resource_group is contained in var.infrastructure 
 Variable              : var.infrastructure defined empty 
 Module Caller         : Pass var.infrastructure object into module as infrastructure 
 Input                 : Any overrides are inserted (JSON or TFVARS) 
 Main                  : Defines empty var.infrastructure object {} 
  
 Default) 
 1)  Variable          : local.prefix derived from var.infrastructure.resource_group.name if present in JSON, otherwise default to var.naming.prefix.DEPLOYER 
 Override) 
 Variable        : var.infrastructure.resource_group.name is contained in var.infrastructure.resource_group 
 Variable        : var.infrastructure.resource_group is contained in var.infrastructure 
 Variable        : var.infrastructure defined empty 
 Module Caller   : Pass var.infrastructure object into module 
 Input           : Any overrides are inserted (JSON or TFVARS) 
 Main            : Defines empty var.infrastructure object {} 
  
 Default) 
 Variable        : var.naming.prefix.DEPLOYER is contained in var.naming.prefix 
 Variable        : var.naming.prefix is contained in var.naming 
 Variable        : var.naming defined empty 
 Module Caller   : Pass module.sap_namegenerator.naming object into module as naming 
  
 2)  Variable          : local.resource_suffixes.deployer_rg is an object contained in local.resource_suffixes 
 Variable          : local.resource_suffixes is a copy of var.naming.resource_suffixes 
 Variable          : var.naming.resource_suffixes is contained in var.naming 
 Variable          : var.naming defined empty 
 Module Caller     : Pass module.sap_namegenerator.naming object into module as naming 
  
  
 local.region 
 Variable                  : local.region derived from var.infrastructure.region 
 Variable                  : var.infrastructure.region is contained in var.infrastructure 
 Variable                  : var.infrastructure defined empty 
 Module Caller             : Pass var.infrastructure object into module as infrastructure 
 Input                     : Required INPUT parameter (JSON or TFVARS) 
 Main                      : Defines empty var.infrastructure object {} 
 */ ","resource ""azurerm_resource_group"" ""deployer"" {
  count    = local.enable_deployers && !local.rg_exists ? 1 : 0
  name     = local.rg_name
  location = local.region
  tags     = var.infrastructure.tags

  lifecycle {
    ignore_changes = [
      tags
    ]
  }

}
",resource,"resource ""azurerm_resource_group"" ""deployer"" {
  count                                = !local.resource_group_exists ? 1 : 0
  name                                 = local.resourcegroup_name
  location                             = var.infrastructure.region
  tags                                 = var.infrastructure.tags

  lifecycle {
              ignore_changes = [
                tags
              ]
            }

}
",resource,7,7.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,db20ac2a47d9d00329385330cb4af6b3c726c400,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf#L7,https://github.com/Azure/sap-automation/blob/db20ac2a47d9d00329385330cb4af6b3c726c400/deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf#L7,2021-11-17 19:29:07+02:00,2024-03-11 23:15:11+05:30,24,0,0,1,0,0,0,0,0,0
https://github.com/Azure/sap-automation,20,deploy/terraform/terraform-units/modules/sap_library/storage_accounts.tf,deploy/terraform/terraform-units/modules/sap_library/storage_accounts.tf,0,fix,#ToDo Fix later,#ToDo Fix later,"resource ""azurerm_key_vault_secret"" ""saplibrary_access_key"" {
  provider     = azurerm.deployer
  count        = length(local.deployer_kv_user_arm_id) > 0 ? 1 : 0
  name         = ""sapbits-access-key""
  value        = local.sa_sapbits_exists ? data.azurerm_storage_account.storage_sapbits[0].primary_access_key : azurerm_storage_account.storage_sapbits[0].primary_access_key
  key_vault_id = local.deployer_kv_user_arm_id
}
",resource,"resource ""azurerm_key_vault_secret"" ""saplibrary_access_key"" {
  provider = azurerm.deployer
  count    = length(local.deployer_kv_user_arm_id) > 0 ? 1 : 0
  name     = ""sapbits-access-key""
  value = local.sa_sapbits_exists ? (
    data.azurerm_storage_account.storage_sapbits[0].primary_access_key) : (
    azurerm_storage_account.storage_sapbits[0].primary_access_key
  )
  key_vault_id = local.deployer_kv_user_arm_id
}
",resource,193,,6ff0b891114c36d3aeccb850d830b698cd1fe52a,0492ee8d72aec4579718e357853c13cfb0a7dc16,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_library/storage_accounts.tf#L193,https://github.com/Azure/sap-automation/blob/0492ee8d72aec4579718e357853c13cfb0a7dc16/deploy/terraform/terraform-units/modules/sap_library/storage_accounts.tf,2021-11-17 19:29:07+02:00,2022-04-08 14:42:32+03:00,9,1,0,1,0,1,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,249,modules/extensions/gatekeeper.tf,modules/extensions/gatekeeper.tf,0,todo,# TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593,# TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593,"data ""helm_template"" ""gatekeeper"" {
  count        = local.gatekeeper_enabled ? 1 : 0
  chart        = ""gatekeeper""
  repository   = ""https://open-policy-agent.github.io/gatekeeper/charts""
  version      = var.gatekeeper_helm_version
  kube_version = var.kubernetes_version

  name             = ""gatekeeper""
  namespace        = var.gatekeeper_namespace
  create_namespace = true
  include_crds     = true
  skip_tests       = true
  values = length(var.gatekeeper_helm_values_files) > 0 ? [
    for path in var.gatekeeper_helm_values_files : file(path)
  ] : null

  # TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593
  set {
    name  = ""postInstall.labelNamespace.enabled""
    value = ""false""
  }

  # TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593
  set {
    name  = ""postInstall.probeWebhook.enabled""
    value = ""false""
  }

  dynamic ""set"" {
    for_each = var.gatekeeper_helm_values
    iterator = helm_value
    content {
      name  = helm_value.key
      value = helm_value.value
    }
  }

  lifecycle {
    precondition {
      condition = alltrue([for path in var.gatekeeper_helm_values_files : fileexists(path)])
      error_message = format(""Missing Helm values files in configuration: %s"",
        jsonencode([for path in var.gatekeeper_helm_values_files : path if !fileexists(path)])
      )
    }
  }
}
",data,"data ""helm_template"" ""gatekeeper"" {
  count        = local.gatekeeper_enabled ? 1 : 0
  chart        = ""gatekeeper""
  repository   = ""https://open-policy-agent.github.io/gatekeeper/charts""
  version      = var.gatekeeper_helm_version
  kube_version = var.kubernetes_version

  name             = ""gatekeeper""
  namespace        = var.gatekeeper_namespace
  create_namespace = true
  include_crds     = true
  skip_tests       = true
  values = length(var.gatekeeper_helm_values_files) > 0 ? [
    for path in var.gatekeeper_helm_values_files : file(path)
  ] : null

  # TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593
  set {
    name  = ""postInstall.labelNamespace.enabled""
    value = ""false""
  }

  # TODO Remove after merge: https://github.com/open-policy-agent/gatekeeper/pull/2593
  set {
    name  = ""postInstall.probeWebhook.enabled""
    value = ""false""
  }

  dynamic ""set"" {
    for_each = var.gatekeeper_helm_values
    iterator = helm_value
    content {
      name  = helm_value.key
      value = helm_value.value
    }
  }

  lifecycle {
    precondition {
      condition = alltrue([for path in var.gatekeeper_helm_values_files : fileexists(path)])
      error_message = format(""Missing Helm values files in configuration: %s"",
        jsonencode([for path in var.gatekeeper_helm_values_files : path if !fileexists(path)])
      )
    }
  }
}
",data,32,32.0,79845fb791998bdde1b58fa656b6c381f7d26510,03cb7854e38bd5f3051907a9ea9add7083b831c1,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/79845fb791998bdde1b58fa656b6c381f7d26510/modules/extensions/gatekeeper.tf#L32,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/03cb7854e38bd5f3051907a9ea9add7083b831c1/modules/extensions/gatekeeper.tf#L32,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,4,0,1,1,0,0,0,0,0,0
https://github.com/CDCgov/prime-simplereport,6,ops/services/app_functions/report_stream_batched_publisher/main.tf,ops/services/app_functions/report_stream_batched_publisher/infra/main.tf,1,# todo,### TODO: Figure out the KeyVault permissioning issue that prevents this reference from working,"### TODO: Figure out the KeyVault permissioning issue that prevents this reference from working 
 # REPORT_STREAM_TOKEN            = ""@Microsoft.KeyVault(SecretUri=${data.azurerm_key_vault_secret.datahub_api_key.id})""","resource ""azurerm_function_app"" ""functions"" {
  name                       = ""${var.prefix}-${var.environment}""
  location                   = var.location
  resource_group_name        = local.resource_group_name
  app_service_plan_id        = azurerm_app_service_plan.asp.id
  storage_account_name       = data.azurerm_storage_account.app.name
  storage_account_access_key = data.azurerm_storage_account.app.primary_access_key
  https_only                 = true
  version                    = ""~3""
  os_type                    = ""linux""
  site_config {
    linux_fx_version          = ""node|14""
    use_32_bit_worker_process = false
  }

  app_settings = {
    https_only                     = true
    FUNCTIONS_WORKER_RUNTIME       = ""node""
    WEBSITE_NODE_DEFAULT_VERSION   = ""~14""
    FUNCTION_APP_EDIT_MODE         = ""readonly""
    HASH                           = ""${base64encode(filesha256(""${var.function_app_source}""))}""
    WEBSITE_RUN_FROM_PACKAGE       = ""https://${data.azurerm_storage_account.app.name}.blob.core.windows.net/${azurerm_storage_container.deployments.name}/${azurerm_storage_blob.appcode.name}${data.azurerm_storage_account_sas.sas.sas}""
    APPINSIGHTS_INSTRUMENTATIONKEY = data.azurerm_application_insights.app.instrumentation_key
    AZ_STORAGE_QUEUE_SVC_URL       = ""https://${data.azurerm_storage_account.app.name}.queue.core.windows.net/""
    AZ_STORAGE_ACCOUNT_NAME        = data.azurerm_storage_account.app.name
    AZ_STORAGE_ACCOUNT_KEY         = data.azurerm_storage_account.app.primary_access_key
    TEST_EVENT_QUEUE_NAME          = var.test_event_queue_name
    REPORT_STREAM_URL              = local.report_stream_url
    ### TODO: Figure out the KeyVault permissioning issue that prevents this reference from working
    # REPORT_STREAM_TOKEN            = ""@Microsoft.KeyVault(SecretUri=${data.azurerm_key_vault_secret.datahub_api_key.id})""
    REPORT_STREAM_TOKEN         = var.report_stream_api_token
    REPORT_STREAM_BATCH_MINIMUM = ""1""
    REPORT_STREAM_BATCH_MAXIMUM = ""5000""
  }
}
",resource,"resource ""azurerm_function_app"" ""functions"" {
  name                       = ""${var.prefix}-${var.environment}""
  location                   = var.location
  resource_group_name        = local.resource_group_name
  app_service_plan_id        = azurerm_app_service_plan.asp.id
  storage_account_name       = data.azurerm_storage_account.app.name
  storage_account_access_key = data.azurerm_storage_account.app.primary_access_key
  https_only                 = true
  version                    = ""~3""
  os_type                    = ""linux""
  site_config {
    linux_fx_version          = ""node|14""
    use_32_bit_worker_process = false
  }

  identity {
    type = ""SystemAssigned""
  }

  app_settings = {
    https_only                                           = true
    FUNCTIONS_WORKER_RUNTIME                             = ""node""
    WEBSITE_NODE_DEFAULT_VERSION                         = ""~14""
    FUNCTION_APP_EDIT_MODE                               = ""readonly""
    HASH                                                 = ""${base64encode(filesha256(""${local.function_app_source}""))}""
    WEBSITE_RUN_FROM_PACKAGE                             = ""https://${data.azurerm_storage_account.app.name}.blob.core.windows.net/${azurerm_storage_container.deployments.name}/${azurerm_storage_blob.appcode.name}${data.azurerm_storage_account_sas.sas.sas}""
    APPINSIGHTS_INSTRUMENTATIONKEY                       = data.azurerm_application_insights.app.instrumentation_key
    AZ_STORAGE_QUEUE_SVC_URL                             = ""https://${data.azurerm_storage_account.app.name}.queue.core.windows.net/""
    AZ_STORAGE_ACCOUNT_NAME                              = data.azurerm_storage_account.app.name
    AZ_STORAGE_ACCOUNT_KEY                               = data.azurerm_storage_account.app.primary_access_key
    AZ_STORAGE_QUEUE_CXN_STRING                          = data.azurerm_storage_account.app.primary_connection_string
    TEST_EVENT_QUEUE_NAME                                = var.test_event_queue_name
    REPORTING_EXCEPTION_QUEUE_NAME                       = var.reporting_exception_queue_name
    REPORT_STREAM_URL                                    = local.report_stream_url
    REPORT_STREAM_TOKEN                                  = ""@Microsoft.KeyVault(SecretUri=${data.azurerm_key_vault_secret.datahub_api_key.id})""
    REPORT_STREAM_BATCH_MINIMUM                          = var.report_stream_batch_minimum
    REPORT_STREAM_BATCH_MAXIMUM                          = var.report_stream_batch_maximum
    SIMPLE_REPORT_CB_URL                                 = local.simple_report_callback_url
    SIMPLE_REPORT_CB_TOKEN                               = ""@Microsoft.KeyVault(SecretUri=${data.azurerm_key_vault_secret.simple_report_callback_token.id})""
    ""AzureWebJobs.ReportStreamExceptionHandler.Disabled"" = ""1""
  }
}
",resource,65,,c5666e6b48724d4b80ed9dfcf43c30c5c2361d26,0bf22d422d33072bea31abc40b60e6affe808843,https://github.com/CDCgov/prime-simplereport/blob/c5666e6b48724d4b80ed9dfcf43c30c5c2361d26/ops/services/app_functions/report_stream_batched_publisher/main.tf#L65,https://github.com/CDCgov/prime-simplereport/blob/0bf22d422d33072bea31abc40b60e6affe808843/ops/services/app_functions/report_stream_batched_publisher/infra/main.tf,2021-09-27 17:00:55-07:00,2022-02-17 16:45:15-06:00,6,1,1,1,0,1,0,0,0,0
https://github.com/gruntwork-io/terraform-aws-utilities,1,modules/require-executable/main.tf,modules/require-executable/main.tf,0,fix,# TODO: Once the issue is fixed. Update the version constraint to the latest non-breaking version.,"# Updating the Terraform external provider to 2.3.0 caused an undocumented breaking change (as evidenced by 
 # issues like https://github.com/hashicorp/terraform-provider-external/issues/193). The solution is to pin 
 # the version to a working version for now. 
 # Special thanks to Lorelei Rupp for reporting and discovering the root cause of this issue! 
 # TODO: Once the issue is fixed. Update the version constraint to the latest non-breaking version.","terraform {
  # This module is now only being tested with Terraform 1.1.x. However, to make upgrading easier, we are setting 1.0.0 as the minimum version.
  required_version = "">= 1.0.0""

  # Updating the Terraform external provider to 2.3.0 caused an undocumented breaking change (as evidenced by
  # issues like https://github.com/hashicorp/terraform-provider-external/issues/193). The solution is to pin 
  # the version to a working version for now. 
  # Special thanks to Lorelei Rupp for reporting and discovering the root cause of this issue!
  # TODO: Once the issue is fixed. Update the version constraint to the latest non-breaking version.
  required_providers {
    external = {
      source  = ""hashicorp/external""
      version = ""= 2.2.3""
    }
  }
}
",terraform,"terraform {
  required_version = "">= 1.0.0""

  # Updating the Terraform external provider to 2.3.0 caused an undocumented breaking change (as evidenced by
  # issues like https://github.com/hashicorp/terraform-provider-external/issues/193). The solution is to pin 
  # the version to a working version for now. 
  # Special thanks to Lorelei Rupp for reporting and discovering the root cause of this issue!
  # TODO: Once the issue is fixed. Update the version constraint to the latest non-breaking version.
  required_providers {
    external = {
      source  = ""hashicorp/external""
      version = ""= 2.2.3""
    }
  }
}
",terraform,9,8.0,63b1195794b0ce24d6b225e2ef66579ca52b6d43,6d1f4a3752365cc2385fcb39b970830c7f2e9861,https://github.com/gruntwork-io/terraform-aws-utilities/blob/63b1195794b0ce24d6b225e2ef66579ca52b6d43/modules/require-executable/main.tf#L9,https://github.com/gruntwork-io/terraform-aws-utilities/blob/6d1f4a3752365cc2385fcb39b970830c7f2e9861/modules/require-executable/main.tf#L8,2023-03-06 11:06:57-08:00,2023-10-12 10:02:56-07:00,3,0,0,1,1,0,0,0,0,0
https://github.com/Worklytics/psoxy,50,infra/dev-personal/main.tf,infra/dev-personal/main.tf,0,# todo,# TODO: recommend migrate this to `PSOXY_{{function_name}}_SERVICE_ACCOUNT_KEY`,# TODO: recommend migrate this to `PSOXY_{{function_name}}_SERVICE_ACCOUNT_KEY`,"module ""gmail-connector-auth"" {
  source = ""../modules/gcp-sa-auth-key-secret-manager""

  secret_project     = var.project_id
  service_account_id = module.gmail-connector.service_account_id

  # TODO: recommend migrate this to `PSOXY_{{function_name}}_SERVICE_ACCOUNT_KEY`
  secret_id          = ""PSOXY_SERVICE_ACCOUNT_KEY_gmail""
}
",module,the block associated got renamed or deleted,,58,,af784896e86a12e0451ed698b442510ecb8a0247,be4c88f8f355dd5eb600247c31f7d10da4573c44,https://github.com/Worklytics/psoxy/blob/af784896e86a12e0451ed698b442510ecb8a0247/infra/dev-personal/main.tf#L58,https://github.com/Worklytics/psoxy/blob/be4c88f8f355dd5eb600247c31f7d10da4573c44/infra/dev-personal/main.tf,2021-10-25 12:09:30-07:00,2022-02-04 13:14:46-08:00,10,1,0,1,0,1,0,0,0,0
https://github.com/SUSE/ha-sap-terraform-deployments,207,libvirt/terraform/modules/host/main.tf,libvirt/terraform/modules/host/main.tf,0,hack,// hack: for monitoring module we don't have an additional_disk so just add the main.disk volume otherwise HCL breaks,// hack: for monitoring module we don't have an additional_disk so just add the main.disk volume otherwise HCL breaks,"resource ""libvirt_domain"" ""domain"" {
  name       = ""${terraform.workspace}-${var.name}${var.host_count > 1 ? ""-${count.index + 1}"" : """"}""
  memory     = var.memory
  vcpu       = var.vcpu
  count      = var.host_count
  qemu_agent = true
   dynamic ""disk"" {
    for_each = [
        {
          ""vol_id"" = element(libvirt_volume.main_disk.*.id, count.index)
        },
        {
          ""vol_id"" = element(libvirt_volume.hana_disk.*.id, count.index)
        },
        {
         // hack: for monitoring module we don't have an additional_disk so just add the main.disk volume otherwise HCL breaks
         ""vol_id"" = length(var.additional_disk) > 0 ? lookup(element(var.additional_disk, 0), ""volume_id"", null) :  element(libvirt_volume.main_disk.*.id, count.index)
        },
      ]
    content {
      volume_id = disk.value.vol_id
    }
  }

  network_interface {
    wait_for_lease = true
    network_name   = var.base_configuration[""network_name""]
    bridge         = var.base_configuration[""bridge""]
    mac            = var.mac
  }

  network_interface {
    wait_for_lease = false
    network_id     = var.base_configuration[""isolated_network_id""]
    hostname       = ""${var.name}${var.host_count > 1 ? ""0${count.index + 1}"" : """"}""
    addresses      = [element(var.host_ips, count.index)]
  }

  xml {
    xslt = file(""modules/host/shareable.xsl"")
  }

  console {
    type        = ""pty""
    target_port = ""0""
    target_type = ""serial""
  }

  console {
    type        = ""pty""
    target_type = ""virtio""
    target_port = ""1""
  }

  graphics {
    type        = ""spice""
    listen_type = ""address""
    autoport    = true
  }

  cpu = {
    mode = ""host-passthrough""
  }
}
",resource,"resource ""libvirt_domain"" ""domain"" {
  name       = ""${terraform.workspace}-${var.name}${var.host_count > 1 ? ""-${count.index + 1}"" : """"}""
  memory     = var.memory
  vcpu       = var.vcpu
  count      = var.host_count
  qemu_agent = true
   dynamic ""disk"" {
    for_each = [
        {
          ""vol_id"" = element(libvirt_volume.main_disk.*.id, count.index)
        },
        {
          ""vol_id"" = element(libvirt_volume.hana_disk.*.id, count.index)
        },
      ]
    content {
      volume_id = disk.value.vol_id
    }
  }
  // handle additional disks
  dynamic ""disk"" {
   for_each = var.additional_disk
   content {
     volume_id = disk.value.volume_id
   }
  }

  network_interface {
    wait_for_lease = true
    network_name   = var.base_configuration[""network_name""]
    bridge         = var.base_configuration[""bridge""]
    mac            = var.mac
  }

  network_interface {
    wait_for_lease = false
    network_id     = var.base_configuration[""isolated_network_id""]
    hostname       = ""${var.name}${var.host_count > 1 ? ""0${count.index + 1}"" : """"}""
    addresses      = [element(var.host_ips, count.index)]
  }

  xml {
    xslt = file(""modules/host/shareable.xsl"")
  }

  console {
    type        = ""pty""
    target_port = ""0""
    target_type = ""serial""
  }

  console {
    type        = ""pty""
    target_type = ""virtio""
    target_port = ""1""
  }

  graphics {
    type        = ""spice""
    listen_type = ""address""
    autoport    = true
  }

  cpu = {
    mode = ""host-passthrough""
  }
}
",resource,39,,1ee509fed83de98d8db805453d3ec224b8c7d607,6c4530c42de0f228cf165e1539e916fb874100df,https://github.com/SUSE/ha-sap-terraform-deployments/blob/1ee509fed83de98d8db805453d3ec224b8c7d607/libvirt/terraform/modules/host/main.tf#L39,https://github.com/SUSE/ha-sap-terraform-deployments/blob/6c4530c42de0f228cf165e1539e916fb874100df/libvirt/terraform/modules/host/main.tf,2019-08-07 12:55:38+02:00,2019-08-09 16:01:26+02:00,2,1,1,0,0,0,0,0,1,0
https://github.com/alphagov/govuk-aws,133,terraform/projects/infra-security-groups/content-store.tf,terraform/projects/infra-security-groups/content-store.tf,0,# todo,# TODO: replace this with ingress from the content-store LBs when we build them.,# TODO: replace this with ingress from the content-store LBs when we build them.,"resource ""aws_security_group_rule"" ""allow_management_to_content-store_elb"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  security_group_id        = ""${aws_security_group.content-store_elb.id}""
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,47,,ecacf086aefd6fa707f03540628ca1ed068fa6ff,f758f9ad0a4b5b6b71d189e17d3736d90ccaa313,https://github.com/alphagov/govuk-aws/blob/ecacf086aefd6fa707f03540628ca1ed068fa6ff/terraform/projects/infra-security-groups/content-store.tf#L47,https://github.com/alphagov/govuk-aws/blob/f758f9ad0a4b5b6b71d189e17d3736d90ccaa313/terraform/projects/infra-security-groups/content-store.tf,2017-07-20 13:25:34+01:00,2017-08-31 10:57:31+01:00,2,1,0,1,0,1,1,0,0,0
https://github.com/uyuni-project/sumaform,1695,modules/base/main.tf,modules/base/main.tf,0,workaround,# END OF WORKAROUND,# END OF WORKAROUND,"output ""configuration"" {
  value = merge({
    cc_username              = var.cc_username
    cc_password              = var.cc_password
    timezone                 = var.timezone
    use_ntp                  = var.use_ntp
    ssh_key_path             = var.ssh_key_path
    mirror                   = var.mirror
    use_mirror_images        = var.use_mirror_images
    use_avahi                = var.use_avahi
    domain                   = var.domain
    name_prefix              = var.name_prefix
    use_shared_resources     = var.use_shared_resources
    testsuite                = var.testsuite
    use_eip_bastion          = var.use_eip_bastion
    # WORKAROUND
    # For some reason, the key ""additional_network"" from AWS module gets lost
    # Force it into existence
    additional_network       = null
    # END OF WORKAROUND
  }, module.base_backend.configuration)
}
",output,"output ""configuration"" {
  value = merge({
    cc_username              = var.cc_username
    cc_password              = var.cc_password
    timezone                 = var.timezone
    use_ntp                  = var.use_ntp
    ssh_key_path             = var.ssh_key_path
    mirror                   = var.mirror
    use_mirror_images        = var.use_mirror_images
    use_avahi                = var.use_avahi
    domain                   = var.domain
    name_prefix              = var.name_prefix
    use_shared_resources     = var.use_shared_resources
    testsuite                = var.testsuite
    use_eip_bastion          = var.use_eip_bastion
    # WORKAROUND
    # For some reason, the key ""additional_network"" from AWS module gets lost
    # Force it into existence
    additional_network       = null
    # END OF WORKAROUND
  }, module.base_backend.configuration)
}
",output,41,41.0,9d66731e5b8f88459fa959303036d0585fd3c09c,9d66731e5b8f88459fa959303036d0585fd3c09c,https://github.com/uyuni-project/sumaform/blob/9d66731e5b8f88459fa959303036d0585fd3c09c/modules/base/main.tf#L41,https://github.com/uyuni-project/sumaform/blob/9d66731e5b8f88459fa959303036d0585fd3c09c/modules/base/main.tf#L41,2024-03-15 14:27:16+01:00,2024-03-15 14:27:16+01:00,1,0,0,1,1,0,1,0,0,0
https://github.com/Worklytics/psoxy,1,infra/dev-personal/main.tf,infra/dev-personal/main.tf,0,# todo,# TODO: probably directory too!?!?,# TODO: probably directory too!?!?,"module ""gmail-connector"" {
  source = ""../modules/google-workspace-dwd-connection""

  project_id                   = var.project_id
  connector_service_account_id = ""psoxy-gmail-dwd""
  display_name                 = ""Psoxy Connector - GMail Dev Erik""
  apis_consumed                = [
    ""gmail.googleapis.com"",
    # TODO: probably directory too!?!?
  ]

  depends_on = [
    module.psoxy-gcp
  ]
}
",module,"module ""gmail-connector"" {
  source = ""../modules/google-workspace-dwd-connection""

  project_id                   = var.project_id
  connector_service_account_id = ""psoxy-gmail-dwd""
  display_name                 = ""Psoxy Connector - GMail Dev Erik""
  apis_consumed                = [
    ""gmail.googleapis.com""
  ]

  depends_on = [
    module.psoxy-gcp
  ]
}
",module,32,,1259c535e4d315fea708946a07b95f255b249721,8d12abf0f699d143166a59abeb7943b215749be8,https://github.com/Worklytics/psoxy/blob/1259c535e4d315fea708946a07b95f255b249721/infra/dev-personal/main.tf#L32,https://github.com/Worklytics/psoxy/blob/8d12abf0f699d143166a59abeb7943b215749be8/infra/dev-personal/main.tf,2021-10-06 09:58:36-07:00,2021-10-15 14:47:16-07:00,10,1,0,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,298,terraform/projects/infra-security-groups/frontend.tf,terraform/projects/infra-security-groups/frontend.tf,0,# todo,# TODO: most application instances need to talk to frontend - we could,"# TODO: most application instances need to talk to frontend - we could 
 # split out some security for application and service instances?","resource ""aws_security_group_rule"" ""allow_management_to_frontend_elb_https"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  security_group_id        = ""${aws_security_group.frontend_elb.id}""
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,47,,5229a4367e1e86243aa2400ab49f364d69ddd35b,7fd13330f8d6238e108f76ce76a76a28a99caaaf,https://github.com/alphagov/govuk-aws/blob/5229a4367e1e86243aa2400ab49f364d69ddd35b/terraform/projects/infra-security-groups/frontend.tf#L47,https://github.com/alphagov/govuk-aws/blob/7fd13330f8d6238e108f76ce76a76a28a99caaaf/terraform/projects/infra-security-groups/frontend.tf,2017-09-12 18:04:50+01:00,2018-01-02 17:41:32+00:00,2,1,0,1,0,1,0,0,0,0
https://github.com/claranet/terraform-datadog-monitors,2,cloud/aws/elasticsearch/monitors-elasticsearch.tf,cloud/aws/elasticsearch/monitors-elasticsearch.tf,0,workaround,"/*Note about the query     - If aws.es.cluster_statusred is 1 --> query value (= 2.1) > 2 : critical     - If aws.es.cluster_statusyellow is 1 --> 1 < query value (=1.1) < 2 : warning     Workaround : in the query, we add ""0.1"" to the result and we use the comparator "">="". No alert was triggered without that.*/","### Elasticsearch cluster status monitor ### 
 /* Note about the query 
 - If aws.es.cluster_statusred is 1 --> query value (= 2.1) > 2 : critical 
 - If aws.es.cluster_statusyellow is 1 --> 1 < query value (=1.1) < 2 : warning 
 Workaround : in the query, we add ""0.1"" to the result and we use the comparator "">="". No alert was triggered without that. */","resource ""datadog_monitor"" ""es_cluster_status"" {
  name    = ""[${var.environment}] ElasticSearch cluster status is not green""
  message = ""${coalesce(var.es_cluster_status_message, var.message)}""

  type = ""metric alert""

  query = <<EOF
  max(last_30m): (
    avg:aws.es.cluster_statusred{${data.template_file.filter.rendered}} by {region,name} * 2 +
    (avg:aws.es.cluster_statusyellow{${data.template_file.filter.rendered}} by {region,name} + 0.1)
  ) >= 2
EOF

  thresholds {
    warning  = 1
    critical = 2
  }

  notify_no_data      = true
  evaluation_delay    = ""${var.delay}""
  renotify_interval   = 0
  notify_audit        = false
  timeout_h           = 0
  include_tags        = true
  locked              = false
  require_full_window = false
  new_host_delay      = ""${var.delay}""
  no_data_timeframe   = 20

  silenced = ""${var.es_cluster_status_silenced}""

  tags = [""env:${var.environment}"", ""resource:elasticsearch"", ""team:aws"", ""provider:aws""]
}
",resource,"resource ""datadog_monitor"" ""es_cluster_status"" {
  count   = var.es_cluster_status_enabled == ""true"" ? 1 : 0
  name    = ""${var.prefix_slug == """" ? """" : ""[${var.prefix_slug}]""}[${var.environment}] ElasticSearch cluster status is not green""
  message = coalesce(var.es_cluster_status_message, var.message)
  type    = ""query alert""

  query = <<EOQ
  max(${var.es_cluster_status_timeframe}): (
    avg:aws.es.cluster_statusred${module.filter-tags.query_alert} by {region,name} * 2 +
    (avg:aws.es.cluster_statusyellow${module.filter-tags.query_alert} by {region,name} + 0.1)
  ) >= 2
EOQ

  monitor_thresholds {
    warning  = 1
    critical = 2
  }

  evaluation_delay    = var.evaluation_delay
  new_host_delay      = var.new_host_delay
  new_group_delay     = var.new_group_delay
  notify_no_data      = var.notify_no_data
  no_data_timeframe   = var.es_cluster_status_no_data_timeframe
  renotify_interval   = 0
  notify_audit        = false
  timeout_h           = var.timeout_h
  include_tags        = true
  require_full_window = false

  tags = concat(local.common_tags, var.tags, var.es_cluster_status_extra_tags)
}
",resource,10,2.0,fcf6b3239358bcc0c5827445544a734d58141333,a449a1360a67ebf9abddf3e4e6ff6fa17c50b12a,https://github.com/claranet/terraform-datadog-monitors/blob/fcf6b3239358bcc0c5827445544a734d58141333/cloud/aws/elasticsearch/monitors-elasticsearch.tf#L10,https://github.com/claranet/terraform-datadog-monitors/blob/a449a1360a67ebf9abddf3e4e6ff6fa17c50b12a/cloud/aws/elasticsearch/monitors-elasticsearch.tf#L2,2018-03-23 15:33:59+01:00,2023-12-12 16:00:34+01:00,35,0,0,0,0,0,0,0,1,0
https://github.com/CDCgov/prime-simplereport,41,ops/services/postgres_db/networking.tf,ops/services/postgres_db/networking.tf,0,// todo,// TODO: delete this when removing old DB configuration - Flexible,"// TODO: delete this when removing old DB configuration - Flexible 
 // Server uses VNet injection instead of Private Link for non- 
 // public connections so this is no longer needed.","resource ""azurerm_private_endpoint"" ""db"" {
  name                = ""${var.env}-db-privatelink""
  location            = var.rg_location
  resource_group_name = var.rg_name
  subnet_id           = var.old_subnet_id

  private_service_connection {
    name                           = ""${var.env}-db-privatelink""
    is_manual_connection           = false
    private_connection_resource_id = azurerm_postgresql_server.db.id
    subresource_names              = [""postgresqlServer""]
  }

  private_dns_zone_group {
    name                 = ""default""
    private_dns_zone_ids = [var.dns_zone_id]
  }

  tags = {
    environment : var.env
  }
}
",resource,,,1,0.0,3e4185fa549937cff9213c325bc0fee780e41eb0,fb9a18eb71f31044ca7a58958a25dea489263ca7,https://github.com/CDCgov/prime-simplereport/blob/3e4185fa549937cff9213c325bc0fee780e41eb0/ops/services/postgres_db/networking.tf#L1,https://github.com/CDCgov/prime-simplereport/blob/fb9a18eb71f31044ca7a58958a25dea489263ca7/ops/services/postgres_db/networking.tf#L0,2022-02-16 12:59:39-05:00,2022-04-28 23:27:57-04:00,2,2,0,1,0,0,1,0,0,0
https://github.com/alphagov/govuk-aws,164,terraform/modules/aws/rds_instance/main.tf,terraform/modules/aws/rds_instance/main.tf,0,todo,"# TODO in production we probably want to re-enable this, possibly using:","# TODO in production we probably want to re-enable this, possibly using: 
 # final_snapshot_identifier = ""${var.name}-final-snapshot""","resource ""aws_db_instance"" ""db_instance"" {
  # the 'name' parameter is not set as that creates a default database
  # of that name in the instance. Which we don't want.
  count = ""${1 - var.create_replicate_source_db}""

  engine                 = ""${var.engine_name}""
  engine_version         = ""${var.engine_version}""
  username               = ""${var.username}""
  password               = ""${var.password}""
  allocated_storage      = ""${var.allocated_storage}""
  instance_class         = ""${var.instance_class}""
  storage_type           = ""${var.storage_type}""
  db_subnet_group_name   = ""${aws_db_subnet_group.subnet_group.name}""
  vpc_security_group_ids = [""${var.security_group_ids}""]
  multi_az               = ""${var.multi_az}""

  # TODO in production we probably want to re-enable this, possibly using:
  # final_snapshot_identifier = ""${var.name}-final-snapshot""
  skip_final_snapshot = true

  tags = ""${merge(var.default_tags, map(""Name"", var.name))}""
}
",resource,"resource ""aws_db_instance"" ""db_instance"" {
  # the 'name' parameter is not set as that creates a default database
  # of that name in the instance. Which we don't want.
  count = ""${1 - var.create_replicate_source_db}""

  engine                  = ""${var.engine_name}""
  engine_version          = ""${var.engine_version}""
  username                = ""${var.username}""
  password                = ""${var.password}""
  allocated_storage       = ""${var.allocated_storage}""
  instance_class          = ""${var.instance_class}""
  storage_type            = ""${var.storage_type}""
  db_subnet_group_name    = ""${aws_db_subnet_group.subnet_group.name}""
  vpc_security_group_ids  = [""${var.security_group_ids}""]
  multi_az                = ""${var.multi_az}""
  parameter_group_name    = ""${var.parameter_group_name}""
  maintenance_window      = ""${var.maintenance_window}""
  backup_retention_period = ""${var.backup_retention_period}""
  backup_window           = ""${var.backup_window}""

  # TODO this should be enabled in a Production environment:
  final_snapshot_identifier = ""${var.name}-final-snapshot""
  skip_final_snapshot       = ""${var.skip_final_snapshot}""

  tags = ""${merge(var.default_tags, map(""Name"", var.name))}""
}
",resource,155,,a2e44a58020dcb6594b2357edcd37630d1683942,96444d23db9cfc15fd26e2ae6051e263204d3860,https://github.com/alphagov/govuk-aws/blob/a2e44a58020dcb6594b2357edcd37630d1683942/terraform/modules/aws/rds_instance/main.tf#L155,https://github.com/alphagov/govuk-aws/blob/96444d23db9cfc15fd26e2ae6051e263204d3860/terraform/modules/aws/rds_instance/main.tf,2017-08-03 14:17:13+01:00,2017-10-19 13:48:30+01:00,4,1,1,1,0,0,0,1,0,0
https://github.com/ministryofjustice/modernisation-platform,231,terraform/environments/core-network-services/cidr-ranges.tf,terraform/environments/core-network-services/cidr-ranges.tf,0,implemented,"# hmpps-production-general-private-subnets = ""10.27.10.0/22"" not yet implemented","# hmpps-production-general-private-subnets = ""10.27.10.0/22"" not yet implemented","locals {
  mp_core_cidr_ranges = {
    mp-core                     = ""10.20.0.0/16""
    mp-development-test         = ""10.26.0.0/16""
    mp-preproduction-production = ""10.27.0.0/16""
  }

  # This will take the vpc CIDR ranges for each business/env general subnet set, from the environments-networks files
  # e.g. `hmpps-development = ""10.26.24.0/21""
  platform_general_set_cidr_ranges = {
    for key, value in local.core-vpcs : key => value.cidr.subnet_sets.general.cidr
  }

  other_cidr_ranges = {
    alpha-vpn                        = ""100.64.0.0/16""
    analytical-platform-airflow-dev  = ""10.200.0.0/16""
    analytical-platform-airflow-prod = ""10.201.0.0/16""
    atos_arkc_ras                    = ""10.175.0.0/16"" # for DOM1 devices connected to Cisco RAS VPN
    atos_arkf_ras                    = ""10.176.0.0/16"" # for DOM1 devices connected to Cisco RAS VPN
    cloud-platform                   = ""172.20.0.0/16""
    global-protect                   = ""10.184.0.0/16""
    i2n                              = ""10.110.0.0/16""
    moj-core-azure-1                 = ""10.50.25.0/27""
    moj-core-azure-2                 = ""10.50.26.0/24""
    parole-board                     = ""10.50.0.0/16""
    psn                              = ""51.0.0.0/8""
    psn-ppud                         = ""51.247.2.115/32""
    vodafone_wan_nicts_aggregate     = ""10.80.0.0/12"" # for devices connected to Prison Networks

    # hmpps azure cidr ranges
    noms-live-vnet                 = ""10.40.0.0/18""
    noms-live-dr-vnet              = ""10.40.64.0/18""
    noms-mgmt-live-vnet            = ""10.40.128.0/20""
    noms-mgmt-live-dr-vnet         = ""10.40.144.0/20""
    noms-transit-live-vnet         = ""10.40.160.0/20""
    noms-transit-live-dr-vnet      = ""10.40.176.0/20""
    noms-test-vnet                 = ""10.101.0.0/16""
    noms-mgmt-vnet                 = ""10.102.0.0/16""
    noms-test-dr-vnet              = ""10.111.0.0/16""
    noms-mgmt-dr-vnet              = ""10.112.0.0/16""
    aks-studio-hosting-live-1-vnet = ""10.244.0.0/20""
    aks-studio-hosting-dev-1-vnet  = ""10.247.0.0/20""
    aks-studio-hosting-ops-1-vnet  = ""10.247.32.0/20""
    nomisapi-t2-root-vnet          = ""10.47.0.192/26""
    nomisapi-t3-root-vnet          = ""10.47.0.0/26""
    nomisapi-preprod-root-vnet     = ""10.47.0.64/26""
    nomisapi-prod-root-vnet        = ""10.47.0.128/26""

    # hmpps aws cidr ranges
    delius-eng-dev  = ""10.161.98.0/25""
    delius-eng-prod = ""10.160.98.0/25""
    delius-core-dev = ""10.161.20.0/22""
    delius-mis-dev  = ""10.162.32.0/20""
    delius-test     = ""10.162.0.0/20""
    delius-stage    = ""10.160.32.0/20""
    delius-pre-prod = ""10.160.0.0/20""
    delius-training = ""10.162.96.0/20""
    delius-prod     = ""10.160.16.0/20""

    # laa landing zone cidr ranges
    laa-lz-development             = ""10.202.0.0/20""
    laa-lz-test                    = ""10.203.0.0/20""
    laa-lz-uat                     = ""10.206.0.0/20""
    laa-lz-staging                 = ""10.204.0.0/20""
    laa-lz-production              = ""10.205.0.0/20""
    laa-lz-shared-services-nonprod = ""10.200.0.0/20""
    laa-lz-shared-services-prod    = ""10.200.16.0/20""
    laa-appstream-vpc              = ""10.200.32.0/19""
    laa-appstream-vpc_additional   = ""10.200.68.0/22""

    hmpps-preproduction-general-private-subnets = ""10.27.0.0/22""
    # hmpps-production-general-private-subnets = ""10.27.10.0/22"" not yet implemented
  }

  all_cidr_ranges = merge(
    local.mp_core_cidr_ranges,
    local.platform_general_set_cidr_ranges,
    local.other_cidr_ranges
  )
}
",locals,"locals {
  mp_core_cidr_ranges = {
    mp-core                     = ""10.20.0.0/16""
    mp-development-test         = ""10.26.0.0/16""
    mp-preproduction-production = ""10.27.0.0/16""
  }

  # This will take the vpc CIDR ranges for each business/env general subnet set, from the environments-networks files
  # e.g. `hmpps-development = ""10.26.24.0/21""
  platform_general_set_cidr_ranges = {
    for key, value in local.core-vpcs : key => value.cidr.subnet_sets.general.cidr
  }

  other_cidr_ranges = {
    alpha-vpn                        = ""100.64.0.0/16""
    analytical-platform-airflow-dev  = ""10.200.0.0/16""
    analytical-platform-airflow-prod = ""10.201.0.0/16""
    atos_arkc_ras                    = ""10.175.0.0/16"" # for DOM1 devices connected to Cisco RAS VPN
    atos_arkf_ras                    = ""10.176.0.0/16"" # for DOM1 devices connected to Cisco RAS VPN
    cloud-platform                   = ""172.20.0.0/16""
    global-protect                   = ""10.184.0.0/16""
    i2n                              = ""10.110.0.0/16""
    moj-core-azure-1                 = ""10.50.25.0/27""
    moj-core-azure-2                 = ""10.50.26.0/24""
    parole-board                     = ""10.50.0.0/16""
    psn                              = ""51.0.0.0/8""
    psn-ppud                         = ""51.247.2.115/32""
    vodafone_wan_nicts_aggregate     = ""10.80.0.0/12"" # for devices connected to Prison Networks

    # hmpps azure cidr ranges
    noms-live-vnet                 = ""10.40.0.0/18""
    noms-live-dr-vnet              = ""10.40.64.0/18""
    noms-mgmt-live-vnet            = ""10.40.128.0/20""
    noms-mgmt-live-dr-vnet         = ""10.40.144.0/20""
    noms-transit-live-vnet         = ""10.40.160.0/20""
    noms-transit-live-dr-vnet      = ""10.40.176.0/20""
    noms-test-vnet                 = ""10.101.0.0/16""
    noms-mgmt-vnet                 = ""10.102.0.0/16""
    noms-test-dr-vnet              = ""10.111.0.0/16""
    noms-mgmt-dr-vnet              = ""10.112.0.0/16""
    aks-studio-hosting-live-1-vnet = ""10.244.0.0/20""
    aks-studio-hosting-dev-1-vnet  = ""10.247.0.0/20""
    aks-studio-hosting-ops-1-vnet  = ""10.247.32.0/20""
    nomisapi-t2-root-vnet          = ""10.47.0.192/26""
    nomisapi-t3-root-vnet          = ""10.47.0.0/26""
    nomisapi-preprod-root-vnet     = ""10.47.0.64/26""
    nomisapi-prod-root-vnet        = ""10.47.0.128/26""

    # hmpps aws cidr ranges
    delius-eng-dev  = ""10.161.98.0/25""
    delius-eng-prod = ""10.160.98.0/25""
    delius-core-dev = ""10.161.20.0/22""
    delius-mis-dev  = ""10.162.32.0/20""
    delius-test     = ""10.162.0.0/20""
    delius-stage    = ""10.160.32.0/20""
    delius-pre-prod = ""10.160.0.0/20""
    delius-training = ""10.162.96.0/20""
    delius-prod     = ""10.160.16.0/20""

    # laa landing zone cidr ranges
    laa-lz-development             = ""10.202.0.0/20""
    laa-lz-test                    = ""10.203.0.0/20""
    laa-lz-uat                     = ""10.206.0.0/20""
    laa-lz-staging                 = ""10.204.0.0/20""
    laa-lz-production              = ""10.205.0.0/20""
    laa-lz-shared-services-nonprod = ""10.200.0.0/20""
    laa-lz-shared-services-prod    = ""10.200.16.0/20""
    laa-appstream-vpc              = ""10.200.32.0/19""
    laa-appstream-vpc_additional   = ""10.200.68.0/22""

    hmpps-preproduction-general-private-subnets = ""10.27.0.0/22""
    hmpps-production-general-private-subnets = ""10.27.10.0/22""
  }

  all_cidr_ranges = merge(
    local.mp_core_cidr_ranges,
    local.platform_general_set_cidr_ranges,
    local.other_cidr_ranges
  )
}
",locals,72,,c40f0f81d52046129fb0dd1c39b5f6a628b53717,737c2b496144efa9a95a30de2b2a345370a110eb,https://github.com/ministryofjustice/modernisation-platform/blob/c40f0f81d52046129fb0dd1c39b5f6a628b53717/terraform/environments/core-network-services/cidr-ranges.tf#L72,https://github.com/ministryofjustice/modernisation-platform/blob/737c2b496144efa9a95a30de2b2a345370a110eb/terraform/environments/core-network-services/cidr-ranges.tf,2023-11-07 17:40:47+00:00,2023-11-17 12:49:48+00:00,2,1,0,1,0,0,1,1,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,595,examples/data-solutions/data-platform-foundations/03-orchestration.tf,examples/data-solutions/data-platform-foundations/03-orchestration.tf,0,#todo,#TODO make keys variables,#TODO make keys variables,"module ""orc-vpc"" {
  count      = var.network_config.network != null ? 0 : 1
  source     = ""../../../modules/net-vpc""
  project_id = module.orc-prj.project_id
  name       = ""${local.prefix_orc}-vpc""
  subnets = [
    {
      ip_cidr_range      = var.network_config.vpc_subnet.orchestration.range
      name               = ""${local.prefix_orc}-subnet""
      region             = var.location_config.region
      secondary_ip_range = {}
      secondary_ip_range = {
        #TODO make keys variables
        pods     = var.network_config.vpc_subnet.orchestration.secondary_range.pods
        services = var.network_config.vpc_subnet.orchestration.secondary_range.services
      }
    }
  ]
}
",module,"module ""orc-vpc"" {
  count      = var.network_config.network != null ? 0 : 1
  source     = ""../../../modules/net-vpc""
  project_id = module.orc-prj.project_id
  name       = ""${local.prefix_orc}-vpc""
  subnets = [
    {
      ip_cidr_range      = var.network_config.vpc_subnet.orchestration.range
      name               = ""${local.prefix_orc}-subnet""
      region             = var.location_config.region
      secondary_ip_range = {}
      secondary_ip_range = {
        pods     = var.network_config.vpc_subnet.orchestration.secondary_range.pods
        services = var.network_config.vpc_subnet.orchestration.secondary_range.services
      }
    }
  ]
}
",module,120,,74b850b4b8edb1acfb80958f665c2aad10945fd0,2e560407c118e7b7abc32f8ac1788a3f48563f21,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/74b850b4b8edb1acfb80958f665c2aad10945fd0/examples/data-solutions/data-platform-foundations/03-orchestration.tf#L120,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/2e560407c118e7b7abc32f8ac1788a3f48563f21/examples/data-solutions/data-platform-foundations/03-orchestration.tf,2022-02-05 09:04:18+01:00,2022-02-07 17:51:06+01:00,3,1,0,1,0,0,1,0,0,0
https://github.com/apache/beam,1,playground/terraform/infrastructure/memorystore/main.tf,playground/terraform/infrastructure/memorystore/main.tf,0,// todo,"// TODO: remove when replica_count, etc is generally available","// TODO: remove when replica_count, etc is generally available","resource ""google_redis_instance"" ""cache"" {
  // TODO: remove when replica_count, etc is generally available
  provider       = google-beta
  project        = var.project_id
  region         = var.redis_region
  name           = var.redis_name
  tier           = var.redis_tier
  memory_size_gb = var.redis_memory_size_gb
  replica_count  = var.redis_replica_count
  redis_version      = var.redis_version
  display_name       = var.display_name
  read_replicas_mode = var.read_replicas_mode
  authorized_network = data.google_compute_network.default.id
}
",resource,"resource ""google_redis_instance"" ""cache"" {
  // TODO: remove when replica_count, etc is generally available
  provider           = google-beta
  project            = var.project_id
  region             = var.region
  name               = var.name
  tier               = var.tier
  memory_size_gb     = var.memory_size_gb
  replica_count      = var.replica_count
  authorized_network = var.network
  read_replicas_mode = var.replicas_mode
  redis_version      = var.redis_version
  display_name       = var.display_name

}
",resource,36,24.0,675c0bc10f813ea593702f5e6a0fd2ce38caf720,ad21d8353c856152346408f1d5029c9af05957c8,https://github.com/apache/beam/blob/675c0bc10f813ea593702f5e6a0fd2ce38caf720/playground/terraform/infrastructure/memorystore/main.tf#L36,https://github.com/apache/beam/blob/ad21d8353c856152346408f1d5029c9af05957c8/playground/terraform/infrastructure/memorystore/main.tf#L24,2022-02-22 10:04:20-08:00,2022-03-16 14:13:22-07:00,2,0,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1574,fast/stages/0-bootstrap/variables.tf,fast/stages/0-bootstrap/variables.tf,0,fix,# TODO: fix validation,"# TODO: fix validation 
 # validation { 
 #   condition     = var.federated_identity_providers.custom_settings == null 
 #   error_message = ""Custom settings cannot be null."" 
 # }","variable ""federated_identity_providers"" {
  description = ""Workload Identity Federation pools. The `cicd_repositories` variable references keys here.""
  type = map(object({
    attribute_condition = optional(string)
    issuer              = string
    custom_settings = optional(object({
      issuer_uri        = optional(string)
      allowed_audiences = optional(list(string), [])
    }), {})
  }))
  default  = {}
  nullable = false
  # TODO: fix validation
  # validation {
  #   condition     = var.federated_identity_providers.custom_settings == null
  #   error_message = ""Custom settings cannot be null.""
  # }
}
",variable,"variable ""workload_identity_providers"" {
  description = ""Workload Identity Federation pools. The `cicd_repositories` variable references keys here.""
  type = map(object({
    attribute_condition = optional(string)
    issuer              = string
    custom_settings = optional(object({
      issuer_uri = optional(string)
      audiences  = optional(list(string), [])
      jwks_json  = optional(string)
    }), {})
  }))
  default  = {}
  nullable = false
  # TODO: fix validation
  # validation {
  #   condition     = var.federated_identity_providers.custom_settings == null
  #   error_message = ""Custom settings cannot be null.""
  # }
}
",variable,125,298.0,47daeaafe132730cab7b164c239e988854329c77,be9214f99a0718eb8698e9d539e2ad93cb442ac7,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/47daeaafe132730cab7b164c239e988854329c77/fast/stages/0-bootstrap/variables.tf#L125,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/be9214f99a0718eb8698e9d539e2ad93cb442ac7/fast/stages/0-bootstrap/variables.tf#L298,2023-08-03 16:09:45+00:00,2024-05-21 10:39:47+02:00,23,0,0,1,0,1,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,290,variables-network.tf,variables-network.tf,0,todo,// TODO Align with subnets declaration in map,"variable ""create_nsgs"" { // TODO Align with subnets declaration in map","variable ""create_nsgs"" { // TODO Align with subnets declaration in map
  default     = true
  description = ""Whether to create standard network security groups.""
  type        = bool
}
",variable,the block associated got renamed or deleted,,10,,cf7f4da8a0c56d0350bd86c2ef1011e3f6c2f3b2,32cf3b275cc82bf2119d9d27231c8bc86b6e0ed1,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/cf7f4da8a0c56d0350bd86c2ef1011e3f6c2f3b2/variables-network.tf#L10,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/32cf3b275cc82bf2119d9d27231c8bc86b6e0ed1/variables-network.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,5,1,0,1,0,1,1,0,0,0
https://github.com/Worklytics/psoxy,1531,infra/modules/worklytics-connectors-google-workspace/main.tf,infra/modules/worklytics-connectors-google-workspace/main.tf,0,implementation,"# problem with that is that it's something of an implementation detail, right?","# rather than this merge thing, should we this as a distinct output? 
 # problem with that is that it's something of an implementation detail, right?","locals {
  enabled_api_connectors = {
    for k, v in module.worklytics_connector_specs.enabled_google_workspace_connectors :
    k => merge(v, {
      # rather than this merge thing, should we this as a distinct output?
      # problem with that is that it's something of an implementation detail, right?
      secured_variables = concat(
        try([v.secured_variables], []),
        [
          {
            name     = ""SERVICE_ACCOUNT_KEY""
            value    = module.google_workspace_connection_auth[k].key_value
            writable = false
          }
        ]
      )
    })
  }
}
",locals,"locals {
  enabled_api_connectors = {
    for k, v in module.worklytics_connector_specs.enabled_google_workspace_connectors :
    k => merge(v, {
      # rather than this merge thing, should we this as a distinct output?
      # problem with that is that it's something of an implementation detail, right?
      secured_variables = concat(
        try([v.secured_variables], []),
        [
          {
            name                = ""SERVICE_ACCOUNT_KEY""
            value               = module.google_workspace_connection_auth[k].key_value
            writable            = false
            sensitive           = true
            value_managed_by_tf = true
            description         = ""The API key for the GCP Service Account that is the OAuth Client for accessing the Google Workspace APIs used by the ${k} connector.""
          }
        ]
      )
    })
  }
}",locals,51,57.0,f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e,0db6077bf0549cf79dc2e0cb57563d5ac2453feb,https://github.com/Worklytics/psoxy/blob/f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e/infra/modules/worklytics-connectors-google-workspace/main.tf#L51,https://github.com/Worklytics/psoxy/blob/0db6077bf0549cf79dc2e0cb57563d5ac2453feb/infra/modules/worklytics-connectors-google-workspace/main.tf#L57,2023-06-16 14:08:45-07:00,2024-04-03 10:54:59-07:00,8,0,0,1,0,0,0,0,0,0
https://github.com/compiler-explorer/infra,266,terraform/alb.tf,terraform/alb.tf,0,todo,// TODO clean this repetition up,// TODO clean this repetition up,"resource ""aws_alb_listener_rule"" ""compiler-explorer-alb-listen-http-beta"" {
  priority = 1
  action {
    type             = ""forward""
    target_group_arn = aws_alb_target_group.ce[""beta""].arn
  }
  condition {
    path_pattern {
      values = [""/beta*""]
    }
  }
  listener_arn = aws_alb_listener.compiler-explorer-alb-listen-http.arn
}
",resource,"resource ""aws_alb_listener_rule"" ""compiler-explorer-alb-listen-http-beta"" {
  priority = 1
  action {
    type             = ""forward""
    target_group_arn = aws_alb_target_group.ce[""beta""].arn
  }
  condition {
    path_pattern {
      values = [""/beta*""]
    }
  }
  listener_arn = aws_alb_listener.compiler-explorer-alb-listen-http.arn
}
",resource,30,30.0,85295c876b56c7417ea7917c51c0a20ddb9b0a07,34c263985780c3210aeb376a2943c9eb7789af39,https://github.com/compiler-explorer/infra/blob/85295c876b56c7417ea7917c51c0a20ddb9b0a07/terraform/alb.tf#L30,https://github.com/compiler-explorer/infra/blob/34c263985780c3210aeb376a2943c9eb7789af39/terraform/alb.tf#L30,2022-11-14 21:02:28-06:00,2023-03-18 12:12:19+01:00,5,0,0,1,0,0,1,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-iam,1,modules/iam-user/main.tf,modules/iam-user/main.tf,0,# todo,# TODO: Remove once https://github.com/hashicorp/terraform-provider-aws/issues/23567 is resolved,# TODO: Remove once https://github.com/hashicorp/terraform-provider-aws/issues/23567 is resolved,"resource ""aws_iam_user_login_profile"" ""this"" {
  count = var.create_user && var.create_iam_user_login_profile ? 1 : 0

  user                    = aws_iam_user.this[0].name
  pgp_key                 = var.pgp_key
  password_length         = var.password_length
  password_reset_required = var.password_reset_required

  # TODO: Remove once https://github.com/hashicorp/terraform-provider-aws/issues/23567 is resolved
  lifecycle {
    ignore_changes = [password_reset_required]
  }
}
",resource,"resource ""aws_iam_user_login_profile"" ""this"" {
  count = var.create_user && var.create_iam_user_login_profile ? 1 : 0

  user                    = aws_iam_user.this[0].name
  pgp_key                 = var.pgp_key
  password_length         = var.password_length
  password_reset_required = var.password_reset_required

  # TODO: Remove once https://github.com/hashicorp/terraform-provider-aws/issues/23567 is resolved
  lifecycle {
    ignore_changes = [password_reset_required]
  }
}
",resource,20,20.0,358f7d438d033df9f463b518ef229333f1027bf6,543f101e286a628d5f324ca794c73b60962ff4ae,https://github.com/terraform-aws-modules/terraform-aws-iam/blob/358f7d438d033df9f463b518ef229333f1027bf6/modules/iam-user/main.tf#L20,https://github.com/terraform-aws-modules/terraform-aws-iam/blob/543f101e286a628d5f324ca794c73b60962ff4ae/modules/iam-user/main.tf#L20,2022-08-25 11:48:52+02:00,2023-11-04 11:13:26+01:00,4,0,0,1,1,1,0,0,0,0
https://github.com/alphagov/govuk-aws,944,terraform/projects/infra-public-services/main.tf,terraform/projects/infra-public-services/main.tf,0,xxx,# XXX Need to verify healthcheck config,# XXX Need to verify healthcheck config,"module ""licensify_backend_public_lb"" {
  # XXX Need to verify healthcheck config
  source                                     = ""../../modules/aws/lb""
  name                                       = ""${var.stackname}-licensify-backend-public""
  internal                                   = false
  vpc_id                                     = ""${data.terraform_remote_state.infra_vpc.vpc_id}""
  access_logs_bucket_name                    = ""${data.terraform_remote_state.infra_monitoring.aws_logging_bucket_id}""
  access_logs_bucket_prefix                  = ""elb/${var.stackname}-licensify-backend-public-elb""
  listener_certificate_domain_name           = ""${var.elb_public_certname}""
  listener_secondary_certificate_domain_name = ""${var.elb_public_secondary_certname}""

  listener_action = {
    ""HTTPS:443"" = ""HTTP:80""
  }

  subnets         = [""${data.terraform_remote_state.infra_networking.public_subnet_ids}""]
  security_groups = [""${data.terraform_remote_state.infra_security_groups.sg_licensify-backend_external_elb_id}""]
  alarm_actions   = [""${data.terraform_remote_state.infra_monitoring.sns_topic_cloudwatch_alarms_arn}""]

  default_tags = {
    Project         = ""${var.stackname}""
    aws_migration   = ""licensify_backend""
    aws_environment = ""${var.aws_environment}""
  }
}
",module,"module ""licensify_backend_public_lb"" {
  source                                     = ""../../modules/aws/lb""
  name                                       = ""licensify-backend-public""
  internal                                   = false
  vpc_id                                     = ""${data.terraform_remote_state.infra_vpc.vpc_id}""
  access_logs_bucket_name                    = ""${data.terraform_remote_state.infra_monitoring.aws_logging_bucket_id}""
  access_logs_bucket_prefix                  = ""elb/licensify-backend-public-elb""
  listener_certificate_domain_name           = ""${var.elb_public_certname}""
  listener_secondary_certificate_domain_name = ""${var.elb_public_secondary_certname}""

  listener_action = {
    ""HTTPS:443"" = ""HTTP:80""
  }

  subnets         = [""${data.terraform_remote_state.infra_networking.public_subnet_ids}""]
  security_groups = [""${data.terraform_remote_state.infra_security_groups.sg_licensify-backend_external_elb_id}""]
  alarm_actions   = [""${data.terraform_remote_state.infra_monitoring.sns_topic_cloudwatch_alarms_arn}""]

  default_tags = {
    Project         = ""${var.stackname}""
    aws_migration   = ""licensify_backend""
    aws_environment = ""${var.aws_environment}""
  }
}
",module,1678,,5a72a7fddd6d14951653f13bbb93b6096b2a3a73,4337784ffc75431260bcc9f5f58563f8a04e66db,https://github.com/alphagov/govuk-aws/blob/5a72a7fddd6d14951653f13bbb93b6096b2a3a73/terraform/projects/infra-public-services/main.tf#L1678,https://github.com/alphagov/govuk-aws/blob/4337784ffc75431260bcc9f5f58563f8a04e66db/terraform/projects/infra-public-services/main.tf,2019-08-08 17:17:58+01:00,2019-08-09 10:44:09+01:00,2,1,0,0,0,0,1,0,0,1
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,696,fast/stages/01-resman/branch-dataplatform.tf,fast/stages/01-resman/branch-dataplatform.tf,0,#todo,"#TODO check if I can delete those modules, Would you create a data-platform TF to run dev/prod?","#TODO check if I can delete those modules, Would you create a data-platform TF to run dev/prod? 
 # module ""branch-dp-sa"" { 
 #   source      = ""../../../modules/iam-service-account"" 
 #   project_id  = var.automation_project_id 
 #   name        = ""resman-dp-0"" 
 #   description = ""Terraform Data Platform production service account."" 
 #   prefix      = local.prefixes.prod 
 # }  
 # module ""branch-dp-gcs"" { 
 #   source     = ""../../../modules/gcs"" 
 #   project_id = var.automation_project_id 
 #   name       = ""dp-0"" 
 #   prefix     = local.prefixes.prod 
 #   versioning = true 
 #   iam = { 
 #     ""roles/storage.objectAdmin"" = [module.branch-dp-sa.iam_email] 
 #   } 
 # }  
 # environment: development folder ","module ""branch-dp-dev-folder"" {
  source = ""../../../modules/folder""
  parent = module.branch-dp-folder.id
  # naming: environment descriptive name
  name = ""Data Platform - Development""
  # environment-wide human permissions on the whole Data Platform environment
  group_iam = {}
  iam = {
    # remove owner here and at project level if SA does not manage project resources
    ""roles/owner"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/logging.admin"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/resourcemanager.folderAdmin"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/resourcemanager.projectCreator"" = [
      module.branch-dp-dev-sa.iam_email
    ]
  }
}
",module,"module ""branch-dp-dev-folder"" {
  source = ""../../../modules/folder""
  parent = module.branch-dp-folder.id
  # naming: environment descriptive name
  name = ""Development""
  # environment-wide human permissions on the whole Data Platform environment
  group_iam = {}
  iam = {
    # remove owner here and at project level if SA does not manage project resources
    ""roles/owner"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/logging.admin"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/resourcemanager.folderAdmin"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/resourcemanager.projectCreator"" = [
      module.branch-dp-dev-sa.iam_email
    ]
    ""roles/compute.xpnAdmin"" = [
      module.branch-teams-dev-projectfactory-sa.iam_email
    ]
  }
}
",module,27,,bf64a3dfda0fc6a023cf7cf1cad3dccb48708f67,7252e7ec01d799ac1f3faba852d3de8138ff8917,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/bf64a3dfda0fc6a023cf7cf1cad3dccb48708f67/fast/stages/01-resman/branch-dataplatform.tf#L27,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/7252e7ec01d799ac1f3faba852d3de8138ff8917/fast/stages/01-resman/branch-dataplatform.tf,2022-02-11 17:32:16+01:00,2022-02-14 16:54:42+01:00,2,1,0,1,0,0,0,1,0,1
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1555,modules/vpc-sc/outputs.tf,modules/vpc-sc/outputs.tf,0,# todo,# TODO: deprecate in favor of id,# TODO: deprecate in favor of id,"output ""access_policy_name"" {
  description = ""Access policy name.""
  value       = local.access_policy
}
",output,"output ""access_policy_name"" {
  description = ""Access policy name.""
  value       = local.access_policy
}
",output,35,35.0,884cb8b4bf4caa8baa1d0148deb5a000a70a9920,3af7e257d21f889ffaf7b32a3bab974fdbfda6e4,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/884cb8b4bf4caa8baa1d0148deb5a000a70a9920/modules/vpc-sc/outputs.tf#L35,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/3af7e257d21f889ffaf7b32a3bab974fdbfda6e4/modules/vpc-sc/outputs.tf#L35,2023-06-02 16:07:22+02:00,2024-04-17 10:23:48+02:00,2,0,0,1,0,1,0,0,0,0
https://github.com/nasa/cumulus,4,packages/s3-credentials-endpoint/main.tf,packages/s3-credentials-endpoint/main.tf,0,todo,# TODO Fetch this from ... somewhere. Or package it with the module zip file? Probably the better option,# TODO Fetch this from ... somewhere. Or package it with the module zip file? Probably the better option,"resource ""aws_lambda_function"" ""s3_credentials"" {
  function_name = ""${var.prefix}-s3-credentials-endpoint""
  # TODO Fetch this from ... somewhere. Or package it with the module zip file? Probably the better option
  filename         = ""${path.module}/dist/src.zip""
  source_code_hash = filebase64sha256(""${path.module}/dist/src.zip"")
  handler          = ""index.handler""
  role             = aws_iam_role.s3_credentials_lambda.arn
  runtime          = ""nodejs8.10""
  timeout          = 10
  memory_size      = 320
  environment {
    variables = {
      DISTRIBUTION_REDIRECT_ENDPOINT = ""https://${var.rest_api.id}.execute-api.${var.region}.amazonaws.com/${var.stage_name}/${var.redirect_path}""
      # TODO Remove this stub value
      # public_buckets            = """"
      EARTHDATA_BASE_URL        = var.urs_url
      EARTHDATA_CLIENT_ID       = var.urs_client_id
      EARTHDATA_CLIENT_PASSWORD = var.urs_client_password
      AccessTokensTable         = aws_dynamodb_table.access_tokens.id
      STSCredentialsLambda      = var.sts_credentials_lambda_arn
    }
  }
}
",resource,"resource ""aws_lambda_function"" ""s3_credentials"" {
  function_name    = ""${var.prefix}-s3-credentials-endpoint""
  filename         = ""${local.dist_dir}/index.js""
  source_code_hash = data.archive_file.s3_credentials_endpoint_package.output_base64sha256
  handler          = ""index.handler""
  role             = aws_iam_role.s3_credentials_lambda.arn
  runtime          = ""nodejs8.10""
  timeout          = 10
  memory_size      = 320
  vpc_config {
    subnet_ids = var.subnet_ids
    security_group_ids = var.ngap_sgs
  }
  environment {
    variables = {
      DISTRIBUTION_REDIRECT_ENDPOINT = ""https://${var.rest_api.id}.execute-api.${var.region}.amazonaws.com/${var.stage_name}/${var.redirect_path}""
      public_buckets            = var.public_buckets
      EARTHDATA_BASE_URL        = var.urs_url
      EARTHDATA_CLIENT_ID       = var.urs_client_id
      EARTHDATA_CLIENT_PASSWORD = var.urs_client_password
      AccessTokensTable         = aws_dynamodb_table.access_tokens.id
      STSCredentialsLambda      = var.sts_credentials_lambda_arn
    }
  }
}
",resource,53,,b37630397418a4cb61e428974577b0e21a636fae,6af6a727f927229cc2c252726bf45b1ab093c4be,https://github.com/nasa/cumulus/blob/b37630397418a4cb61e428974577b0e21a636fae/packages/s3-credentials-endpoint/main.tf#L53,https://github.com/nasa/cumulus/blob/6af6a727f927229cc2c252726bf45b1ab093c4be/packages/s3-credentials-endpoint/main.tf,2019-07-02 10:24:14-04:00,2019-07-17 18:01:16-05:00,3,1,1,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,175,terraform/projects/infra-security-groups/exception-handler.tf,terraform/projects/infra-security-groups/exception-handler.tf,0,# todo,# TODO: test and remove,# TODO: test and remove,"resource ""aws_security_group_rule"" ""allow_exception_handler_internal_elb_egress"" {
  type              = ""egress""
  from_port         = 0
  to_port           = 0
  protocol          = ""-1""
  cidr_blocks       = [""0.0.0.0/0""]
  security_group_id = ""${aws_security_group.exception_handler_internal_elb.id}""
}
",resource,,,57,0.0,2cff2fc034b9d6965115413f19d57f075add40d1,e9eedd137147b22192731aeae308202f0447d3cf,https://github.com/alphagov/govuk-aws/blob/2cff2fc034b9d6965115413f19d57f075add40d1/terraform/projects/infra-security-groups/exception-handler.tf#L57,https://github.com/alphagov/govuk-aws/blob/e9eedd137147b22192731aeae308202f0447d3cf/terraform/projects/infra-security-groups/exception-handler.tf#L0,2017-08-08 15:38:20+01:00,2017-11-23 16:24:54+00:00,5,2,0,1,0,1,0,0,0,1
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,983,fast/stages/03-gke-multitenant/module/gke-hub.tf,fast/stages/03-gke-multitenant/module/gke-hub.tf,0,# todo,# TODO: add condition,# TODO: add condition,"locals {
  fleet_enabled = (
    var.fleet_features != null || var.fleet_workload_identity
  )
  # TODO: add condition
  fleet_mcs_enabled = false
}
",locals,"locals {
  fleet_enabled = (
    var.fleet_features != null || var.fleet_workload_identity
  )
  fleet_mcs_enabled = local.fleet_enabled && lookup(
    coalesce(var.fleet_features, {}), ""multiclusterservicediscovery"", false
  ) == true
}
",locals,26,,133fd078232ef202140450d921bb8018b60e700f,c24e66138339bb5c599e52cd88236267acac4611,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/133fd078232ef202140450d921bb8018b60e700f/fast/stages/03-gke-multitenant/module/gke-hub.tf#L26,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/c24e66138339bb5c599e52cd88236267acac4611/fast/stages/03-gke-multitenant/module/gke-hub.tf,2022-07-29 11:31:34+02:00,2022-07-29 14:01:35+02:00,2,1,0,1,0,0,0,0,0,0
https://github.com/Worklytics/psoxy,1167,infra/modules/worklytics-connector-specs/outputs.tf,infra/modules/worklytics-connector-specs/outputs.tf,0,# todo,# TODO: better name for these MSFT/Google are also OAuth main difference is that those support,"# TODO: better name for these; MSFT/Google are also OAuth; main difference is that those support 
 # configuring the oauth clients via Terraform (and their respective APIs), whereas these require 
 # data source admins to provision clients outside of Terraform","output ""enabled_oauth_long_access_connectors"" {
  description = ""List of enabled OAuth connectors""
  value       = local.enabled_oauth_long_access_connectors
}
",output,"output ""enabled_oauth_long_access_connectors"" {
  description = ""List of enabled OAuth connectors""
  value       = local.enabled_oauth_long_access_connectors
}
",output,11,11.0,201800b288eeb8318174c9693684e8eb301b7150,8d6a95e38deba907c6c6c8a3ba6cb912260abf51,https://github.com/Worklytics/psoxy/blob/201800b288eeb8318174c9693684e8eb301b7150/infra/modules/worklytics-connector-specs/outputs.tf#L11,https://github.com/Worklytics/psoxy/blob/8d6a95e38deba907c6c6c8a3ba6cb912260abf51/infra/modules/worklytics-connector-specs/outputs.tf#L11,2023-05-10 19:48:59+00:00,2023-09-08 11:08:04-07:00,3,0,0,1,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,383,terraform/modules/aws/rds_instance/main.tf,terraform/modules/aws/rds_instance/main.tf,0,todo,# TODO this should be enabled in a Production environment:,# TODO this should be enabled in a Production environment:,"resource ""aws_db_instance"" ""db_instance"" {
  # the 'name' parameter is not set as that creates a default database
  # of that name in the instance. Which we don't want.
  count = ""${1 - var.create_replicate_source_db}""

  engine                  = ""${var.engine_name}""
  engine_version          = ""${var.engine_version}""
  username                = ""${var.username}""
  password                = ""${var.password}""
  allocated_storage       = ""${var.allocated_storage}""
  instance_class          = ""${var.instance_class}""
  storage_type            = ""${var.storage_type}""
  db_subnet_group_name    = ""${aws_db_subnet_group.subnet_group.name}""
  vpc_security_group_ids  = [""${var.security_group_ids}""]
  multi_az                = ""${var.multi_az}""
  parameter_group_name    = ""${var.parameter_group_name}""
  maintenance_window      = ""${var.maintenance_window}""
  backup_retention_period = ""${var.backup_retention_period}""
  backup_window           = ""${var.backup_window}""

  # TODO this should be enabled in a Production environment:
  final_snapshot_identifier = ""${var.name}-final-snapshot""
  skip_final_snapshot       = ""${var.skip_final_snapshot}""

  tags = ""${merge(var.default_tags, map(""Name"", var.name))}""
}
",resource,"resource ""aws_db_instance"" ""db_instance"" {
  # the 'name' parameter is not set as that creates a default database
  # of that name in the instance. Which we don't want.
  count = ""${1 - var.create_replicate_source_db}""

  engine                  = ""${var.engine_name}""
  engine_version          = ""${var.engine_version}""
  username                = ""${var.username}""
  password                = ""${var.password}""
  allocated_storage       = ""${var.allocated_storage}""
  instance_class          = ""${var.instance_class}""
  identifier              = ""${var.instance_name}""
  storage_type            = ""${var.storage_type}""
  db_subnet_group_name    = ""${aws_db_subnet_group.subnet_group.name}""
  vpc_security_group_ids  = [""${var.security_group_ids}""]
  multi_az                = ""${var.multi_az}""
  parameter_group_name    = ""${var.parameter_group_name}""
  maintenance_window      = ""${var.maintenance_window}""
  backup_retention_period = ""${var.backup_retention_period}""
  backup_window           = ""${var.backup_window}""
  copy_tags_to_snapshot   = ""${var.copy_tags_to_snapshot}""
  snapshot_identifier     = ""${var.snapshot_identifier}""

  timeouts {
    create = ""${var.terraform_create_rds_timeout}""
    delete = ""${var.terraform_delete_rds_timeout}""
    update = ""${var.terraform_update_rds_timeout}""
  }

  final_snapshot_identifier = ""${var.name}-final-snapshot""
  skip_final_snapshot       = ""${var.skip_final_snapshot}""

  tags = ""${merge(var.default_tags, map(""Name"", var.name))}""
}
",resource,189,,96444d23db9cfc15fd26e2ae6051e263204d3860,7e188f1d7431757d358d13789818bca6a6d956f6,https://github.com/alphagov/govuk-aws/blob/96444d23db9cfc15fd26e2ae6051e263204d3860/terraform/modules/aws/rds_instance/main.tf#L189,https://github.com/alphagov/govuk-aws/blob/7e188f1d7431757d358d13789818bca6a6d956f6/terraform/modules/aws/rds_instance/main.tf,2017-10-19 13:48:30+01:00,2018-09-06 15:02:47+01:00,13,1,1,1,0,0,0,1,0,0
https://github.com/Azure/sap-automation,14,deploy/terraform/terraform-units/modules/sap_deployer/variables_local.tf,deploy/terraform/terraform-units/modules/sap_deployer/variables_local.tf,0,fix,// Post fix for all deployed resources,// Post fix for all deployed resources,"locals {

  storageaccount_names = var.naming.storageaccount_names.DEPLOYER
  virtualmachine_names = var.naming.virtualmachine_names.DEPLOYER
  keyvault_names       = var.naming.keyvault_names.DEPLOYER
  resource_suffixes    = var.naming.resource_suffixes

  // Default option(s):
  enable_secure_transfer    = try(var.options.enable_secure_transfer, true)
  enable_deployer_public_ip = try(var.options.enable_deployer_public_ip, false)

  // Resource group and location
  region = try(var.infrastructure.region, """")
  prefix = length(var.infrastructure.resource_group.name) > 0 ? var.infrastructure.resource_group.name : var.naming.prefix.DEPLOYER

  rg_arm_id = try(var.infrastructure.resource_group.arm_id, """")
  rg_exists = length(local.rg_arm_id) > 0 ? true : false
  // If resource ID is specified extract the resourcegroup name from it otherwise read it either from input of create using the naming convention
  rg_name = local.rg_exists ? (
    split(""/"", local.rg_arm_id)[4]) : (
    length(var.infrastructure.resource_group.name) > 0 ? (
      var.infrastructure.resource_group.name) : (
      format(""%s%s"", local.prefix, local.resource_suffixes.deployer_rg)
    )
  )

  // Post fix for all deployed resources
  postfix = random_id.deployer.hex

  // Management vnet
  vnet_mgmt        = try(var.infrastructure.vnets.management, {})
  vnet_mgmt_arm_id = try(local.vnet_mgmt.arm_id, """")
  vnet_mgmt_exists = length(local.vnet_mgmt_arm_id) > 0

  // If resource ID is specified extract the vnet name from it otherwise read it either from input of create using the naming convention
  vnet_mgmt_name = local.vnet_mgmt_exists ? (
    split(""/"", local.vnet_mgmt_arm_id)[8]) : (
    length(local.vnet_mgmt.name) > 0 ? (
      local.vnet_mgmt.name) : (
      format(""%s%s"", local.prefix, local.resource_suffixes.vnet)
    )
  )

  vnet_mgmt_addr = local.vnet_mgmt_exists ? """" : try(local.vnet_mgmt.address_space, """")

  // Management subnet
  sub_mgmt        = try(local.vnet_mgmt.subnet_mgmt, {})
  sub_mgmt_arm_id = try(local.sub_mgmt.arm_id, """")
  sub_mgmt_exists = length(local.sub_mgmt_arm_id) > 0

  // If resource ID is specified extract the subnet name from it otherwise read it either from input of create using the naming convention
  sub_mgmt_name = local.sub_mgmt_exists ? (
    split(""/"", local.sub_mgmt_arm_id)[10]) : (
    length(local.sub_mgmt.name) > 0 ? (
      local.sub_mgmt.name) : (
      format(""%s%s"", local.prefix, local.resource_suffixes.deployer_subnet)
  ))

  sub_mgmt_prefix = local.sub_mgmt_exists ? """" : try(local.sub_mgmt.prefix, """")

  sub_mgmt_deployed = local.sub_mgmt_exists ? data.azurerm_subnet.subnet_mgmt[0] : azurerm_subnet.subnet_mgmt[0]

  // Management NSG
  sub_mgmt_nsg        = try(local.sub_mgmt.nsg, {})
  sub_mgmt_nsg_arm_id = try(local.sub_mgmt_nsg.arm_id, """")
  sub_mgmt_nsg_exists = length(local.sub_mgmt_nsg_arm_id) > 0
  // If resource ID is specified extract the nsg name from it otherwise read it either from input of create using the naming convention
  sub_mgmt_nsg_name = local.sub_mgmt_nsg_exists ? (
    split(""/"", local.sub_mgmt_nsg_arm_id)[8]) : (
    length(local.sub_mgmt_nsg.name) > 0 ? (
      local.sub_mgmt_nsg.name) : (
      format(""%s%s"", local.prefix, local.resource_suffixes.deployer_subnet_nsg)
  ))

  sub_mgmt_nsg_allowed_ips = local.sub_mgmt_nsg_exists ? (
    []) : (
    length(local.sub_mgmt_nsg.allowed_ips) > 0 ? (
      local.sub_mgmt_nsg.allowed_ips) : (
      [""0.0.0.0/0""]
    )
  )
  sub_mgmt_nsg_deployed = local.sub_mgmt_nsg_exists ? data.azurerm_network_security_group.nsg_mgmt[0] : azurerm_network_security_group.nsg_mgmt[0]

  // Firewall subnet
  sub_fw_snet        = try(local.vnet_mgmt.subnet_fw, {})
  sub_fw_snet_arm_id = try(local.sub_fw_snet.arm_id, """")
  sub_fw_snet_exists = length(local.sub_fw_snet_arm_id) > 0
  sub_fw_snet_name   = ""AzureFirewallSubnet""
  sub_fw_snet_prefix = local.sub_fw_snet_exists ? """" : try(local.sub_fw_snet.prefix, """")

  firewall_service_tags = format(""AzureCloud.%s"", local.region)

  // Deployer(s) information from input
  deployer_input = var.deployers

  // Deployer(s) information with default override
  enable_deployers = length(local.deployer_input) > 0 ? true : false

  // Deployer(s) authentication method with default
  enable_password = try(local.deployer_input[0].authentication.type, ""key"") == ""password""
  enable_key      = !local.enable_password

  username = local.enable_deployers ? (
    local.username_exist ? (
      data.azurerm_key_vault_secret.username[0].value) : (
      try(var.authentication.username, ""azureadm"")
    )) : (
    """"
  )

  // By default use generated password. Provide password under authentication overides it
  password = (local.enable_deployers && local.enable_password) ? (
    local.pwd_exist ? (
      data.azurerm_key_vault_secret.pwd[0].value) : (
      try(var.authentication.password, random_password.deployer[0].result)
    )) : (
    null
  )

  // By default use generated public key. Provide authentication.path_to_public_key and path_to_private_key overides it
  public_key = (local.enable_deployers && local.enable_key) ? (
    local.key_exist ? (
      data.azurerm_key_vault_secret.pk[0].value) : (
      try(file(var.authentication.path_to_public_key), tls_private_key.deployer[0].public_key_openssh)
    )) : (
    null
  )

  private_key = (local.enable_deployers && local.enable_key) ? (
    local.key_exist ? (
      data.azurerm_key_vault_secret.ppk[0].value) : (
      try(file(var.authentication.path_to_private_key), tls_private_key.deployer[0].private_key_pem)
    )) : (
    null
  )

  deployers = [
    for idx, deployer in local.deployer_input : {
      ""name""                 = local.virtualmachine_names[idx],
      ""destroy_after_deploy"" = true,
      ""size""                 = try(deployer.size, ""Standard_D4ds_v4""),
      ""disk_type""            = try(deployer.disk_type, ""Premium_LRS"")
      ""use_DHCP""             = try(deployer.use_DHCP, false)
      ""os"" = {
        ""source_image_id"" = try(deployer.os.source_image_id, """")
        ""publisher""       = try(deployer.os.source_image_id, """") == """" ? try(deployer.os.publisher, ""Canonical"") : """"
        ""offer""           = try(deployer.os.source_image_id, """") == """" ? try(deployer.os.offer, ""0001-com-ubuntu-server-focal"") : """"
        ""sku""             = try(deployer.os.source_image_id, """") == """" ? try(deployer.os.sku, ""20_04-lts"") : """"
        ""version""         = try(deployer.os.source_image_id, """") == """" ? try(deployer.os.version, ""latest"") : """"
      },
      ""authentication"" = {
        ""type""     = try(deployer.authentication.type, ""key"")
        ""username"" = local.username
        ""sshkey"" = {
          ""public_key""  = local.public_key
          ""private_key"" = local.private_key
        }
        ""password"" = local.password
      },
      ""components"" = [
        ""terraform"",
        ""ansible""
      ],
      ""private_ip_address"" = length(deployer.private_ip_address) > 0 ? deployer.private_ip_address : cidrhost(local.sub_mgmt_deployed.address_prefixes[0], idx + 4),
      ""users"" = {
        ""object_id"" = try(deployer.users.object_id, [])
      }
    }
  ]

  // Deployer(s) information with updated pip
  deployers_updated = [
    for idx, deployer in local.deployers : merge({
      ""public_ip_address"" = local.enable_deployer_public_ip ? azurerm_public_ip.deployer[idx].ip_address : """"
    }, deployer)
  ]

  // This is to be aligned with sap_library design.
  // If no additonal user going to be supported, this part needs to be changed.
  deployer_users_id = distinct(
    flatten([
      for deployer in local.deployers :
      deployer.users.object_id
    ])
  )

  // public ip address list of deployers
  deployer_public_ip_address_list = distinct(flatten([
    for pip_deployer in azurerm_public_ip.deployer :
    pip_deployer.ip_address
  ]))

  // public ip address of the first deployer
  deployer_public_ip_address = local.enable_deployers && local.enable_deployer_public_ip ? local.deployer_public_ip_address_list[0] : """"


  // If the user specifies arm id of key vaults in input, the key vault will be imported instead of creating new key vaults
  user_key_vault_id = try(var.key_vault.kv_user_id, """")
  prvt_key_vault_id = try(var.key_vault.kv_prvt_id, """")
  user_kv_exist     = length(local.user_key_vault_id) > 0
  prvt_kv_exist     = length(local.prvt_key_vault_id) > 0

  // If the user specifies the secret name of key pair/password in input, the secrets will be imported instead of creating new secrets
  input_public_key_secret_name  = try(var.key_vault.kv_sshkey_pub, """")
  input_private_key_secret_name = try(var.key_vault.kv_sshkey_prvt, """")
  input_password_secret_name    = try(var.key_vault.kv_pwd, """")
  input_username_secret_name    = try(var.key_vault.kv_username, """")

  // If public key secret name is provided, need to provide private key secret name as well, otherwise fail with error.
  key_exist      = try(length(local.input_public_key_secret_name) > 0, false)
  pwd_exist      = try(length(local.input_password_secret_name) > 0, false)
  username_exist = try(length(local.input_username_secret_name) > 0, false)

  ppk_secret_name      = local.key_exist ? local.input_private_key_secret_name : format(""%s-sshkey"", local.prefix)
  pk_secret_name       = local.key_exist ? local.input_public_key_secret_name : format(""%s-sshkey-pub"", local.prefix)
  pwd_secret_name      = local.pwd_exist ? local.input_password_secret_name : format(""%s-password"", local.prefix)
  username_secret_name = local.username_exist ? local.input_username_secret_name : format(""%s-username"", local.prefix)

  // Extract information from the specified key vault arm ids
  user_kv_name    = local.user_kv_exist ? split(""/"", local.user_key_vault_id)[8] : local.keyvault_names.user_access
  user_kv_rg_name = local.user_kv_exist ? split(""/"", local.user_key_vault_id)[4] : """"

  prvt_kv_name    = local.prvt_kv_exist ? split(""/"", local.prvt_key_vault_id)[8] : local.keyvault_names.private_access
  prvt_kv_rg_name = local.prvt_kv_exist ? split(""/"", local.prvt_key_vault_id)[4] : """"

  // Tags
  tags = try(var.deployers[0].tags, { ""JumpboxName"" = ""Deployer"" })


}
",locals,"locals {

  storageaccount_names                 = var.naming.storageaccount_names.DEPLOYER
  virtualmachine_names                 = var.naming.virtualmachine_names.DEPLOYER
  keyvault_names                       = var.naming.keyvault_names.DEPLOYER

  // Default option(s):
  enable_secure_transfer               = try(var.options.enable_secure_transfer, true)
  enable_deployer_public_ip            = try(var.options.enable_deployer_public_ip, false)
  Agent_IP                             = try(var.Agent_IP, """")


  // Resource group
  prefix                               = var.naming.prefix.DEPLOYER

  resource_group_exists                = length(var.infrastructure.resource_group.arm_id) > 0
  // If resource ID is specified extract the resourcegroup name from it otherwise read it either from input of create using the naming convention
  resourcegroup_name                   = local.resource_group_exists ? (
                                           split(""/"", var.infrastructure.resource_group.arm_id)[4]) : (
                                           length(var.infrastructure.resource_group.name) > 0 ? (
                                             var.infrastructure.resource_group.name) : (
                                             format(""%s%s%s"",
                                               var.naming.resource_prefixes.deployer_rg,
                                               local.prefix,
                                               var.naming.resource_suffixes.deployer_rg
                                             )
                                           )
                                         )
  rg_appservice_location               = local.resource_group_exists ? data.azurerm_resource_group.deployer[0].location : azurerm_resource_group.deployer[0].location

  // Post fix for all deployed resources
  postfix                              = random_id.deployer.hex

  // Management vnet
  vnet_mgmt_arm_id                     = try(var.infrastructure.vnets.management.arm_id, """")
  vnet_mgmt_exists                     = length(local.vnet_mgmt_arm_id) > 0

  // If resource ID is specified extract the vnet name from it otherwise read it either from input of create using the naming convention
  vnet_mgmt_name                      = local.vnet_mgmt_exists ? (
                                          split(""/"", local.vnet_mgmt_arm_id)[8]) : (
                                          length(var.infrastructure.vnets.management.name) > 0 ? (
                                            var.infrastructure.vnets.management.name) : (
                                            format(""%s%s%s"",
                                              var.naming.resource_prefixes.vnet,
                                              length(local.prefix) > 0 ? (
                                                local.prefix) : (
                                                var.infrastructure.environment
                                              ),
                                              var.naming.resource_suffixes.vnet
                                            )
                                          )
                                        )

  vnet_mgmt_addr                       = local.vnet_mgmt_exists ? """" : try(var.infrastructure.vnets.management.address_space, """")

  // Management subnet
  management_subnet_arm_id             = try(var.infrastructure.vnets.management.subnet_mgmt.arm_id, """")
  management_subnet_exists             = length(local.management_subnet_arm_id) > 0

  // If resource ID is specified extract the subnet name from it otherwise read it either from input of create using the naming convention
  management_subnet_name               = local.management_subnet_exists ? (
                                           split(""/"", var.infrastructure.vnets.management.subnet_mgmt.arm_id)[10]) : (
                                           length(var.infrastructure.vnets.management.subnet_mgmt.name) > 0 ? (
                                             var.infrastructure.vnets.management.subnet_mgmt.name) : (
                                             format(""%s%s%s"",
                                               var.naming.resource_prefixes.deployer_subnet,
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                               ),
                                               var.naming.resource_suffixes.deployer_subnet
                                             )
                                         ))

  management_subnet_prefix             = local.management_subnet_exists ? (
                                           """") : (
                                           try(var.infrastructure.vnets.management.subnet_mgmt.prefix, """")
                                         )
  management_subnet_deployed_prefixes  = local.management_subnet_exists ? (
                                           data.azurerm_subnet.subnet_mgmt[0].address_prefixes) : (
                                           try(azurerm_subnet.subnet_mgmt[0].address_prefixes, [])
                                         )

  // Management NSG
  management_subnet_nsg_arm_id         = try(var.infrastructure.vnets.management.subnet_mgmt.nsg.arm_id, """")
  management_subnet_nsg_exists         = length(local.management_subnet_nsg_arm_id) > 0
  // If resource ID is specified extract the nsg name from it otherwise read it either from input of create using the naming convention
  management_subnet_nsg_name           = local.management_subnet_nsg_exists ? (
                                           split(""/"", local.management_subnet_nsg_arm_id)[8]) : (
                                           length(var.infrastructure.vnets.management.subnet_mgmt.nsg.name) > 0 ? (
                                             var.infrastructure.vnets.management.subnet_mgmt.nsg.name) : (
                                             format(""%s%s%s"",
                                               var.naming.resource_prefixes.deployer_subnet_nsg,
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                               ),
                                               var.naming.resource_suffixes.deployer_subnet_nsg
                                             )
                                         ))

  management_subnet_nsg_allowed_ips    = local.management_subnet_nsg_exists ? (
                                           []) : (
                                           length(var.infrastructure.vnets.management.subnet_mgmt.nsg.allowed_ips) > 0 ? (
                                             var.infrastructure.vnets.management.subnet_mgmt.nsg.allowed_ips) : (
                                             [""0.0.0.0/0""]
                                           )
                                         )

  // Firewall subnet
  firewall_subnet_arm_id               = try(var.infrastructure.vnets.management.subnet_fw.arm_id, """")
  firewall_subnet_exists               = length(local.firewall_subnet_arm_id) > 0
  firewall_subnet_name                 = ""AzureFirewallSubnet""
  firewall_subnet_prefix               = local.firewall_subnet_exists ? (
                                           """") : (
                                           try(var.infrastructure.vnets.management.subnet_fw.prefix, """")
                                         )

  # Not all region names are the same as their service tags
  # https://docs.microsoft.com/en-us/azure/virtual-network/service-tags-overview#available-service-tags
  regioncode_exceptions                = {
                                           ""francecentral""      = ""centralfrance""
                                           ""francesouth""        = ""southfrance""
                                           ""germanynorth""       = ""germanyn""
                                           ""germanywestcentral"" = ""germanywc""
                                           ""norwayeast""         = ""norwaye""
                                           ""norwaywest""         = ""norwayw""
                                           ""southcentralus""     = ""usstagee""
                                           ""southcentralusstg""  = ""usstagec""
                                           ""switzerlandnorth""   = ""switzerlandn""
                                           ""switzerlandwest""    = ""switzerlandw""
                                         }

  firewall_service_tags                = format(""AzureCloud.%s"", lookup(local.regioncode_exceptions, var.infrastructure.region, var.infrastructure.region))

  // Bastion subnet
  management_bastion_subnet_arm_id     = try(var.infrastructure.vnets.management.subnet_bastion.arm_id, """")
  bastion_subnet_exists                = length(local.management_bastion_subnet_arm_id) > 0
  bastion_subnet_name                  = ""AzureBastionSubnet""
  bastion_subnet_prefix                = local.bastion_subnet_exists ? (
                                           """") : (
                                           try(var.infrastructure.vnets.management.subnet_bastion.prefix, """")
                                         )

  // Webapp subnet
  webapp_subnet_arm_id                 = try(var.infrastructure.vnets.management.subnet_webapp.arm_id, """")
  webapp_subnet_exists                 = length(local.webapp_subnet_arm_id) > 0
  webapp_subnet_name                   = ""AzureWebappSubnet""
  webapp_subnet_prefix                 = local.webapp_subnet_exists ? """" : try(var.infrastructure.vnets.management.subnet_webapp.prefix, """")

  enable_password                      = try(var.deployer.authentication.type, ""key"") == ""password""
  enable_key                           = !local.enable_password

  username                             = local.username_exist ? (
                                           data.azurerm_key_vault_secret.username[0].value) : (
                                           try(var.authentication.username, ""azureadm"")
                                         )

  // By default use generated password. Provide password under authentication overides it
  password                             = local.enable_password ? (
                                           local.pwd_exist ? (
                                             data.azurerm_key_vault_secret.pwd[0].value) : (
                                             coalesce(var.authentication.password, random_password.deployer[0].result)
                                           )) : (
                                           """"
                                         )

  // By default use generated public key. Provide authentication.path_to_public_key and path_to_private_key overides it
  public_key                           = local.enable_key ? (
                                           local.key_exist ? (
                                             data.azurerm_key_vault_secret.pk[0].value) : (
                                             try(file(var.authentication.path_to_public_key), tls_private_key.deployer[0].public_key_openssh)
                                           )) : (
                                           null
                                         )

  private_key                          = local.enable_key ? (
                                           local.key_exist ? (
                                             data.azurerm_key_vault_secret.ppk[0].value) : (
                                             try(file(var.authentication.path_to_private_key), tls_private_key.deployer[0].private_key_pem)
                                           )) : (
                                           null
                                         )

  // If the user specifies arm id of key vaults in input, the key vault will be imported instead of creating new key vaults
  prvt_key_vault_id                    = try(var.key_vault.kv_prvt_id, """")
  automation_keyvault_exist            = length(local.prvt_key_vault_id) > 0

  // If the user specifies the secret name of key pair/password in input, the secrets will be imported instead of creating new secrets
  input_public_key_secret_name         = try(var.key_vault.kv_sshkey_pub, """")
  input_private_key_secret_name        = try(var.key_vault.kv_sshkey_prvt, """")
  input_password_secret_name           = try(var.key_vault.kv_pwd, """")
  input_username_secret_name           = try(var.key_vault.kv_username, """")

  // If public key secret name is provided, need to provide private key secret name as well, otherwise fail with error.
  key_exist                            = try(length(local.input_public_key_secret_name) > 0, false)
  pwd_exist                            = try(length(local.input_password_secret_name) > 0, false)
  username_exist                       = try(length(local.input_username_secret_name) > 0, false)

  ppk_secret_name                      = local.key_exist ? (
                                           local.input_private_key_secret_name) : (
                                           replace(
                                             format(""%s-sshkey"",
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                             )),
                                             ""/[^A-Za-z0-9-]/""
                                           , """")
                                         )
  pk_secret_name                       = local.key_exist ? (
                                           local.input_public_key_secret_name) : (
                                           replace(
                                             format(""%s-sshkey-pub"",
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                               ),
                                             ),
                                             ""/[^A-Za-z0-9-]/"",
                                             """"
                                           )
                                         )
  pwd_secret_name                      = local.pwd_exist ? (
                                           local.input_password_secret_name) : (
                                           replace(
                                             format(""%s-password"",
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                               ),
                                             ),
                                             ""/[^A-Za-z0-9-]/""
                                           , """")
                                         )
  username_secret_name                 = local.username_exist ? (
                                           local.input_username_secret_name) : (
                                           replace(
                                             format(""%s-username"",
                                               length(local.prefix) > 0 ? (
                                                 local.prefix) : (
                                                 var.infrastructure.environment
                                               ),
                                             ),
                                             ""/[^A-Za-z0-9-]/""
                                           , """")
                                         )

  // Extract information from the specified key vault arm ids
  user_keyvault_name                   = var.key_vault.kv_exists ? split(""/"", var.key_vault.kv_user_id)[8] : local.keyvault_names.user_access
  # user_keyvault_resourcegroup_name     = var.key_vault.kv_exists ? split(""/"", var.key_vault.kv_user_id)[4] : """"

  automation_keyvault_name             = local.automation_keyvault_exist ? split(""/"", local.prvt_key_vault_id)[8] : local.keyvault_names.private_access
  # automation_keyvault_resourcegroup_name = local.automation_keyvault_exist ? split(""/"", local.prvt_key_vault_id)[4] : """"

  // Tags
  tags                                 = try(var.deployer.tags, { ""Role"" = ""Deployer"" })

}
",locals,59,39.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,db20ac2a47d9d00329385330cb4af6b3c726c400,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_deployer/variables_local.tf#L59,https://github.com/Azure/sap-automation/blob/db20ac2a47d9d00329385330cb4af6b3c726c400/deploy/terraform/terraform-units/modules/sap_deployer/variables_local.tf#L39,2021-11-17 19:29:07+02:00,2024-03-11 23:15:11+05:30,33,0,0,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,11,terraform/projects/app-deploy/main.tf,terraform/projects/app-deploy/main.tf,0,# todo,# TODO: Add external record when we have the external zones working,# TODO: Add external record when we have the external zones working,"module ""deploy"" {
  source                               = ""../../modules/aws/node_group""
  name                                 = ""${var.stackname}-deploy""
  vpc_id                               = ""${data.terraform_remote_state.govuk_vpc.vpc_id}""
  default_tags                         = ""${map(""Project"", var.stackname, ""aws_migration"", ""deploy"", ""aws_hostname"", ""jenkins-1"")}""
  instance_subnet_ids                  = ""${data.terraform_remote_state.govuk_networking.private_subnet_ids}""
  instance_security_group_ids          = [""${data.terraform_remote_state.govuk_security_groups.sg_deploy_id}"", ""${data.terraform_remote_state.govuk_security_groups.sg_management_id}""]
  instance_type                        = ""t2.medium""
  create_instance_key                  = true
  instance_key_name                    = ""${var.stackname}-deploy""
  instance_public_key                  = ""${var.ssh_public_key}""
  instance_additional_user_data_script = ""${file(""${path.module}/deploy_additional_user_data.txt"")}""
  instance_elb_ids                     = [""${aws_elb.deploy_elb.id}""]
}
",module,"module ""deploy"" {
  source                               = ""../../modules/aws/node_group""
  name                                 = ""${var.stackname}-deploy""
  vpc_id                               = ""${data.terraform_remote_state.infra_vpc.vpc_id}""
  default_tags                         = ""${map(""Project"", var.stackname, ""aws_stackname"", var.stackname, ""aws_environment"", var.aws_environment, ""aws_migration"", ""jenkins"", ""aws_hostname"", ""jenkins-1"")}""
  instance_subnet_ids                  = ""${data.terraform_remote_state.infra_networking.private_subnet_ids}""
  instance_security_group_ids          = [""${data.terraform_remote_state.infra_security_groups.sg_deploy_id}"", ""${data.terraform_remote_state.infra_security_groups.sg_management_id}""]
  instance_type                        = ""t2.medium""
  create_instance_key                  = true
  instance_key_name                    = ""${var.stackname}-deploy""
  instance_public_key                  = ""${var.ssh_public_key}""
  instance_additional_user_data_script = ""${file(""${path.module}/additional_user_data.txt"")}""
  instance_elb_ids                     = [""${aws_elb.deploy_elb.id}""]
}
",module,137,,f84e8337b7bc27a4db18c59933f06bf2d15f1042,b3bce600a83827c1693499f22d455c6acb269d4f,https://github.com/alphagov/govuk-aws/blob/f84e8337b7bc27a4db18c59933f06bf2d15f1042/terraform/projects/app-deploy/main.tf#L137,https://github.com/alphagov/govuk-aws/blob/b3bce600a83827c1693499f22d455c6acb269d4f/terraform/projects/app-deploy/main.tf,2017-07-10 16:37:00+01:00,2017-07-18 19:07:34+01:00,9,1,1,1,0,0,1,0,0,0
https://github.com/google/go-cloud,111,internal/cmd/gocdk/internal/static/_assets/resource/secrets/azurekeyvault.tf,internal/cmd/gocdk/internal/static/_assets/resource/secrets/azurekeyvault.tf,0,workaround,"# This is a a workaround to get it by shelling out to the ""az"" CLI.","# The azurerm Terraform provider doesn't have a way to get the ID of the 
 # current user: 
 # https://github.com/terraform-providers/terraform-provider-azurerm/issues/3234 
 # This is a a workaround to get it by shelling out to the ""az"" CLI.","data ""external"" ""current_azure_user"" {
  program = [""az"",""ad"",""signed-in-user"",""show"",""--query"",""{displayName: displayName,objectId: objectId,objectType: objectType}""]
}
",data,,,10,0.0,07955d904b2e3651fb9f8ac6f8039144f5645b18,6a2dc1826d0b0192c7846ecf45b13faa648f4b84,https://github.com/google/go-cloud/blob/07955d904b2e3651fb9f8ac6f8039144f5645b18/internal/cmd/gocdk/internal/static/_assets/resource/secrets/azurekeyvault.tf#L10,https://github.com/google/go-cloud/blob/6a2dc1826d0b0192c7846ecf45b13faa648f4b84/internal/cmd/gocdk/internal/static/_assets/resource/secrets/azurekeyvault.tf#L0,2019-07-09 10:45:21-07:00,2019-09-05 12:21:22-07:00,3,2,0,0,1,0,0,0,0,0
https://github.com/Azure/sap-automation,11,deploy/terraform/terraform-units/modules/sap_deployer/key_vault.tf,deploy/terraform/terraform-units/modules/sap_deployer/key_vault.tf,0,todo,# TODO Add this back when we separate the usage,# TODO Add this back when we separate the usage,"data ""azurerm_key_vault"" ""kv_prvt"" {
  # TODO Add this back when we separate the usage
  count               = (local.enable_deployers && local.prvt_kv_exist) ? 0 : 0
  name                = split(""/"", local.prvt_key_vault_id)[8]
  resource_group_name = split(""/"", local.prvt_key_vault_id)[4]
}
",data,the block associated got renamed or deleted,,25,,6ff0b891114c36d3aeccb850d830b698cd1fe52a,7b60debc6f454bd8ed6f8d77622ac31feb6cbea1,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_deployer/key_vault.tf#L25,https://github.com/Azure/sap-automation/blob/7b60debc6f454bd8ed6f8d77622ac31feb6cbea1/deploy/terraform/terraform-units/modules/sap_deployer/key_vault.tf,2021-11-17 19:29:07+02:00,2022-06-01 12:40:16+05:30,8,1,0,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,651,examples/data-solutions/data-platform-foundations/02-load.tf,examples/data-solutions/data-platform-foundations/02-load.tf,0,# todo,# TODO: worker service account,# TODO: worker service account,"module ""load-project"" {
  source          = ""../../../modules/project""
  parent          = var.folder_id
  billing_account = var.billing_account_id
  prefix          = var.prefix
  name            = ""lod""
  group_iam = {
    (local.groups.data-engineers) = [
      ""roles/compute.viewer"",
      ""roles/dataflow.admin"",
      ""roles/dataflow.developer"",
      ""roles/viewer"",
    ]
  }
  iam = {
    ""roles/bigquery.jobUser"" = [module.load-sa-df-0.iam_email]
    ""roles/dataflow.admin"" = [
      module.orch-sa-cmp-0.iam_email, module.load-sa-df-0.iam_email
    ]
    ""roles/dataflow.worker""     = [module.load-sa-df-0.iam_email]
    ""roles/storage.objectAdmin"" = local.load_service_accounts
    # TODO: these are needed on the shared VPC?
    # ""roles/compute.serviceAgent"" = [
    #   ""serviceAccount:${module.load-project.service_accounts.robots.compute}""
    # ]
    # ""roles/dataflow.serviceAgent"" = [
    #   ""serviceAccount:${module.load-project.service_accounts.robots.dataflow}""
    # ]
  }
  services = concat(var.project_services, [
    ""bigquery.googleapis.com"",
    ""bigqueryreservation.googleapis.com"",
    ""bigquerystorage.googleapis.com"",
    ""cloudkms.googleapis.com"",
    ""compute.googleapis.com"",
    ""dataflow.googleapis.com"",
    ""dlp.googleapis.com"",
    ""pubsub.googleapis.com"",
    ""servicenetworking.googleapis.com"",
    ""storage.googleapis.com"",
    ""storage-component.googleapis.com""
  ])
  service_encryption_key_ids = {
    pubsub   = [try(local.service_encryption_keys.pubsub, null)]
    dataflow = [try(local.service_encryption_keys.dataflow, null)]
    storage  = [try(local.service_encryption_keys.storage, null)]
  }
  shared_vpc_service_config = local.shared_vpc_project == null ? null : {
    attach       = true
    host_project = local.shared_vpc_project
    service_identity_iam = {
      # TODO: worker service account
      ""compute.networkUser"" = [""dataflow""]
    }
  }
}
",module,"module ""load-project"" {
  source          = ""../../../modules/project""
  parent          = var.folder_id
  billing_account = var.billing_account_id
  prefix          = var.prefix
  name            = ""lod""
  group_iam = {
    (local.groups.data-engineers) = [
      ""roles/compute.viewer"",
      ""roles/dataflow.admin"",
      ""roles/dataflow.developer"",
      ""roles/viewer"",
    ]
  }
  iam = {
    ""roles/bigquery.jobUser"" = [module.load-sa-df-0.iam_email]
    ""roles/dataflow.admin"" = [
      module.orch-sa-cmp-0.iam_email, module.load-sa-df-0.iam_email
    ]
    ""roles/dataflow.worker""     = [module.load-sa-df-0.iam_email]
    ""roles/storage.objectAdmin"" = local.load_service_accounts
    # TODO: these are needed on the shared VPC?
    # ""roles/compute.serviceAgent"" = [
    #   ""serviceAccount:${module.load-project.service_accounts.robots.compute}""
    # ]
    # ""roles/dataflow.serviceAgent"" = [
    #   ""serviceAccount:${module.load-project.service_accounts.robots.dataflow}""
    # ]
  }
  services = concat(var.project_services, [
    ""bigquery.googleapis.com"",
    ""bigqueryreservation.googleapis.com"",
    ""bigquerystorage.googleapis.com"",
    ""cloudkms.googleapis.com"",
    ""compute.googleapis.com"",
    ""dataflow.googleapis.com"",
    ""dlp.googleapis.com"",
    ""pubsub.googleapis.com"",
    ""servicenetworking.googleapis.com"",
    ""storage.googleapis.com"",
    ""storage-component.googleapis.com""
  ])
  service_encryption_key_ids = {
    pubsub   = [try(local.service_encryption_keys.pubsub, null)]
    dataflow = [try(local.service_encryption_keys.dataflow, null)]
    storage  = [try(local.service_encryption_keys.storage, null)]
  }
  shared_vpc_service_config = local.shared_vpc_project == null ? null : {
    attach               = true
    host_project         = local.shared_vpc_project
    service_identity_iam = {}
    # service_identity_iam = {
    #   ""compute.networkUser"" = [""dataflow""]
    # }
  }
}
",module,87,,4f4a9cd7ac2cee3a1b2e413cd19f6b6b07c35622,26a26e63b37f84678683ada11bd2fcaa42d192bc,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/4f4a9cd7ac2cee3a1b2e413cd19f6b6b07c35622/examples/data-solutions/data-platform-foundations/02-load.tf#L87,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/26a26e63b37f84678683ada11bd2fcaa42d192bc/examples/data-solutions/data-platform-foundations/02-load.tf,2022-02-09 17:01:25+01:00,2022-02-10 08:47:16+01:00,3,1,0,1,0,1,0,0,0,0
https://github.com/uyuni-project/sumaform,1359,backend_modules/aws/host/main.tf,backend_modules/aws/host/main.tf,0,hack,// after first apply terraform removes those thats. This hack avoid this behavior.,"// ## HACH 
 // SUSE aws account add some special tags identifying the instance owner (""PrincipalId"", ""Owner"") 
 // after first apply terraform removes those thats. This hack avoid this behavior. 
 // Correct way to do it would be by ignoring those ttags, which is not support yet by aws terraform provider 
 // https://github.com/terraform-providers/terraform-provider-aws/issues/10689","resource ""aws_instance"" ""instance"" {
  ami                    = local.ami
  instance_type          = local.provider_settings[""instance_type""]
  count                  = var.quantity
  availability_zone      = local.availability_zone
  key_name               = local.provider_settings[""key_name""]
  subnet_id              = local.provider_settings[""public_instance""] ? local.public_subnet_id : local.private_subnet_id
  vpc_security_group_ids = [local.provider_settings[""public_instance""] ? local.public_security_group_id : local.private_security_group_id]

  root_block_device {
    volume_size = local.provider_settings[""volume_size""]
  }

  # HACK: ephemeral block devices are defined in any case
  # they will only be used for instance types that provide them
  ephemeral_block_device {
    device_name  = ""xvdb""
    virtual_name = ""ephemeral0""
  }

  ephemeral_block_device {
    device_name  = ""xvdc""
    virtual_name = ""ephemeral1""
  }

  tags = {
    Name = ""${local.resource_name_prefix}${var.quantity > 1 ? ""-${count.index + 1}"" : """"}""
  }

  // ## HACH
  // SUSE aws account add some special tags identifying the instance owner (""PrincipalId"", ""Owner"")
  // after first apply terraform removes those thats. This hack avoid this behavior.
  // Correct way to do it would be by ignoring those ttags, which is not support yet by aws terraform provider
  // https://github.com/terraform-providers/terraform-provider-aws/issues/10689
  lifecycle {
    ignore_changes = [tags]
  }
}
",resource,"resource ""aws_instance"" ""instance"" {
  ami                    = local.ami
  instance_type          = local.provider_settings[""instance_type""]
  count                  = var.quantity
  availability_zone      = local.availability_zone
  key_name               = local.provider_settings[""key_name""]
  subnet_id              = local.provider_settings[""public_instance""] ? local.public_subnet_id : local.private_subnet_id
  vpc_security_group_ids = [local.provider_settings[""public_instance""] ? local.public_security_group_id : local.private_security_group_id]

  root_block_device {
    volume_size = local.provider_settings[""volume_size""]
  }

  user_data = data.template_file.user_data[count.index].rendered

  # HACK: ephemeral block devices are defined in any case
  # they will only be used for instance types that provide them
  ephemeral_block_device {
    device_name  = ""xvdb""
    virtual_name = ""ephemeral0""
  }

  ephemeral_block_device {
    device_name  = ""xvdc""
    virtual_name = ""ephemeral1""
  }

  tags = {
    Name = ""${local.resource_name_prefix}${var.quantity > 1 ? ""-${count.index + 1}"" : """"}""
  }

  # HACK
  # SUSE internal openbare AWS accounts add special tags to identify the instance owner (""PrincipalId"", ""Owner"").
  # After the first `apply`, terraform removes those tags. The following block avoids this behavior.
  # The correct way to do it would be by ignoring those tags, which is not supported yet by the AWS terraform provider
  # https://github.com/terraform-providers/terraform-provider-aws/issues/10689
  lifecycle {
    ignore_changes = [tags]
  }
}
",resource,69,,90f28af5d33ad772b19d9a72e5ad16657077bd6f,15bd77941377320f15ab95c290aff17bfe80d0e7,https://github.com/uyuni-project/sumaform/blob/90f28af5d33ad772b19d9a72e5ad16657077bd6f/backend_modules/aws/host/main.tf#L69,https://github.com/uyuni-project/sumaform/blob/15bd77941377320f15ab95c290aff17bfe80d0e7/backend_modules/aws/host/main.tf,2020-05-04 19:34:32+01:00,2020-05-04 19:34:32+01:00,2,1,1,1,1,1,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,633,modules/_user_data/main.tf,modules/_user_data/main.tf,0,hack,"# This is a hacky way to make that logic work, otherwise Terraform always wants a value","# The `cluster_service_cidr` is required when `create == true` 
 # This is a hacky way to make that logic work, otherwise Terraform always wants a value 
 # and supplying any old value like `""""` or `null` is not valid and will silently 
 # fail to join nodes to the cluster","resource ""null_resource"" ""validate_cluster_service_cidr"" {
  lifecycle {
    precondition {
      # The length 6 is currently arbitrary, but it's a safe bet that the CIDR will be longer than that
      # The main point is that a value needs to be provided when `create = true`
      condition     = var.create ? length(local.cluster_service_cidr) > 6 : true
      error_message = ""`cluster_service_cidr` is required when `create = true`.""
    }
  }
}
",resource,"resource ""null_resource"" ""validate_cluster_service_cidr"" {
  lifecycle {
    precondition {
      # The length 6 is currently arbitrary, but it's a safe bet that the CIDR will be longer than that
      # The main point is that a value needs to be provided when `create = true`
      condition     = var.create ? length(local.cluster_service_cidr) > 6 : true
      error_message = ""`cluster_service_cidr` is required when `create = true`.""
    }
  }
}
",resource,2,2.0,aeb9f0c990b259320a6c3e5ff93be3f064bb9238,74d39187d855932dd976da6180eda42dcfe09873,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/aeb9f0c990b259320a6c3e5ff93be3f064bb9238/modules/_user_data/main.tf#L2,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/_user_data/main.tf#L2,2024-03-12 10:36:19-04:00,2024-05-08 08:04:19-04:00,2,0,1,1,1,0,0,0,0,0
https://github.com/apache/beam,12,playground/terraform/provider.tf,playground/terraform/provider.tf,0,// todo,// TODO: required by artifact registry and memorystore remove when generally available,// TODO: required by artifact registry and memorystore remove when generally available,"provider ""google-beta"" {
  region = var.region
  project = var.project_id
  // TODO may need to run module.setup first independent of this solution and add the terraform service account as a variable
  // This allows us to use a service account to provision resources without downloading or storing service account keys
  #  impersonate_service_account = module.setup.terraform_service_account_email
}",provider,"provider ""google-beta"" {
  region = var.region
  project = var.project_id
  // TODO may need to run module.setup first independent of this solution and add the terraform service account as a variable
  // This allows us to use a service account to provision resources without downloading or storing service account keys
  #  impersonate_service_account = module.setup.terraform_service_account_email
}",provider,41,41.0,ad21d8353c856152346408f1d5029c9af05957c8,ad21d8353c856152346408f1d5029c9af05957c8,https://github.com/apache/beam/blob/ad21d8353c856152346408f1d5029c9af05957c8/playground/terraform/provider.tf#L41,https://github.com/apache/beam/blob/ad21d8353c856152346408f1d5029c9af05957c8/playground/terraform/provider.tf#L41,2022-03-16 14:13:22-07:00,2022-03-16 14:13:22-07:00,1,0,0,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,251,modules/utilities/drain.tf,modules/utilities/drain.tf,0,todo,# TODO Drain nodes for draining pools,"      ""echo kubectl drain --ignore-daemonsets"", # TODO Drain nodes for draining pools","resource ""null_resource"" ""drain_workers"" {
  triggers = {
    drain_count = jsonencode(keys(local.worker_pools_draining))
  }

  connection {
    bastion_host        = var.bastion_host
    bastion_user        = var.bastion_user
    bastion_private_key = var.ssh_private_key
    host                = var.operator_host
    user                = var.operator_user
    private_key         = var.ssh_private_key
    timeout             = ""40m""
    type                = ""ssh""
  }

  provisioner ""remote-exec"" {
    inline = [
      ""echo kubectl get nodes ..."",             # TODO List nodes by label for draining pools
      ""echo kubectl drain --ignore-daemonsets"", # TODO Drain nodes for draining pools
    ]
  }
}
",resource,"resource ""null_resource"" ""drain_workers"" {
  count = local.drain_enabled ? 1 : 0
  triggers = {
    drain_pools    = jsonencode(sort(local.drain_pools))
    drain_commands = jsonencode(local.drain_commands)
  }

  connection {
    bastion_host        = var.bastion_host
    bastion_user        = var.bastion_user
    bastion_private_key = var.ssh_private_key
    host                = var.operator_host
    user                = var.operator_user
    private_key         = var.ssh_private_key
    timeout             = ""40m""
    type                = ""ssh""
  }

  provisioner ""remote-exec"" {
    inline = local.drain_commands
  }
}
",resource,27,,79845fb791998bdde1b58fa656b6c381f7d26510,5c4fc186cf8eeac1c0af855954593058edae675b,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/79845fb791998bdde1b58fa656b6c381f7d26510/modules/utilities/drain.tf#L27,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/5c4fc186cf8eeac1c0af855954593058edae675b/modules/utilities/drain.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,4,1,0,0,0,0,0,1,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,886,modules/gke-hub/main.tf,modules/gke-hub/main.tf,0,# todo,# TODO(jccb): allow cluster member without WIF,# TODO(jccb): allow cluster member without WIF,"resource ""google_gke_hub_membership"" ""membership"" {
  provider      = google-beta
  for_each      = var.member_clusters
  membership_id = each.key
  project       = var.project_id
  endpoint {
    gke_cluster {
      resource_link = each.value
    }
  }
  # TODO(jccb): allow cluster member without WIF
  authority {
    issuer = ""https://container.googleapis.com/v1/${each.value}""
  }
}
",resource,"resource ""google_gke_hub_membership"" ""membership"" {
  provider      = google-beta
  for_each      = var.member_clusters
  membership_id = each.key
  project       = var.project_id
  endpoint {
    gke_cluster {
      resource_link = each.value
    }
  }
}
",resource,27,,9bcae7b1809d3da9ad33a72a05328e0016ef523b,824353a42bd73211b2352373e310c779d5cf4817,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/9bcae7b1809d3da9ad33a72a05328e0016ef523b/modules/gke-hub/main.tf#L27,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/824353a42bd73211b2352373e310c779d5cf4817/modules/gke-hub/main.tf,2022-06-08 11:42:04+02:00,2022-07-15 17:58:39+02:00,3,1,1,0,0,1,0,0,0,0
https://github.com/kubernetes/k8s.io,92,infra/gcp/clusters/modules/gke-cluster/variables.tf,infra/gcp/terraform/modules/gke-cluster/variables.tf,1,// todo,// TODO: default this true (and/or remove this option) once kubernetes-public/aaa uses this module,// TODO: default this true (and/or remove this option) once kubernetes-public/aaa uses this module,"variable ""dns_cache_enabled"" {
  description = <<EOF
  Whether the cluster has the NodeLocal DNSCache add-on enabled

  NOTE: changes to this value require node recreation to take effect (will happen during next maintenance window, or if gcloud command is used)

  More information available here: https://cloud.google.com/kubernetes-engine/docs/how-to/nodelocal-dns-cache
EOF
  type        = string
  // TODO: default this true (and/or remove this option) once kubernetes-public/aaa uses this module
  default     = ""false""
}
",variable,"variable ""dns_cache_enabled"" {
  description = <<EOF
  Whether the cluster has the NodeLocal DNSCache add-on enabled

  NOTE: changes to this value require node recreation to take effect (will happen during next maintenance window, or if gcloud command is used)

  More information available here: https://cloud.google.com/kubernetes-engine/docs/how-to/nodelocal-dns-cache
EOF
  type        = string
  // TODO: default this true (and/or remove this option) once kubernetes-public/aaa uses this module
  default = ""false""
}
",variable,64,70.0,d0ea46ac7085959d405efa320b8186b03d2ccc2d,4043b0be97bdcb95ac05debb497fc56093a9444f,https://github.com/kubernetes/k8s.io/blob/d0ea46ac7085959d405efa320b8186b03d2ccc2d/infra/gcp/clusters/modules/gke-cluster/variables.tf#L64,https://github.com/kubernetes/k8s.io/blob/4043b0be97bdcb95ac05debb497fc56093a9444f/infra/gcp/terraform/modules/gke-cluster/variables.tf#L70,2021-02-19 12:16:13-05:00,2021-11-02 22:40:25+01:00,4,0,0,1,0,0,1,0,0,0
https://github.com/uyuni-project/sumaform,24,openstack_host/main.tf,openstack_host/main.tf,0,hack,// HACK: id is taken from instance in order to establish dependencies,"// HACK: id is taken from instance in order to establish dependencies 
 // with other modules - not working when using hostname","output ""hostname"" {
// HACK: id is taken from instance in order to establish dependencies
// with other modules - not working when using hostname
  value = ""${coalesce(var.name + var.avahi-domain, openstack_compute_instance_v2.instance.id)}""
}
",output,"output ""hostname"" {
  // HACK: this output artificially depends on the instance id
  // any resource using this output will have to wait until instance is fully up
  value = ""${coalesce(""${var.name}.${var.domain}"", openstack_compute_instance_v2.instance.id)}""
}
",output,63,,3408f778c78b671606ea03857a98bdc78fc26f83,7b44a14d4d6a74a6e0387ceb7238c62df9765b92,https://github.com/uyuni-project/sumaform/blob/3408f778c78b671606ea03857a98bdc78fc26f83/openstack_host/main.tf#L63,https://github.com/uyuni-project/sumaform/blob/7b44a14d4d6a74a6e0387ceb7238c62df9765b92/openstack_host/main.tf,2016-06-30 17:51:29+02:00,2016-09-05 14:18:52+02:00,8,1,1,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,10,terraform/projects/app-deploy/main.tf,terraform/projects/app-deploy/main.tf,0,# todo,# TODO: change to 443 once we prove the host puppets,# TODO: change to 443 once we prove the host puppets,"resource ""aws_elb"" ""deploy_elb"" {
  name            = ""${var.stackname}-deploy""
  subnets         = [""${data.terraform_remote_state.govuk_networking.public_subnet_ids}""]
  security_groups = [""${data.terraform_remote_state.govuk_security_groups.sg_deploy_elb_id}""]
  internal        = ""false""

  listener {
    instance_port     = 443
    instance_protocol = ""tcp""
    lb_port           = 443
    lb_protocol       = ""tcp""
  }

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3

    # TODO: change to 443 once we prove the host puppets
    target   = ""TCP:22""
    interval = 30
  }

  cross_zone_load_balancing   = true
  idle_timeout                = 400
  connection_draining         = true
  connection_draining_timeout = 400

  tags = ""${map(""Name"", ""${var.stackname}-deploy"", ""Project"", var.stackname, ""aws_migration"", ""deploy"")}""
}
",resource,"resource ""aws_elb"" ""deploy_elb"" {
  name            = ""${var.stackname}-deploy""
  subnets         = [""${data.terraform_remote_state.infra_networking.public_subnet_ids}""]
  security_groups = [""${data.terraform_remote_state.infra_security_groups.sg_deploy_elb_id}""]
  internal        = ""false""

  listener {
    instance_port     = 443
    instance_protocol = ""tcp""
    lb_port           = 443
    lb_protocol       = ""tcp""
  }

  health_check {
    healthy_threshold   = 2
    unhealthy_threshold = 2
    timeout             = 3

    target   = ""TCP:443""
    interval = 30
  }

  cross_zone_load_balancing   = true
  idle_timeout                = 400
  connection_draining         = true
  connection_draining_timeout = 400

  tags = ""${map(""Name"", ""${var.stackname}-deploy"", ""Project"", var.stackname, ""aws_environment"", var.aws_environment, ""aws_migration"", ""jenkins"")}""
}
",resource,124,,f84e8337b7bc27a4db18c59933f06bf2d15f1042,b3bce600a83827c1693499f22d455c6acb269d4f,https://github.com/alphagov/govuk-aws/blob/f84e8337b7bc27a4db18c59933f06bf2d15f1042/terraform/projects/app-deploy/main.tf#L124,https://github.com/alphagov/govuk-aws/blob/b3bce600a83827c1693499f22d455c6acb269d4f/terraform/projects/app-deploy/main.tf,2017-07-10 16:37:00+01:00,2017-07-18 19:07:34+01:00,9,1,0,1,0,0,1,0,0,0
https://github.com/compiler-explorer/infra,132,terraform/security.tf,terraform/security.tf,0,// todo,// TODO: remove this comment once we're happy with the builder:,"// TODO: remove this comment once we're happy with the builder:
// * builder used to have AmazonSFullAccess and AmazonSSMReadOnlyAccess","resource ""aws_iam_role"" ""Builder"" {
  name               = ""Builder""
  description        = ""Compiler Explorer compiler and library building role""
  assume_role_policy = data.aws_iam_policy_document.InstanceAssumeRolePolicy.json
}
",resource,"resource ""aws_iam_role"" ""Builder"" {
  name               = ""Builder""
  description        = ""Compiler Explorer compiler and library building role""
  assume_role_policy = data.aws_iam_policy_document.InstanceAssumeRolePolicy.json
}
",resource,310,415.0,2eaefccbb0f3e28949710984dfe0f9c6067a61be,e1b1416e3a1af2b54c905c5b90153208afdd87e7,https://github.com/compiler-explorer/infra/blob/2eaefccbb0f3e28949710984dfe0f9c6067a61be/terraform/security.tf#L310,https://github.com/compiler-explorer/infra/blob/e1b1416e3a1af2b54c905c5b90153208afdd87e7/terraform/security.tf#L415,2021-09-02 08:22:34-05:00,2024-04-22 22:51:52+02:00,28,0,0,1,0,1,0,0,0,0
https://github.com/Azure/sap-automation,2133,deploy/terraform/terraform-units/modules/sap_system/anydb_node/vm-observer.tf,deploy/terraform/terraform-units/modules/sap_system/anydb_node/vm-observer.tf,0,todo,# ToDo Add back later,"# ToDo Add back later 
 # patch_mode                           = var.infrastructure.patch_mode ","resource ""azurerm_windows_virtual_machine"" ""observer"" {
  provider                             = azurerm.main
  count                                = local.deploy_observer  && upper(local.anydb_ostype) == ""WINDOWS"" ? local.db_zone_count : 0
  depends_on                           = [var.anchor_vm]
  resource_group_name                  = var.resource_group[0].name
  location                             = var.resource_group[0].location

  name                                 = format(""%s%s%s%s%s"",
                                           var.naming.resource_prefixes.vm,
                                           local.prefix,
                                           var.naming.separator,
                                           var.naming.virtualmachine_names.OBSERVER_VMNAME[count.index],
                                           local.resource_suffixes.vm
                                         )
  computer_name                         = var.naming.virtualmachine_names.OBSERVER_COMPUTERNAME[count.index]

  admin_username                        = var.sid_username
  admin_password                        = var.sid_password

  zone                                 = local.zonal_deployment ? local.zones[count.index % max(local.db_zone_count, 1)] : null

  network_interface_ids                = [
                                           azurerm_network_interface.observer[count.index].id
                                         ]
  size                                 = local.observer_size
  source_image_id                      = local.observer_custom_image ? local.observer_custom_image_id : null

  custom_data                          = var.deployment == ""new"" ? var.cloudinit_growpart_config : null

  license_type                         = length(var.license_type) > 0 ? var.license_type : null
  # ToDo Add back later
# patch_mode                           = var.infrastructure.patch_mode

  tags                                 = merge(local.tags, var.tags)


  os_disk {
            name = format(""%s%s%s%s%s"",
              var.naming.resource_prefixes.osdisk,
              local.prefix,
              var.naming.separator,
              var.naming.virtualmachine_names.OBSERVER_VMNAME[count.index],
              local.resource_suffixes.osdisk
            )
            caching                = ""ReadWrite""
            storage_account_type   = ""Premium_LRS""
            disk_encryption_set_id = try(var.options.disk_encryption_set_id, null)
          }


  dynamic ""source_image_reference"" {
                                     for_each = range(local.observer_custom_image ? 0 : 1)
                                     content {
                                       publisher = local.observer_os.publisher
                                       offer     = local.observer_os.offer
                                       sku       = local.observer_os.sku
                                       version   = local.observer_os.version
                                     }
                                   }

  boot_diagnostics {
                     storage_account_uri = var.storage_bootdiag_endpoint
                   }
  lifecycle {
    ignore_changes = [
      source_image_id
    ]
  }
}
",resource,"resource ""azurerm_windows_virtual_machine"" ""observer"" {
  provider                             = azurerm.main
  count                                = local.deploy_observer  && upper(local.anydb_ostype) == ""WINDOWS"" ? local.db_zone_count : 0
  depends_on                           = [var.anchor_vm]
  resource_group_name                  = var.resource_group[0].name
  location                             = var.resource_group[0].location

  name                                 = format(""%s%s%s%s%s"",
                                           var.naming.resource_prefixes.vm,
                                           local.prefix,
                                           var.naming.separator,
                                           var.naming.virtualmachine_names.OBSERVER_VMNAME[count.index],
                                           local.resource_suffixes.vm
                                         )
  computer_name                         = var.naming.virtualmachine_names.OBSERVER_COMPUTERNAME[count.index]

  admin_username                        = var.sid_username
  admin_password                        = var.sid_password

  zone                                 = local.zonal_deployment ? local.zones[count.index % max(local.db_zone_count, 1)] : null

  network_interface_ids                = [
                                           azurerm_network_interface.observer[count.index].id
                                         ]
  size                                 = local.observer_size
  source_image_id                      = local.observer_custom_image ? local.observer_custom_image_id : null

  custom_data                          = var.deployment == ""new"" ? var.cloudinit_growpart_config : null

  license_type                         = length(var.license_type) > 0 ? var.license_type : null
  # ToDo Add back later
# patch_mode                           = var.infrastructure.patch_mode

  tags                                 = merge(local.tags, var.tags)


  os_disk {
            name = format(""%s%s%s%s%s"",
              var.naming.resource_prefixes.osdisk,
              local.prefix,
              var.naming.separator,
              var.naming.virtualmachine_names.OBSERVER_VMNAME[count.index],
              local.resource_suffixes.osdisk
            )
            caching                = ""ReadWrite""
            storage_account_type   = ""Premium_LRS""
            disk_encryption_set_id = try(var.options.disk_encryption_set_id, null)
          }


  dynamic ""source_image_reference"" {
                                     for_each = range(local.observer_custom_image ? 0 : 1)
                                     content {
                                       publisher = local.observer_os.publisher
                                       offer     = local.observer_os.offer
                                       sku       = local.observer_os.sku
                                       version   = local.observer_os.version
                                     }
                                   }

  boot_diagnostics {
                     storage_account_uri = var.storage_bootdiag_endpoint
                   }
  lifecycle {
    ignore_changes = [
      source_image_id
    ]
  }
}
",resource,153,153.0,df063c58945a9efa2cb2ba303762c43f0b9c1d8f,df063c58945a9efa2cb2ba303762c43f0b9c1d8f,https://github.com/Azure/sap-automation/blob/df063c58945a9efa2cb2ba303762c43f0b9c1d8f/deploy/terraform/terraform-units/modules/sap_system/anydb_node/vm-observer.tf#L153,https://github.com/Azure/sap-automation/blob/df063c58945a9efa2cb2ba303762c43f0b9c1d8f/deploy/terraform/terraform-units/modules/sap_system/anydb_node/vm-observer.tf#L153,2024-05-17 12:37:17+03:00,2024-05-17 12:37:17+03:00,1,0,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1713,modules/billing-account/variables.tf,modules/billing-account/variables.tf,0,# todo,# TODO: align all other factory variable names,# TODO: align all other factory variable names,"variable ""factory_config"" {
  # TODO: align all other factory variable names
  description = ""Path to folder containing budget alerts data files.""
  type = object({
    budgets_data_path = optional(string, ""data/billing-budgets"")
  })
  nullable = false
  default  = {}
}
",variable,the block associated got renamed or deleted,,122,,671f06a3a483753599a50e255a989250618aa504,6941313c7d1139dbfb0c016abb50fbef64902603,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/671f06a3a483753599a50e255a989250618aa504/modules/billing-account/variables.tf#L122,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/6941313c7d1139dbfb0c016abb50fbef64902603/modules/billing-account/variables.tf,2023-10-29 11:24:52+01:00,2024-02-26 10:16:52+00:00,6,1,0,1,0,0,0,0,0,0
https://github.com/ManagedKube/kubernetes-ops,11,terraform-modules/aws/msk_1.0.9/module/security-group-variables.tf,terraform-modules/aws/msk_1.0.9/module/security-group-variables.tf,0,implement,## - too hard to implement,"## 
 ## allowed_* inputs are optional, because the same thing can be accomplished by 
 ## providing `additional_security_group_rules`. However, if the rules this 
 ## module creates are non-trivial (for example, opening ports based on 
 ## feature settings, see https://github.com/cloudposse/terraform-aws-msk-apache-kafka-cluster/blob/3fe23c402cc420799ae721186812482335f78d24/main.tf#L14-L53 ) 
 ## then it makes sense to include these. 
 ## Reasons not to include some or all of these inputs include 
 ## - too hard to implement 
 ## - does not make sense (particularly the IPv6 inputs if the underlying resource does not yet support IPv6) 
 ## - likely to confuse users 
 ## - likely to invite count/for_each issues","variable ""allowed_security_group_ids"" {
  type        = list(string)
  description = <<-EOT
    A list of IDs of Security Groups to allow access to the security group created by this module.
    The length of this list must be known at ""plan"" time.
    EOT
  default     = []
}
",variable,"variable ""allowed_security_group_ids"" {
  type        = list(string)
  description = <<-EOT
    A list of IDs of Security Groups to allow access to the security group created by this module.
    The length of this list must be known at ""plan"" time.
    EOT
  default     = []
}
",variable,44,44.0,c8193c7d74e2f7c624f0867337294cb66a2b9469,c8193c7d74e2f7c624f0867337294cb66a2b9469,https://github.com/ManagedKube/kubernetes-ops/blob/c8193c7d74e2f7c624f0867337294cb66a2b9469/terraform-modules/aws/msk_1.0.9/module/security-group-variables.tf#L44,https://github.com/ManagedKube/kubernetes-ops/blob/c8193c7d74e2f7c624f0867337294cb66a2b9469/terraform-modules/aws/msk_1.0.9/module/security-group-variables.tf#L44,2023-12-14 10:29:30-08:00,2023-12-14 10:29:30-08:00,1,0,0,1,0,1,0,0,0,0
https://github.com/Worklytics/psoxy,928,infra/modular-examples/aws-google-workspace/variables.tf,infra/modular-examples/aws-google-workspace/variables.tf,0,# todo,# TODO: true in v0.5,default     = false # TODO: true in v0.5,"variable ""pseudonymize_app_ids"" {
  type        = string
  description = ""if set, will set value of PSEUDONYMIZE_APP_IDS environment variable to this value for all sources""
  default     = false # TODO: true in v0.5
}
",variable,"variable ""pseudonymize_app_ids"" {
  type        = string
  description = ""if set, will set value of PSEUDONYMIZE_APP_IDS environment variable to this value for all sources""
  default     = false # TODO: true in v0.5
}
",variable,119,134.0,e7cb7c668f443515fed7f39bfa62ebda2352859d,eab9e60f692eba74b5a3e95ae53442762bc56994,https://github.com/Worklytics/psoxy/blob/e7cb7c668f443515fed7f39bfa62ebda2352859d/infra/modular-examples/aws-google-workspace/variables.tf#L119,https://github.com/Worklytics/psoxy/blob/eab9e60f692eba74b5a3e95ae53442762bc56994/infra/modular-examples/aws-google-workspace/variables.tf#L134,2023-04-07 14:29:36-07:00,2024-01-02 10:53:59-08:00,13,0,0,1,0,0,0,0,0,0
https://github.com/aws-ia/terraform-aws-eks-blueprints,35,main.tf,main.tf,0,#todo,#TODO Create KMS alias and assign it,"# --------------------------------------------------------------------------------------------------------------------- 
 # EKS CONTROL PLANE 
 # --------------------------------------------------------------------------------------------------------------------- 
 #TODO Create KMS alias and assign it","resource ""aws_kms_key"" ""eks"" {
  description = ""EKS Cluster Secret Encryption Key""
}
",resource,"resource ""aws_kms_key"" ""eks"" {
  description = ""EKS Cluster Secret Encryption Key""
}
",resource,34,,3da0c361bbb41fefe963f07cb541bb81eaba6e49,1592e2418f402e3ab9ed178a8fdc7f7912f09444,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/3da0c361bbb41fefe963f07cb541bb81eaba6e49/main.tf#L34,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/1592e2418f402e3ab9ed178a8fdc7f7912f09444/main.tf,2021-10-09 20:33:37+01:00,2022-01-07 21:39:47+00:00,16,1,0,1,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,1462,terraform/projects/infra-database-backups-bucket/reader.tf,terraform/projects/infra-database-backups-bucket/reader.tf,0,// todo,// TODO: delete these once db-admin machines are gone.,"// IAM policies for legacy db-admin EC2 bastion hosts. 
 // TODO: delete these once db-admin machines are gone. ","resource ""aws_iam_policy"" ""integration_mongo_api_database_backups_reader"" {
  name        = ""govuk-integration-mongo-api_database_backups-reader-policy""
  policy      = data.aws_iam_policy_document.integration_mongo_api_database_backups_reader.json
  description = ""Allows reading the mongo-api database_backups bucket""
}
",resource,"resource ""aws_iam_policy"" ""integration_mongo_api_database_backups_reader"" {
  name        = ""govuk-integration-mongo-api_database_backups-reader-policy""
  policy      = data.aws_iam_policy_document.integration_mongo_api_database_backups_reader.json
  description = ""Allows reading the mongo-api database_backups bucket""
}
",resource,2,2.0,04b817e5e25eb8691b316964e87f01ab15d339aa,20bc67be4a7d62f92027f56128eeabe46679e8a2,https://github.com/alphagov/govuk-aws/blob/04b817e5e25eb8691b316964e87f01ab15d339aa/terraform/projects/infra-database-backups-bucket/reader.tf#L2,https://github.com/alphagov/govuk-aws/blob/20bc67be4a7d62f92027f56128eeabe46679e8a2/terraform/projects/infra-database-backups-bucket/reader.tf#L2,2023-10-31 20:03:46+00:00,2023-11-22 15:00:38+00:00,2,0,1,0,0,1,0,0,0,0
https://github.com/Azure/Avere,1,src/terraform/examples/vfxt/vdbench/main.tf,src/terraform/examples/vfxt/vdbench/main.tf,0,// todo,// TODO: test and then add the vFXT or HPC Cache above,"// TODO: test and then add the vFXT or HPC Cache above  
 // the vdbench module","module ""vdbench_configure"" {
    source = ""../../../modules/vdbench_config""

    node_address = controller_address
    admin_username = local.admin_username
    admin_password = local.admin_password
    ssh_key_data = local.ssh_key_data
    nfs_address = local.mount_addresses[0]
    nfs_export_path = local.nfs_export_path
    vdbench_url = local.vdbench_url
}
",module,"module ""vdbench_configure"" {
    source = ""../../../modules/vdbench_config""

    node_address = module.vfxtcontroller.controller_address
    admin_username = module.vfxtcontroller.controller_username
    admin_password = local.vm_ssh_key_data != null && local.vm_ssh_key_data != """" ? """" : local.vm_admin_password
    ssh_key_data = local.vm_ssh_key_data
    nfs_address = tolist(avere_vfxt.vfxt.vserver_ip_addresses)[0]
    nfs_export_path = local.nfs_export_path
    vdbench_url = local.vdbench_url
}
",module,37,,865d4c7927c002dc6ef575251446a7b58ef71259,2c40c6047d8e1840034c986c8eff93b2098fd934,https://github.com/Azure/Avere/blob/865d4c7927c002dc6ef575251446a7b58ef71259/src/terraform/examples/vfxt/vdbench/main.tf#L37,https://github.com/Azure/Avere/blob/2c40c6047d8e1840034c986c8eff93b2098fd934/src/terraform/examples/vfxt/vdbench/main.tf,2020-03-04 16:32:15+11:00,2020-03-08 21:10:10-04:00,2,1,1,1,0,0,0,0,1,1
https://github.com/pingcap/tidb-operator,56,deploy/modules/gcp/tidb-cluster/data.tf,deploy/modules/gcp/tidb-cluster/data.tf,0,todo,# TODO Update related code when node locations is avaiable in attributes of cluster resource.,# TODO Update related code when node locations is avaiable in attributes of cluster resource.,"locals {
  # TODO Update related code when node locations is avaiable in attributes of cluster resource.
  cmd_get_cluster_locations = <<EOT
gcloud --project ${var.gcp_project} container clusters list --filter='name=${var.gke_cluster_name}' --format='json[no-heading](locations)' --region ${var.gke_cluster_location} | jq '.[0] | .locations |= join("","")'
EOT
}
",locals,the block associated got renamed or deleted,,22,,bbcc3677d6e0d9c17e9f00f4e118b069a8d05750,32e1f58b34ea891d653e436f263485578df5ce63,https://github.com/pingcap/tidb-operator/blob/bbcc3677d6e0d9c17e9f00f4e118b069a8d05750/deploy/modules/gcp/tidb-cluster/data.tf#L22,https://github.com/pingcap/tidb-operator/blob/32e1f58b34ea891d653e436f263485578df5ce63/deploy/modules/gcp/tidb-cluster/data.tf,2019-08-21 12:33:58-07:00,2020-07-23 15:01:18+08:00,6,1,1,1,0,0,0,0,0,0
