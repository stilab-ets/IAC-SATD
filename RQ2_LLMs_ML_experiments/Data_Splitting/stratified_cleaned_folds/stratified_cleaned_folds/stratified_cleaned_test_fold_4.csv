Repo URL,Satd Comment Id,File Path Of First Occurence,File Path Of Last Occurence,renamed,Keyword,SATD Comment,context,bloc of first occurrence,bloc type of first occurrence,bloc of last occurrence,bloc type of last occurrence,SATD Comment Line Of First Occurence,SATD Comment Line Of Last Occurence,first Commit Hash,last Commit Hash,Link To The File Of First Occurence,Link To The File Of Last Occurence/When Adressed,Introduction Time,Last Occurence (even solved or not),number of commits,adressed ?,Computing Management Debt,IaC Code Debt,Dependency Management,Security Debt,Networking Debt,Environment-Based Configuration Debt,Monitoring and Logging Debt,Test Debt
https://github.com/oracle-terraform-modules/terraform-oci-oke,171,workergroups.tf,workerpools.tf,1,implementation,# Default workergroup sub-module implementation for OKE cluster,"# Copyright (c) 2022, 2023 Oracle Corporation and/or its affiliates. 
 # Licensed under the Universal Permissive License v 1.0 as shown at https://oss.oracle.com/licenses/upl  
 # Default workergroup sub-module implementation for OKE cluster","module ""workergroup"" {
  source                          = ""./modules/workergroup""
  config_file_profile             = var.config_file_profile
  worker_groups                   = var.worker_groups
  tenancy_id                      = local.tenancy_id
  compartment_id                  = local.worker_compartment_id
  region                          = var.region
  cluster_id                      = coalesce(var.cluster_id, module.oke.cluster_id)
  apiserver_private_host          = try(split("":"", module.oke.endpoints[0].private_endpoint)[0], """")
  apiserver_public_host           = try(split("":"", module.oke.endpoints[0].public_endpoint)[0], """")
  image_id                        = local.worker_image_id
  image_type                      = local.worker_image_type
  os                              = var.node_pool_os
  os_version                      = var.node_pool_os_version
  enabled                         = var.worker_group_enabled
  mode                            = var.worker_group_mode
  boot_volume_size                = var.worker_group_boot_volume_size
  memory                          = var.worker_group_memory
  ocpus                           = var.worker_group_ocpus
  shape                           = var.worker_group_shape
  size                            = var.worker_group_size
  cloudinit                       = var.cloudinit_nodepool_common
  cluster_ca_cert                 = var.cluster_ca_cert
  kubernetes_version              = var.kubernetes_version
  pod_nsg_ids                     = try(split("","", lookup(module.network.nsg_ids, ""pods"", """")), [])
  worker_nsg_ids                  = coalescelist(var.worker_nsgs, try(split("","", lookup(module.network.nsg_ids, ""workers"", """")), []))
  assign_public_ip                = var.worker_type == ""public""
  subnet_id                       = coalesce(var.worker_group_primary_subnet_id, lookup(module.network.subnet_ids, ""workers"", """"))
  enable_pv_encryption_in_transit = var.enable_pv_encryption_in_transit
  sriov_num_vfs                   = var.sriov_num_vfs
  ssh_public_key                  = var.ssh_public_key
  ssh_public_key_path             = var.ssh_public_key_path
  timezone                        = var.node_pool_timezone
  volume_kms_key_id               = var.node_pool_volume_kms_key_id
  defined_tags                    = lookup(lookup(var.defined_tags, ""oke"", {}), ""node"", {})
  freeform_tags                   = lookup(lookup(var.freeform_tags, ""oke"", {}), ""node"", {})
  providers = {
    oci.home = oci.home
  }
}
",module,the block associated got renamed or deleted,,4,,4d2b3f3d672a8f41655da3a7c58fded42c6858f3,897bae1fd6cdbd22478066e6f93643a8f7482757,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/4d2b3f3d672a8f41655da3a7c58fded42c6858f3/workergroups.tf#L4,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/897bae1fd6cdbd22478066e6f93643a8f7482757/workerpools.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,2,1,1,0,0,0,0,0,0,0
https://github.com/ManagedKube/kubernetes-ops,6,terraform-modules/aws/opensearch/main.tf,terraform-modules/aws/opensearch/main.tf,0,ineffici,"# you can identify slow search operations and investigate potential causes, such as inefficient queries, resource constraints, or heavy search loads.","  # These logs record search and query operations that exceed the specified threshold, usually in terms of time taken to process the operation.
  # Search operations involve running queries against the OpenSearch index to retrieve documents. By analyzing search slow logs, 
  # you can identify slow search operations and investigate potential causes, such as inefficient queries, resource constraints, or heavy search loads.","resource ""aws_opensearch_domain"" ""this"" {
  domain_name    = var.domain_name
  engine_version = ""OpenSearch_2.5""

  cluster_config {
    instance_type          = var.instance_type
    zone_awareness_enabled = var.zone_awareness_enabled
    instance_count         = var.instance_count
  }

  ebs_options {
    ebs_enabled = var.ebs_enabled
    volume_size = var.volume_size
  }

  encrypt_at_rest {
    enabled = true
  }

  node_to_node_encryption {
    enabled = true
  }

  domain_endpoint_options {
    enforce_https       = var.enforce_https
    tls_security_policy = var.tls_security_policy
  }

  # the dynamic block creates a vpc_options block with the specified security group and subnet IDs.
  # If the variable vpc_enabled is set to false, the dynamic block is not created, 
  # and the aws_opensearch_domain resource will not include a vpc_options block, 
  # creating the OpenSearch domain publicly.
  dynamic ""vpc_options"" {
    for_each = var.vpc_enabled ? [1] : []
    content {
      security_group_ids = concat([aws_security_group.opensearch_sg.id], var.additional_security_group_ids)
      subnet_ids         = var.subnet_ids
    }
  }

  # The current configuration with Principal = { AWS = ""*"" } allows any authenticated AWS user or role to access the OpenSearch domain but the policy enforces that the access must be over a secure transport (HTTPS),
  # as specified in the Condition block.
  # Plese refer the Documentation for access policies https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/opensearch_domain#access-policy
  # use variable allowed_roles to update the policy with a user role who can access this
  access_policies = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = ""es:*""
        Effect = ""Allow""
        Principal = {
          AWS = var.allowed_roles
        }
        Resource = ""arn:aws:es:${var.aws_region}:${var.account_id}:domain/${var.domain_name}/*""
        Condition = var.vpc_enabled ? {
          Bool = {
            ""aws:SecureTransport"" = ""true""
          }
        } : {}
      }
    ]
  })

  # Index and search slow logs are logs generated by OpenSearch (formerly Elasticsearch) to record operations that take longer than a specified threshold. 
  # These logs help identify performance issues and bottlenecks within the OpenSearch cluster

  # Index Slow Logs: These logs record indexing operations that exceed the specified threshold, usually in terms of time taken to process the operation. 
  # Indexing operations involve adding, updating, or deleting documents in the OpenSearch index. By analyzing index slow logs, 
  # you can identify slow indexing operations and investigate potential causes, such as complex mappings, resource constraints, or heavy indexing loads.

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.opensearch_slow_logs.arn
    log_type                 = ""INDEX_SLOW_LOGS""
  }

  # These logs record search and query operations that exceed the specified threshold, usually in terms of time taken to process the operation.
  # Search operations involve running queries against the OpenSearch index to retrieve documents. By analyzing search slow logs, 
  # you can identify slow search operations and investigate potential causes, such as inefficient queries, resource constraints, or heavy search loads.
  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.opensearch_slow_logs.arn
    log_type                 = ""SEARCH_SLOW_LOGS""
  }

  depends_on = [aws_security_group.opensearch_sg]
}
",resource,"resource ""aws_opensearch_domain"" ""this"" {
  domain_name    = var.domain_name
  engine_version = ""OpenSearch_2.5""

  cluster_config {
    instance_type          = var.instance_type
    zone_awareness_enabled = var.zone_awareness_enabled
    instance_count         = var.instance_count
  }

  ebs_options {
    ebs_enabled = var.ebs_enabled
    volume_size = var.volume_size
  }

  encrypt_at_rest {
    enabled = true
  }

  node_to_node_encryption {
    enabled = true
  }

  domain_endpoint_options {
    enforce_https       = var.enforce_https
    tls_security_policy = var.tls_security_policy
  }

  # the dynamic block creates a vpc_options block with the specified security group and subnet IDs.
  # If the variable vpc_enabled is set to false, the dynamic block is not created, 
  # and the aws_opensearch_domain resource will not include a vpc_options block, 
  # creating the OpenSearch domain publicly.
  dynamic ""vpc_options"" {
    for_each = var.vpc_enabled ? [1] : []
    content {
      security_group_ids = concat([aws_security_group.opensearch_sg.id], var.additional_security_group_ids)
      subnet_ids         = var.subnet_ids
    }
  }

  # The current configuration with Principal = { AWS = ""*"" } allows any authenticated AWS user or role to access the OpenSearch domain but the policy enforces that the access must be over a secure transport (HTTPS),
  # as specified in the Condition block.
  # Plese refer the Documentation for access policies https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/opensearch_domain#access-policy
  # use variable allowed_roles to update the policy with a user role who can access this
  access_policies = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = ""es:*""
        Effect = ""Allow""
        Principal = {
          AWS = var.allowed_roles
        }
        Resource = ""arn:aws:es:${var.aws_region}:${var.account_id}:domain/${var.domain_name}/*""
        Condition = var.vpc_enabled ? {
          Bool = {
            ""aws:SecureTransport"" = ""true""
          }
        } : {}
      }
    ]
  })

  # Index and search slow logs are logs generated by OpenSearch (formerly Elasticsearch) to record operations that take longer than a specified threshold. 
  # These logs help identify performance issues and bottlenecks within the OpenSearch cluster

  # Index Slow Logs: These logs record indexing operations that exceed the specified threshold, usually in terms of time taken to process the operation. 
  # Indexing operations involve adding, updating, or deleting documents in the OpenSearch index. By analyzing index slow logs, 
  # you can identify slow indexing operations and investigate potential causes, such as complex mappings, resource constraints, or heavy indexing loads.

  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.opensearch_slow_logs.arn
    log_type                 = ""INDEX_SLOW_LOGS""
  }

  # These logs record search and query operations that exceed the specified threshold, usually in terms of time taken to process the operation.
  # Search operations involve running queries against the OpenSearch index to retrieve documents. By analyzing search slow logs, 
  # you can identify slow search operations and investigate potential causes, such as inefficient queries, resource constraints, or heavy search loads.
  log_publishing_options {
    cloudwatch_log_group_arn = aws_cloudwatch_log_group.opensearch_slow_logs.arn
    log_type                 = ""SEARCH_SLOW_LOGS""
  }

  depends_on = [aws_security_group.opensearch_sg]
}
",resource,104,104.0,7c2c662a68a16d435ce56177a7a5ae659f94618d,7c2c662a68a16d435ce56177a7a5ae659f94618d,https://github.com/ManagedKube/kubernetes-ops/blob/7c2c662a68a16d435ce56177a7a5ae659f94618d/terraform-modules/aws/opensearch/main.tf#L104,https://github.com/ManagedKube/kubernetes-ops/blob/7c2c662a68a16d435ce56177a7a5ae659f94618d/terraform-modules/aws/opensearch/main.tf#L104,2023-03-21 13:14:52-07:00,2023-03-21 13:14:52-07:00,1,0,1,0,0,0,0,0,1,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,26,modules/gke-cluster/main.tf,modules/gke-cluster/main.tf,0,# todo,# TODO(ludomagno): compute addons map in locals and use a single dynamic block,"# node_config 
 # TODO(ludomagno): compute addons map in locals and use a single dynamic block ","resource ""google_container_cluster"" ""cluster"" {
  provider                    = google-beta
  project                     = var.project_id
  name                        = var.name
  description                 = var.description
  location                    = var.location
  node_locations              = length(var.node_locations) == 0 ? null : var.node_locations
  min_master_version          = var.min_master_version
  network                     = var.network
  subnetwork                  = var.subnetwork
  logging_service             = var.logging_service
  monitoring_service          = var.monitoring_service
  resource_labels             = var.labels
  default_max_pods_per_node   = var.default_max_pods_per_node
  enable_binary_authorization = var.enable_binary_authorization
  enable_intranode_visibility = var.enable_intranode_visibility
  enable_shielded_nodes       = var.enable_shielded_nodes
  enable_tpu                  = var.enable_tpu
  initial_node_count          = 1
  remove_default_node_pool    = true

  # node_config
  # TODO(ludomagno): compute addons map in locals and use a single dynamic block

  addons_config {
    dns_cache_config {
      enabled = var.addons.dns_cache_config
    }
    http_load_balancing {
      disabled = ! var.addons.http_load_balancing
    }
    horizontal_pod_autoscaling {
      disabled = ! var.addons.horizontal_pod_autoscaling
    }
    network_policy_config {
      disabled = ! var.addons.network_policy_config
    }
    # beta addons
    # cloudrun is dynamic as it tends to trigger cluster recreation on change
    dynamic cloudrun_config {
      for_each = var.addons.istio_config.enabled && var.addons.cloudrun_config ? [""""] : []
      content {
        disabled = false
      }
    }
    istio_config {
      disabled = ! var.addons.istio_config.enabled
      auth     = var.addons.istio_config.tls ? ""AUTH_MUTUAL_TLS"" : ""AUTH_NONE""
    }
  }

  # TODO(ludomagno): support setting address ranges instead of range names
  # https://www.terraform.io/docs/providers/google/r/container_cluster.html#cluster_ipv4_cidr_block
  ip_allocation_policy {
    cluster_secondary_range_name  = var.secondary_range_pods
    services_secondary_range_name = var.secondary_range_services
  }

  # TODO(ludomagno): make optional, and support beta feature
  # https://www.terraform.io/docs/providers/google/r/container_cluster.html#daily_maintenance_window
  maintenance_policy {
    daily_maintenance_window {
      start_time = var.maintenance_start_time
    }
  }

  master_auth {
    client_certificate_config {
      issue_client_certificate = false
    }
  }

  dynamic master_authorized_networks_config {
    for_each = length(var.master_authorized_ranges) == 0 ? [] : list(var.master_authorized_ranges)
    iterator = ranges
    content {
      dynamic cidr_blocks {
        for_each = ranges.value
        iterator = range
        content {
          cidr_block   = range.value
          display_name = range.key
        }
      }
    }
  }

  dynamic network_policy {
    for_each = var.addons.network_policy_config ? [""""] : []
    content {
      enabled  = true
      provider = ""CALICO""
    }
  }

  dynamic private_cluster_config {
    for_each = local.is_private ? [var.private_cluster_config] : []
    iterator = config
    content {
      enable_private_nodes    = config.value.enable_private_nodes
      enable_private_endpoint = config.value.enable_private_endpoint
      master_ipv4_cidr_block  = config.value.master_ipv4_cidr_block
    }
  }

  # beta features

  dynamic authenticator_groups_config {
    for_each = var.authenticator_security_group == null ? [] : [""""]
    content {
      security_group = var.authenticator_security_group
    }
  }

  dynamic cluster_autoscaling {
    for_each = var.cluster_autoscaling.enabled ? [var.cluster_autoscaling] : []
    iterator = config
    content {
      enabled = true
      resource_limits {
        resource_type = ""cpu""
        minimum       = config.cpu_min
        maximum       = config.cpu_max
      }
      resource_limits {
        resource_type = ""memory""
        minimum       = config.memory_min
        maximum       = config.memory_max
      }
    }
  }

  dynamic database_encryption {
    for_each = var.database_encryption.enabled ? [var.database_encryption] : []
    iterator = config
    content {
      state    = config.value.state
      key_name = config.value.key_name
    }
  }

  dynamic pod_security_policy_config {
    for_each = var.pod_security_policy != null ? [""""] : []
    content {
      enabled = var.pod_security_policy
    }
  }

  dynamic release_channel {
    for_each = var.release_channel != null ? [""""] : []
    content {
      channel = var.release_channel
    }
  }

  dynamic resource_usage_export_config {
    for_each = (
      var.resource_usage_export_config.enabled != null
      &&
      var.resource_usage_export_config.dataset != null
      ? [""""] : []
    )
    content {
      enable_network_egress_metering = var.resource_usage_export_config.enabled
      bigquery_destination {
        dataset_id = var.resource_usage_export_config.dataset
      }
    }
  }

  dynamic vertical_pod_autoscaling {
    for_each = var.vertical_pod_autoscaling == null ? [] : [""""]
    content {
      enabled = var.vertical_pod_autoscaling
    }
  }

  dynamic workload_identity_config {
    for_each = var.workload_identity ? [""""] : []
    content {
      identity_namespace = ""${var.project_id}.svc.id.goog""
    }
  }

}
",resource,"resource ""google_container_cluster"" ""cluster"" {
  provider    = google-beta
  project     = var.project_id
  name        = var.name
  description = var.description
  location    = var.location
  node_locations = (
    length(var.node_locations) == 0 ? null : var.node_locations
  )
  min_master_version = var.min_master_version
  network            = var.vpc_config.network
  subnetwork         = var.vpc_config.subnetwork
  resource_labels    = var.labels
  default_max_pods_per_node = (
    var.enable_features.autopilot ? null : var.max_pods_per_node
  )
  enable_intranode_visibility = (
    var.enable_features.autopilot ? null : var.enable_features.intranode_visibility
  )
  enable_l4_ilb_subsetting = var.enable_features.l4_ilb_subsetting
  enable_shielded_nodes = (
    var.enable_features.autopilot ? null : var.enable_features.shielded_nodes
  )
  enable_tpu               = var.enable_features.tpu
  initial_node_count       = 1
  remove_default_node_pool = var.enable_features.autopilot ? null : true
  datapath_provider = (
    var.enable_features.dataplane_v2
    ? ""ADVANCED_DATAPATH""
    : ""DATAPATH_PROVIDER_UNSPECIFIED""
  )
  enable_autopilot = var.enable_features.autopilot ? true : null

  # the default nodepool is deleted here, use the gke-nodepool module instead
  # node_config {}

  addons_config {
    dynamic ""dns_cache_config"" {
      for_each = !var.enable_features.autopilot ? [""""] : []
      content {
        enabled = var.enable_addons.dns_cache
      }
    }
    http_load_balancing {
      disabled = !var.enable_addons.http_load_balancing
    }
    horizontal_pod_autoscaling {
      disabled = !var.enable_addons.horizontal_pod_autoscaling
    }
    dynamic ""network_policy_config"" {
      for_each = !var.enable_features.autopilot ? [""""] : []
      content {
        disabled = !var.enable_addons.network_policy
      }
    }
    cloudrun_config {
      disabled = !var.enable_addons.cloudrun
    }
    istio_config {
      disabled = var.enable_addons.istio == null
      auth = (
        try(var.enable_addons.istio.enable_tls, false) ? ""AUTH_MUTUAL_TLS"" : ""AUTH_NONE""
      )
    }
    gce_persistent_disk_csi_driver_config {
      enabled = var.enable_addons.gce_persistent_disk_csi_driver
    }
    dynamic ""gcp_filestore_csi_driver_config"" {
      for_each = !var.enable_features.autopilot ? [""""] : []
      content {
        enabled = var.enable_addons.gcp_filestore_csi_driver
      }
    }
    kalm_config {
      enabled = var.enable_addons.kalm
    }
    config_connector_config {
      enabled = var.enable_addons.config_connector
    }
    gke_backup_agent_config {
      enabled = var.enable_addons.gke_backup_agent
    }
  }

  dynamic ""authenticator_groups_config"" {
    for_each = var.enable_features.groups_for_rbac != null ? [""""] : []
    content {
      security_group = var.enable_features.groups_for_rbac
    }
  }

  dynamic ""binary_authorization"" {
    for_each = var.enable_features.binary_authorization ? [""""] : []
    content {
      evaluation_mode = ""PROJECT_SINGLETON_POLICY_ENFORCE""
    }
  }

  dynamic ""cluster_autoscaling"" {
    for_each = var.cluster_autoscaling == null ? [] : [""""]
    content {
      enabled = true
      dynamic ""resource_limits"" {
        for_each = var.cluster_autoscaling.cpu_limits != null ? [""""] : []
        content {
          resource_type = ""cpu""
          minimum       = var.cluster_autoscaling.cpu_limits.min
          maximum       = var.cluster_autoscaling.cpu_limits.max
        }
      }
      dynamic ""resource_limits"" {
        for_each = var.cluster_autoscaling.mem_limits != null ? [""""] : []
        content {
          resource_type = ""cpu""
          minimum       = var.cluster_autoscaling.mem_limits.min
          maximum       = var.cluster_autoscaling.mem_limits.max
        }
      }
      // TODO: support GPUs too
    }
  }

  dynamic ""database_encryption"" {
    for_each = var.enable_features.database_encryption != null ? [""""] : []
    content {
      state    = var.enable_features.database_encryption.state
      key_name = var.enable_features.database_encryption.key_name
    }
  }

  dynamic ""dns_config"" {
    for_each = var.enable_features.cloud_dns != null ? [""""] : []
    content {
      cluster_dns        = enable_features.cloud_dns.cluster_dns
      cluster_dns_scope  = enable_features.cloud_dns.cluster_dns_scope
      cluster_dns_domain = enable_features.cloud_dns.cluster_dns_domain
    }
  }

  dynamic ""ip_allocation_policy"" {
    for_each = var.vpc_config.secondary_range_blocks != null ? [""""] : []
    content {
      cluster_ipv4_cidr_block  = var.vpc_config.secondary_range_blocks.pods
      services_ipv4_cidr_block = var.vpc_config.secondary_range_blocks.services
    }
  }
  dynamic ""ip_allocation_policy"" {
    for_each = var.vpc_config.secondary_range_names != null ? [""""] : []
    content {
      cluster_secondary_range_name  = var.vpc_config.secondary_range_names.pods
      services_secondary_range_name = var.vpc_config.secondary_range_names.services
    }
  }

  dynamic ""logging_config"" {
    for_each = var.logging_config != null ? [""""] : []
    content {
      enable_components = var.logging_config
    }
  }

  maintenance_policy {
    dynamic ""daily_maintenance_window"" {
      for_each = (
        try(var.maintenance_config.daily_window_start_time, null) != null
        ? [""""]
        : []
      )
      content {
        start_time = var.maintenance_config.daily_window_start_time
      }
    }
    dynamic ""recurring_window"" {
      for_each = (
        try(var.maintenance_config.recurring_window, null) != null
        ? [""""]
        : []
      )
      content {
        start_time = var.maintenance_config.recurring_window.start_time
        end_time   = var.maintenance_config.recurring_window.end_time
        recurrence = var.maintenance_config.recurring_window.recurrence
      }
    }
    dynamic ""maintenance_exclusion"" {
      for_each = (
        try(var.maintenance_config.maintenance_exclusions, null) == null
        ? []
        : var.maintenance_config.maintenance_exclusions
      )
      iterator = exclusion
      content {
        exclusion_name = exclusion.value.name
        start_time     = exclusion.value.start_time
        end_time       = exclusion.value.end_time
      }
    }
  }

  master_auth {
    client_certificate_config {
      issue_client_certificate = var.issue_client_certificate
    }
  }

  dynamic ""master_authorized_networks_config"" {
    for_each = var.vpc_config.master_authorized_ranges != null ? [""""] : []
    content {
      dynamic ""cidr_blocks"" {
        for_each = var.vpc_config.master_authorized_ranges
        iterator = range
        content {
          cidr_block   = range.value
          display_name = range.key
        }
      }
    }
  }

  dynamic ""monitoring_config"" {
    for_each = var.monitoring_config != null ? [""""] : []
    content {
      enable_components = var.monitoring_config
    }
  }

  # dataplane v2 has bult-in network policies
  dynamic ""network_policy"" {
    for_each = (
      var.enable_addons.network_policy && !var.enable_features.dataplane_v2
      ? [""""]
      : []
    )
    content {
      enabled  = true
      provider = ""CALICO""
    }
  }

  dynamic ""notification_config"" {
    for_each = var.enable_features.upgrade_notifications != null ? [""""] : []
    content {
      pubsub {
        enabled = true
        topic = (
          try(var.enable_features.upgrade_notifications.topic_id, null) != null
          ? var.enable_features.upgrade_notifications.topic_id
          : google_pubsub_topic.notifications[0].id
        )
      }
    }
  }

  dynamic ""private_cluster_config"" {
    for_each = (
      var.private_cluster_config != null ? [""""] : []
    )
    content {
      enable_private_nodes    = true
      enable_private_endpoint = var.private_cluster_config.enable_private_endpoint
      master_ipv4_cidr_block  = var.private_cluster_config.master_ipv4_cidr_block
      master_global_access_config {
        enabled = var.private_cluster_config.master_global_access
      }
    }
  }

  dynamic ""pod_security_policy_config"" {
    for_each = var.enable_features.pod_security_policy ? [""""] : []
    content {
      enabled = var.enable_features.pod_security_policy
    }
  }

  dynamic ""release_channel"" {
    for_each = var.release_channel != null ? [""""] : []
    content {
      channel = var.release_channel
    }
  }

  dynamic ""resource_usage_export_config"" {
    for_each = (
      try(var.enable_features.resource_usage_export.dataset, null) != null
      ? [""""]
      : []
    )
    content {
      enable_network_egress_metering = (
        var.enable_features.resource_usage_export.enable_network_egress_metering
      )
      enable_resource_consumption_metering = (
        var.enable_features.resource_usage_export.enable_resource_consumption_metering
      )
      bigquery_destination {
        dataset_id = var.enable_features.resource_usage_export.dataset
      }
    }
  }

  dynamic ""vertical_pod_autoscaling"" {
    for_each = var.enable_features.vertical_pod_autoscaling ? [""""] : []
    content {
      enabled = var.enable_features.vertical_pod_autoscaling
    }
  }

  dynamic ""workload_identity_config"" {
    for_each = var.enable_features.workload_identity ? [""""] : []
    content {
      workload_pool = ""${var.project_id}.svc.id.goog""
    }
  }
}
",resource,49,,587f6113b214d466f45a5ad7eff73262426b7397,16822e94ab70d75099214b9db786affcb231fbf6,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/587f6113b214d466f45a5ad7eff73262426b7397/modules/gke-cluster/main.tf#L49,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/16822e94ab70d75099214b9db786affcb231fbf6/modules/gke-cluster/main.tf,2020-04-23 09:54:04+02:00,2022-10-10 09:38:21+02:00,34,1,1,1,0,0,0,0,0,0
https://github.com/CDCgov/prime-simplereport,94,ops/services/virtual_network/main.tf,ops/services/virtual_network/main.tf,0,# todo,# TODO: Import the existing links for each standing environment.,"# DNS/VNet linkage for Flexible DB functionality 
 # TODO: Import the existing links for each standing environment.","resource ""azurerm_private_dns_zone_virtual_network_link"" ""vnet_link"" {
  name                  = ""${var.env}-vnet-dns-link""
  resource_group_name   = var.resource_group_name
  private_dns_zone_name = azurerm_private_dns_zone.default.name
  virtual_network_id    = azurerm_virtual_network.vn.id
}
",resource,"resource ""azurerm_private_dns_zone_virtual_network_link"" ""vnet_link"" {
  name                  = ""${var.env}-vnet-dns-link""
  resource_group_name   = var.resource_group_name
  private_dns_zone_name = azurerm_private_dns_zone.default.name
  virtual_network_id    = azurerm_virtual_network.vn.id
}
",resource,66,67.0,c617c1ab4838016aa686ecff84fde0e6be45b8a5,7bfb9a5275daaed20cb854ea8390e176b3cd8536,https://github.com/CDCgov/prime-simplereport/blob/c617c1ab4838016aa686ecff84fde0e6be45b8a5/ops/services/virtual_network/main.tf#L66,https://github.com/CDCgov/prime-simplereport/blob/7bfb9a5275daaed20cb854ea8390e176b3cd8536/ops/services/virtual_network/main.tf#L67,2022-05-05 00:48:15-05:00,2023-05-30 21:03:57-05:00,4,0,0,1,0,0,1,1,0,0
https://github.com/kbst/terraform-kubestack,27,aws/cluster-local/configuration.tf,aws/cluster-local/configuration.tf,0,implementation,# in the local implementation we don't have access to that,"# on AWS the region is determined by the provider configuration 
 # in the local implementation we don't have access to that 
 # to still support multi-region setups locally, we hash the availability zones 
 # and use that as the region part of the cluster name prefixed with eks-","locals {
  # current workspace config
  cfg = module.configuration.merged[terraform.workspace]

  name_prefix = local.cfg[""name_prefix""]

  base_domain = local.cfg[""base_domain""]

  http_port_default = terraform.workspace == ""apps"" ? 80 : 8080
  http_port         = lookup(local.cfg, ""http_port"", local.http_port_default)

  https_port_default = terraform.workspace == ""apps"" ? 443 : 8443
  https_port         = lookup(local.cfg, ""https_port"", local.https_port_default)

  manifest_path_default = ""manifests/overlays/${terraform.workspace}""
  manifest_path         = var.manifest_path != null ? var.manifest_path : local.manifest_path_default

  disable_default_ingress = lookup(local.cfg, ""disable_default_ingress"", false)

  node_image = lookup(local.cfg, ""node_image"", ""kindest/node:v1.18.0"")

  node_count = lookup(local.cfg, ""cluster_min_size"", 1)
  nodes = [
    for node, _ in range(local.node_count) :
    ""worker""
  ]
  extra_nodes = join("","", local.nodes)

  # on AWS the region is determined by the provider configuration
  # in the local implementation we don't have access to that
  # to still support multi-region setups locally, we hash the availability zones
  # and use that as the region part of the cluster name prefixed with eks-
  cluster_availability_zones_lookup = lookup(local.cfg, ""cluster_availability_zones"", """")
  fake_region_hash                  = substr(sha256(local.cluster_availability_zones_lookup), 0, 7)
  fake_region                       = ""eks-${local.fake_region_hash}""
}
",locals,"locals {
  # current workspace config
  cfg = module.configuration.merged[terraform.workspace]

  name_prefix = local.cfg[""name_prefix""]

  base_domain = local.cfg[""base_domain""]

  http_port_default = terraform.workspace == ""apps"" ? 80 : 8080
  http_port         = lookup(local.cfg, ""http_port"", local.http_port_default)

  https_port_default = terraform.workspace == ""apps"" ? 443 : 8443
  https_port         = lookup(local.cfg, ""https_port"", local.https_port_default)

  disable_default_ingress = lookup(local.cfg, ""disable_default_ingress"", false)

  node_image = lookup(local.cfg, ""node_image"", null)

  node_count = lookup(local.cfg, ""cluster_min_size"", 1)
  nodes = [
    for node, _ in range(local.node_count) :
    ""worker""
  ]
  extra_nodes = join("","", local.nodes)

  # on AWS the region is determined by the provider configuration
  # in the local implementation we don't have access to that
  # to still support multi-region setups locally, we hash the availability zones
  # and use that as the region part of the cluster name prefixed with eks-
  cluster_availability_zones_lookup = lookup(local.cfg, ""cluster_availability_zones"", """")
  fake_region_hash                  = substr(sha256(local.cluster_availability_zones_lookup), 0, 7)
  fake_region                       = ""eks-${local.fake_region_hash}""
}
",locals,37,34.0,40af925aa6e6543373a298870aadf27d1672f58d,67b7dfce00f2dc67a9293d74ef5ac80879de5a2b,https://github.com/kbst/terraform-kubestack/blob/40af925aa6e6543373a298870aadf27d1672f58d/aws/cluster-local/configuration.tf#L37,https://github.com/kbst/terraform-kubestack/blob/67b7dfce00f2dc67a9293d74ef5ac80879de5a2b/aws/cluster-local/configuration.tf#L34,2020-09-29 15:18:43+02:00,2021-05-25 21:22:58+02:00,3,0,0,1,1,1,0,0,0,0
https://github.com/uyuni-project/sumaform,20,openstack_host/variables.tf,openstack_host/variables.tf,0,# todo,# TODO: instead of root/vagrant,"# TODO: instead of root/vagrant 
 #variable ""openstack_keypair"" { 
 #    description = ""The keypair to be used."" 
 #    default  = """" 
 #} ","variable ""avahi-domain"" {
  default = ""vagrant.local""
}
",variable,"variable ""avahi-domain"" {
  default = ""vagrant.local""
}
",variable,16,,89f41bf3e6d1f35e418daeb0663dfb81d05b1eb4,f16a1b7a10364b97d987a840f038f1bd89573ff8,https://github.com/uyuni-project/sumaform/blob/89f41bf3e6d1f35e418daeb0663dfb81d05b1eb4/openstack_host/variables.tf#L16,https://github.com/uyuni-project/sumaform/blob/f16a1b7a10364b97d987a840f038f1bd89573ff8/openstack_host/variables.tf,2016-06-30 17:49:17+02:00,2016-07-01 17:14:45+02:00,3,1,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-slo,7,modules/slo/main.tf,modules/slo/main.tf,0,fix,# is fixed.,"# Temporary code to replace module invocation (see bottom of this file) until 
 # https://github.com/terraform-google-modules/terraform-google-event-function/issues/37 
 # is fixed.","resource ""google_cloud_scheduler_job"" ""job"" {
  name        = local.full_name
  project     = var.project_id
  region      = var.region
  description = var.config.slo_description
  schedule    = var.schedule
  time_zone   = var.time_zone

  pubsub_target {
    topic_name = ""projects/${var.project_id}/topics/${module.pubsub_topic.topic}""
    data       = var.message_data
  }
}
",resource,the block associated got renamed or deleted,,44,,825194fc70002c5b310442faceccf313321768d0,7b2bb290a79dab58f9a7232441909c6949bfcab1,https://github.com/terraform-google-modules/terraform-google-slo/blob/825194fc70002c5b310442faceccf313321768d0/modules/slo/main.tf#L44,https://github.com/terraform-google-modules/terraform-google-slo/blob/7b2bb290a79dab58f9a7232441909c6949bfcab1/modules/slo/main.tf,2019-12-07 23:32:23+01:00,2019-12-13 16:05:15-08:00,2,1,1,1,1,0,0,0,0,0
https://github.com/alphagov/govuk-aws,1091,terraform/projects/infra-database-backups-bucket/main.tf,terraform/projects/infra-database-backups-bucket/main.tf,0,# todo,# TODO: these are all set to the same var.expiration_time so just replace,"# Integration-specific lifecycle rules. These rules are created in all 
 # environments but are only enabled in Integration. 
 # 
 # TODO: create these only in environments where they're needed, instead of 
 # creating them everywhere and leaving them disabled. 
 # 
 # TODO: these are all set to the same var.expiration_time so just replace 
 # them with one rule. Similarly for the prod ones above. ","resource ""aws_s3_bucket"" ""database_backups"" {
  bucket = ""govuk-${var.aws_environment}-database-backups""
  region = ""${var.aws_region}""

  tags {
    Name            = ""govuk-${var.aws_environment}-database-backups""
    aws_environment = ""${var.aws_environment}""
  }

  logging {
    target_bucket = ""${data.terraform_remote_state.infra_monitoring.aws_logging_bucket_id}""
    target_prefix = ""s3/govuk-${var.aws_environment}-database-backups/""
  }

  # Production/Staging lifecycle rules.
  #
  # TODO: make staging use the same rules as integration. We don't need to
  # retain backups of staging for very long.

  lifecycle_rule {
    id      = ""mysql_lifecycle_rule""
    prefix  = ""mysql/""
    enabled = ""${var.aws_environment != ""integration""}""

    transition {
      storage_class = ""STANDARD_IA""
      days          = ""${var.standard_s3_storage_time}""
    }

    transition {
      storage_class = ""GLACIER""
      days          = ""${var.glacier_storage_time}""
    }

    expiration {
      days = 120
    }
  }
  lifecycle_rule {
    id      = ""postgres_lifecycle_rule""
    prefix  = ""postgres/""
    enabled = ""${var.aws_environment != ""integration""}""

    transition {
      storage_class = ""STANDARD_IA""
      days          = ""${var.standard_s3_storage_time}""
    }

    transition {
      storage_class = ""GLACIER""
      days          = ""${var.glacier_storage_time}""
    }

    expiration {
      days = 120
    }
  }
  lifecycle_rule {
    id      = ""mongo_daily_lifecycle_rule""
    prefix  = ""mongodb/daily""
    enabled = ""${var.aws_environment != ""integration""}""

    transition {
      storage_class = ""STANDARD_IA""
      days          = ""${var.standard_s3_storage_time}""
    }

    transition {
      storage_class = ""GLACIER""
      days          = ""${var.glacier_storage_time}""
    }

    expiration {
      days = 120
    }
  }
  lifecycle_rule {
    id      = ""mongo_regular_lifecycle_rule""
    prefix  = ""mongodb/regular""
    enabled = true

    expiration {
      days = ""${var.expiration_time_whisper_mongo}""
    }
  }
  lifecycle_rule {
    id      = ""whisper_lifecycle_rule""
    prefix  = ""whisper/""
    enabled = true

    expiration {
      days = ""${var.expiration_time_whisper_mongo}""
    }
  }

  # Integration-specific lifecycle rules. These rules are created in all
  # environments but are only enabled in Integration.
  #
  # TODO: create these only in environments where they're needed, instead of
  # creating them everywhere and leaving them disabled.
  #
  # TODO: these are all set to the same var.expiration_time so just replace
  # them with one rule. Similarly for the prod ones above.

  lifecycle_rule {
    id      = ""mysql_lifecycle_rule_integration""
    prefix  = ""mysql/""
    enabled = ""${var.aws_environment == ""integration""}""

    expiration {
      days = ""${var.expiration_time}""
    }
  }
  lifecycle_rule {
    id      = ""postgres_lifecycle_rule_integration""
    prefix  = ""postgres/""
    enabled = ""${var.aws_environment == ""integration""}""

    expiration {
      days = ""${var.expiration_time}""
    }
  }
  lifecycle_rule {
    id      = ""mongo_daily_lifecycle_rule_integration""
    prefix  = ""mongodb/daily""
    enabled = ""${var.aws_environment == ""integration""}""

    expiration {
      days = ""${var.expiration_time}""
    }
  }
  lifecycle_rule {
    id      = ""whole_bucket_lifecycle_rule_integration""
    prefix  = """"
    enabled = ""${var.aws_environment == ""integration""}""

    expiration {
      days = ""${var.expiration_time}""
    }

    noncurrent_version_expiration {
      days = ""1""
    }
  }

  # End of Integration-specific lifecycle rules.


  # Lifecycle rule for coronavirus find support backup

  lifecycle_rule {
    id      = ""coronavirus_find_support_lifecycle_rule""
    prefix  = ""coronavirus-find-support/production.sql.gzip""
    enabled = true

    expiration {
      days = 365
    }
  }

  # Lifecycle rule for coronavirus business volunteer form backup

  lifecycle_rule {
    id      = ""coronavirus_business_volunteer_form_lifecycle_rule""
    prefix  = ""coronavirus-business-volunteer-form/production.sql.gzip""
    enabled = true

    expiration {
      days = 365
    }
  }
  versioning {
    enabled = true
  }
  replication_configuration {
    role = ""${aws_iam_role.backup_replication_role.arn}""

    rules {
      id     = ""main_replication_rule""
      prefix = """"
      status = ""${var.replication_setting}""

      destination {
        bucket        = ""${aws_s3_bucket.database_backups_replica.arn}""
        storage_class = ""STANDARD""
      }
    }
  }
}
",resource,"resource ""aws_s3_bucket"" ""database_backups"" {
  bucket = ""govuk-${var.aws_environment}-database-backups""
  region = ""${var.aws_region}""

  tags {
    Name            = ""govuk-${var.aws_environment}-database-backups""
    aws_environment = ""${var.aws_environment}""
  }

  logging {
    target_bucket = ""${data.terraform_remote_state.infra_monitoring.aws_logging_bucket_id}""
    target_prefix = ""s3/govuk-${var.aws_environment}-database-backups/""
  }

  versioning {
    # It's not entirely clear if versioning is useful on this bucket ��� but it was previously configured this way,
    # so we've decided not to change it. Whilst it helps protect against accidental deletion, it doesn't protect
    # against malicious actors, so shouldn't be considered a security feature.
    enabled = true
  }

  lifecycle_rule {
    # Use a long retention period in production
    id      = ""long_retention_period""
    enabled = ""${var.aws_environment == ""production""}""

    # Ideally everything would go in the Standard (Infrequent Access) storage class when created.
    # But newly created objects always go into Standard, and can only move into IA after at least 30 days.
    # https://docs.aws.amazon.com/AmazonS3/latest/userguide/lifecycle-transition-general-considerations.html
    transition {
      storage_class = ""STANDARD_IA""
      days          = 30
    }

    # Likewise, we have to wait at least another 30 days before we can move objects into Glacier storage.
    transition {
      storage_class = ""GLACIER""
      days          = 60
    }

    # Versioning is enabled on this bucket, so this rule will 'soft delete' objects.
    # In AWS lingo, this means a 'delete marker' will be set on the current version of the object.
    # More info on how expiration rules apply to versioned buckets here:
    # https://docs.aws.amazon.com/AmazonS3/latest/userguide/intro-lifecycle-rules.html#intro-lifecycle-rules-actions
    expiration {
      days = 120
    }

    # This rule will 'hard delete' objects 1 day after they were 'soft deleted'.
    # In other words: old database backups will be permanently deleted 1 day after they've expired.
    noncurrent_version_expiration {
      days = ""1""
    }
  }

  lifecycle_rule {
    # Use a short retention period in integration and staging
    id      = ""short_retention_period""
    enabled = ""${var.aws_environment != ""production""}""

    expiration {
      days = ""3""
    }

    noncurrent_version_expiration {
      days = ""1""
    }
  }

  replication_configuration {
    role = ""${aws_iam_role.backup_replication_role.arn}""

    rules {
      id     = ""main_replication_rule""
      status = ""Enabled""

      destination {
        bucket        = ""${aws_s3_bucket.database_backups_replica.arn}""
        storage_class = ""STANDARD_IA""
      }
    }
  }
}
",resource,201,,d1fcb45657475a7de489503eae548845ec8e4296,78cc3f5ce73fb5a8f6d5126ff694ac87e5a0eb79,https://github.com/alphagov/govuk-aws/blob/d1fcb45657475a7de489503eae548845ec8e4296/terraform/projects/infra-database-backups-bucket/main.tf#L201,https://github.com/alphagov/govuk-aws/blob/78cc3f5ce73fb5a8f6d5126ff694ac87e5a0eb79/terraform/projects/infra-database-backups-bucket/main.tf,2020-11-24 17:53:04+00:00,2022-01-31 17:30:52+00:00,4,1,1,1,0,0,0,1,0,0
https://github.com/Worklytics/psoxy,1511,infra/modules/aws/variables.tf,infra/modules/aws/variables.tf,0,todo,"# TODO : change default in v0.5, or remove; should be based on deployment_id","# TODO : change default in v0.5, or remove; should be based on deployment_id","variable ""api_function_name_prefix"" {
  type        = string
  description = ""prefix for API function names""
  default     = ""psoxy-""
}
",variable,"variable ""api_function_name_prefix"" {
  type        = string
  description = ""prefix for API function names""
  default     = ""psoxy-""
}
",variable,85,96.0,f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e,5ed7bc9ef2e9108a02f4d42e7d0d156eb5c7184d,https://github.com/Worklytics/psoxy/blob/f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e/infra/modules/aws/variables.tf#L85,https://github.com/Worklytics/psoxy/blob/5ed7bc9ef2e9108a02f4d42e7d0d156eb5c7184d/infra/modules/aws/variables.tf#L96,2023-06-16 14:08:45-07:00,2024-01-31 10:34:59-08:00,4,0,0,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd,123,modules/gke-cloudbuild-private-pool/main.tf,modules/gke-cloudbuild-private-pool/main.tf,0,# todo,# TODO: dynamic block --> 2 tunnels per destination GKE VPC,# TODO: dynamic block --> 2 tunnels per destination GKE VPC,"module ""vpn_ha-1"" {
  source     = ""terraform-google-modules/vpn/google//modules/vpn_ha""
  version    = ""~> 1.3.0""
  project_id = var.project_id
  region     = var.location
  network    = google_compute_network.private_pool_vpc.self_link
  name       = ""cloudbuild-to-gke""
  peer_gcp_gateway = module.vpn_ha-2.self_link
  router_asn = 64514
  # TODO: dynamic block --> 2 tunnels per destination GKE VPC
  tunnels = {
    remote-0 = {
      bgp_peer = {
        address = ""169.254.1.1""
        asn     = 64513
      }
      bgp_peer_options  = null
      bgp_session_range = ""169.254.1.2/30""
      ike_version       = 2
      vpn_gateway_interface = 0
      peer_external_gateway_interface = null
      shared_secret     = """"
    }
    remote-1 = {
      bgp_peer = {
        address = ""169.254.2.1""
        asn     = 64513
      }
      bgp_peer_options  = null
      bgp_session_range = ""169.254.2.2/30""
      ike_version       = 2
      vpn_gateway_interface = 1
      peer_external_gateway_interface = null
      shared_secret     = """"
    }
  }
}
",module,"module ""vpn_ha-1"" {
  count = length(local.gke_networks)

  source     = ""terraform-google-modules/vpn/google//modules/vpn_ha""
  version    = ""~> 1.3.0""
  project_id = var.project_id
  region     = var.location
  network    = google_compute_network.private_pool_vpc.self_link
  name       = ""cloudbuild-to-${local.gke_networks[count.index].network}""
  peer_gcp_gateway = module.vpn_ha-2[count.index].self_link
  router_asn = 65001+(count.index*2)
  tunnels = {
    remote-0 = {
      bgp_peer = {
        address = ""169.254.${1+(count.index*2)}.2""
        asn     = 65002+(count.index*2)
      }
      bgp_peer_options  = null
      bgp_session_range = ""169.254.${1+(count.index*2)}.1/30""
      ike_version       = 2
      vpn_gateway_interface = 0
      peer_external_gateway_interface = null
      shared_secret     = """"
    }
    remote-1 = {
      bgp_peer = {
        address = ""169.254.${2+(count.index*2)}.2""
        asn     = 65002+(count.index*2)
      }
      bgp_peer_options  = null
      bgp_session_range = ""169.254.${2+(count.index*2)}.1/30""
      ike_version       = 2
      vpn_gateway_interface = 1
      peer_external_gateway_interface = null
      shared_secret     = """"
    }
  }
}
",module,73,,a384bc29c9bcb80dd1b1f60ece9dee723b4bf378,e29ac91f2eedf8a48e82065434b81010d298a423,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/a384bc29c9bcb80dd1b1f60ece9dee723b4bf378/modules/gke-cloudbuild-private-pool/main.tf#L73,https://github.com/GoogleCloudPlatform/terraform-google-secure-cicd/blob/e29ac91f2eedf8a48e82065434b81010d298a423/modules/gke-cloudbuild-private-pool/main.tf,2021-11-30 12:07:36-06:00,2021-12-06 17:46:36-06:00,2,1,0,1,0,0,1,0,0,0
https://github.com/Azure/sap-automation,9,deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf,deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf,0,implemented,//        Management lock should be implemented id a seperate Terraform workspace,"// TODO: Add management lock when this issue is addressed https://github.com/terraform-providers/terraform-provider-azurerm/issues/5473 
 //        Management lock should be implemented id a seperate Terraform workspace   
 // Create/Import management vnet","resource ""azurerm_virtual_network"" ""vnet_mgmt"" {
  count               = (local.enable_deployers && !local.vnet_mgmt_exists) ? 1 : 0
  name                = local.vnet_mgmt_name
  resource_group_name = local.rg_exists ? data.azurerm_resource_group.deployer[0].name : azurerm_resource_group.deployer[0].name
  location            = local.rg_exists ? data.azurerm_resource_group.deployer[0].location : azurerm_resource_group.deployer[0].location
  address_space       = [local.vnet_mgmt_addr]
}
",resource,"resource ""azurerm_virtual_network"" ""vnet_mgmt"" {
  count                                = (!local.vnet_mgmt_exists) ? 1 : 0
  name                                 = local.vnet_mgmt_name
  resource_group_name                  = local.resource_group_exists ? data.azurerm_resource_group.deployer[0].name : azurerm_resource_group.deployer[0].name
  location                             = local.resource_group_exists ? data.azurerm_resource_group.deployer[0].location : azurerm_resource_group.deployer[0].location
  address_space                        = [local.vnet_mgmt_addr]
}
",resource,94,35.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,db20ac2a47d9d00329385330cb4af6b3c726c400,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf#L94,https://github.com/Azure/sap-automation/blob/db20ac2a47d9d00329385330cb4af6b3c726c400/deploy/terraform/terraform-units/modules/sap_deployer/infrastructure.tf#L35,2021-11-17 19:29:07+02:00,2024-03-11 23:15:11+05:30,24,0,0,1,1,0,1,0,0,0
https://github.com/kubernetes/k8s.io,436,infra/aws/terraform/prow-build-cluster/node_group_blue.tf,infra/aws/terraform/prow-build-cluster/node_group_blue.tf,0,# todo,# TODO(xmudrii-ubuntu): Temporarily disabled because it's not supported by Bottlerocket Linux,"# TODO(xmudrii-ubuntu): Temporarily disabled because it's not supported by Bottlerocket Linux 
 # ami_id                     = var.node_ami_blue 
 # enable_bootstrap_user_data = true ","locals {
  node_group_build_blue = {
    name            = ""build-managed-blue""
    description     = ""EKS managed node group called blue used to facilitate node rotations/rollouts""
    use_name_prefix = true

    cluster_version = var.node_group_version_blue

    taints = var.node_taints_blue
    labels = var.node_labels_blue

    subnet_ids = module.vpc.public_subnets

    min_size     = var.node_min_size_blue
    max_size     = var.node_max_size_blue
    desired_size = var.node_desired_size_blue

    iam_role_permissions_boundary = data.aws_iam_policy.eks_resources_permission_boundary.arn

    # TODO(xmudrii-ubuntu): Temporarily disabled because it's not supported by Bottlerocket Linux
    # ami_id                     = var.node_ami_blue
    # enable_bootstrap_user_data = true

    ami_type             = ""BOTTLEROCKET_x86_64""
    platform             = ""bottlerocket""
    bootstrap_extra_args = <<-EOT
      # Bottlerocket instances don't have SSH installed by default, but
      # there's the admin container that can be enabled and that comes
      # with SSH installed and enabled
      [settings.host-containers.admin]
      enabled = true

      # Bootstrap the instance using our bootstrap script embeded in a Docker image
      [settings.bootstrap-containers.bootstrap]
      source = ""public.ecr.aws/q4o2z4d8/k8s-prow-bottlerocket:v0.0.1""
      mode = ""always""
      essential = true
    EOT

    force_update_version = false
    update_config = {
      max_unavailable_percentage = var.node_max_unavailable_percentage
    }

    pre_bootstrap_user_data = file(""${path.module}/bootstrap/node_bootstrap.sh"")

    capacity_type  = ""ON_DEMAND""
    instance_types = var.node_instance_types_blue

    ebs_optimized     = true
    enable_monitoring = true

    key_name = aws_key_pair.eks_nodes.key_name

    block_device_mappings = {
      # This must be sda1 in order to match the root volume,
      # otherwise a new volume is created.
      sda1 = {
        device_name = ""/dev/sda1""
        ebs = {
          volume_size           = var.node_volume_size
          volume_type           = ""gp3""
          iops                  = 16000 # Maximum for gp3 volume.
          throughput            = 1000  # Maximum for gp3 volume.
          encrypted             = false
          delete_on_termination = true
        }
      }
    }

    enclave_options = {
      enabled = true
    }

    timeouts = {
      update = ""180m""
    }

    tags = merge(
      local.tags,
      local.auto_scaling_tags,
      var.additional_node_group_tags_blue
    )
  }
}
",locals,"locals {
  node_group_build_blue = {
    name            = ""build-managed-blue""
    description     = ""EKS managed node group called blue used to facilitate node rotations/rollouts""
    use_name_prefix = true

    cluster_version = var.node_group_version_blue

    taints = var.node_taints_blue
    labels = var.node_labels_blue

    subnet_ids = module.vpc.public_subnets

    min_size     = var.node_min_size_blue
    max_size     = var.node_max_size_blue
    desired_size = var.node_desired_size_blue

    iam_role_permissions_boundary = data.aws_iam_policy.eks_resources_permission_boundary.arn

    ami_type             = ""BOTTLEROCKET_x86_64""
    platform             = ""bottlerocket""
    bootstrap_extra_args = <<-EOT
      # Bottlerocket instances don't have SSH installed by default, but
      # there's the admin container that can be enabled and that comes
      # with SSH installed and enabled
      [settings.host-containers.admin]
      enabled = true

      # Bootstrap the instance using our bootstrap script embeded in a Docker image
      [settings.bootstrap-containers.bootstrap]
      source = ""public.ecr.aws/q4o2z4d8/k8s-prow-bottlerocket:v0.0.2""
      mode = ""always""
      essential = true

      [settings.kernel.sysctl]
      ""fs.inotify.max_user_watches"" = ""1048576""
      ""fs.inotify.max_user_instances"" = ""8192""
      ""vm.min_free_kbytes"" = ""540672""
    EOT

    force_update_version = false
    update_config = {
      max_unavailable_percentage = var.node_max_unavailable_percentage
    }

    pre_bootstrap_user_data = file(""${path.module}/bootstrap/node_bootstrap.sh"")

    capacity_type  = ""ON_DEMAND""
    instance_types = var.node_instance_types_blue

    ebs_optimized     = true
    enable_monitoring = true

    key_name = aws_key_pair.eks_nodes.key_name

    block_device_mappings = {
      # This must be sda1 in order to match the root volume,
      # otherwise a new volume is created.
      sda1 = {
        device_name = ""/dev/sda1""
        ebs = {
          volume_size           = var.node_volume_size
          volume_type           = ""gp3""
          iops                  = 16000 # Maximum for gp3 volume.
          throughput            = 1000  # Maximum for gp3 volume.
          encrypted             = false
          delete_on_termination = true
        }
      }
    }

    enclave_options = {
      enabled = true
    }

    timeouts = {
      update = ""180m""
    }

    tags = merge(
      local.tags,
      local.auto_scaling_tags,
      var.additional_node_group_tags_blue
    )
  }
}
",locals,36,,445da81d263c7f1f6dae465f8047c5aa6b9a2934,f8cb33e74bada53999da408888d92a324eec52b2,https://github.com/kubernetes/k8s.io/blob/445da81d263c7f1f6dae465f8047c5aa6b9a2934/infra/aws/terraform/prow-build-cluster/node_group_blue.tf#L36,https://github.com/kubernetes/k8s.io/blob/f8cb33e74bada53999da408888d92a324eec52b2/infra/aws/terraform/prow-build-cluster/node_group_blue.tf,2023-10-16 10:30:36+02:00,2024-01-09 11:56:09+01:00,3,1,0,1,1,0,0,0,0,0
https://github.com/nasa/cumulus,20,tf-modules/archive/iam.tf,tf-modules/archive/iam.tf,0,todo,# TODO Refactor so this doesn't make assumptions about table name prefixes,# TODO Refactor so this doesn't make assumptions about table name prefixes,"data ""aws_iam_policy_document"" ""lambda_api_gateway_policy"" {
  statement {
    actions   = [""ecs:RunTask""]
    resources = [aws_ecs_task_definition.async_operation.arn]
  }

  statement {
    actions = [
      ""logs:DescribeLogStreams"",
      ""logs:CreateLogGroup"",
      ""logs:CreateLogStream"",
      ""logs:PutLogEvents"",
      ""lambda:GetFunction"",
      ""lambda:invokeFunction"",
      ""lambda:CreateEventSourceMapping"",
      ""lambda:UpdateEventSourceMapping"",
      ""lambda:DeleteEventSourceMapping"",
      ""lambda:GetEventSourceMapping"",
      ""lambda:ListEventSourceMappings"",
      ""lambda:AddPermission"",
      ""lambda:RemovePermission""
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""dynamodb:DeleteItem"",
      ""dynamodb:GetItem"",
      ""dynamodb:PutItem"",
      ""dynamodb:Query"",
      ""dynamodb:Scan"",
      ""dynamodb:UpdateItem""
    ]
    # TODO Refactor so this doesn't make assumptions about table name prefixes
    resources = [""arn:aws:dynamodb:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:table/${var.prefix}-*""]
  }

  statement {
    actions = [
      ""dynamodb:GetRecords"",
      ""dynamodb:GetShardIterator"",
      ""dynamodb:DescribeStream"",
      ""dynamodb:ListStreams""
    ]
    # TODO Refactor so this doesn't make assumptions about table name prefixes
    resources = [""arn:aws:dynamodb:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:table/${var.prefix}-*/stream/*""]
  }

  statement {
    actions   = [""dynamodb:ListTables""]
    resources = [""*""]
  }

  statement {
    actions = [
      ""s3:GetAccelerateConfiguration"",
      ""s3:GetLifecycleConfiguration"",
      ""s3:GetReplicationConfiguration"",
      ""s3:GetBucket*"",
      ""s3:PutAccelerateConfiguration"",
      ""s3:PutLifecycleConfiguration"",
      ""s3:PutReplicationConfiguration"",
      ""s3:PutBucket*"",
      ""s3:ListBucket*""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}""]
  }

  statement {
    actions = [
      ""s3:GetObject*"",
      ""s3:PutObject*"",
      ""s3:ListMultipartUploadParts"",
      ""s3:DeleteObject"",
      ""s3:DeleteObjectVersion""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}/*""]
  }

  statement {
    actions   = [""s3:ListAllMyBuckets""]
    resources = [""*""]
  }

  statement {
    actions = [
      ""sns:publish"",
      ""sns:Subscribe"",
      ""sns:Unsubscribe"",
      ""sns:List*"",
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""sqs:GetQueueUrl"",
      ""sqs:GetQueueAttributes"",
      ""sqs:SendMessage"",
    ]
    resources = [""arn:aws:sqs:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:${var.prefix}-*""]
  }

  statement {
    actions = [
      ""cloudwatch:List*"",
      ""cloudwatch:Get*"",
      ""cloudwatch:Describe*"",
    ]
    resources = [""*""]
  }

  statement {
    actions   = [""apigateway:GET""]
    resources = [""arn:aws:apigateway:${data.aws_region.current.name}::/restapis/*/stages""]
  }

  statement {
    actions = [
      ""events:DisableRule"",
      ""events:DeleteRule"",
      ""events:EnableRule"",
      ""events:ListRules"",
      ""events:PutRule"",
      ""events:DescribeRule"",
      ""events:PutTargets"",
      ""events:RemoveTargets"",
    ]
    resources = [""arn:aws:events:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:rule/${var.prefix}-*""]
  }

  statement {
    actions = [
      ""states:DescribeExecution"",
      ""states:DescribeStateMachine"",
      ""states:GetExecutionHistory"",
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""ec2:CreateNetworkInterface"",
      ""ec2:DescribeNetworkInterfaces"",
      ""ec2:DeleteNetworkInterface"",
    ]
    resources = [""*""]
  }
}
",data,"data ""aws_iam_policy_document"" ""lambda_api_gateway_policy"" {
  statement {
    actions   = [""ecs:RunTask""]
    resources = [aws_ecs_task_definition.async_operation.arn]
  }

  statement {
    actions = [
      ""logs:DescribeLogStreams"",
      ""logs:CreateLogGroup"",
      ""logs:CreateLogStream"",
      ""logs:PutLogEvents"",
      ""lambda:GetFunction"",
      ""lambda:invokeFunction"",
      ""lambda:CreateEventSourceMapping"",
      ""lambda:UpdateEventSourceMapping"",
      ""lambda:DeleteEventSourceMapping"",
      ""lambda:GetEventSourceMapping"",
      ""lambda:ListEventSourceMappings"",
      ""lambda:AddPermission"",
      ""lambda:RemovePermission""
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""dynamodb:DeleteItem"",
      ""dynamodb:GetItem"",
      ""dynamodb:PutItem"",
      ""dynamodb:Query"",
      ""dynamodb:Scan"",
      ""dynamodb:UpdateItem""
    ]
    resources = [for k, v in var.dynamo_tables : v.arn]
  }

  statement {
    actions = [
      ""dynamodb:GetRecords"",
      ""dynamodb:GetShardIterator"",
      ""dynamodb:DescribeStream"",
      ""dynamodb:ListStreams""
    ]
    resources = [for k, v in var.dynamo_tables : ""${v.arn}/stream/*""]
  }

  statement {
    actions   = [""dynamodb:ListTables""]
    resources = [""*""]
  }

  statement {
    actions = [
      ""s3:GetAccelerateConfiguration"",
      ""s3:GetLifecycleConfiguration"",
      ""s3:GetReplicationConfiguration"",
      ""s3:GetBucket*"",
      ""s3:PutAccelerateConfiguration"",
      ""s3:PutLifecycleConfiguration"",
      ""s3:PutReplicationConfiguration"",
      ""s3:PutBucket*"",
      ""s3:ListBucket*""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}""]
  }

  statement {
    actions = [
      ""s3:GetObject*"",
      ""s3:PutObject*"",
      ""s3:ListMultipartUploadParts"",
      ""s3:DeleteObject"",
      ""s3:DeleteObjectVersion""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}/*""]
  }

  statement {
    actions   = [""s3:ListAllMyBuckets""]
    resources = [""*""]
  }

  statement {
    actions = [
      ""sns:publish"",
      ""sns:Subscribe"",
      ""sns:Unsubscribe"",
      ""sns:List*"",
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""sqs:GetQueueUrl"",
      ""sqs:GetQueueAttributes"",
      ""sqs:SendMessage"",
    ]
    resources = [""arn:aws:sqs:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:${var.prefix}-*""]
  }

  statement {
    actions = [
      ""cloudwatch:List*"",
      ""cloudwatch:Get*"",
      ""cloudwatch:Describe*"",
    ]
    resources = [""*""]
  }

  statement {
    actions   = [""apigateway:GET""]
    resources = [""arn:aws:apigateway:${data.aws_region.current.name}::/restapis/*/stages""]
  }

  statement {
    actions = [
      ""events:DisableRule"",
      ""events:DeleteRule"",
      ""events:EnableRule"",
      ""events:ListRules"",
      ""events:PutRule"",
      ""events:DescribeRule"",
      ""events:PutTargets"",
      ""events:RemoveTargets"",
    ]
    resources = [""arn:aws:events:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:rule/${var.prefix}-*""]
  }

  statement {
    actions = [
      ""states:DescribeExecution"",
      ""states:DescribeStateMachine"",
      ""states:GetExecutionHistory"",
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""ec2:CreateNetworkInterface"",
      ""ec2:DescribeNetworkInterfaces"",
      ""ec2:DeleteNetworkInterface"",
    ]
    resources = [""*""]
  }
}
",data,64,,1da53282470313085da6e713a94458500df71f6c,275b9a88869f413f231765ff1784ed9b3c6e042b,https://github.com/nasa/cumulus/blob/1da53282470313085da6e713a94458500df71f6c/tf-modules/archive/iam.tf#L64,https://github.com/nasa/cumulus/blob/275b9a88869f413f231765ff1784ed9b3c6e042b/tf-modules/archive/iam.tf,2019-08-02 16:32:51-04:00,2019-08-26 10:31:45-04:00,3,1,1,1,0,1,0,0,0,0
https://github.com/compiler-explorer/infra,267,terraform/cloudfront_gpu.tf,terraform/cloudfront_gpu.tf,0,todo,// TODO delete me,// TODO delete me,"resource ""aws_cloudfront_distribution"" ""gpu-compiler-explorer-com"" {
  origin {
    domain_name = ""compiler-explorer.s3.amazonaws.com""
    origin_id   = ""S3-compiler-explorer""
  }
  origin {
    domain_name = aws_alb.GccExplorerApp.dns_name
    origin_id   = ""GccExplorerApp""
    custom_origin_config {
      http_port                = 1081
      https_port               = 1444
      origin_read_timeout      = 60
      origin_keepalive_timeout = 60
      origin_protocol_policy   = ""https-only""
      origin_ssl_protocols     = [
        ""TLSv1"",
        ""TLSv1.2"",
        ""TLSv1.1""
      ]
    }
  }

  enabled          = true
  is_ipv6_enabled  = true
  retain_on_delete = true
  aliases          = [
    ""gpu.compiler-explorer.com""
  ]

  viewer_certificate {
    acm_certificate_arn      = data.aws_acm_certificate.godbolt-org-et-al.arn
    ssl_support_method       = ""sni-only""
    minimum_protocol_version = ""TLSv1.1_2016""
  }

  logging_config {
    include_cookies = false
    bucket          = ""compiler-explorer-logs.s3.amazonaws.com""
    prefix          = ""cloudfront/""
  }

  http_version = ""http2""

  restrictions {
    geo_restriction {
      restriction_type = ""blacklist""
      locations        = [
        ""CU"",
        ""IR"",
        ""KP"",
        ""SD"",
        ""SY""
      ]
    }
  }

  default_cache_behavior {
    allowed_methods = [
      ""HEAD"",
      ""DELETE"",
      ""POST"",
      ""GET"",
      ""OPTIONS"",
      ""PUT"",
      ""PATCH""
    ]
    cached_methods = [
      ""HEAD"",
      ""GET""
    ]
    forwarded_values {
      cookies {
        forward = ""all""
      }
      query_string = true
      headers      = [
        ""Accept"",
        ""Host"",
        ""Authorization""
      ]
    }
    target_origin_id       = ""GccExplorerApp""
    viewer_protocol_policy = ""redirect-to-https""
    compress               = true
  }
}
",resource,,,1,0.0,85295c876b56c7417ea7917c51c0a20ddb9b0a07,7e0840cb5b4fdc5b0c79ab82b68ed66fcd522e01,https://github.com/compiler-explorer/infra/blob/85295c876b56c7417ea7917c51c0a20ddb9b0a07/terraform/cloudfront_gpu.tf#L1,https://github.com/compiler-explorer/infra/blob/7e0840cb5b4fdc5b0c79ab82b68ed66fcd522e01/terraform/cloudfront_gpu.tf#L0,2022-11-14 21:02:28-06:00,2022-11-15 07:39:11-06:00,2,2,1,1,0,0,0,0,0,0
https://github.com/rancherfederal/rke2-aws-tf,38,modules/nlb/main.tf,modules/nlb/main.tf,0,ill,# Handle case where target group/load balancer name exceeds 32 character limit without creating illegal names,# Handle case where target group/load balancer name exceeds 32 character limit without creating illegal names,"locals {
  # Handle case where target group/load balancer name exceeds 32 character limit without creating illegal names
  controlplane_name = ""${substr(var.name, 0, 23)}-rke2-cp""
  server_name       = ""${substr(var.name, 0, 18)}-rke2-server""
  supervisor_name   = ""${substr(var.name, 0, 15)}-rke2-supervisor""
}
",locals,"locals {
  # Handle case where target group/load balancer name exceeds 32 character limit without creating illegal names
  controlplane_name = ""${substr(var.name, 0, 23)}-rke2-cp""
  server_name       = ""${substr(var.name, 0, 18)}-rke2-server""
  supervisor_name   = ""${substr(var.name, 0, 15)}-rke2-supervisor""
}
",locals,2,2.0,feee0b4e4d0f1f0c368eef2e591dae2d5cf8b8fa,9849d3f890c60c9c88a29b31272a14c464c084ef,https://github.com/rancherfederal/rke2-aws-tf/blob/feee0b4e4d0f1f0c368eef2e591dae2d5cf8b8fa/modules/nlb/main.tf#L2,https://github.com/rancherfederal/rke2-aws-tf/blob/9849d3f890c60c9c88a29b31272a14c464c084ef/modules/nlb/main.tf#L2,2022-12-15 07:04:45-05:00,2023-12-18 13:59:14-06:00,3,0,0,1,0,0,1,0,0,0
https://github.com/terraform-google-modules/terraform-google-kubernetes-engine,10,modules/safer-cluster/main.tf,modules/safer-cluster/main.tf,0,// todo,// TODO(mmontan): investigate whether this should be a recommended setting,// TODO(mmontan): investigate whether this should be a recommended setting,"module ""gke"" {
  source             = ""../beta-private-cluster/""
  project_id         = var.project_id
  name               = var.name
  regional           = var.regional
  region             = var.region
  network            = var.network
  network_project_id = var.network_project_id

  // We need to enforce a minimum Kubernetes Version to ensure
  // that the necessary security features are enabled.
  kubernetes_version = ""latest""

  // Nodes are created with a default version. The nodepool enables
  // auto_upgrade so that the node versions can be kept up to date with
  // the master upgrades.
  //
  // https://cloud.google.com/kubernetes-engine/versioning-and-upgrades
  node_version = """"

  master_authorized_networks_config = var.master_authorized_networks_config

  subnetwork        = var.subnetwork
  ip_range_pods     = var.ip_range_pods
  ip_range_services = var.ip_range_services

  horizontal_pod_autoscaling = var.horizontal_pod_autoscaling
  http_load_balancing        = var.http_load_balancing

  // Disable the dashboard. It creates risk by running as a very sensitive user.
  kubernetes_dashboard = false

  // We suggest the use coarse network policies to enforce restrictions in the
  // communication between pods.
  //
  // NOTE: Enabling network policy is not sufficient to enforce restrictions.
  // NetworkPolicies need to be configured in every namespace. The network
  // policies should be under the control of a cental cluster management team,
  // rather than individual teams.
  network_policy          = true
  network_policy_provider = ""CALICO""

  maintenance_start_time = var.maintenance_start_time

  initial_node_count = var.initial_node_count

  // We suggest removing the default node pull, as it cannot be modified without
  // destroying the cluster.
  remove_default_node_pool = true

  disable_legacy_metadata_endpoints = true

  node_pools        = var.node_pools
  node_pools_labels = var.node_pools_labels

  // TODO(mmontan): check whether we need to restrict these
  // settings.
  node_pools_metadata = var.node_pools_metadata
  node_pools_taints   = var.node_pools_taints
  node_pools_tags     = var.node_pools_tags

  // TODO(mmontan): we generally considered applying
  // just the cloud-platofrm scope and use Cloud IAM
  // If we have Workload Identity, are there advantages
  // in restricting scopes even more?
  node_pools_oauth_scopes = var.node_pools_oauth_scopes

  stub_domains         = var.stub_domains
  upstream_nameservers = var.upstream_nameservers

  // We should use IP Alias.
  configure_ip_masq = false

  logging_service    = var.logging_service
  monitoring_service = var.monitoring_service

  // We never use the default service account for the cluster. The default
  // project/editor permissions can create problems if nodes were to be ever
  // compromised.

  // We either:
  // - Create a dedicated service account with minimal permissions to run nodes.
  //   All applications shuold run with an identity defined via Workload Identity anyway.
  // - Use a service account passed as a parameter to the module, in case the user
  //   wants to maintain control of their service accounts.
  create_service_account = length(var.compute_engine_service_account) > 0 ? false : true
  service_account        = var.compute_engine_service_account

  // TODO(mmontan): define a registry_project parameter in the private_beta_cluster,
  // so that we can give GCS permissions to the service account on a project
  // that hosts only container-images and not data.
  grant_registry_access = true

  // Basic Auth disabled
  basic_auth_username = """"
  basic_auth_password = """"

  issue_client_certificate = false

  cluster_ipv4_cidr = var.cluster_ipv4_cidr

  cluster_resource_labels = var.cluster_resource_labels

  // We enable private endpoints to limit exposure.
  enable_private_endpoint       = true
  deploy_using_private_endpoint = true

  // Private nodes better control public exposure, and reduce
  // the ability of nodes to reach to the Internet without
  // additional configurations.
  enable_private_nodes = true

  master_ipv4_cidr_block = var.master_ipv4_cidr_block

  // Istio is recommended for pod-to-pod communications.
  istio    = var.istio
  cloudrun = var.cloudrun

  default_max_pods_per_node = var.default_max_pods_per_node

  database_encryption = var.database_encryption

  // We suggest to define policies about  which images can run on a cluster.
  enable_binary_authorization = true

  // Define PodSecurityPolicies for differnet applications.
  // TODO(mmontan): link to a couple of policies.
  pod_security_policy_config = [{
    ""enabled"" = true
  }]

  resource_usage_export_dataset_id = var.resource_usage_export_dataset_id
  node_metadata                    = ""SECURE""

  // Sandbox is needed if the cluster is going to run any untrusted workload (e.g., user submitted code).
  // Sandbox can also provide increased protection in other cases, at some performance cost.
  sandbox_enabled = var.sandbox_enabled

  // TODO(mmontan): investigate whether this should be a recommended setting
  enable_intranode_visibility = var.enable_intranode_visibility

  enable_vertical_pod_autoscaling = var.enable_vertical_pod_autoscaling

  // We enable identity namespace by default.
  identity_namespace = ""${var.project_id}.svc.id.goog""

  authenticator_security_group = var.authenticator_security_group
}
",module,"module ""gke"" {
  source             = ""../beta-private-cluster/""
  project_id         = var.project_id
  name               = var.name
  regional           = var.regional
  region             = var.region
  network            = var.network
  network_project_id = var.network_project_id

  // We need to enforce a minimum Kubernetes Version to ensure
  // that the necessary security features are enabled.
  kubernetes_version = ""latest""

  // Nodes are created with a default version. The nodepool enables
  // auto_upgrade so that the node versions can be kept up to date with
  // the master upgrades.
  //
  // https://cloud.google.com/kubernetes-engine/versioning-and-upgrades
  node_version = """"

  master_authorized_networks_config = var.master_authorized_networks_config

  subnetwork        = var.subnetwork
  ip_range_pods     = var.ip_range_pods
  ip_range_services = var.ip_range_services

  horizontal_pod_autoscaling = var.horizontal_pod_autoscaling
  http_load_balancing        = var.http_load_balancing

  // We suggest the use coarse network policies to enforce restrictions in the
  // communication between pods.
  //
  // NOTE: Enabling network policy is not sufficient to enforce restrictions.
  // NetworkPolicies need to be configured in every namespace. The network
  // policies should be under the control of a cental cluster management team,
  // rather than individual teams.
  network_policy = true

  maintenance_start_time = var.maintenance_start_time

  initial_node_count = var.initial_node_count

  // We suggest removing the default node pull, as it cannot be modified without
  // destroying the cluster.
  remove_default_node_pool = true

  node_pools        = var.node_pools
  node_pools_labels = var.node_pools_labels

  // TODO(mmontan): check whether we need to restrict these
  // settings.
  node_pools_metadata = var.node_pools_metadata
  node_pools_taints   = var.node_pools_taints
  node_pools_tags     = var.node_pools_tags

  node_pools_oauth_scopes = var.node_pools_oauth_scopes

  stub_domains         = var.stub_domains
  upstream_nameservers = var.upstream_nameservers

  logging_service    = var.logging_service
  monitoring_service = var.monitoring_service

  // We never use the default service account for the cluster. The default
  // project/editor permissions can create problems if nodes were to be ever
  // compromised.

  // We either:
  // - Create a dedicated service account with minimal permissions to run nodes.
  //   All applications shuold run with an identity defined via Workload Identity anyway.
  // - Use a service account passed as a parameter to the module, in case the user
  //   wants to maintain control of their service accounts.
  create_service_account = var.compute_engine_service_account == """" ? true : false
  service_account        = var.compute_engine_service_account
  registry_project_id    = var.registry_project_id
  grant_registry_access  = true

  // Basic Auth disabled
  basic_auth_username = """"
  basic_auth_password = """"

  issue_client_certificate = false

  cluster_ipv4_cidr = var.cluster_ipv4_cidr

  cluster_resource_labels = var.cluster_resource_labels

  // We enable private endpoints to limit exposure.
  enable_private_endpoint       = true
  deploy_using_private_endpoint = true

  // Private nodes better control public exposure, and reduce
  // the ability of nodes to reach to the Internet without
  // additional configurations.
  enable_private_nodes = true

  master_ipv4_cidr_block = var.master_ipv4_cidr_block

  // Istio is recommended for pod-to-pod communications.
  istio    = var.istio
  cloudrun = var.cloudrun

  default_max_pods_per_node = var.default_max_pods_per_node

  database_encryption = var.database_encryption

  // We suggest to define policies about  which images can run on a cluster.
  enable_binary_authorization = true

  // Define PodSecurityPolicies for differnet applications.
  // Example: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#example
  pod_security_policy_config = [{
    ""enabled"" = true
  }]

  resource_usage_export_dataset_id = var.resource_usage_export_dataset_id

  // Sandbox is needed if the cluster is going to run any untrusted workload (e.g., user submitted code).
  // Sandbox can also provide increased protection in other cases, at some performance cost.
  sandbox_enabled = var.sandbox_enabled

  // Intranode Visibility enables you to capture flow logs for traffic between pods and create FW rules that apply to traffic between pods.
  enable_intranode_visibility = var.enable_intranode_visibility

  enable_vertical_pod_autoscaling = var.enable_vertical_pod_autoscaling

  // We enable identity namespace by default.
  identity_namespace = ""${var.project_id}.svc.id.goog""

  authenticator_security_group = var.authenticator_security_group

  enable_shielded_nodes = var.enable_shielded_nodes
}
",module,157,,e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5,5a194719faa144ad0a7ee578663d336358f5073c,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5/modules/safer-cluster/main.tf#L157,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/5a194719faa144ad0a7ee578663d336358f5073c/modules/safer-cluster/main.tf,2019-10-04 15:21:33-07:00,2019-11-13 15:10:12-06:00,6,1,1,1,0,0,0,0,0,1
https://github.com/terraform-google-modules/terraform-google-iam,19,test/fixtures/additive/outputs.tf,test/fixtures/additive/outputs.tf,0,# todo,"# TODO: This has to be pure integer, but InSpec attributes don't seem","# TODO: This has to be pure integer, but InSpec attributes don't seem 
 #       to support neither of the types number, integer, int, float, double","output ""roles"" {
  # TODO: This has to be pure integer, but InSpec attributes don't seem
  #       to support neither of the types number, integer, int, float, double
  value       = tostring(var.roles)
  description = ""Amount of roles assigned. Useful for testing how the module behaves on updates.""
}
",output,"output ""roles"" {
  # workaround InSpec lack of support for integer
  value       = tostring(var.roles)
  description = ""Amount of roles assigned. Useful for testing how the module behaves on updates.""
}
",output,119,,40c4014c903788118f39c6decda3f02858721890,2529fe6173f7540994a346066d5ab141144861e9,https://github.com/terraform-google-modules/terraform-google-iam/blob/40c4014c903788118f39c6decda3f02858721890/test/fixtures/additive/outputs.tf#L119,https://github.com/terraform-google-modules/terraform-google-iam/blob/2529fe6173f7540994a346066d5ab141144861e9/test/fixtures/additive/outputs.tf,2019-10-21 15:23:47+03:00,2019-10-23 19:31:30+03:00,2,1,0,1,0,0,0,0,0,1
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,474,tests/modules/net_xlb/fixture/variables.tf,tests/modules/net_glb/fixture/variables.tf,1,hack,"# Will lookup for ids in health_chacks_config first,","# Optional health check ids for backend service groups. 
 # Will lookup for ids in health_chacks_config first, 
 # then will use the id as is. If no ids are defined 
 # at all (null, []) health_checks_config_defaults is used","variable ""backend_services_config"" {
  description = ""The backends services configuration.""
  type = map(object({
    enable_cdn = bool

    cdn_config = object({
      cache_mode                   = string
      client_ttl                   = number
      default_ttl                  = number
      max_ttl                      = number
      negative_caching             = bool
      negative_caching_policy      = map(number)
      serve_while_stale            = bool
      signed_url_cache_max_age_sec = string
    })

    bucket_config = object({
      bucket_name = string
      options = object({
        custom_response_headers = list(string)
      })
    })

    group_config = object({
      backends = list(object({
        group = string # IG or NEG FQDN address
        options = object({
          balancing_mode               = string # Can be UTILIZATION, RATE, CONNECTION
          capacity_scaler              = number # Valid range is [0.0,1.0]
          max_connections              = number
          max_connections_per_instance = number
          max_connections_per_endpoint = number
          max_rate                     = number
          max_rate_per_instance        = number
          max_rate_per_endpoint        = number
          max_utilization              = number
        })
      }))

      # Optional health check ids for backend service groups.
      # Will lookup for ids in health_chacks_config first,
      # then will use the id as is. If no ids are defined
      # at all (null, []) health_checks_config_defaults is used
      health_checks = list(string)

      log_config = object({
        enable      = bool
        sample_rate = number # must be in [0, 1]
      })

      options = object({
        affinity_cookie_ttl_sec         = number
        custom_request_headers          = list(string)
        custom_response_headers         = list(string)
        connection_draining_timeout_sec = number
        load_balancing_scheme           = string # only EXTERNAL (default) makes sense here
        locality_lb_policy              = string
        port_name                       = string
        protocol                        = string
        security_policy                 = string
        session_affinity                = string
        timeout_sec                     = number

        circuits_breakers = object({
          max_requests_per_connection = number # Set to 1 to disable keep-alive
          max_connections             = number # Defaults to 1024
          max_pending_requests        = number # Defaults to 1024
          max_requests                = number # Defaults to 1024
          max_retries                 = number # Defaults to 3
        })

        consistent_hash = object({
          http_header_name  = string
          minimum_ring_size = string
          http_cookie = object({
            name = string
            path = string
            ttl = object({
              seconds = number
              nanos   = number
            })
          })
        })

        iap = object({
          oauth2_client_id            = string
          oauth2_client_secret        = string
          oauth2_client_secret_sha256 = string
        })
      })
    })
  }))
  default = {}
}
",variable,,,86,0.0,ca82d5157a8c51690567ad2740cc84092f385764,46f694be082aa5c42e39094143acadbc1f2181be,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/ca82d5157a8c51690567ad2740cc84092f385764/tests/modules/net_xlb/fixture/variables.tf#L86,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/46f694be082aa5c42e39094143acadbc1f2181be/tests/modules/net_glb/fixture/variables.tf#L0,2022-01-14 16:05:10+01:00,2022-12-08 17:35:44+01:00,3,2,0,1,0,0,0,0,0,0
https://github.com/nebari-dev/nebari,12,qhub/template/stages/07-kubernetes-services/modules/kubernetes/services/dask-gateway/crds.tf,qhub/template/stages/07-kubernetes-services/modules/kubernetes/services/dask-gateway/crds.tf,0,fix,# FIXME: Make this an actual schema instead of this dummy schema that,"# FIXME: Make this an actual schema instead of this dummy schema that 
 #        is a workaround to meet the requirement of having a schema.","resource ""kubernetes_manifest"" ""main"" {
  manifest = {
    apiVersion = ""apiextensions.k8s.io/v1""
    kind       = ""CustomResourceDefinition""
    metadata = {
      name = ""daskclusters.gateway.dask.org""
    }
    spec = {
      group   = ""gateway.dask.org""
      names = {
        kind     = ""DaskCluster""
        listKind = ""DaskClusterList""
        plural   = ""daskclusters""
        singular = ""daskcluster""
      }
      scope = ""Namespaced""
      versions = [{
        name = ""v1alpha1""
        served = true
        storage = true
        subresources = {
          status = {}
        }

        # NOTE: While we define a schema, it is a dummy schema that doesn't
        #       validate anything. We just have it to comply with the schema of
        #       a CustomResourceDefinition that requires it.
        #
        #       A decision has been made to not implement an actual schema at
        #       this point in time due to the additional maintenance work it
        #       would require.
        #
        #       Reference: https://github.com/dask/dask-gateway/issues/434
        #
        schema = {
          openAPIV3Schema = {
            type = ""object""
            # FIXME: Make this an actual schema instead of this dummy schema that
            #        is a workaround to meet the requirement of having a schema.
            x-kubernetes-preserve-unknown-fields = true
          }
        }
      }]
    }
  }
}
",resource,"resource ""kubernetes_manifest"" ""main"" {
  manifest = {
    apiVersion = ""apiextensions.k8s.io/v1""
    kind       = ""CustomResourceDefinition""
    metadata = {
      name = ""daskclusters.gateway.dask.org""
    }
    spec = {
      group = ""gateway.dask.org""
      names = {
        kind     = ""DaskCluster""
        listKind = ""DaskClusterList""
        plural   = ""daskclusters""
        singular = ""daskcluster""
      }
      scope = ""Namespaced""
      versions = [{
        name    = ""v1alpha1""
        served  = true
        storage = true
        subresources = {
          status = {}
        }

        # NOTE: While we define a schema, it is a dummy schema that doesn't
        #       validate anything. We just have it to comply with the schema of
        #       a CustomResourceDefinition that requires it.
        #
        #       A decision has been made to not implement an actual schema at
        #       this point in time due to the additional maintenance work it
        #       would require.
        #
        #       Reference: https://github.com/dask/dask-gateway/issues/434
        #
        schema = {
          openAPIV3Schema = {
            type = ""object""
            # FIXME: Make this an actual schema instead of this dummy schema that
            #        is a workaround to meet the requirement of having a schema.
            x-kubernetes-preserve-unknown-fields = true
          }
        }
      }]
    }
  }
}
",resource,38,38.0,e65621ed9fc3e374626cc3929742df6ba94fc8d7,d0cc26638fbc9e69aa736105ffd61cfb50d561d6,https://github.com/nebari-dev/nebari/blob/e65621ed9fc3e374626cc3929742df6ba94fc8d7/qhub/template/stages/07-kubernetes-services/modules/kubernetes/services/dask-gateway/crds.tf#L38,https://github.com/nebari-dev/nebari/blob/d0cc26638fbc9e69aa736105ffd61cfb50d561d6/qhub/template/stages/07-kubernetes-services/modules/kubernetes/services/dask-gateway/crds.tf#L38,2022-02-03 11:12:40-05:00,2022-05-26 14:22:33-07:00,2,0,1,1,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,646,modules/self-managed-node-group/main.tf,modules/self-managed-node-group/main.tf,0,todo,# TODO - Temporary stopgap for backwards compatibility until v21.0,# TODO - Temporary stopgap for backwards compatibility until v21.0,"locals {
  # Just to ensure templating doesn't fail when values are not provided
  ssm_cluster_version = var.cluster_version != null ? var.cluster_version : """"

  # TODO - Temporary stopgap for backwards compatibility until v21.0
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  # Map the AMI type to the respective SSM param path
  ami_type_to_ssm_param = {
    AL2_x86_64                 = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2/recommended/image_id""
    AL2_x86_64_GPU             = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2-gpu/recommended/image_id""
    AL2_ARM_64                 = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2-arm64/recommended/image_id""
    BOTTLEROCKET_ARM_64        = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}/arm64/latest/image_id""
    BOTTLEROCKET_x86_64        = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}/x86_64/latest/image_id""
    BOTTLEROCKET_ARM_64_NVIDIA = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}-nvidia/arm64/latest/image_id""
    BOTTLEROCKET_x86_64_NVIDIA = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}-nvidia/x86_64/latest/image_id""
    WINDOWS_CORE_2019_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_FULL_2019_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2019-English-Core-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_CORE_2022_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2022-English-Full-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_FULL_2022_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2022-English-Core-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    AL2023_x86_64_STANDARD     = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2023/x86_64/standard/recommended/image_id""
    AL2023_ARM_64_STANDARD     = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2023/arm64/standard/recommended/image_id""
  }
}
",locals,"locals {
  # Just to ensure templating doesn't fail when values are not provided
  ssm_cluster_version = var.cluster_version != null ? var.cluster_version : """"

  # TODO - Temporary stopgap for backwards compatibility until v21.0
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  # Map the AMI type to the respective SSM param path
  ami_type_to_ssm_param = {
    AL2_x86_64                 = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2/recommended/image_id""
    AL2_x86_64_GPU             = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2-gpu/recommended/image_id""
    AL2_ARM_64                 = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2-arm64/recommended/image_id""
    BOTTLEROCKET_ARM_64        = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}/arm64/latest/image_id""
    BOTTLEROCKET_x86_64        = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}/x86_64/latest/image_id""
    BOTTLEROCKET_ARM_64_NVIDIA = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}-nvidia/arm64/latest/image_id""
    BOTTLEROCKET_x86_64_NVIDIA = ""/aws/service/bottlerocket/aws-k8s-${local.ssm_cluster_version}-nvidia/x86_64/latest/image_id""
    WINDOWS_CORE_2019_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2019-English-Full-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_FULL_2019_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2019-English-Core-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_CORE_2022_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2022-English-Full-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    WINDOWS_FULL_2022_x86_64   = ""/aws/service/ami-windows-latest/Windows_Server-2022-English-Core-EKS_Optimized-${local.ssm_cluster_version}/image_id""
    AL2023_x86_64_STANDARD     = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2023/x86_64/standard/recommended/image_id""
    AL2023_ARM_64_STANDARD     = ""/aws/service/eks/optimized-ami/${local.ssm_cluster_version}/amazon-linux-2023/arm64/standard/recommended/image_id""
  }
}
",locals,12,12.0,74d39187d855932dd976da6180eda42dcfe09873,74d39187d855932dd976da6180eda42dcfe09873,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/self-managed-node-group/main.tf#L12,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/self-managed-node-group/main.tf#L12,2024-05-08 08:04:19-04:00,2024-05-08 08:04:19-04:00,1,0,0,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,166,modules/workergroup/instancepools.tf,modules/workers/instancepools.tf,1,todo,# TODO From dynamic creation when no lb_id provided introspected fields when present,# TODO From dynamic creation when no lb_id provided introspected fields when present,"resource ""oci_core_instance_pool"" ""instance_pools"" {
  # Create an OCI Instance Pool resource for each enabled entry of the worker_groups map with that mode.
  for_each                  = local.enabled_instance_pools
  compartment_id            = each.value.compartment_id
  display_name              = ""${each.value.label_prefix}-${each.key}""
  size                      = each.value.size
  instance_configuration_id = oci_core_instance_configuration.instance_configuration[each.key].id
  defined_tags              = merge(local.defined_tags, contains(keys(each.value), ""defined_tags"") ? each.value.defined_tags : {})
  freeform_tags             = merge(local.freeform_tags, contains(keys(each.value), ""freeform_tags"") ? each.value.freeform_tags : { worker_group = each.key })

  dynamic ""placement_configurations"" {
    # Define each configured availability domain for placement, with bounds on # available
    # Configured AD numbers e.g. [1,2,3] are converted into tenancy/compartment-specific names
    iterator = ad_number
    for_each = (contains(keys(each.value), ""placement_ads"")
      ? tolist(setintersection(each.value.placement_ads, local.ad_numbers))
      : local.ad_numbers
    )

    content {
      availability_domain = lookup(local.ad_number_to_name, ad_number.value, local.first_ad_name)
      primary_subnet_id   = each.value.subnet_id
    }
  }

  lifecycle {
    ignore_changes = [
      display_name, defined_tags, freeform_tags,
      placement_configurations,
    ]
  }

  dynamic ""load_balancers"" {
    # Associate the instance pool with 0+ load balancers for ingress traffic
    # TODO Accept full definition to create
    for_each = contains(keys(each.value), ""load_balancers"") ? each.value.load_balancers : {}

    content {
      # TODO From dynamic creation when no lb_id provided; introspected fields when present
      backend_set_name = lookup(lb, ""backend_set_name"", display_name)
      load_balancer_id = lookup(lb, ""lb_id"", lb_id)
      port             = lookup(lb, ""port"", 8080)

      // Possible values are ""PrimaryVnic"" or the displayName of
      // one of the secondary VNICs on the instance configuration
      // that is associated with the instance pool.
      vnic_selection = lookup(lb, ""vnic_selection"", ""PrimaryVnic"") # TODO Support w/ named secondary VNICs
    }
  }

  depends_on = [
    oci_core_instance_configuration.instance_configuration,
  ]
}",resource,the block associated got renamed or deleted,,43,,4d2b3f3d672a8f41655da3a7c58fded42c6858f3,f49f1da39d79cf260d80dcb10ee8e399828e6e1c,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/4d2b3f3d672a8f41655da3a7c58fded42c6858f3/modules/workergroup/instancepools.tf#L43,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/f49f1da39d79cf260d80dcb10ee8e399828e6e1c/modules/workers/instancepools.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,4,1,1,1,0,0,1,0,0,0
https://github.com/Worklytics/psoxy,1021,infra/modules/gcp-tf-runner/main.tf,infra/modules/gcp-tf-runner/main.tf,0,hack,# hacky way to determine if Terraform running as a service account or not,# hacky way to determine if Terraform running as a service account or not,"locals {
  # hacky way to determine if Terraform running as a service account or not
  tf_is_service_account = endswith(data.google_client_openid_userinfo.me.email, ""iam.gserviceaccount.com"")

  tf_qualifier          = local.tf_is_service_account ? ""serviceAccount:"" : ""user:""
  tf_principal          = ""${local.tf_qualifier}${data.google_client_openid_userinfo.me.email}""
}
",locals,"locals {
  jwt_payload = try(split(""."", data.google_service_account_id_token.identity[0].id_token)[1], """")

  # convert base64url encoding to base64 encoding
  padding                   = join("""", formatlist(""%s"", [for _ in range(4 - length(local.jwt_payload) % 4) : ""=""]))
  jwt_payload_padded        = ""${local.jwt_payload}${local.padding}""
  jwt_payload_base64encoded = replace(replace(local.jwt_payload_padded, ""-"", ""+""), ""_"", ""/"")

  # decode to JSON, then extract email field
  email_from_jwt = try(nonsensitive(jsondecode(base64decode(local.jwt_payload_base64encoded)).email), """")

  # coalesce failing here implies we failed to detect the auth'd gcp user
  authed_user_email = coalesce(
    try(data.external.identity.result.gcp_terraform_sa_account_email, """"), # """" if no such value
    data.google_client_openid_userinfo.me.email,
    local.email_from_jwt
  )

  # hacky way to determine if Terraform running as a service account or not
  tf_is_service_account = endswith(local.authed_user_email, ""iam.gserviceaccount.com"")

  tf_qualifier = local.tf_is_service_account ? ""serviceAccount:"" : ""user:""
  tf_principal = ""${local.tf_qualifier}${local.authed_user_email}""
}
",locals,13,60.0,5b70c56e12136c245e8032e353322be2ccf4c055,2c788b347439df06399004184cbfe1b9ce9987e7,https://github.com/Worklytics/psoxy/blob/5b70c56e12136c245e8032e353322be2ccf4c055/infra/modules/gcp-tf-runner/main.tf#L13,https://github.com/Worklytics/psoxy/blob/2c788b347439df06399004184cbfe1b9ce9987e7/infra/modules/gcp-tf-runner/main.tf#L60,2023-04-21 09:17:45-07:00,2023-10-24 20:36:35-07:00,5,0,0,0,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,24,modules/net-vpc/outputs.tf,modules/net-vpc/outputs.tf,0,# todo,# TODO(ludoo): use input names as keys,# TODO(ludoo): use input names as keys,"output ""subnets"" {
  description = ""Subnet resources.""
  value       = { for k, v in google_compute_subnetwork.subnetwork : k => v }
}
",output,"output ""subnets"" {
  description = ""Subnet resources.""
  value       = { for k, v in google_compute_subnetwork.subnetwork : k => v }
}
",output,45,,c486bfc66f9814e33b410602cb557a5e4d532912,884cb8b4bf4caa8baa1d0148deb5a000a70a9920,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/c486bfc66f9814e33b410602cb557a5e4d532912/modules/net-vpc/outputs.tf#L45,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/884cb8b4bf4caa8baa1d0148deb5a000a70a9920/modules/net-vpc/outputs.tf,2020-04-03 14:06:48+02:00,2023-06-02 16:07:22+02:00,12,1,0,1,0,1,0,0,0,0
https://github.com/kubernetes/k8s.io,387,infra/aws/terraform/prow-build-cluster/iam.tf,infra/aws/terraform/prow-build-cluster/iam.tf,0,# todo,# TODO(pkprzekwas): remove after applying changes on prow-build-cluster,"/* 
 Copyright 2023 The Kubernetes Authors. 
  
 Licensed under the Apache License, Version 2.0 (the ""License""); 
 you may not use this file except in compliance with the License. 
 You may obtain a copy of the License at 
  
 http://www.apache.org/licenses/LICENSE-2.0 
  
 Unless required by applicable law or agreed to in writing, software 
 distributed under the License is distributed on an ""AS IS"" BASIS, 
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 See the License for the specific language governing permissions and 
 limitations under the License. 
 */  
 # TODO(pkprzekwas): remove after applying changes on prow-build-cluster","module ""iam"" {
  count = var.cluster_name == ""prow-build-cluster"" ? 1 : 0

  source = ""./modules/iam""

  eks_admins = var.eks_cluster_admins
}
",module,the block associated got renamed or deleted,,17,,d6f2d24051e866e453d920130509ce7b285311f9,1cdb9ebe968e412627b5334131803bbc8a9fecdb,https://github.com/kubernetes/k8s.io/blob/d6f2d24051e866e453d920130509ce7b285311f9/infra/aws/terraform/prow-build-cluster/iam.tf#L17,https://github.com/kubernetes/k8s.io/blob/1cdb9ebe968e412627b5334131803bbc8a9fecdb/infra/aws/terraform/prow-build-cluster/iam.tf,2023-04-27 18:01:09+02:00,2023-04-28 14:47:31+02:00,4,1,0,1,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,129,terraform/projects/infra-security-groups/api.tf,terraform/projects/infra-security-groups/api.tf,0,# todo,# TODO: replace this with ingress from the api LBs when we build them.,# TODO: replace this with ingress from the api LBs when we build them.,"resource ""aws_security_group_rule"" ""allow_management_to_api_elb"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  security_group_id        = ""${aws_security_group.api_elb.id}""
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,47,,231e1767403d873f174f96001a2f84b9ecb2b12f,97bf0282ce176d8e44cf9475826feaa9094125e5,https://github.com/alphagov/govuk-aws/blob/231e1767403d873f174f96001a2f84b9ecb2b12f/terraform/projects/infra-security-groups/api.tf#L47,https://github.com/alphagov/govuk-aws/blob/97bf0282ce176d8e44cf9475826feaa9094125e5/terraform/projects/infra-security-groups/api.tf,2017-07-20 12:51:53+01:00,2017-08-14 11:25:10+01:00,2,1,0,1,0,1,1,0,0,0
https://github.com/Azure/sap-automation,31,deploy/terraform/terraform-units/modules/sap_system/app_tier/vm-webdisp.tf,deploy/terraform/terraform-units/modules/sap_system/app_tier/vm-webdisp.tf,0,#todo,"#ToDo: Remove once feature is GA  patch_mode = ""Manual""","#ToDo: Remove once feature is GA  patch_mode = ""Manual""","resource ""azurerm_windows_virtual_machine"" ""web"" {
  provider            = azurerm.main
  count               = local.enable_deployment ? (upper(local.web_ostype) == ""WINDOWS"" ? local.webdispatcher_count : 0) : 0
  name                = format(""%s%s%s%s"", local.prefix, var.naming.separator, var.naming.virtualmachine_names.WEB_VMNAME[count.index], local.resource_suffixes.vm)
  computer_name       = var.naming.virtualmachine_names.WEB_COMPUTERNAME[count.index]
  location            = var.resource_group[0].location
  resource_group_name = var.resource_group[0].name

  //If no ppg defined do not put the web dispatchers in a proximity placement group
  proximity_placement_group_id = local.web_no_ppg ? (
    null) : (
    local.web_zonal_deployment ? var.ppg[count.index % max(local.web_zone_count, 1)].id : var.ppg[0].id
  )

  //If more than one servers are deployed into a single zone put them in an availability set and not a zone
  availability_set_id = local.use_web_avset ? azurerm_availability_set.web[count.index % max(local.web_zone_count, 1)].id : null

  //If length of zones > 1 distribute servers evenly across zones
  zone = local.use_web_avset ? null : local.web_zones[count.index % max(local.web_zone_count, 1)]

  network_interface_ids = var.application.dual_nics ? (
    var.options.legacy_nic_order ? (
      [azurerm_network_interface.web_admin[count.index].id, azurerm_network_interface.web[count.index].id]) : (
      [azurerm_network_interface.web[count.index].id, azurerm_network_interface.web_admin[count.index].id]
    )
    ) : (
    [azurerm_network_interface.web[count.index].id]
  )

  size           = local.web_sizing.compute.vm_size
  admin_username = var.sid_username
  admin_password = var.sid_password

  dynamic ""os_disk"" {
    iterator = disk
    for_each = flatten(
      [
        for storage_type in local.web_sizing.storage : [
          for disk_count in range(storage_type.count) :
          {
            name      = storage_type.name,
            id        = disk_count,
            disk_type = storage_type.disk_type,
            size_gb   = storage_type.size_gb,
            caching   = storage_type.caching
          }
        ]
        if storage_type.name == ""os""
      ]
    )

    content {
      name                   = format(""%s%s%s%s"", local.prefix, var.naming.separator, var.naming.virtualmachine_names.WEB_VMNAME[count.index], local.resource_suffixes.osdisk)
      caching                = disk.value.caching
      storage_account_type   = disk.value.disk_type
      disk_size_gb           = disk.value.size_gb
      disk_encryption_set_id = try(var.options.disk_encryption_set_id, null)
    }
  }

  source_image_id = local.web_custom_image ? local.web_os.source_image_id : null

  dynamic ""source_image_reference"" {
    for_each = range(local.web_custom_image ? 0 : 1)
    content {
      publisher = local.web_os.publisher
      offer     = local.web_os.offer
      sku       = local.web_os.sku
      version   = local.web_os.version
    }
  }

  boot_diagnostics {
    storage_account_uri = var.storage_bootdiag_endpoint
  }


  #ToDo: Remove once feature is GA  patch_mode = ""Manual""
  license_type = length(var.license_type) > 0 ? var.license_type : null

  tags = try(var.application.web_tags, {})
}
",resource,"resource ""azurerm_windows_virtual_machine"" ""web"" {
  provider                             = azurerm.main
  count                                = local.enable_deployment && upper(var.application_tier.web_os.os_type) == ""WINDOWS"" ? (
                                           local.webdispatcher_count) : (
                                           0
                                         )
  name                                 = format(""%s%s%s%s%s"",
                                           var.naming.resource_prefixes.vm,
                                           local.prefix,
                                           var.naming.separator,
                                           var.naming.virtualmachine_names.WEB_VMNAME[count.index],
                                           local.resource_suffixes.vm
                                         )
  computer_name                        = var.naming.virtualmachine_names.WEB_COMPUTERNAME[count.index]
  location                             = var.resource_group[0].location
  resource_group_name                  = var.resource_group[0].name

  proximity_placement_group_id         = var.application_tier.web_use_ppg ? (
                                           local.web_zonal_deployment ? var.ppg[count.index % max(local.web_zone_count, 1)] : var.ppg[0]) : (
                                           null
                                         )

  //If more than one servers are deployed into a single zone put them in an availability set and not a zone
  availability_set_id                  = local.use_web_avset ? (
                                           azurerm_availability_set.web[count.index % max(length(azurerm_availability_set.web), 1)].id
                                           ) : (
                                           null
                                         )

  virtual_machine_scale_set_id         = length(var.scale_set_id) > 0 ? var.scale_set_id : null

  //If length of zones > 1 distribute servers evenly across zones
  zone                                 = local.use_web_avset ? (
                                           null) : (
                                           try(local.web_zones[count.index % max(local.web_zone_count, 1)], null)
                                         )

  network_interface_ids                = var.application_tier.dual_nics ? (
                                           var.options.legacy_nic_order ? (
                                             [
                                               azurerm_network_interface.web_admin[count.index].id,
                                               azurerm_network_interface.web[count.index].id
                                             ]) : (
                                             [
                                               azurerm_network_interface.web[count.index].id,
                                               azurerm_network_interface.web_admin[count.index].id
                                             ]
                                           )
                                           ) : (
                                           [azurerm_network_interface.web[count.index].id]
                                         )

  size                                 = local.web_sizing.compute.vm_size
  admin_username                       = var.sid_username
  admin_password                       = var.sid_password

  source_image_id                      = var.application_tier.web_os.type == ""custom"" ? var.application_tier.web_os.source_image_id : null

  #ToDo: Remove once feature is GA  patch_mode = ""Manual""
  license_type                         = length(var.license_type) > 0 ? var.license_type : null
  # ToDo Add back later
# patch_mode                           = var.infrastructure.patch_mode

  tags                                 = merge(var.application_tier.web_tags, var.tags)

  dynamic ""os_disk"" {
                      iterator = disk
                      for_each = flatten(
                        [
                          for storage_type in local.web_sizing.storage : [
                            for disk_count in range(storage_type.count) :
                            {
                              name      = storage_type.name,
                              id        = disk_count,
                              disk_type = storage_type.disk_type,
                              size_gb   = storage_type.size_gb < 128 ? 128 : storage_type.size_gb,
                              caching   = storage_type.caching
                            }
                          ]
                          if storage_type.name == ""os""
                        ]
                      )

                      content {
                                name = format(""%s%s%s%s%s"",
                                  var.naming.resource_prefixes.osdisk,
                                  local.prefix,
                                  var.naming.separator,
                                  var.naming.virtualmachine_names.WEB_VMNAME[count.index],
                                  local.resource_suffixes.osdisk
                                )
                                caching                = disk.value.caching
                                storage_account_type   = disk.value.disk_type
                                disk_size_gb           = disk.value.size_gb
                                disk_encryption_set_id = try(var.options.disk_encryption_set_id, null)
                              }
                    }

  dynamic ""source_image_reference"" {
                                     for_each = range(var.application_tier.web_os.type == ""marketplace"" || var.application_tier.web_os.type == ""marketplace_with_plan"" ? 1 : 0)
                                     content {
                                               publisher = var.application_tier.web_os.publisher
                                               offer     = var.application_tier.web_os.offer
                                               sku       = var.application_tier.web_os.sku
                                               version   = var.application_tier.web_os.version
                                             }
                                   }
  dynamic ""plan"" {
                   for_each = range(var.application_tier.web_os.type == ""marketplace_with_plan"" ? 1 : 0)
                   content {
                             name      = var.application_tier.web_os.sku
                             publisher = var.application_tier.web_os.publisher
                             product   = var.application_tier.web_os.offer
                           }
                 }

  boot_diagnostics {
                     storage_account_uri = var.storage_bootdiag_endpoint
                   }
  dynamic ""identity""   {
                         for_each = range(length(var.application_tier.user_assigned_identity_id) > 0 ? 1 : 0)
                         content {
                                   type         = ""UserAssigned""
                                   identity_ids = [var.application_tier.user_assigned_identity_id]
                                 }
                       }
  lifecycle {
    ignore_changes = [
      source_image_id
    ]
  }

}
",resource,224,314.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,df063c58945a9efa2cb2ba303762c43f0b9c1d8f,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_system/app_tier/vm-webdisp.tf#L224,https://github.com/Azure/sap-automation/blob/df063c58945a9efa2cb2ba303762c43f0b9c1d8f/deploy/terraform/terraform-units/modules/sap_system/app_tier/vm-webdisp.tf#L314,2021-11-17 19:29:07+02:00,2024-05-17 12:37:17+03:00,54,0,1,1,0,0,0,0,0,0
https://github.com/Worklytics/psoxy,1532,infra/modules/worklytics-connectors-msft-365/outputs.tf,infra/modules/worklytics-connectors-msft-365/outputs.tf,0,fix,# TODO: fix this. tf complain is:,"# TODO: fix this. tf complain is: 
 # ���     ��� while calling max(numbers...) 
 # ���     ��� local.next_todo_steps is empty list of dynamic 
 #  ���     ��� var.todo_step is 1 ","output ""next_todo_step"" {
  # TODO: fix this. tf complain is:
  # ���     ��� while calling max(numbers...)
  # ���     ��� local.next_todo_steps is empty list of dynamic
  #  ���     ��� var.todo_step is 1

  value = try(max(concat([var.todo_step], local.next_todo_steps)), var.todo_step + 1)
}
",output,"output ""next_todo_step"" {
  # TODO: fix this. tf complain is:
  # ���     ��� while calling max(numbers...)
  # ���     ��� local.next_todo_steps is empty list of dynamic
  #  ���     ��� var.todo_step is 1

  value = try(max(concat([var.todo_step], local.next_todo_steps)), var.todo_step + 1)
}
",output,18,18.0,f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e,69a63fd34e47423da0c3cd430eaccbc15d7286af,https://github.com/Worklytics/psoxy/blob/f6f60a1c3c6fa3e2898c9b0c26a8430f0000bd7e/infra/modules/worklytics-connectors-msft-365/outputs.tf#L18,https://github.com/Worklytics/psoxy/blob/69a63fd34e47423da0c3cd430eaccbc15d7286af/infra/modules/worklytics-connectors-msft-365/outputs.tf#L18,2023-06-16 14:08:45-07:00,2023-08-25 09:02:49-07:00,3,0,0,1,1,0,0,0,0,0
https://github.com/google/go-cloud,1,samples/guestbook/aws/main.tf,samples/guestbook/aws/main.tf,0,# todo,# TODO(light): Reuse credentials from Terraform.,# TODO(light): Reuse credentials from Terraform.,"resource ""aws_db_instance"" ""guestbook"" {
  identifier_prefix      = ""guestbook""
  engine                 = ""mysql""
  engine_version         = ""5.6.39""
  instance_class         = ""db.t2.micro""
  allocated_storage      = 20
  username               = ""root""
  password               = ""${random_string.db_password.result}""
  name                   = ""guestbook""
  publicly_accessible    = true
  vpc_security_group_ids = [""${aws_security_group.guestbook.id}""]
  skip_final_snapshot    = true

  provisioner ""local-exec"" {
    # TODO(light): Reuse credentials from Terraform.
    command = ""cat '${path.module}'/../schema.sql '${path.module}'/../roles.sql | '${path.module}'/provision-db.sh '${aws_db_instance.guestbook.address}' '${aws_security_group.guestbook.id}' guestbook '${random_string.db_password.result}'""
  }
}
",resource,"resource ""aws_db_instance"" ""guestbook"" {
  identifier_prefix      = ""guestbook""
  engine                 = ""mysql""
  engine_version         = ""5.6.39""
  instance_class         = ""db.t2.micro""
  allocated_storage      = 20
  username               = ""root""
  password               = random_string.db_password.result
  name                   = ""guestbook""
  publicly_accessible    = true
  vpc_security_group_ids = [aws_security_group.guestbook.id]
  skip_final_snapshot    = true

  provisioner ""local-exec"" {
    # TODO(light): Reuse credentials from Terraform.
    command = ""go run '${path.module}'/provision_db/main.go -host='${aws_db_instance.guestbook.address}' -region='${var.region}' -security_group='${aws_security_group.guestbook.id}' -database=guestbook -password='${random_string.db_password.result}' -schema='${path.module}'/../schema.sql""
  }
}
",resource,84,88.0,2f807406236dfb6b662001bea3c3dabe0dc79b1c,9b5268f0a2b98af6ac6714a0013f9ccd264b1606,https://github.com/google/go-cloud/blob/2f807406236dfb6b662001bea3c3dabe0dc79b1c/samples/guestbook/aws/main.tf#L84,https://github.com/google/go-cloud/blob/9b5268f0a2b98af6ac6714a0013f9ccd264b1606/samples/guestbook/aws/main.tf#L88,2018-06-14 14:45:08-07:00,2019-07-02 13:57:39-07:00,9,0,1,1,0,1,0,0,0,0
https://github.com/kubernetes/k8s.io,132,infra/gcp/clusters/projects/kubernetes-public/aaa/k8s-infra-prow.tf,infra/gcp/terraform/kubernetes-public/k8s-infra-prow.tf,1,//todo,//TODO(ameukam): switch to allUsers when https://github.com/kubernetes/k8s.io/issues/752 is closed.,//TODO(ameukam): switch to allUsers when https://github.com/kubernetes/k8s.io/issues/752 is closed.,"resource ""google_storage_bucket_iam_member"" ""k8s_infra_prow_oncall"" {
  bucket = google_storage_bucket.k8s_infra_prow_bucket.name
  role   = ""roles/storage.objectViewer""
  //TODO(ameukam): switch to allUsers when https://github.com/kubernetes/k8s.io/issues/752 is closed.
  member = ""group:k8s-infra-prow-oncall@kubernetes.io""
}
",resource,"resource ""google_storage_bucket_iam_member"" ""k8s_infra_prow_owners"" {
  bucket = google_storage_bucket.k8s_infra_prow_bucket.name
  role   = ""roles/storage.objectViewer""
  //TODO(ameukam): switch to allUsers when https://github.com/kubernetes/k8s.io/issues/752 is closed.
  member = ""group:${local.prow_owners}""
}
",resource,82,107.0,a4f7666b489b8f409f0edc3c728946e839b70879,5e69979eb5251d9a1ad6ca6ec8856c99a5927034,https://github.com/kubernetes/k8s.io/blob/a4f7666b489b8f409f0edc3c728946e839b70879/infra/gcp/clusters/projects/kubernetes-public/aaa/k8s-infra-prow.tf#L82,https://github.com/kubernetes/k8s.io/blob/5e69979eb5251d9a1ad6ca6ec8856c99a5927034/infra/gcp/terraform/kubernetes-public/k8s-infra-prow.tf#L107,2021-06-11 23:05:47+02:00,2024-01-03 18:16:49+00:00,9,0,1,1,1,1,0,0,0,0
https://github.com/chanzuckerberg/cztack,126,snowflake-table-grant-all/main.tf,snowflake-table-grant-all/main.tf,0,hack,"// HACK(el): The way the provider works, we can only have one grant per (db, share, table, on_future, with_grant_option) grant","// HACK(el): The way the provider works, we can only have one grant per (db, share, table, on_future, with_grant_option) grant 
 //           because of this, if we simulate an ALL grant for a tuple X for role foo through this module 
 //           we couldn't then issue a SELECT grant for the same tuple X for a different role bar. 
 //           We therefore expand this module so that you can issue specific privilege grants to other roles and shares 
 //           It is a bit of a hack but probably can't do much better with the current structure of the provider (and its limitations).","resource snowflake_table_grant all {
  for_each = toset(local.privileges)

  database_name = var.database_name
  schema_name   = var.schema_name
  table_name    = var.table_name

  // HACK(el): The way the provider works, we can only have one grant per (db, share, table, on_future, with_grant_option) grant
  //           because of this, if we simulate an ALL grant for a tuple X for role foo through this module
  //           we couldn't then issue a SELECT grant for the same tuple X for a different role bar.
  //           We therefore expand this module so that you can issue specific privilege grants to other roles and shares
  //           It is a bit of a hack but probably can't do much better with the current structure of the provider (and its limitations).
  roles = setunion(
    var.roles,
    lookup(var.per_privilege_grants, each.value, { roles = [], shares = [] }).roles,
  )
  shares = setunion(
    var.shares,
    lookup(var.per_privilege_grants, each.value, { roles = [], shares = [] }).shares,
  )

  on_future         = var.on_future
  with_grant_option = var.with_grant_option

  privilege = each.value
}
",resource,,,20,0.0,fafd05ae12d4d162cb2ba2715fc61c36b14a53a7,7cebb2e1dd3a50f9ef31130f550d44a6ac273813,https://github.com/chanzuckerberg/cztack/blob/fafd05ae12d4d162cb2ba2715fc61c36b14a53a7/snowflake-table-grant-all/main.tf#L20,https://github.com/chanzuckerberg/cztack/blob/7cebb2e1dd3a50f9ef31130f550d44a6ac273813/snowflake-table-grant-all/main.tf#L0,2020-12-04 12:50:00-08:00,2020-12-10 10:30:42-08:00,2,2,1,0,1,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1056,examples/third-party-solutions/wordpress/cloudrun/variables.tf,examples/third-party-solutions/wordpress/cloudrun/variables.tf,0,# todo,# TODO: check locals,type        = string # TODO: check locals,"variable ""project_id"" {
  description = ""Project id, references existing project if `project_create` is null.""
  type        = string # TODO: check locals
}
",variable,"variable ""project_id"" {
  description = ""Project id, references existing project if `project_create` is null.""
  type        = string
}
",variable,34,,cc60ae850e4c62b900f0ce1c38beb329437ec54e,d27f09e7797bfd8567f05966646c94836ee908f2,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/cc60ae850e4c62b900f0ce1c38beb329437ec54e/examples/third-party-solutions/wordpress/cloudrun/variables.tf#L34,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/d27f09e7797bfd8567f05966646c94836ee908f2/examples/third-party-solutions/wordpress/cloudrun/variables.tf,2022-08-19 12:24:58+00:00,2022-08-31 14:19:54+00:00,2,1,0,1,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,165,examples/launch_templates_with_managed_node_groups/launchtemplate.tf,examples/launch_templates_with_managed_node_groups/launchtemplate.tf,0,xxx,// this is based on the LT that EKS would create if no custom one is specified (aws ec2 describe-launch-template-versions --launch-template-id xxx),"// this is based on the LT that EKS would create if no custom one is specified (aws ec2 describe-launch-template-versions --launch-template-id xxx) 
 // there are several more options one could set but you probably dont need to modify them 
 // you can take the default and add your custom AMI and/or custom tags 
 // 
 // Trivia: AWS transparently creates a copy of your LaunchTemplate and actually uses that copy then for the node group. If you DONT use a custom AMI, 
 // then the default user-data for bootstrapping a cluster is merged in the copy.","resource ""aws_launch_template"" ""default"" {
  name_prefix            = ""eks-example-""
  description            = ""Default Launch-Template""
  update_default_version = true

  block_device_mappings {
    device_name = ""/dev/xvda""

    ebs {
      volume_size           = 100
      volume_type           = ""gp2""
      delete_on_termination = true
      //encrypted             = true
      // enable this if you want to encrypt your node root volumes with a KMS/CMK. encryption of PVCs is handled via k8s StorageClass tho
      // you also need to attach data.aws_iam_policy_document.ebs_decryption.json from the disk_encryption_policy.tf to the KMS/CMK key then !!
      //kms_key_id            = var.kms_key_arn 
    }
  }

  instance_type = var.instance_type

  monitoring {
    enabled = true
  }

  network_interfaces {
    associate_public_ip_address = false
    delete_on_termination       = true
    security_groups             = [module.eks.worker_security_group_id]
  }

  //image_id      = var.ami_id // if you want to use a custom AMI

  // if you use a custom AMI, you need to supply via user-data, the bootstrap script as EKS DOESNT merge its managed user-data then
  // you can add more than the minimum code you see in the template, e.g. install SSM agent, see https://github.com/aws/containers-roadmap/issues/593#issuecomment-577181345
  //
  // (optionally you can use https://registry.terraform.io/providers/hashicorp/cloudinit/latest/docs/data-sources/cloudinit_config to render the script, example: https://github.com/terraform-aws-modules/terraform-aws-eks/pull/997#issuecomment-705286151)

  // user_data = base64encode(
  //   data.template_file.launch_template_userdata.rendered,
  // )


  // supplying custom tags to EKS instances is another use-case for LaunchTemplates
  tag_specifications {
    resource_type = ""instance""

    tags = {
      CustomTag = ""EKS example""
    }
  }

  // supplying custom tags to EKS instances root volumes is another use-case for LaunchTemplates. (doesnt add tags to dynamically provisioned volumes via PVC tho)
  tag_specifications {
    resource_type = ""volume""

    tags = {
      CustomTag = ""EKS example""
    }
  }

  // tag the LT itself
  tags = {
    CustomTag = ""EKS example""
  }

  lifecycle {
    create_before_destroy = true
  }
}
",resource,"resource ""aws_launch_template"" ""default"" {
  name_prefix            = ""eks-example-""
  description            = ""Default Launch-Template""
  update_default_version = true

  block_device_mappings {
    device_name = ""/dev/xvda""

    ebs {
      volume_size           = 100
      volume_type           = ""gp2""
      delete_on_termination = true
      # encrypted             = true

      # Enable this if you want to encrypt your node root volumes with a KMS/CMK. encryption of PVCs is handled via k8s StorageClass tho
      # you also need to attach data.aws_iam_policy_document.ebs_decryption.json from the disk_encryption_policy.tf to the KMS/CMK key then !!
      # kms_key_id            = var.kms_key_arn
    }
  }

  instance_type = var.instance_type

  monitoring {
    enabled = true
  }

  network_interfaces {
    associate_public_ip_address = false
    delete_on_termination       = true
    security_groups             = [module.eks.worker_security_group_id]
  }

  # if you want to use a custom AMI
  # image_id      = var.ami_id

  # If you use a custom AMI, you need to supply via user-data, the bootstrap script as EKS DOESNT merge its managed user-data then
  # you can add more than the minimum code you see in the template, e.g. install SSM agent, see https://github.com/aws/containers-roadmap/issues/593#issuecomment-577181345
  #
  # (optionally you can use https://registry.terraform.io/providers/hashicorp/cloudinit/latest/docs/data-sources/cloudinit_config to render the script, example: https://github.com/terraform-aws-modules/terraform-aws-eks/pull/997#issuecomment-705286151)

  # user_data = base64encode(
  #   data.template_file.launch_template_userdata.rendered,
  # )


  # Supplying custom tags to EKS instances is another use-case for LaunchTemplates
  tag_specifications {
    resource_type = ""instance""

    tags = {
      CustomTag = ""EKS example""
    }
  }

  # Supplying custom tags to EKS instances root volumes is another use-case for LaunchTemplates. (doesnt add tags to dynamically provisioned volumes via PVC tho)
  tag_specifications {
    resource_type = ""volume""

    tags = {
      CustomTag = ""EKS example""
    }
  }

  # Tag the LT itself
  tags = {
    CustomTag = ""EKS example""
  }

  lifecycle {
    create_before_destroy = true
  }
}
",resource,14,,127a3a883189d887eac3d0c9e91b7aa335d53b77,571e4e7f4bca0c30a6d714a4cbebb9aaaf69c88a,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/127a3a883189d887eac3d0c9e91b7aa335d53b77/examples/launch_templates_with_managed_node_groups/launchtemplate.tf#L14,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/571e4e7f4bca0c30a6d714a4cbebb9aaaf69c88a/examples/launch_templates_with_managed_node_groups/launchtemplate.tf,2020-11-02 08:19:10+01:00,2020-11-02 08:35:12+01:00,2,1,1,0,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-kubernetes-engine,7,modules/safer-cluster/main.tf,modules/safer-cluster/main.tf,0,// todo,// TODO(mmontan): we generally considered applying,"// TODO(mmontan): we generally considered applying 
 // just the cloud-platofrm scope and use Cloud IAM 
 // If we have Workload Identity, are there advantages 
 // in restricting scopes even more?","module ""gke"" {
  source             = ""../beta-private-cluster/""
  project_id         = var.project_id
  name               = var.name
  regional           = var.regional
  region             = var.region
  network            = var.network
  network_project_id = var.network_project_id

  // We need to enforce a minimum Kubernetes Version to ensure
  // that the necessary security features are enabled.
  kubernetes_version = ""latest""

  // Nodes are created with a default version. The nodepool enables
  // auto_upgrade so that the node versions can be kept up to date with
  // the master upgrades.
  //
  // https://cloud.google.com/kubernetes-engine/versioning-and-upgrades
  node_version = """"

  master_authorized_networks_config = var.master_authorized_networks_config

  subnetwork        = var.subnetwork
  ip_range_pods     = var.ip_range_pods
  ip_range_services = var.ip_range_services

  horizontal_pod_autoscaling = var.horizontal_pod_autoscaling
  http_load_balancing        = var.http_load_balancing

  // Disable the dashboard. It creates risk by running as a very sensitive user.
  kubernetes_dashboard = false

  // We suggest the use coarse network policies to enforce restrictions in the
  // communication between pods.
  //
  // NOTE: Enabling network policy is not sufficient to enforce restrictions.
  // NetworkPolicies need to be configured in every namespace. The network
  // policies should be under the control of a cental cluster management team,
  // rather than individual teams.
  network_policy          = true
  network_policy_provider = ""CALICO""

  maintenance_start_time = var.maintenance_start_time

  initial_node_count = var.initial_node_count

  // We suggest removing the default node pull, as it cannot be modified without
  // destroying the cluster.
  remove_default_node_pool = true

  disable_legacy_metadata_endpoints = true

  node_pools        = var.node_pools
  node_pools_labels = var.node_pools_labels

  // TODO(mmontan): check whether we need to restrict these
  // settings.
  node_pools_metadata = var.node_pools_metadata
  node_pools_taints   = var.node_pools_taints
  node_pools_tags     = var.node_pools_tags

  // TODO(mmontan): we generally considered applying
  // just the cloud-platofrm scope and use Cloud IAM
  // If we have Workload Identity, are there advantages
  // in restricting scopes even more?
  node_pools_oauth_scopes = var.node_pools_oauth_scopes

  stub_domains         = var.stub_domains
  upstream_nameservers = var.upstream_nameservers

  // We should use IP Alias.
  configure_ip_masq = false

  logging_service    = var.logging_service
  monitoring_service = var.monitoring_service

  // We never use the default service account for the cluster. The default
  // project/editor permissions can create problems if nodes were to be ever
  // compromised.

  // We either:
  // - Create a dedicated service account with minimal permissions to run nodes.
  //   All applications shuold run with an identity defined via Workload Identity anyway.
  // - Use a service account passed as a parameter to the module, in case the user
  //   wants to maintain control of their service accounts.
  create_service_account = length(var.compute_engine_service_account) > 0 ? false : true
  service_account        = var.compute_engine_service_account

  // TODO(mmontan): define a registry_project parameter in the private_beta_cluster,
  // so that we can give GCS permissions to the service account on a project
  // that hosts only container-images and not data.
  grant_registry_access = true

  // Basic Auth disabled
  basic_auth_username = """"
  basic_auth_password = """"

  issue_client_certificate = false

  cluster_ipv4_cidr = var.cluster_ipv4_cidr

  cluster_resource_labels = var.cluster_resource_labels

  // We enable private endpoints to limit exposure.
  enable_private_endpoint       = true
  deploy_using_private_endpoint = true

  // Private nodes better control public exposure, and reduce
  // the ability of nodes to reach to the Internet without
  // additional configurations.
  enable_private_nodes = true

  master_ipv4_cidr_block = var.master_ipv4_cidr_block

  // Istio is recommended for pod-to-pod communications.
  istio    = var.istio
  cloudrun = var.cloudrun

  default_max_pods_per_node = var.default_max_pods_per_node

  database_encryption = var.database_encryption

  // We suggest to define policies about  which images can run on a cluster.
  enable_binary_authorization = true

  // Define PodSecurityPolicies for differnet applications.
  // TODO(mmontan): link to a couple of policies.
  pod_security_policy_config = [{
    ""enabled"" = true
  }]

  resource_usage_export_dataset_id = var.resource_usage_export_dataset_id
  node_metadata                    = ""SECURE""

  // Sandbox is needed if the cluster is going to run any untrusted workload (e.g., user submitted code).
  // Sandbox can also provide increased protection in other cases, at some performance cost.
  sandbox_enabled = var.sandbox_enabled

  // TODO(mmontan): investigate whether this should be a recommended setting
  enable_intranode_visibility = var.enable_intranode_visibility

  enable_vertical_pod_autoscaling = var.enable_vertical_pod_autoscaling

  // We enable identity namespace by default.
  identity_namespace = ""${var.project_id}.svc.id.goog""

  authenticator_security_group = var.authenticator_security_group
}
",module,"module ""gke"" {
  source             = ""../beta-private-cluster/""
  project_id         = var.project_id
  name               = var.name
  regional           = var.regional
  region             = var.region
  network            = var.network
  network_project_id = var.network_project_id

  // We need to enforce a minimum Kubernetes Version to ensure
  // that the necessary security features are enabled.
  kubernetes_version = ""latest""

  // Nodes are created with a default version. The nodepool enables
  // auto_upgrade so that the node versions can be kept up to date with
  // the master upgrades.
  //
  // https://cloud.google.com/kubernetes-engine/versioning-and-upgrades
  node_version = """"

  master_authorized_networks_config = var.master_authorized_networks_config

  subnetwork        = var.subnetwork
  ip_range_pods     = var.ip_range_pods
  ip_range_services = var.ip_range_services

  horizontal_pod_autoscaling = var.horizontal_pod_autoscaling
  http_load_balancing        = var.http_load_balancing

  // We suggest the use coarse network policies to enforce restrictions in the
  // communication between pods.
  //
  // NOTE: Enabling network policy is not sufficient to enforce restrictions.
  // NetworkPolicies need to be configured in every namespace. The network
  // policies should be under the control of a cental cluster management team,
  // rather than individual teams.
  network_policy = true

  maintenance_start_time = var.maintenance_start_time

  initial_node_count = var.initial_node_count

  // We suggest removing the default node pull, as it cannot be modified without
  // destroying the cluster.
  remove_default_node_pool = true

  node_pools        = var.node_pools
  node_pools_labels = var.node_pools_labels

  // TODO(mmontan): check whether we need to restrict these
  // settings.
  node_pools_metadata = var.node_pools_metadata
  node_pools_taints   = var.node_pools_taints
  node_pools_tags     = var.node_pools_tags

  node_pools_oauth_scopes = var.node_pools_oauth_scopes

  stub_domains         = var.stub_domains
  upstream_nameservers = var.upstream_nameservers

  logging_service    = var.logging_service
  monitoring_service = var.monitoring_service

  // We never use the default service account for the cluster. The default
  // project/editor permissions can create problems if nodes were to be ever
  // compromised.

  // We either:
  // - Create a dedicated service account with minimal permissions to run nodes.
  //   All applications shuold run with an identity defined via Workload Identity anyway.
  // - Use a service account passed as a parameter to the module, in case the user
  //   wants to maintain control of their service accounts.
  create_service_account = var.compute_engine_service_account == """" ? true : false
  service_account        = var.compute_engine_service_account
  registry_project_id    = var.registry_project_id
  grant_registry_access  = true

  // Basic Auth disabled
  basic_auth_username = """"
  basic_auth_password = """"

  issue_client_certificate = false

  cluster_ipv4_cidr = var.cluster_ipv4_cidr

  cluster_resource_labels = var.cluster_resource_labels

  // We enable private endpoints to limit exposure.
  enable_private_endpoint       = true
  deploy_using_private_endpoint = true

  // Private nodes better control public exposure, and reduce
  // the ability of nodes to reach to the Internet without
  // additional configurations.
  enable_private_nodes = true

  master_ipv4_cidr_block = var.master_ipv4_cidr_block

  // Istio is recommended for pod-to-pod communications.
  istio    = var.istio
  cloudrun = var.cloudrun

  default_max_pods_per_node = var.default_max_pods_per_node

  database_encryption = var.database_encryption

  // We suggest to define policies about  which images can run on a cluster.
  enable_binary_authorization = true

  // Define PodSecurityPolicies for differnet applications.
  // Example: https://kubernetes.io/docs/concepts/policy/pod-security-policy/#example
  pod_security_policy_config = [{
    ""enabled"" = true
  }]

  resource_usage_export_dataset_id = var.resource_usage_export_dataset_id

  // Sandbox is needed if the cluster is going to run any untrusted workload (e.g., user submitted code).
  // Sandbox can also provide increased protection in other cases, at some performance cost.
  sandbox_enabled = var.sandbox_enabled

  // Intranode Visibility enables you to capture flow logs for traffic between pods and create FW rules that apply to traffic between pods.
  enable_intranode_visibility = var.enable_intranode_visibility

  enable_vertical_pod_autoscaling = var.enable_vertical_pod_autoscaling

  // We enable identity namespace by default.
  identity_namespace = ""${var.project_id}.svc.id.goog""

  authenticator_security_group = var.authenticator_security_group

  enable_shielded_nodes = var.enable_shielded_nodes
}
",module,80,,e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5,5a194719faa144ad0a7ee578663d336358f5073c,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5/modules/safer-cluster/main.tf#L80,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/5a194719faa144ad0a7ee578663d336358f5073c/modules/safer-cluster/main.tf,2019-10-04 15:21:33-07:00,2019-11-13 15:10:12-06:00,6,1,1,1,0,1,0,0,0,0
https://github.com/Worklytics/psoxy,204,infra/modules/psoxy-package/main.tf,infra/modules/psoxy-package/main.tf,0,implementation,# can't build implementation package to deploy until core pkg is built and installed to local mvn repo,# can't build implementation package to deploy until core pkg is built and installed to local mvn repo,"resource ""null_resource"" ""deployment_package"" {
  triggers = {
    pom_hash = filebase64sha256(""${local.path_to_impl_module}/pom.xml"")
  }

  provisioner ""local-exec"" {
    working_dir = local.path_to_impl_module
    command     = ""mvn package""
  }

  # can't build implementation package to deploy until core pkg is built and installed to local mvn repo
  depends_on = [
    null_resource.core_package
  ]
}
",resource,the block associated got renamed or deleted,,34,,450629d23c2f1ec4eb34e057d6d2c3ae5215abf2,d30ea8e93bb4e9b7f7eb27dfada16817ee3541f0,https://github.com/Worklytics/psoxy/blob/450629d23c2f1ec4eb34e057d6d2c3ae5215abf2/infra/modules/psoxy-package/main.tf#L34,https://github.com/Worklytics/psoxy/blob/d30ea8e93bb4e9b7f7eb27dfada16817ee3541f0/infra/modules/psoxy-package/main.tf,2022-01-19 08:22:58-08:00,2022-01-19 10:55:08-08:00,2,1,0,1,0,0,0,1,0,0
https://github.com/Worklytics/psoxy,505,infra/modules/gcp-psoxy-rest/main.tf,infra/modules/gcp-psoxy-rest/main.tf,0,# todo,"# TODO: Support version, by default now is latest","# TODO: Support version, by default now is latest","resource ""google_cloudfunctions_function"" ""function"" {
  name        = var.instance_id
  description = ""Psoxy Connector - ${var.source_kind}""
  runtime     = ""java11""
  project     = var.project_id
  region      = var.region

  available_memory_mb   = 1024
  source_archive_bucket = var.artifacts_bucket_name
  source_archive_object = var.deployment_bundle_object_name
  entry_point           = ""co.worklytics.psoxy.Route""
  service_account_email = var.service_account_email

  environment_variables = merge(
    var.path_to_config == null ? {} : yamldecode(file(var.path_to_config)),
    var.environment_variables
  )

  dynamic ""secret_environment_variables"" {
    for_each = local.secret_bindings
    iterator = secret_environment_variable

    content {
      key        = secret_environment_variable.key
      project_id = data.google_project.project.number
      secret     = secret_environment_variable.value.secret_id
      version    = secret_environment_variable.value.version_number
    }
  }

  dynamic ""secret_volumes"" {
    for_each = var.secret_volumes
    iterator = secret_volume

    content {
      project_id = data.google_project.project.number
      secret     = secret_volume.value.secret_id
      mount_path = ""/etc/secrets/${secret_volume.key}""

      # TODO: Support version, by default now is latest
    }
  }

  trigger_http = true

  lifecycle {
    ignore_changes = [
      labels
    ]
  }

  depends_on = [
    google_secret_manager_secret_iam_member.grant_sa_accessor_on_secret
  ]
}
",resource,"resource ""google_cloudfunctions_function"" ""function"" {
  name        = var.instance_id
  description = ""Psoxy Connector - ${var.source_kind}""
  runtime     = ""java11""
  project     = var.project_id
  region      = var.region

  available_memory_mb   = 1024
  source_archive_bucket = var.artifacts_bucket_name
  source_archive_object = var.deployment_bundle_object_name
  entry_point           = ""co.worklytics.psoxy.Route""
  service_account_email = var.service_account_email

  environment_variables = merge(
    var.path_to_config == null ? {} : yamldecode(file(var.path_to_config)),
    var.environment_variables
  )

  dynamic ""secret_environment_variables"" {
    for_each = local.secret_bindings
    iterator = secret_environment_variable

    content {
      key        = secret_environment_variable.key
      project_id = data.google_project.project.number
      secret     = secret_environment_variable.value.secret_id
      version    = secret_environment_variable.value.version_number
    }
  }

  trigger_http = true

  lifecycle {
    ignore_changes = [
      labels
    ]
  }

  depends_on = [
    google_secret_manager_secret_iam_member.grant_sa_accessor_on_secret
  ]
}
",resource,73,,5c45b21ff779761f52696850549448cfca58f601,454c610080da3d260517b8aa102bf2de5411189c,https://github.com/Worklytics/psoxy/blob/5c45b21ff779761f52696850549448cfca58f601/infra/modules/gcp-psoxy-rest/main.tf#L73,https://github.com/Worklytics/psoxy/blob/454c610080da3d260517b8aa102bf2de5411189c/infra/modules/gcp-psoxy-rest/main.tf,2022-11-09 21:46:45+01:00,2022-11-10 21:14:03+01:00,2,1,1,1,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,408,examples/karpenter/main.tf,examples/karpenter/main.tf,0,workaround,# Workaround - https://github.com/hashicorp/terraform-provider-kubernetes/issues/1380#issuecomment-967022975,# Workaround - https://github.com/hashicorp/terraform-provider-kubernetes/issues/1380#issuecomment-967022975,"resource ""kubectl_manifest"" ""karpenter_provisioner"" {
  yaml_body = <<-YAML
  apiVersion: karpenter.sh/v1alpha5
  kind: Provisioner
  metadata:
    name: default
  spec:
    requirements:
      - key: karpenter.sh/capacity-type
        operator: In
        values: [""spot""]
    limits:
      resources:
        cpu: 1000
    provider:
      subnetSelector:
        karpenter.sh/discovery: ${local.name}
      securityGroupSelector:
        karpenter.sh/discovery: ${local.name}
      tags:
        karpenter.sh/discovery: ${local.name}
    ttlSecondsAfterEmpty: 30
  YAML

  depends_on = [
    helm_release.karpenter
  ]
}
",resource,"resource ""kubectl_manifest"" ""karpenter_provisioner"" {
  yaml_body = <<-YAML
    apiVersion: karpenter.sh/v1alpha5
    kind: Provisioner
    metadata:
      name: default
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: [""spot""]
      limits:
        resources:
          cpu: 1000
      providerRef:
        name: default
      ttlSecondsAfterEmpty: 30
  YAML

  depends_on = [
    helm_release.karpenter
  ]
}
",resource,154,,3ff17205a4ead51cca993547ef3de42cc080043b,f24de3326d3c12ce61fbaefe1e3dbe7418d8bc85,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/3ff17205a4ead51cca993547ef3de42cc080043b/examples/karpenter/main.tf#L154,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/f24de3326d3c12ce61fbaefe1e3dbe7418d8bc85/examples/karpenter/main.tf,2022-04-07 20:47:22+02:00,2022-11-21 13:50:34-05:00,4,1,1,0,1,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1598,fast/stages-multitenant/0-bootstrap-tenant/organization.tf,fast/stages-multitenant/0-bootstrap-tenant/organization.tf,0,# todo,# TODO: use tag IAM with id in the organization module,# TODO: use tag IAM with id in the organization module,"resource ""google_tags_tag_value_iam_member"" ""resman_tag_user"" {
  for_each  = var.tag_values
  tag_value = each.value
  role      = ""roles/resourcemanager.tagUser""
  member    = module.automation-tf-resman-sa.iam_email
}
",resource,,,79,0.0,819894d2bab4b440f1b52b1ac8035912fb107004,7a5dd4e6db197daa52da8a8d877ce86b5c93182e,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/819894d2bab4b440f1b52b1ac8035912fb107004/fast/stages-multitenant/0-bootstrap-tenant/organization.tf#L79,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/7a5dd4e6db197daa52da8a8d877ce86b5c93182e/fast/stages-multitenant/0-bootstrap-tenant/organization.tf#L0,2023-08-20 09:44:20+02:00,2024-05-15 09:17:13+00:00,3,2,0,1,0,1,0,0,0,0
https://github.com/Worklytics/psoxy,230,infra/modules/azuread-grant-all-users/main.tf,infra/modules/azuread-grant-all-users/main.tf,0,todo,"# TODO: if grant can be made fully through API, do it here; until then, TODO file is best option","# TODO: if grant can be made fully through API, do it here; until then, TODO file is best option  
 # NOTE: using `azuread_service_principal_delegated_permission_grant` seems to NOT work for this, 
 # presumably it ONLY supports oauth scopes (delegated permissions) not application roles 
 # (application permissions) 
 # however, even using it JUST for delegated permissions seems to create an inconsistency when user 
 # manually grants the application permissions (resource seems to really create a 'delegated_permission_grant' 
 # entity in Azure, which is overwritten by the user and then missing on subsequent terraform runs) ","resource ""local_file"" ""todo"" {
  filename = ""TODO ${var.application_name}.md""

  content = <<EOT
# Authorize ${var.application_name}

Visit the following page in the Azure AD console and grant the required application permissions:

https://portal.azure.com/#blade/Microsoft_AAD_RegisteredApps/ApplicationMenuBlade/CallAnAPI/appId/${var.application_id}/isMSAApp/

If you are not a sufficiently privileged Azure AD Administrator (likely Application or Global
Administrator), you made need assistance from an appropriately privileged member of your IT team.

The required grants are:
```
${join(""\n"", concat(var.app_roles, var.oauth2_permission_scopes))}
```

EOT
}
",resource,"locals {
  instance_id  = coalesce(var.psoxy_instance_id, var.application_name)
  todo_content = <<EOT
# Authorize ${var.application_name}

Visit the following page in the Azure AD console and grant the required application permissions:

https://portal.azure.com/#blade/Microsoft_AAD_RegisteredApps/ApplicationMenuBlade/CallAnAPI/appId/${var.application_id}/isMSAApp/

If you are not a sufficiently privileged Azure AD Administrator (likely Application or Global
Administrator), you may need assistance from an appropriately privileged member of your IT team.

The required grants are:
```
${join(""\n"", concat(var.app_roles, var.oauth2_permission_scopes))}
```

EOT
}
",locals,13,5.0,e60f54ba57c150249298c3fcf1af52e6a2ea06ee,ce24a85e38bd513c005f315db934b61c950962a6,https://github.com/Worklytics/psoxy/blob/e60f54ba57c150249298c3fcf1af52e6a2ea06ee/infra/modules/azuread-grant-all-users/main.tf#L13,https://github.com/Worklytics/psoxy/blob/ce24a85e38bd513c005f315db934b61c950962a6/infra/modules/azuread-grant-all-users/main.tf#L5,2022-01-27 21:03:35-08:00,2024-04-17 08:37:10-07:00,10,0,0,1,0,1,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,639,modules/_user_data/main.tf,modules/_user_data/main.tf,0,todo,# TODO - platform will be removed in v21.0 and only `ami_type` will be valid,"# Converts AMI type into user data type that represents the underlying format (bash, toml, PS1, nodeadm) 
 # TODO - platform will be removed in v21.0 and only `ami_type` will be valid","locals {
  # Converts AMI type into user data type that represents the underlying format (bash, toml, PS1, nodeadm)
  # TODO - platform will be removed in v21.0 and only `ami_type` will be valid
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  template_path = {
    al2023       = ""${path.module}/../../templates/al2023_user_data.tpl""
    bottlerocket = ""${path.module}/../../templates/bottlerocket_user_data.tpl""
    linux        = ""${path.module}/../../templates/linux_user_data.tpl""
    windows      = ""${path.module}/../../templates/windows_user_data.tpl""
  }

  cluster_service_cidr = try(coalesce(var.cluster_service_ipv4_cidr, var.cluster_service_cidr), """")

  user_data = base64encode(templatefile(
    coalesce(var.user_data_template_path, local.template_path[local.user_data_type]),
    {
      # https://docs.aws.amazon.com/eks/latest/userguide/launch-templates.html#launch-template-custom-ami
      enable_bootstrap_user_data = var.enable_bootstrap_user_data

      # Required to bootstrap node
      cluster_name        = var.cluster_name
      cluster_endpoint    = var.cluster_endpoint
      cluster_auth_base64 = var.cluster_auth_base64

      cluster_service_cidr = local.cluster_service_cidr
      cluster_ip_family    = var.cluster_ip_family
      # Bottlerocket
      cluster_dns_ip = try(cidrhost(local.cluster_service_cidr, 10), """")

      # Optional
      bootstrap_extra_args     = var.bootstrap_extra_args
      pre_bootstrap_user_data  = var.pre_bootstrap_user_data
      post_bootstrap_user_data = var.post_bootstrap_user_data
    }
  ))

  user_data_type_to_rendered = {
    al2023 = {
      user_data = var.create ? try(data.cloudinit_config.al2023_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    bottlerocket = {
      user_data = var.create && local.user_data_type == ""bottlerocket"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.bootstrap_extra_args != """") ? local.user_data : """"
    }
    linux = {
      user_data = var.create ? try(data.cloudinit_config.linux_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    windows = {
      user_data = var.create && local.user_data_type == ""windows"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.pre_bootstrap_user_data != """") ? local.user_data : """"
    }
  }
}
",locals,"locals {
  # Converts AMI type into user data type that represents the underlying format (bash, toml, PS1, nodeadm)
  # TODO - platform will be removed in v21.0 and only `ami_type` will be valid
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  template_path = {
    al2023       = ""${path.module}/../../templates/al2023_user_data.tpl""
    bottlerocket = ""${path.module}/../../templates/bottlerocket_user_data.tpl""
    linux        = ""${path.module}/../../templates/linux_user_data.tpl""
    windows      = ""${path.module}/../../templates/windows_user_data.tpl""
  }

  cluster_service_cidr = try(coalesce(var.cluster_service_ipv4_cidr, var.cluster_service_cidr), """")

  user_data = base64encode(templatefile(
    coalesce(var.user_data_template_path, local.template_path[local.user_data_type]),
    {
      # https://docs.aws.amazon.com/eks/latest/userguide/launch-templates.html#launch-template-custom-ami
      enable_bootstrap_user_data = var.enable_bootstrap_user_data

      # Required to bootstrap node
      cluster_name        = var.cluster_name
      cluster_endpoint    = var.cluster_endpoint
      cluster_auth_base64 = var.cluster_auth_base64

      cluster_service_cidr = local.cluster_service_cidr
      cluster_ip_family    = var.cluster_ip_family
      # Bottlerocket
      cluster_dns_ip = try(cidrhost(local.cluster_service_cidr, 10), """")

      # Optional
      bootstrap_extra_args     = var.bootstrap_extra_args
      pre_bootstrap_user_data  = var.pre_bootstrap_user_data
      post_bootstrap_user_data = var.post_bootstrap_user_data
    }
  ))

  user_data_type_to_rendered = {
    al2023 = {
      user_data = var.create ? try(data.cloudinit_config.al2023_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    bottlerocket = {
      user_data = var.create && local.user_data_type == ""bottlerocket"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.bootstrap_extra_args != """") ? local.user_data : """"
    }
    linux = {
      user_data = var.create ? try(data.cloudinit_config.linux_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    windows = {
      user_data = var.create && local.user_data_type == ""windows"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.pre_bootstrap_user_data != """") ? local.user_data : """"
    }
  }
}
",locals,18,18.0,74d39187d855932dd976da6180eda42dcfe09873,74d39187d855932dd976da6180eda42dcfe09873,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/_user_data/main.tf#L18,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/_user_data/main.tf#L18,2024-05-08 08:04:19-04:00,2024-05-08 08:04:19-04:00,1,0,0,1,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-bigquery,3,main.tf,main.tf,0,#todo,#TODO: Need to find a way to dynamically assign a dict object(s),#TODO: Need to find a way to dynamically assign a dict object(s),"resource ""google_bigquery_dataset"" ""default"" {
  dataset_id                  = ""${var.dataset_id}""
  friendly_name               = ""${var.dataset_name}""
  description                 = ""${var.description}""
  #TODO: add if condition to validate if neither US or EU are supplied
  location                    = ""${var.region}""
  #TODO: format this ne excluded by default but can optionally be defined if the user wishes
  default_table_expiration_ms = ""${var.expiration}""
  project                     = ""${var.project_id}""

  #TODO: Need to find a way to dynamically assign a dict object(s)
  labels {
    env = ""default""
    foo = ""bar""
    tonyd = ""tonyd""
  }

  //TODO: array of users or groups needs to be added to have access. Need to figure out the best method of customers to allocate users or groups.
  # access {
  #   role   = ""READER""
  #   domain = ""adigangi.com""
  # }
  #
  # access {
  #   role           = ""WRITER""
  #   user_by_email = ""adigangi@adigangi.com""
  # }
  #
  # access {
  #   role           = ""OWNER""
  #   special_group  = ""projectOwners""
  # }
}
",resource,the block associated got renamed or deleted,,32,,d56aa2c9a80343d60eed3e1a7d24962be31ee0b6,7f922f7e9df197df38c9b09dfa6e3614d71f19f5,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/d56aa2c9a80343d60eed3e1a7d24962be31ee0b6/main.tf#L32,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/7f922f7e9df197df38c9b09dfa6e3614d71f19f5/main.tf,2018-11-20 10:30:15-05:00,2019-01-16 18:10:54-05:00,3,1,1,1,0,0,0,0,0,0
https://github.com/Worklytics/psoxy,94,infra/modules/aws-psoxy-instance/main.tf,infra/modules/aws-psoxy-instance/main.tf,0,#todo,#TODO: verify that it's also going to pass through GET??,"integration_method        = ""POST"" #TODO: verify that it's also going to pass through GET?? 
 #TODO: match on subpath equivalent to var.function_name","resource ""aws_apigatewayv2_integration"" ""map"" {
  api_id                    = var.api_gateway.id
  integration_type          = ""AWS_PROXY""
  connection_type           = ""INTERNET""

  integration_method        = ""POST"" #TODO: verify that it's also going to pass through GET??
  #TODO: match on subpath equivalent to var.function_name
  integration_uri           = aws_lambda_function.psoxy-instance.invoke_arn
}
",resource,"resource ""aws_apigatewayv2_integration"" ""map"" {
  api_id                    = var.api_gateway.id
  integration_type          = ""AWS_PROXY""
  connection_type           = ""INTERNET""

  #TODO: match on subpath equivalent to var.function_name ?

  integration_method        = ""POST""
  integration_uri           = aws_lambda_function.psoxy-instance.invoke_arn
  request_parameters        = {}
  request_templates         = {}
}
",resource,19,,10047f65e7f6a188f52736d1178dd326651a0662,7444d0de8dc052089b9c9dc91394cf5172660cdd,https://github.com/Worklytics/psoxy/blob/10047f65e7f6a188f52736d1178dd326651a0662/infra/modules/aws-psoxy-instance/main.tf#L19,https://github.com/Worklytics/psoxy/blob/7444d0de8dc052089b9c9dc91394cf5172660cdd/infra/modules/aws-psoxy-instance/main.tf,2022-01-06 11:38:28-08:00,2022-01-06 11:41:26-08:00,2,1,1,1,0,0,1,0,0,0
https://github.com/CDCgov/prime-simplereport,95,ops/services/web_application_firewall/main.tf,ops/services/web_application_firewall/main.tf,0,//todo,//TODO: add exception for whoami,"rule_group_name = ""REQUEST-932-APPLICATION-ATTACK-RCE"" //TODO: add exception for whoami","resource ""azurerm_web_application_firewall_policy"" ""sr_waf_policy"" {
  name                = ""${var.name}-wafpolicy""
  resource_group_name = var.resource_group_name
  location            = var.resource_group_location

  custom_rules {
    name      = ""Block_Sanctioned_Entities""
    priority  = 1
    rule_type = ""MatchRule""

    match_conditions {
      match_variables {
        variable_name = ""RemoteAddr""
      }
      operator           = ""GeoMatch""
      negation_condition = false
      match_values = [
        ""AF"", //Afghanistan (ITAR)
        ""AL"", //Albania (OFAC)
        ""BA"", //Bosnia and Herzegovinia (OFAC)
        ""BG"", //Bulgaria (OFAC)
        ""BY"", //Belarus (ITAR, OFAC)
        ""CD"", //Democratic Republic of the Congo (ITAR)
        ""CF"", //Central African Republic (ITAR, OFAC)
        ""CG"", //Congo (ITAR, OFAC)
        ""CI"", //C��te d'Ivoire (ITAR)
        ""CN"", //People's Republic of China (EAR, ITAR)
        ""CU"", //Cuba (EAR, ITAR, OFAC)
        ""CY"", //Cyprus (ITAR)
        ""ER"", //Eritrea (ITAR)
        ""ET"", //Ethiopia (ITAR-adjacent, due to ongoing conflict with Eritrea)
        ""GE"", //Georgia (preemptive, due to presence of separatist regions sympathetic to Russian Federation)
        ""HK"", //Hong Kong SAR (due to oversight by People's Republic of China)
        ""HR"", //Croatia (OFAC)
        ""HT"", //Haiti (ITAR)
        ""IQ"", //Iraq (EAR, ITAR, OFAC)
        ""IR"", //Iran, Islamic Republic of (EAR, ITAR, OFAC)
        ""KP"", //Korea, Democratic People's Republic of (EAR, ITAR, OFAC)
        ""LB"", //Lebanon (ITAR, OFAC)
        ""LK"", //Sri Lanka (ITAR)
        ""LR"", //Liberia (ITAR, OFAC)
        ""LY"", //Libya (ITAR, OFAC)
        ""MD"", //Moldova, Republic of (preemptive, due to presence of separatist regions sympathetic to Russian Federation)
        ""ME"", //Montenegro (OFAC)
        ""MK"", //North Macedonia (OFAC)
        ""MM"", //Myanmar (ITAR)
        ""MO"", //Macao SAR (due to oversight by People's Republic of China)
        ""NI"", //Nicaragua (preemptive, due to association with sanctioned entities)
        ""RS"", //Serbia (OFAC)
        ""RU"", //Russian Federation (EAR, OFAC)
        ""SO"", //Somalia (ITAR, OFAC)
        ""SY"", //Syrian Arab Republic (EAR, ITAR, OFAC)
        ""UA"", //Ukraine (OFAC, due to occupation by the Russian Federation)
        ""VE"", //Venezuela (EAR, ITAR, OFAC)
        ""VN"", //Vietnam (ITAR)
        ""XK"", //Kosovo (OFAC)
        ""YE"", //Yemen (OFAC)
        ""ZW""  //Zimbabwe (ITAR)
      ]
    }
    action = ""Block""
  }

  managed_rules {
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""ai_session""
      selector_match_operator = ""StartsWith""
    }
    managed_rule_set {
      type    = ""OWASP""
      version = ""3.2""

      rule_group_override {
        rule_group_name = ""REQUEST-942-APPLICATION-ATTACK-SQLI""
        disabled_rules = [
          ""942430"",
          ""942260"",
          ""942200""
        ]
      }

      rule_group_override {
        rule_group_name = ""REQUEST-932-APPLICATION-ATTACK-RCE"" //TODO: add exception for whoami
        disabled_rules = [
          ""932100"",
          ""932105"",
          ""932115""
        ]
      }
    }
  }

  policy_settings {
    enabled                     = true
    mode                        = ""Detection"" //Can use ""Detection"" for testing, to see which requests would be blocked. ""Prevention"" turns on active blocking.
    request_body_check          = true
    file_upload_limit_in_mb     = 100
    max_request_body_size_in_kb = 128 //Can go to 2000 in modern provider version. Proposed is 1024.
  }
}",resource,"resource ""azurerm_web_application_firewall_policy"" ""sr_waf_policy"" {
  name                = ""${var.name}-wafpolicy""
  resource_group_name = var.resource_group_name
  location            = var.resource_group_location

  custom_rules {
    name      = ""Block_Sanctioned_Entities""
    priority  = 1
    rule_type = ""MatchRule""

    match_conditions {
      match_variables {
        variable_name = ""RemoteAddr""
      }
      operator           = ""GeoMatch""
      negation_condition = false
      match_values = [
        ""AF"", //Afghanistan (ITAR)
        ""AL"", //Albania (OFAC)
        ""BA"", //Bosnia and Herzegovinia (OFAC)
        ""BG"", //Bulgaria (OFAC)
        ""BY"", //Belarus (ITAR, OFAC)
        ""CD"", //Democratic Republic of the Congo (ITAR)
        ""CF"", //Central African Republic (ITAR, OFAC)
        ""CG"", //Congo (ITAR, OFAC)
        ""CI"", //C��te d'Ivoire (ITAR)
        ""CN"", //People's Republic of China (EAR, ITAR)
        ""CU"", //Cuba (EAR, ITAR, OFAC)
        ""CY"", //Cyprus (ITAR)
        ""ER"", //Eritrea (ITAR)
        ""ET"", //Ethiopia (ITAR-adjacent, due to ongoing conflict with Eritrea)
        ""GE"", //Georgia (preemptive, due to presence of separatist regions sympathetic to Russian Federation)
        ""HK"", //Hong Kong SAR (due to oversight by People's Republic of China)
        ""HR"", //Croatia (OFAC)
        ""HT"", //Haiti (ITAR)
        ""IQ"", //Iraq (EAR, ITAR, OFAC)
        ""IR"", //Iran, Islamic Republic of (EAR, ITAR, OFAC)
        ""KP"", //Korea, Democratic People's Republic of (EAR, ITAR, OFAC)
        ""LB"", //Lebanon (ITAR, OFAC)
        ""LK"", //Sri Lanka (ITAR)
        ""LR"", //Liberia (ITAR, OFAC)
        ""LY"", //Libya (ITAR, OFAC)
        ""MD"", //Moldova, Republic of (preemptive, due to presence of separatist regions sympathetic to Russian Federation)
        ""ME"", //Montenegro (OFAC)
        ""MK"", //North Macedonia (OFAC)
        ""MM"", //Myanmar (ITAR)
        ""MO"", //Macao SAR (due to oversight by People's Republic of China)
        ""NI"", //Nicaragua (preemptive, due to association with sanctioned entities)
        ""RS"", //Serbia (OFAC)
        ""RU"", //Russian Federation (EAR, OFAC)
        ""SO"", //Somalia (ITAR, OFAC)
        ""SY"", //Syrian Arab Republic (EAR, ITAR, OFAC)
        ""UA"", //Ukraine (OFAC, due to occupation by the Russian Federation)
        ""VE"", //Venezuela (EAR, ITAR, OFAC)
        ""VN"", //Vietnam (ITAR)
        ""XK"", //Kosovo (OFAC)
        ""YE"", //Yemen (OFAC)
        ""ZW""  //Zimbabwe (ITAR)
      ]
    }
    action = ""Block""
  }

  managed_rules {

    /*
     * Exclusions for specific request components.
     * Azure supports three specific values for match_variable:
     *  - RequestArgNames
     *  - RequestCookieNames
     *  - RequestHeaderNames
     */
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""ai_session"" //Part of Azure Application Insights
      selector_match_operator = ""StartsWith""
    }
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""ai_user"" //Part of Azure Application Insights
      selector_match_operator = ""StartsWith""
    }
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""iss""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""ssm_au""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestCookieNames""
      selector                = ""ssm_au_c""
      selector_match_operator = ""Equals""
    }

    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""iss""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.testResultList""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.namePrefixMatch""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.street""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.orderingProviderStreet""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""operations""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""map""
      selector_match_operator = ""Equals""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""phoneNumbers.number""
      selector_match_operator = ""Contains""
    }
    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.model""
      selector_match_operator = ""Equals""
    }

    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""query""
      selector_match_operator = ""Equals""
    }

    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""visualization_settings""
      selector_match_operator = ""Equals""
    }

    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""query.filters""
      selector_match_operator = ""Contains""
    }

    exclusion {
      match_variable          = ""RequestArgNames""
      selector                = ""variables.email""
      selector_match_operator = ""Contains""
    }

    managed_rule_set {
      type    = ""OWASP""
      version = ""3.2""

      /*
       * Each rule group in the OWASP ruleset can be overridden. These blocks contain a list of
       * rules within each specific group that we've chosen to override, due to how the application
       * is structured.
       *
       * These rules should be periodically reviewed for relevance.
       */
      rule_group_override {
        rule_group_name = ""REQUEST-920-PROTOCOL-ENFORCEMENT""
        dynamic ""rule"" {
          for_each = [
            ""920300"",
            ""920320""
          ]
          content {
            id      = rule.value
            enabled = false
          }
        }
      }

      rule_group_override {
        rule_group_name = ""REQUEST-932-APPLICATION-ATTACK-RCE""
        dynamic ""rule"" {
          for_each = [
            ""932100"",
            ""932105"",
            ""932115""
          ]
          content {
            id      = rule.value
            enabled = false
          }
        }
      }

      rule_group_override {
        rule_group_name = ""REQUEST-942-APPLICATION-ATTACK-SQLI""
        dynamic ""rule"" {
          for_each = [
            ""942110"",
            ""942150"",
            ""942190"",
            ""942200"",
            ""942260"",
            ""942330"",
            ""942361"",
            ""942370"",
            ""942410"",
            ""942430"",
            ""942440""
          ]
          content {
            id      = rule.value
            enabled = false
          }
        }
      }
    }
  }

  policy_settings {
    enabled                     = true
    mode                        = ""Prevention"" //Can use ""Detection"" for testing, to see which requests would be blocked. ""Prevention"" turns on active blocking.
    request_body_check          = true
    file_upload_limit_in_mb     = 100
    max_request_body_size_in_kb = 128 //Can go to 2000 in modern provider version. Proposed is 1024.
  }
}",resource,84,,1b6d28d585168f92bb42a25b50549d825f1fbb7f,331706d3af8e41e76113d6e6f72ee5ae0a862a9b,https://github.com/CDCgov/prime-simplereport/blob/1b6d28d585168f92bb42a25b50549d825f1fbb7f/ops/services/web_application_firewall/main.tf#L84,https://github.com/CDCgov/prime-simplereport/blob/331706d3af8e41e76113d6e6f72ee5ae0a862a9b/ops/services/web_application_firewall/main.tf,2022-05-09 14:43:05-05:00,2023-05-18 08:54:04-07:00,12,1,0,1,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,128,terraform/projects/app-logs-elasticsearch/main.tf,terraform/projects/app-logs-elasticsearch/main.tf,0,# todo,# TODO: Instance 2 and 3,# TODO: Instance 2 and 3,"resource ""aws_iam_policy"" ""logs_elasticsearch_iam_policy"" {
  name   = ""${var.stackname}-logs-elasticsearch-additional""
  path   = ""/""
  policy = ""${file(""${path.module}/additional_policy.json"")}""
}
",resource,"resource ""aws_iam_policy"" ""logs_elasticsearch_iam_policy"" {
  name   = ""${var.stackname}-logs-elasticsearch-additional""
  path   = ""/""
  policy = ""${file(""${path.module}/additional_policy.json"")}""
}
",resource,143,,feace08700bf50ef4a40578685362bb1cc004190,06852b4e39e5c4f33e658b99ebee182ea59a55ad,https://github.com/alphagov/govuk-aws/blob/feace08700bf50ef4a40578685362bb1cc004190/terraform/projects/app-logs-elasticsearch/main.tf#L143,https://github.com/alphagov/govuk-aws/blob/06852b4e39e5c4f33e658b99ebee182ea59a55ad/terraform/projects/app-logs-elasticsearch/main.tf,2017-07-20 12:48:33+01:00,2017-07-26 18:30:00+01:00,3,1,0,0,0,1,0,0,0,0
https://github.com/chanzuckerberg/cztack,168,databricks-cluster-log-permissions/main.tf,databricks-cluster-log-permissions/main.tf,0,hack,# hacky way to validate if this workspace/cluster should have read permissions,"# hacky way to validate if this workspace/cluster should have read permissions 
 # tflint-ignore: terraform_unused_declarations","locals {
  default_role_name    = ""cluster_log_cluster_role"" # standard role for clusters - allows both writing and reading cluster logs for only the same workspace
  read_write_role_name = ""cluster_log_rw_role""      # special role - allows both writing and reading cluster logs for all workspaces
  path                 = ""/databricks/""

  # hacky way to validate if this workspace/cluster should have read permissions
  # tflint-ignore: terraform_unused_declarations
  validate_add_reader = (var.add_reader == true && var.env != var.global_reader_env) ? tobool(""add_reader is not supported for this environment"") : true

  databricks_bucket_cluster_log_prefix = ""cluster-logs""

  # kms grants - all roles can read and write
  read_write_operations = [""Encrypt"", ""GenerateDataKey"", ""Decrypt""]
}
",locals,"locals {
  default_role_name    = ""cluster_log_cluster_role"" # standard role for clusters - allows both writing and reading cluster logs for only the same workspace
  read_write_role_name = ""cluster_log_rw_role""      # special role - allows both writing and reading cluster logs for all workspaces
  path                 = ""/databricks/""

  # hacky way to validate if this workspace/cluster should have read permissions
  # tflint-ignore: terraform_unused_declarations
  validate_add_reader = (var.add_reader == true && var.env != var.global_reader_env) ? tobool(""add_reader is not supported for this environment"") : true

  databricks_bucket_cluster_log_prefix = ""cluster-logs""

  # kms grants - all roles can read and write
  read_write_operations = [""Encrypt"", ""GenerateDataKey"", ""Decrypt""]
}
",locals,10,10.0,2e5974a61defa36d339a1a28ce7c90a17bd22685,2e5974a61defa36d339a1a28ce7c90a17bd22685,https://github.com/chanzuckerberg/cztack/blob/2e5974a61defa36d339a1a28ce7c90a17bd22685/databricks-cluster-log-permissions/main.tf#L10,https://github.com/chanzuckerberg/cztack/blob/2e5974a61defa36d339a1a28ce7c90a17bd22685/databricks-cluster-log-permissions/main.tf#L10,2023-10-31 13:12:50-07:00,2023-10-31 13:12:50-07:00,1,0,0,0,0,1,0,0,0,1
https://github.com/Azure/sap-automation,15,deploy/terraform/terraform-units/modules/sap_landscape/iscsi.tf,deploy/terraform/terraform-units/modules/sap_landscape/iscsi.tf,0,// todo,// TODO: Add nsr to iSCSI's nsg,"// TODO: Add nsr to iSCSI's nsg  
 /* 
 iSCSI device IP address range: .4 - 
 */ 
 // Creates the NIC and IP address for iSCSI device","resource ""azurerm_network_interface"" ""iscsi"" {
  provider            = azurerm.main
  count               = local.iscsi_count
  name                = format(""%s%s%s%s"", local.prefix, var.naming.separator, local.virtualmachine_names[count.index], local.resource_suffixes.nic)
  location            = local.rg_exists ? data.azurerm_resource_group.resource_group[0].location : azurerm_resource_group.resource_group[0].location
  resource_group_name = local.rg_exists ? data.azurerm_resource_group.resource_group[0].name : azurerm_resource_group.resource_group[0].name

  ip_configuration {
    name                          = ""ipconfig1""
    subnet_id                     = local.sub_iscsi_exists ? data.azurerm_subnet.iscsi[0].id : azurerm_subnet.iscsi[0].id
    private_ip_address            = local.use_DHCP ? null : local.sub_iscsi_exists ? local.iscsi_nic_ips[count.index] : cidrhost(local.sub_iscsi_prefix, tonumber(count.index) + 4)
    private_ip_address_allocation = local.use_DHCP ? ""Dynamic"" : ""static""
  }
}
",resource,"resource ""azurerm_network_interface"" ""iscsi"" {
  provider                             = azurerm.main
  count                                = local.iscsi_count
  name                                 = format(""%s%s%s%s%s"",
                                           var.naming.resource_prefixes.nic,
                                           local.prefix,
                                           var.naming.separator,
                                           local.virtualmachine_names[count.index],
                                           local.resource_suffixes.nic
                                         )
  resource_group_name                  = local.resource_group_exists ? (
                                           data.azurerm_resource_group.resource_group[0].name) : (
                                           azurerm_resource_group.resource_group[0].name
                                         )
  location                             = local.resource_group_exists ? (
                                          data.azurerm_resource_group.resource_group[0].location) : (
                                          azurerm_resource_group.resource_group[0].location
                                        )
  tags                                 = var.tags

  ip_configuration {
                     name = ""ipconfig1""
                     subnet_id = local.sub_iscsi_exists ? (
                       data.azurerm_subnet.iscsi[0].id) : (
                       azurerm_subnet.iscsi[0].id
                     )
                     private_ip_address = local.use_DHCP ? (
                       null) : (
                       local.sub_iscsi_exists ? (
                         local.iscsi_nic_ips[count.index]) : (
                         cidrhost(local.sub_iscsi_prefix, tonumber(count.index) + 4)
                       )
                     )
                     private_ip_address_allocation = local.use_DHCP ? ""Dynamic"" : ""Static""
                   }
}
",resource,46,62.0,6ff0b891114c36d3aeccb850d830b698cd1fe52a,df063c58945a9efa2cb2ba303762c43f0b9c1d8f,https://github.com/Azure/sap-automation/blob/6ff0b891114c36d3aeccb850d830b698cd1fe52a/deploy/terraform/terraform-units/modules/sap_landscape/iscsi.tf#L46,https://github.com/Azure/sap-automation/blob/df063c58945a9efa2cb2ba303762c43f0b9c1d8f/deploy/terraform/terraform-units/modules/sap_landscape/iscsi.tf#L62,2021-11-17 19:29:07+02:00,2024-05-17 12:37:17+03:00,14,0,0,1,0,1,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1281,modules/net-vpn-ha/main.tf,modules/net-vpn-ha/main.tf,0,fix,# FIXME: can bgp_session_range be null?,# FIXME: can bgp_session_range be null?,"resource ""google_compute_router_interface"" ""router_interface"" {
  for_each = var.tunnels
  project  = var.project_id
  region   = var.region
  name     = ""${var.name}-${each.key}""
  router   = local.router
  # FIXME: can bgp_session_range be null?
  ip_range   = each.value.bgp_session_range == """" ? null : each.value.bgp_session_range
  vpn_tunnel = google_compute_vpn_tunnel.tunnels[each.key].name
}
",resource,"resource ""google_compute_router_interface"" ""router_interface"" {
  for_each = var.tunnels
  project  = var.project_id
  region   = var.region
  name     = ""${var.name}-${each.key}""
  router   = local.router
  # FIXME: can bgp_session_range be null?
  ip_range   = each.value.bgp_session_range == """" ? null : each.value.bgp_session_range
  vpn_tunnel = google_compute_vpn_tunnel.tunnels[each.key].name
}
",resource,117,139.0,798d3a413681b624391eabf9895ca52d0e810e6c,a95e681f059af9e112636befd03efb124439115f,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/798d3a413681b624391eabf9895ca52d0e810e6c/modules/net-vpn-ha/main.tf#L117,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/a95e681f059af9e112636befd03efb124439115f/modules/net-vpn-ha/main.tf#L139,2022-11-30 10:52:24+01:00,2024-04-28 12:11:07+02:00,11,0,0,1,0,0,1,0,0,0
https://github.com/SUSE/ha-sap-terraform-deployments,396,azure/network.tf,azure/network.tf,0,todo,# TODO check if this is needed,"# TODO check if this is needed 
 # Load balancing rules for HANA 1.0 ","resource ""azurerm_lb_rule"" ""lb_30315"" {
  resource_group_name            = azurerm_resource_group.myrg.name
  loadbalancer_id                = azurerm_lb.mylb.id
  name                           = ""hana-lb-30315""
  protocol                       = ""Tcp""
  frontend_ip_configuration_name = ""mylb-frontend""
  frontend_port                  = 30315
  backend_port                   = 30315
  backend_address_pool_id        = azurerm_lb_backend_address_pool.mylb.id
  probe_id                       = azurerm_lb_probe.mylb.id
  idle_timeout_in_minutes        = 30
  enable_floating_ip             = ""true""
}
",resource,"resource ""azurerm_lb_rule"" ""lb_30315"" {
  resource_group_name            = azurerm_resource_group.myrg.name
  loadbalancer_id                = azurerm_lb.mylb.id
  name                           = ""hana-lb-30315""
  protocol                       = ""Tcp""
  frontend_ip_configuration_name = ""mylb-frontend""
  frontend_port                  = 30315
  backend_port                   = 30315
  backend_address_pool_id        = azurerm_lb_backend_address_pool.mylb.id
  probe_id                       = azurerm_lb_probe.mylb.id
  idle_timeout_in_minutes        = 30
  enable_floating_ip             = ""true""
}
",resource,143,,5daf59b3bbcb57130d80f6d844ad35171f7c010a,9adcf152486838f9f5b600ead5e4ef373918a786,https://github.com/SUSE/ha-sap-terraform-deployments/blob/5daf59b3bbcb57130d80f6d844ad35171f7c010a/azure/network.tf#L143,https://github.com/SUSE/ha-sap-terraform-deployments/blob/9adcf152486838f9f5b600ead5e4ef373918a786/azure/network.tf,2019-09-05 00:05:54+02:00,2019-09-05 18:08:13+02:00,2,1,0,1,0,0,1,0,0,1
https://github.com/SUSE/ha-sap-terraform-deployments,347,azure/salt_provisioner.tf,azure/salt_provisioner.tf,0,workaround,# Workaround to let the process start in background properly,] # Workaround to let the process start in background properly,"resource ""null_resource"" ""monitoring_provisioner"" {
  count = var.provisioner == ""salt"" ? 1 : 0


  triggers = {
    monitoring_id = azurerm_virtual_machine.monitoring.id
  }

  connection {
    host        = data.azurerm_public_ip.monitoring.ip_address
    type        = ""ssh""
    user        = var.admin_user
    private_key = file(var.private_key_location)
  }

  provisioner ""file"" {
    source      = ""../salt""
    destination = ""/tmp""
  }

  provisioner ""file"" {
    content     = data.template_file.salt_provisioner.rendered
    destination = ""/tmp/salt_provisioner.sh""
  }

// TODO: add or don't add this (from libvirt)
// network_domain: ${var.network_domain}


  provisioner ""file"" {
    content = <<EOF
provider: azure
role: monitoring
name_prefix: ${terraform.workspace}-${var.name}
hostname: ${terraform.workspace}-${var.name}${var.monitoring_count > 1 ? ""0${count.index + 1}"" : """"}
timezone: ${var.timezone}
reg_code: ${var.reg_code}
reg_email: ${var.reg_email}
reg_additional_modules: {${join("", "",formatlist(""'%s': '%s'"",keys(var.reg_additional_modules),values(var.reg_additional_modules),),)}}
additional_repos: {${join("", "",formatlist(""'%s': '%s'"",keys(var.additional_repos),values(var.additional_repos),),)}}
additional_packages: [${join("", "", formatlist(""'%s'"", var.additional_packages))}]
authorized_keys: [${trimspace(file(var.public_key_location))},${trimspace(file(var.public_key_location))}]
host_ips: [${join("", "", formatlist(""'%s'"", [var.monitoring_srv_ip]))}]
host_ip: ${var.monitoring_srv_ip}
role: monitoring
provider: libvirt
ha_sap_deployment_repo: ${var.ha_sap_deployment_repo}
monitored_services: [${join("", "", formatlist(""'%s'"", var.monitored_services))}]
EOF

destination = ""/tmp/grains""
}

provisioner ""remote-exec"" {
  inline = [
    ""${var.background ? ""nohup"" : """"} sudo sh /tmp/salt_provisioner.sh > /tmp/provisioning.log ${var.background ? ""&"" : """"}"",
    ""return_code=$? && sleep 1 && exit $return_code"",
  ] # Workaround to let the process start in background properly
}

}
",resource,"resource ""null_resource"" ""monitoring_provisioner"" {
  count = var.provisioner == ""salt"" && var.monitoring_enabled ? 1 : 0

  triggers = {
    monitoring_id = azurerm_virtual_machine.monitoring.0.id
  }

  connection {
    host        = data.azurerm_public_ip.monitoring.0.ip_address
    type        = ""ssh""
    user        = var.admin_user
    private_key = file(var.private_key_location)
  }

  provisioner ""file"" {
    source      = ""../salt""
    destination = ""/tmp""
  }

  provisioner ""file"" {
    content     = data.template_file.salt_provisioner.rendered
    destination = ""/tmp/salt_provisioner.sh""
  }

  provisioner ""file"" {
    content = <<EOF
provider: azure
role: monitoring
name_prefix: vmmonitoring
hostname: ""vmmonitoring""
timezone: ${var.timezone}
reg_code: ${var.reg_code}
reg_email: ${var.reg_email}
reg_additional_modules: {${join("", "", formatlist(""'%s': '%s'"", keys(var.reg_additional_modules), values(var.reg_additional_modules), ), )}}
additional_packages: [${join("", "", formatlist(""'%s'"", var.additional_packages))}]
authorized_keys: [${trimspace(file(var.public_key_location))},${trimspace(file(var.public_key_location))}]
host_ips: [${join("", "", formatlist(""'%s'"", [var.monitoring_srv_ip]))}]
host_ip: ${var.monitoring_srv_ip}
ha_sap_deployment_repo: ${var.ha_sap_deployment_repo}
monitored_hosts: [${join("", "", formatlist(""'%s'"", var.host_ips))}]
drbd_monitored_hosts: [${join("", "", formatlist(""'%s'"", var.drbd_enabled ? var.drbd_ips : []))}]
nw_monitored_hosts: [${join("", "", formatlist(""'%s'"", var.netweaver_enabled ? var.netweaver_ips : []))}]
network_domain: ""tf.local""
EOF

    destination = ""/tmp/grains""
  }

  provisioner ""remote-exec"" {
    inline = [
      ""${var.background ? ""nohup"" : """"} sudo sh /tmp/salt_provisioner.sh > /tmp/provisioning.log ${var.background ? ""&"" : """"}"",
      ""return_code=$? && sleep 1 && exit $return_code"",
    ] # Workaround to let the process start in background properly
  }

}
",resource,224,139.0,f41baea2a7a45b527e944b62bcab73612c693e02,2ab3e131e002872c45a5d1aa0293246437fa3009,https://github.com/SUSE/ha-sap-terraform-deployments/blob/f41baea2a7a45b527e944b62bcab73612c693e02/azure/salt_provisioner.tf#L224,https://github.com/SUSE/ha-sap-terraform-deployments/blob/2ab3e131e002872c45a5d1aa0293246437fa3009/azure/salt_provisioner.tf#L139,2019-09-05 00:01:31+02:00,2020-01-28 16:54:26-08:00,24,0,0,1,0,0,0,1,0,0
https://github.com/Azure/terraform-azurerm-caf-enterprise-scale,51,resources.management.tf,resources.management.tf,0,fix,# workspace and Automation Account to fix issue #109.,"# Set explicit dependency on Resource Group, Log Analytics 
 # workspace and Automation Account to fix issue #109. 
 # Ideally we would limit to specific solutions, but the 
 # depends_on block only supports static values.","resource ""azurerm_log_analytics_solution"" ""enterprise_scale"" {
  for_each = local.azurerm_log_analytics_solution_enterprise_scale

  # Mandatory resource attributes
  solution_name         = each.value.template.solution_name
  location              = each.value.template.location
  resource_group_name   = each.value.template.resource_group_name
  workspace_resource_id = each.value.template.workspace_resource_id
  workspace_name        = each.value.template.workspace_name

  plan {
    publisher = each.value.template.plan.publisher
    product   = each.value.template.plan.product
  }

  # Optional resource attributes
  tags = each.value.template.tags

  # Set explicit dependency on Resource Group, Log Analytics
  # workspace and Automation Account to fix issue #109.
  # Ideally we would limit to specific solutions, but the
  # depends_on block only supports static values.
  depends_on = [
    azurerm_resource_group.enterprise_scale,
    azurerm_log_analytics_workspace.enterprise_scale,
    azurerm_automation_account.enterprise_scale,
  ]

}
",resource,"resource ""azurerm_log_analytics_solution"" ""management"" {
  for_each = local.azurerm_log_analytics_solution_management

  provider = azurerm.management

  # Mandatory resource attributes
  solution_name         = each.value.template.solution_name
  location              = each.value.template.location
  resource_group_name   = each.value.template.resource_group_name
  workspace_resource_id = each.value.template.workspace_resource_id
  workspace_name        = each.value.template.workspace_name

  plan {
    publisher = each.value.template.plan.publisher
    product   = each.value.template.plan.product
  }

  # Optional resource attributes
  tags = each.value.template.tags

  # Set explicit dependency on Resource Group, Log Analytics
  # workspace and Automation Account to fix issue #109.
  # Ideally we would limit to specific solutions, but the
  # depends_on block only supports static values.
  depends_on = [
    azurerm_resource_group.management,
    azurerm_log_analytics_workspace.management,
    azurerm_automation_account.management,
    azurerm_log_analytics_linked_service.management,
  ]

}
",resource,49,62.0,18297293ca702ce6610f0117baacdaafcc148ce8,be69a5d92787faec1d895f5d0b35e165ce9de8fd,https://github.com/Azure/terraform-azurerm-caf-enterprise-scale/blob/18297293ca702ce6610f0117baacdaafcc148ce8/resources.management.tf#L49,https://github.com/Azure/terraform-azurerm-caf-enterprise-scale/blob/be69a5d92787faec1d895f5d0b35e165ce9de8fd/resources.management.tf#L62,2021-06-07 13:21:51+01:00,2022-12-23 09:19:54+00:00,5,0,0,1,0,0,0,0,1,0
https://github.com/SUSE/ha-sap-terraform-deployments,356,azure/instances.tf,azure/instances.tf,0,todo,// TODO add variable later,// TODO add variable later,"resource ""azurerm_virtual_machine"" ""monitoring"" {
  name                  = ""${terraform.workspace}-monitoring""
  location              = var.az_region
  // TODO CHECK THIS group
  resource_group_name   = azurerm_resource_group.myrg.name
  // 
  network_interface_ids = [azurerm_network_interface.monitoring.id]
  availability_set_id   = azurerm_availability_set.myas.id
  vm_size               = ""Standard_D2s_v3""

  storage_os_disk {
    name              = ""monitoringOsDisk""
    caching           = ""ReadWrite""
    create_option     = ""FromImage""
    managed_disk_type = ""Premium_LRS""
  }
   // TODO add variable later
  storage_image_reference {
    id        = azurerm_image.monitoring.0.id
    publisher = ""SUSE""
    offer     = ""SLES-SAP-BYOS""
    sku       = ""12-sp4""
    version   = ""2019.03.06""
  }

  storage_data_disk {
    name              = ""monitoringDevices""
    caching           = ""ReadWrite""
    create_option     = ""Empty""
    disk_size_gb      = ""10""
    lun               = ""0""
    managed_disk_type = ""Standard_LRS""
  }

  os_profile {
    computer_name  = ""monitoring""
    admin_username = var.admin_user
  }

  os_profile_linux_config {
    disable_password_authentication = true

    ssh_keys {
      path     = ""/home/${var.admin_user}/.ssh/authorized_keys""
      key_data = file(var.public_key_location)
    }
  }

  boot_diagnostics {
    enabled     = ""true""
    storage_uri = azurerm_storage_account.mytfstorageacc.primary_blob_endpoint
  }

  tags = {
    workspace = terraform.workspace
  }
}
",resource,"resource ""azurerm_virtual_machine"" ""monitoring"" {
  name     = ""${terraform.workspace}-monitoring""
  location = var.az_region
  resource_group_name = azurerm_resource_group.myrg.name
  network_interface_ids = [azurerm_network_interface.monitoring.id]
  availability_set_id   = azurerm_availability_set.myas.id
  vm_size               = ""Standard_D2s_v3""

  storage_os_disk {
    name              = ""monitoringOsDisk""
    caching           = ""ReadWrite""
    create_option     = ""FromImage""
    managed_disk_type = ""Premium_LRS""
  }
  
  storage_image_reference {
    id        = azurerm_image.monitoring.0.id
    publisher = ""SUSE""
    offer     = ""SLES-SAP-BYOS""
    sku       = ""15""
    version   = ""2019.07.17""
  }

  storage_data_disk {
    name              = ""monitoringDevices""
    caching           = ""ReadWrite""
    create_option     = ""Empty""
    disk_size_gb      = ""10""
    lun               = ""0""
    managed_disk_type = ""Standard_LRS""
  }

  os_profile {
    computer_name  = ""monitoring""
    admin_username = var.admin_user
  }

  os_profile_linux_config {
    disable_password_authentication = true

    ssh_keys {
      path     = ""/home/${var.admin_user}/.ssh/authorized_keys""
      key_data = file(var.public_key_location)
    }
  }

  boot_diagnostics {
    enabled     = ""true""
    storage_uri = azurerm_storage_account.mytfstorageacc.primary_blob_endpoint
  }

  tags = {
    workspace = terraform.workspace
  }
}
",resource,151,,5c0d2ffe158dbf6db6c58414cdbc56fa872b4197,9adcf152486838f9f5b600ead5e4ef373918a786,https://github.com/SUSE/ha-sap-terraform-deployments/blob/5c0d2ffe158dbf6db6c58414cdbc56fa872b4197/azure/instances.tf#L151,https://github.com/SUSE/ha-sap-terraform-deployments/blob/9adcf152486838f9f5b600ead5e4ef373918a786/azure/instances.tf,2019-09-05 00:01:31+02:00,2019-09-05 18:08:13+02:00,4,1,1,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,168,modules/workergroup/locals.tf,modules/workerpools/locals.tf,1,todo,# TODO Deprecate,label_prefix     = var.label_prefix # TODO Deprecate,"locals {
  # Stable availability domain selection
  ads        = data.oci_identity_availability_domains.ad_list.availability_domains
  ad_numbers = local.ads != null ? sort(keys(local.ad_number_to_name)) : []
  ad_number_to_name = local.ads != null ? {
    for ad in local.ads : parseint(substr(ad.name, -1, -1), 10) => ad.name
  } : { -1 : """" } # Fallback handles failure when unavailable but not required
  first_ad_name = local.ad_number_to_name[1]

  k8s_version_length = length(var.kubernetes_version)
  k8s_version_only   = substr(var.kubernetes_version, 1, local.k8s_version_length)

  kubeconfig          = try(yamldecode(lookup(data.oci_containerengine_cluster_kube_config.kube_config, ""content"", """")), { ""error"" : ""yamldecode"" })
  kubeconfig_clusters = try(lookup(local.kubeconfig, ""clusters"", []), [])
  kubeconfig_ca_cert  = try(lookup(lookup(local.kubeconfig_clusters[0], ""cluster"", {}), ""certificate-authority-data"", """"), """")
  cluster_ca_cert     = length(var.cluster_ca_cert) > 0 ? var.cluster_ca_cert : local.kubeconfig_ca_cert

  # Instance tags - variables + constant
  defined_tags  = coalesce(var.defined_tags, {})
  freeform_tags = merge(coalesce(var.freeform_tags, {}), { ""role"" = ""worker"" })

  # OKE managed node pool images
  node_pool_images = try(data.oci_containerengine_node_pool_option.np_options.sources, [{
    source_type = ""IMAGE""
  }])

  # Parse platform/operating system information from node pool image names
  parsed_images = {
    for k, v in local.node_pool_images : v.image_id => merge(
      try(element(regexall(""OKE-(?P<k8s_version>[0-9\\.]+)-(?P<build>[0-9]+)"", v.source_name), 0), { k8s_version = ""none"" }),
      {
        arch        = length(regexall(""aarch64"", v.source_name)) > 0 ? ""aarch64"" : ""x86_64""
        image_type  = length(regexall(""OKE"", v.source_name)) > 0 ? ""oke"" : ""platform""
        is_gpu      = length(regexall(""GPU"", v.source_name)) > 0 ? true : false
        os          = trimspace(replace(element(regexall(""^[a-zA-Z-]+"", v.source_name), 0), ""-"", "" ""))
        os_version  = element(regexall(""[0-9\\.]+"", v.source_name), 0)
        source_name = v.source_name
    })
  }

  image_ids = {
    x86_64   = [for k, v in local.parsed_images : k if v.arch == ""x86_64""]
    aarch64  = [for k, v in local.parsed_images : k if v.arch == ""aarch64""]
    oke      = [for k, v in local.parsed_images : k if v.image_type == ""oke"" && v.k8s_version == local.k8s_version_only]
    platform = [for k, v in local.parsed_images : k if v.image_type == ""platform""]
    gpu      = [for k, v in local.parsed_images : k if v.is_gpu]
    nongpu   = [for k, v in local.parsed_images : k if !v.is_gpu]
  }

  worker_groups_default = {
    mode             = var.mode
    size             = var.size
    shape            = var.shape
    image_id         = var.image_id
    image_type       = var.image_type
    os               = var.os
    os_version       = var.os_version
    boot_volume_size = var.boot_volume_size
    memory           = var.memory
    ocpus            = var.ocpus
    compartment_id   = local.worker_compartment_id
    subnet_id        = var.subnet_id
    pod_subnet_id    = var.pod_subnet_id
    pod_nsgs         = var.pod_nsg_ids
    worker_nsgs      = var.worker_nsg_ids
    assign_public_ip = var.assign_public_ip
    label_prefix     = var.label_prefix # TODO Deprecate
    node_labels      = {}
  }

  # Filter worker_groups map variable for enabled entries
  worker_groups_enabled = {
    for k, v in var.worker_groups : k => merge(local.worker_groups_default, v) if lookup(v, ""enabled"", var.enabled)
  }

  worker_compartments = distinct(compact([for k, v in local.worker_groups_enabled : lookup(v, ""compartment_id"", """")]))

  # Number of nodes expected from enabled worker groups
  expected_node_count = length(local.worker_groups_enabled) == 0 ? 0 : sum([for k, v in local.worker_groups_enabled : lookup(v, ""size"", 0)])

  # Filter worker_groups map variable for entries with image_id defined, returning a distinct list
  enabled_worker_group_image_ids = distinct([
    for v in local.worker_groups_enabled : v.image_id if contains(keys(v), ""image_id"")
  ])

  # Intermediate worker image result from data source
  enabled_worker_group_images = data.oci_core_image.worker_images

  # Filter enabled worker_group map entries for node pools
  enabled_node_pools = {
    for k, v in local.worker_groups_enabled : k => v if lookup(v, ""mode"", """") == ""node-pool""
  }

  # Filter enabled worker_group map entries for instance pools
  enabled_instance_configs = {
    for k, v in local.worker_groups_enabled : k => v
    if contains([""cluster-network"", ""instance-pool""], lookup(v, ""mode"", """"))
  }

  # Filter enabled worker_group map entries for instance pools
  enabled_instance_pools = {
    for k, v in local.worker_groups_enabled : k => v if lookup(v, ""mode"", """") == ""instance-pool""
  }

  # Filter enabled worker_group map entries for cluster networks
  enabled_cluster_networks = {
    for k, v in local.worker_groups_enabled : k => v if lookup(v, ""mode"", """") == ""cluster-network""
  }

  # Worker group OCI resources enriched with desired/custom parameters
  worker_node_pools       = { for k, v in oci_containerengine_node_pool.node_pools : k => merge(v, lookup(local.worker_groups_enabled, k, {})) }
  worker_instance_pools   = { for k, v in oci_core_instance_pool.instance_pools : k => merge(v, lookup(local.worker_groups_enabled, k, {})) }
  worker_cluster_networks = { for k, v in oci_core_cluster_network.cluster_networks : k => merge(v, lookup(local.worker_groups_enabled, k, {})) }

  # Intermediate reference to the enabled worker group NLBs to be reconciled
  enabled_worker_group_nlbs = [
    for k, v in local.worker_groups_enabled : {
      for lb_k, lb_v in(contains(keys(v), ""load_balancers"") ? v.load_balancers : {}) : lb_k => lb_v
    } if contains(keys(v), ""load_balancers"")
  ]

  # Sanitized worker_groups output; some conditionally-used defaults would be misleading
  worker_groups_enabled_out = {
    for k, v in local.worker_groups_enabled : k => { for a, b in v : a => b
      if a != ""enabled""                                                                # implied
      && !(a == ""node_labels"" && b == {})                                              # exclude empty
      && !(contains([""os"", ""os_version""], a) && v.image_type == ""custom"")              # unused defaults for custom
      && !(contains([""pod_nsgs"", ""pod_subnet_id""], a) && var.cni_type != ""npn"")        # unused defaults for NPN
      && !(contains([""ocpus"", ""memory""], a) && length(regexall(""Flex"", v.shape)) == 0) # unused defaults for non-Flex shapes
    }
  }

  # Group resource outputs
  worker_groups_active = merge(
    local.worker_cluster_networks,
    local.worker_instance_pools,
    local.worker_node_pools,
  )
}
",locals,"locals {
  # Stable availability domain selection
  ads        = data.oci_identity_availability_domains.ad_list.availability_domains
  ad_numbers = local.ads != null ? sort(keys(local.ad_number_to_name)) : []
  ad_number_to_name = local.ads != null ? {
    for ad in local.ads : parseint(substr(ad.name, -1, -1), 10) => ad.name
  } : { -1 : """" } # Fallback handles failure when unavailable but not required

  k8s_version_length = length(var.kubernetes_version)
  k8s_version_only   = substr(var.kubernetes_version, 1, local.k8s_version_length)

  kubeconfig          = try(yamldecode(lookup(data.oci_containerengine_cluster_kube_config.kube_config, ""content"", """")), { ""error"" : ""yamldecode"" })
  kubeconfig_clusters = try(lookup(local.kubeconfig, ""clusters"", []), [])
  kubeconfig_ca_cert  = try(lookup(lookup(local.kubeconfig_clusters[0], ""cluster"", {}), ""certificate-authority-data"", """"), """")
  cluster_ca_cert     = length(var.cluster_ca_cert) > 0 ? var.cluster_ca_cert : local.kubeconfig_ca_cert

  # Instance tags - variables + constant
  defined_tags  = coalesce(var.defined_tags, {})
  freeform_tags = merge(coalesce(var.freeform_tags, {}), { ""role"" = ""worker"" })

  # OKE managed node pool images
  node_pool_images = try(data.oci_containerengine_node_pool_option.np_options.sources, [])

  # Parse platform/operating system information from node pool image names
  parsed_images = {
    for k, v in local.node_pool_images : v.image_id => merge(
      try(element(regexall(""OKE-(?P<k8s_version>[0-9\\.]+)-(?P<build>[0-9]+)"", v.source_name), 0), { k8s_version = ""none"" }),
      {
        arch        = length(regexall(""aarch64"", v.source_name)) > 0 ? ""aarch64"" : ""x86_64""
        image_type  = length(regexall(""OKE"", v.source_name)) > 0 ? ""oke"" : ""platform""
        is_gpu      = length(regexall(""GPU"", v.source_name)) > 0 ? true : false
        os          = trimspace(replace(element(regexall(""^[a-zA-Z-]+"", v.source_name), 0), ""-"", "" ""))
        os_version  = element(regexall(""[0-9\\.]+"", v.source_name), 0)
        source_name = v.source_name
    })
  }

  image_ids = {
    x86_64   = [for k, v in local.parsed_images : k if v.arch == ""x86_64""]
    aarch64  = [for k, v in local.parsed_images : k if v.arch == ""aarch64""]
    oke      = [for k, v in local.parsed_images : k if v.image_type == ""oke"" && v.k8s_version == local.k8s_version_only]
    platform = [for k, v in local.parsed_images : k if v.image_type == ""platform""]
    gpu      = [for k, v in local.parsed_images : k if v.is_gpu]
    nongpu   = [for k, v in local.parsed_images : k if !v.is_gpu]
  }

  worker_pools_default = {
    mode              = var.mode
    size              = var.size
    shape             = var.shape
    image_id          = var.image_id
    image_type        = var.image_type
    os                = var.os
    os_version        = var.os_version
    boot_volume_size  = var.boot_volume_size
    memory            = var.memory
    ocpus             = var.ocpus
    compartment_id    = local.worker_compartment_id
    placement_ads     = local.ad_numbers
    block_volume_type = var.block_volume_type
    pv_encryption     = var.enable_pv_encryption_in_transit
    subnet_id         = var.subnet_id
    pod_subnet_id     = var.pod_subnet_id
    pod_nsgs          = var.pod_nsg_ids
    worker_nsgs       = var.worker_nsg_ids
    assign_public_ip  = var.assign_public_ip
    node_labels       = {}
  }

  # Filter worker_pools map variable for enabled entries
  worker_pools_enabled = { for x, y in { # Final dynamic configuration for pool requirements
    # Merge desired pool configuration onto defaults
    for k, v in var.worker_pools : k => merge(local.worker_pools_default, v) if lookup(v, ""enabled"", var.enabled)
    } : x => merge(y, {
      # Translate configured + available  AD numbers e.g. 2 into a tenancy/compartment-specific name
      availability_domains = compact([for ad_number in tolist(setintersection(y.placement_ads, local.ad_numbers)) :
        lookup(local.ad_number_to_name, ad_number, null)
      ])
      block_volume_type = y.mode == ""cluster-network"" ? ""iscsi"" : var.block_volume_type
      pv_encryption     = var.enable_pv_encryption_in_transit && y.block_volume_type == ""paravirtualized"" && y.mode != ""cluster-network""
      image_id = (y.image_type == ""custom"" ? y.image_id : element(tolist(setintersection([
        lookup(local.image_ids, y.image_type, null),
        length(regexall(""GPU"", y.shape)) > 0 ? local.image_ids.gpu : local.image_ids.nongpu,
        length(regexall(""A1"", y.shape)) > 0 ? local.image_ids.aarch64 : local.image_ids.x86_64,
        [for parsed_image_id, iv in local.parsed_images : parsed_image_id
          if length(regexall(iv.os, y.os)) > 0 && trimprefix(iv.os_version, y.os_version) != iv.os_version
        ],
      ]...)), 0))
    })
  }

  worker_compartments = distinct(compact([for k, v in local.worker_pools_enabled : lookup(v, ""compartment_id"", """")]))

  # Number of nodes expected from enabled worker pools
  expected_node_count = length(local.worker_pools_enabled) == 0 ? 0 : sum([for k, v in local.worker_pools_enabled : lookup(v, ""size"", 0)])

  # Filter enabled worker_pool map entries for node pools
  enabled_node_pools = {
    for k, v in local.worker_pools_enabled : k => v if lookup(v, ""mode"", """") == ""node-pool""
  }

  # Filter enabled worker_pool map entries for instance pools
  enabled_instance_configs = {
    for k, v in local.worker_pools_enabled : k => v
    if contains([""cluster-network"", ""instance-pool""], lookup(v, ""mode"", """"))
  }

  # Filter enabled worker_pool map entries for instance pools
  enabled_instance_pools = {
    for k, v in local.worker_pools_enabled : k => v if lookup(v, ""mode"", """") == ""instance-pool""
  }

  # Filter enabled worker_pool map entries for cluster networks
  enabled_cluster_networks = {
    for k, v in local.worker_pools_enabled : k => v if lookup(v, ""mode"", """") == ""cluster-network""
  }

  # Worker pool OCI resources enriched with desired/custom parameters
  worker_node_pools       = { for k, v in oci_containerengine_node_pool.workers : k => merge(v, lookup(local.worker_pools_enabled, k, {})) }
  worker_instance_pools   = { for k, v in oci_core_instance_pool.workers : k => merge(v, lookup(local.worker_pools_enabled, k, {})) }
  worker_cluster_networks = { for k, v in oci_core_cluster_network.workers : k => merge(v, lookup(local.worker_pools_enabled, k, {})) }

  # Intermediate reference to the enabled worker pool NLBs to be reconciled
  enabled_worker_pool_nlbs = [
    for k, v in local.worker_pools_enabled : {
      for lb_k, lb_v in(contains(keys(v), ""load_balancers"") ? v.load_balancers : {}) : lb_k => lb_v
    } if contains(keys(v), ""load_balancers"")
  ]

  # Sanitized worker_pools output; some conditionally-used defaults would be misleading
  worker_pools_enabled_out = {
    for k, v in local.worker_pools_enabled : k => { for a, b in v : a => b
      if a != ""enabled""                                                                # implied
      && !(a == ""node_labels"" && b == {})                                              # exclude empty
      && !(contains([""os"", ""os_version""], a) && v.image_type == ""custom"")              # unused defaults for custom
      && !(contains([""pod_nsgs"", ""pod_subnet_id""], a) && var.cni_type != ""npn"")        # unused defaults for NPN
      && !(contains([""ocpus"", ""memory""], a) && length(regexall(""Flex"", v.shape)) == 0) # unused defaults for non-Flex shapes
    }
  }

  # Group resource outputs
  worker_pools_active = merge(
    local.worker_cluster_networks,
    local.worker_instance_pools,
    local.worker_node_pools,
  )
}
",locals,70,,4d2b3f3d672a8f41655da3a7c58fded42c6858f3,897bae1fd6cdbd22478066e6f93643a8f7482757,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/4d2b3f3d672a8f41655da3a7c58fded42c6858f3/modules/workergroup/locals.tf#L70,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/897bae1fd6cdbd22478066e6f93643a8f7482757/modules/workerpools/locals.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,3,1,0,1,0,0,0,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,250,modules/utilities/drain.tf,modules/utilities/drain.tf,0,todo,# TODO List nodes by label for draining pools,"""echo kubectl get nodes ..."",             # TODO List nodes by label for draining pools","resource ""null_resource"" ""drain_workers"" {
  triggers = {
    drain_count = jsonencode(keys(local.worker_pools_draining))
  }

  connection {
    bastion_host        = var.bastion_host
    bastion_user        = var.bastion_user
    bastion_private_key = var.ssh_private_key
    host                = var.operator_host
    user                = var.operator_user
    private_key         = var.ssh_private_key
    timeout             = ""40m""
    type                = ""ssh""
  }

  provisioner ""remote-exec"" {
    inline = [
      ""echo kubectl get nodes ..."",             # TODO List nodes by label for draining pools
      ""echo kubectl drain --ignore-daemonsets"", # TODO Drain nodes for draining pools
    ]
  }
}
",resource,"resource ""null_resource"" ""drain_workers"" {
  count = local.drain_enabled ? 1 : 0
  triggers = {
    drain_pools    = jsonencode(sort(local.drain_pools))
    drain_commands = jsonencode(local.drain_commands)
  }

  connection {
    bastion_host        = var.bastion_host
    bastion_user        = var.bastion_user
    bastion_private_key = var.ssh_private_key
    host                = var.operator_host
    user                = var.operator_user
    private_key         = var.ssh_private_key
    timeout             = ""40m""
    type                = ""ssh""
  }

  provisioner ""remote-exec"" {
    inline = local.drain_commands
  }
}
",resource,26,,79845fb791998bdde1b58fa656b6c381f7d26510,5c4fc186cf8eeac1c0af855954593058edae675b,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/79845fb791998bdde1b58fa656b6c381f7d26510/modules/utilities/drain.tf#L26,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/5c4fc186cf8eeac1c0af855954593058edae675b/modules/utilities/drain.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,4,1,0,0,0,0,0,1,0,0
https://github.com/kubernetes/k8s.io,34,infra/gcp/clusters/modules/gke-cluster/main.tf,infra/gcp/terraform/modules/gke-cluster/main.tf,1,workaround,// Uses a workaround from https://github.com/hashicorp/terraform/issues/22544#issuecomment-582974372,"// Create GKE cluster, but with no node pools. Node pools are provisioned via another module. 
 // 
 // Uses a workaround from https://github.com/hashicorp/terraform/issues/22544#issuecomment-582974372 
 // to set lifecycle.prevent_destroy to false if is_prod_cluster 
 // 
 // IMPORTANT: The prod_ and test_ forms of this resource MUST be kept in sync. 
 //            Any changes in one MUST be reflected in the other.","resource ""google_container_cluster"" ""prod_cluster"" {
  count     = var.is_prod_cluster == ""true"" ? 1 : 0
  
  name     = var.cluster_name
  location = var.cluster_location

  provider = google-beta
  project  = var.project_name

  // NOTE: unique to prod_cluster
  // GKE clusters are critical objects and should not be destroyed
  lifecycle {
    prevent_destroy = true
  }

  // Network config
  network = ""default""

  // Start with a single node, because we're going to delete the default pool
  initial_node_count = 1

  // Removes the default node pool, so we can custom create them as separate
  // objects
  remove_default_node_pool = true

  // Disable local and certificate auth
  master_auth {
    username = """"
    password = """"

    client_certificate_config {
      issue_client_certificate = false
    }
  }

  // Enable google-groups for RBAC
  authenticator_groups_config {
    security_group = ""gke-security-groups@kubernetes.io""
  }

  // Enable workload identity for GCP IAM
  workload_identity_config {
    identity_namespace = ""${var.project_name}.svc.id.goog""
  }

  // Enable Stackdriver Kubernetes Monitoring
  logging_service    = ""logging.googleapis.com/kubernetes""
  monitoring_service = ""monitoring.googleapis.com/kubernetes""

  // Set maintenance time
  maintenance_policy {
    daily_maintenance_window {
      start_time = ""11:00"" // (in UTC), 03:00 PST
    }
  }

  // Restrict master to Google IP space; use Cloud Shell to access
  master_authorized_networks_config {
  }

  // Enable GKE Usage Metering
  resource_usage_export_config {
    enable_network_egress_metering = true
    bigquery_destination {
      dataset_id = google_bigquery_dataset.prod_usage_metering[0].dataset_id
    }
  }

  // Enable GKE Network Policy
  network_policy {
    enabled  = true
    provider = ""CALICO""
  }

  // Configure cluster addons
  addons_config {
    horizontal_pod_autoscaling {
      disabled = false
    }
    http_load_balancing {
      disabled = false
    }
    network_policy_config {
      disabled = false
    }
  }

  // Enable PodSecurityPolicy enforcement
  pod_security_policy_config {
    enabled = false // TODO: we should turn this on
  }

  // Enable VPA
  vertical_pod_autoscaling {
    enabled = true
  }
}
",resource,"resource ""google_container_cluster"" ""prod_cluster"" {
  count = var.is_prod_cluster == ""true"" ? 1 : 0

  name     = var.cluster_name
  location = var.cluster_location

  provider = google-beta
  project  = var.project_name

  // NOTE: unique to prod_cluster
  // GKE clusters are critical objects and should not be destroyed
  lifecycle {
    prevent_destroy = true
  }

  // Network config
  network = ""default""

  // Start with a single node, because we're going to delete the default pool
  initial_node_count = 1

  // Removes the default node pool, so we can custom create them as separate
  // objects
  remove_default_node_pool = true

  // Enable google-groups for RBAC
  authenticator_groups_config {
    security_group = ""gke-security-groups@kubernetes.io""
  }

  // Enable workload identity for GCP IAM
  workload_identity_config {
    workload_pool = ""${var.project_name}.svc.id.goog""
  }

  // Enable Stackdriver Kubernetes Monitoring
  logging_service    = ""logging.googleapis.com/kubernetes""
  monitoring_service = ""monitoring.googleapis.com/kubernetes""

  // Set maintenance time
  maintenance_policy {
    daily_maintenance_window {
      start_time = ""11:00"" // (in UTC), 03:00 PST
    }
  }

  // Restrict master to Google IP space; use Cloud Shell to access
  dynamic ""master_authorized_networks_config"" {
    for_each = var.cloud_shell_access ? [1] : []
    content {
    }
  }

  // Enable GKE Usage Metering
  resource_usage_export_config {
    enable_network_egress_metering = true
    bigquery_destination {
      dataset_id = google_bigquery_dataset.prod_usage_metering[0].dataset_id
    }
  }

  network_policy {
    enabled  = false
  }

  // Configure cluster addons
  addons_config {
    gce_persistent_disk_csi_driver_config {
      enabled = true
    }
    horizontal_pod_autoscaling {
      disabled = false
    }
    http_load_balancing {
      disabled = false
    }
    network_policy_config {
      disabled = false
    }
    dns_cache_config {
      enabled = var.dns_cache_enabled
    }
  }

  // Enable Shielded Nodes feature
  enable_shielded_nodes = var.enable_shielded_nodes

  release_channel {
    channel = var.release_channel
  }

  // Enable VPA
  vertical_pod_autoscaling {
    enabled = true
  }
}
",resource,90,90.0,0d83cf8820bd2d550c7032d8557aacb836bca743,1d001d33e9635f72f381199a008cbee3ec89cf21,https://github.com/kubernetes/k8s.io/blob/0d83cf8820bd2d550c7032d8557aacb836bca743/infra/gcp/clusters/modules/gke-cluster/main.tf#L90,https://github.com/kubernetes/k8s.io/blob/1d001d33e9635f72f381199a008cbee3ec89cf21/infra/gcp/terraform/modules/gke-cluster/main.tf#L90,2020-05-15 18:34:32-07:00,2024-03-07 11:20:21+00:00,10,0,1,1,1,0,0,1,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,258,modules/project/service_accounts.tf,modules/project/service_accounts.tf,0,# todo,# TODO: Find a better place to store BQ service account,# TODO: Find a better place to store BQ service account,"locals {
  service_account_cloud_services = ""${local.project.number}@cloudservices.gserviceaccount.com""
  service_accounts_default = {
    # TODO: Find a better place to store BQ service account
    bq      = ""bq-${local.project.number}@bigquery-encryption.iam.gserviceaccount.com""
    compute = ""${local.project.number}-compute@developer.gserviceaccount.com""
    gae     = ""${local.project.project_id}@appspot.gserviceaccount.com""
  }
  service_accounts_robot_services = {
    cloudasset        = ""gcp-sa-cloudasset""
    cloudbuild        = ""gcp-sa-cloudbuild""
    compute           = ""compute-system""
    container-engine  = ""container-engine-robot""
    containerregistry = ""containerregistry""
    dataflow          = ""dataflow-service-producer-prod""
    dataproc          = ""dataproc-accounts""
    gae-flex          = ""gae-api-prod""
    gcf               = ""gcf-admin-robot""
    pubsub            = ""gcp-sa-pubsub""
    storage           = ""gs-project-accounts""
  }
  service_accounts_robots = {
    for service, name in local.service_accounts_robot_services :
    service => ""service-${local.project.number}@${name}.iam.gserviceaccount.com""
  }
}
",locals,"locals {
  service_account_cloud_services = ""${local.project.number}@cloudservices.gserviceaccount.com""
  service_accounts_default = {
    compute = ""${local.project.number}-compute@developer.gserviceaccount.com""
    gae     = ""${local.project.project_id}@appspot.gserviceaccount.com""
  }
  service_accounts_robot_services = {
    bq                = ""bigquery-encryption""
    cloudasset        = ""gcp-sa-cloudasset""
    cloudbuild        = ""gcp-sa-cloudbuild""
    compute           = ""compute-system""
    container-engine  = ""container-engine-robot""
    containerregistry = ""containerregistry""
    dataflow          = ""dataflow-service-producer-prod""
    dataproc          = ""dataproc-accounts""
    gae-flex          = ""gae-api-prod""
    gcf               = ""gcf-admin-robot""
    pubsub            = ""gcp-sa-pubsub""
    secretmanager     = ""gcp-sa-secretmanager""
    storage           = ""gs-project-accounts""
  }
  service_accounts_robots = {
    for service, name in local.service_accounts_robot_services :
    service => ""${service == ""bq"" ? ""bq"" : ""service""}-${local.project.number}@${name}.iam.gserviceaccount.com""
  }
}
",locals,20,,476d2c79e972ec91a5f1b72ea79a00ce372d81d3,12e69c71e37f125a4cd2927e95d8cfd0a8411cbb,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/476d2c79e972ec91a5f1b72ea79a00ce372d81d3/modules/project/service_accounts.tf#L20,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/12e69c71e37f125a4cd2927e95d8cfd0a8411cbb/modules/project/service_accounts.tf,2021-06-11 16:00:20+02:00,2021-06-14 18:35:53+02:00,3,1,0,1,0,1,0,0,0,0
https://github.com/uyuni-project/sumaform,1667,modules/proxy_containerized/main.tf,modules/proxy_containerized/main.tf,0,implemented,# Not yet implemented in sumaform salt states,helm_chart_url            = var.helm_chart_url # Not yet implemented in sumaform salt states,"module ""proxy_containerized"" {
  source = ""../host""

  roles                         = var.roles
  connect_to_base_network       = true
  connect_to_additional_network = true
  quantity                      = var.quantity
  base_configuration            = var.base_configuration
  image                         = var.image == ""default"" || var.product_version == ""head"" ? var.images[var.product_version] : var.image
  name                          = var.name
  use_os_released_updates       = true
  ssh_key_path                  = var.ssh_key_path
  additional_repos              = var.additional_repos
  additional_repos_only         = var.additional_repos_only
  additional_packages           = var.additional_packages
  provider_settings             = var.provider_settings
  additional_disk_size          = var.repository_disk_size
  second_additional_disk_size   = var.database_disk_size
  volume_provider_settings      = var.volume_provider_settings

  grains = {
    product_version           = var.product_version
    server                    = var.server_configuration[""hostname""]
    first_user_present        = var.server_configuration[""create_first_user""]
    server_username           = var.server_configuration[""username""]
    server_password           = var.server_configuration[""password""]
    auto_configure            = var.auto_configure
    container_runtime         = var.runtime
    container_repository      = var.container_repository
    helm_chart_url            = var.helm_chart_url # Not yet implemented in sumaform salt states
    mirror                    = var.base_configuration[""mirror""]
    avahi_reflector           = var.avahi_reflector
    repository_disk_size      = var.repository_disk_size
    database_disk_size        = var.database_disk_size
  }
}
",module,"module ""proxy_containerized"" {
  source = ""../host""

  roles                         = var.roles
  connect_to_base_network       = true
  connect_to_additional_network = true
  quantity                      = var.quantity
  base_configuration            = var.base_configuration
  image                         = var.image == ""default"" || var.product_version == ""head"" ? var.images[var.product_version] : var.image
  name                          = var.name
  use_os_released_updates       = true
  install_salt_bundle           = var.install_salt_bundle
  ssh_key_path                  = var.ssh_key_path
  additional_repos              = var.additional_repos
  additional_repos_only         = var.additional_repos_only
  additional_packages           = var.additional_packages
  provider_settings             = var.provider_settings
  additional_disk_size          = var.repository_disk_size
  second_additional_disk_size   = var.database_disk_size
  volume_provider_settings      = var.volume_provider_settings

  grains = {
    product_version           = var.product_version
    server                    = var.server_configuration[""hostname""]
    server_username           = var.server_configuration[""username""]
    server_password           = var.server_configuration[""password""]
    auto_configure            = var.auto_configure
    container_runtime         = var.runtime
    container_repository      = var.container_repository
    helm_chart_url            = var.helm_chart_url # Not yet implemented in sumaform salt states
    mirror                    = var.base_configuration[""mirror""]
    avahi_reflector           = var.avahi_reflector
    main_disk_size            = var.main_disk_size
    repository_disk_size      = var.repository_disk_size
    database_disk_size        = var.database_disk_size
  }
}
",module,41,39.0,2601871d9b76286f60fbfd5ddae395a64d944c0f,31f3f833cfe72cfc8efc420eb4b9507f00e16d4b,https://github.com/uyuni-project/sumaform/blob/2601871d9b76286f60fbfd5ddae395a64d944c0f/modules/proxy_containerized/main.tf#L41,https://github.com/uyuni-project/sumaform/blob/31f3f833cfe72cfc8efc420eb4b9507f00e16d4b/modules/proxy_containerized/main.tf#L39,2024-02-01 15:23:28+01:00,2024-04-10 13:00:59+02:00,6,0,1,1,0,0,0,0,0,0
https://github.com/pingcap/tidb-operator,73,deploy/modules/gcp/tidb-operator/versions.tf,deploy/modules/gcp/tidb-operator/versions.tf,0,fix,# TODO: remove the restriction of < 2.19 once the `ip_allocation_policy.0.use_ip_aliases` error fixes,"# TODO: remove the restriction of < 2.19 once the `ip_allocation_policy.0.use_ip_aliases` error fixes 
 # https://github.com/terraform-providers/terraform-provider-google/blob/master/CHANGELOG.md#2190-november-05-2019","terraform {
  required_version = "">= 0.12""
  required_providers {
    # TODO: remove the restriction of < 2.19 once the `ip_allocation_policy.0.use_ip_aliases` error fixes
    # https://github.com/terraform-providers/terraform-provider-google/blob/master/CHANGELOG.md#2190-november-05-2019
    google      = "">= 2.16, < 2.19""
    google-beta = "">= 2.16, < 2.19""
    external    = ""~> 1.2""
    helm        = ""~> 0.10""
    null        = ""~> 2.1""
  }
}
",terraform,"terraform {
  required_version = "">= 0.12""
  required_providers {
    google = ""~> 2.16""
    helm   = ""~> 0.10""
    null   = ""~> 2.1""
  }
}
",terraform,5,,ebc4486509e029ba81b1c3bc6b0de54962196eeb,b2d38ef46b9e52c2c2c2b5334793a9f9a274e95b,https://github.com/pingcap/tidb-operator/blob/ebc4486509e029ba81b1c3bc6b0de54962196eeb/deploy/modules/gcp/tidb-operator/versions.tf#L5,https://github.com/pingcap/tidb-operator/blob/b2d38ef46b9e52c2c2c2b5334793a9f9a274e95b/deploy/modules/gcp/tidb-operator/versions.tf,2019-11-21 13:49:04+08:00,2019-12-31 16:08:33+08:00,2,1,0,1,1,1,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1401,blueprints/data-solutions/vertex-mlops/outputs.tf,blueprints/data-solutions/vertex-mlops/outputs.tf,0,# todo,# TODO(): proper outputs,"/** 
 * Copyright 2022 Google LLC 
 * 
 * Licensed under the Apache License, Version 2.0 (the ""License""); 
 * you may not use this file except in compliance with the License. 
 * You may obtain a copy of the License at 
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0 
 * 
 * Unless required by applicable law or agreed to in writing, software 
 * distributed under the License is distributed on an ""AS IS"" BASIS, 
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 * See the License for the specific language governing permissions and 
 * limitations under the License. 
 */  
 # TODO(): proper outputs  ","locals {
  docker_split = try(split(""/"", module.artifact_registry.id), null)
  docker_repo  = try(""${local.docker_split[3]}-docker.pkg.dev/${local.docker_split[1]}/${local.docker_split[5]}"", null)
  gh_config = {
    WORKLOAD_ID_PROVIDER = try(google_iam_workload_identity_pool_provider.github_provider[0].name, null)
    SERVICE_ACCOUNT      = try(module.service-account-github.email, null)
    PROJECT_ID           = module.project.project_id
    DOCKER_REPO          = local.docker_repo
    SA_MLOPS             = module.service-account-mlops.email
    SUBNETWORK           = local.subnet
  }
}
",locals,"locals {
  docker_split = try(split(""/"", module.artifact_registry.id), null)
  docker_repo  = try(""${local.docker_split[3]}-docker.pkg.dev/${local.docker_split[1]}/${local.docker_split[5]}"", null)
  gh_config = {
    WORKLOAD_ID_PROVIDER = try(google_iam_workload_identity_pool_provider.github_provider[0].name, null)
    SERVICE_ACCOUNT      = try(module.service-account-github.email, null)
    PROJECT_ID           = module.project.project_id
    DOCKER_REPO          = local.docker_repo
    SA_MLOPS             = module.service-account-mlops.email
    SUBNETWORK           = local.subnet
  }
}
",locals,17,,ce1f86d20b6f90a5d688e24813fd9552af67ddd6,edf67fc5d040acfcd852a24a62d04acd2e4038f2,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/ce1f86d20b6f90a5d688e24813fd9552af67ddd6/blueprints/data-solutions/vertex-mlops/outputs.tf#L17,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/edf67fc5d040acfcd852a24a62d04acd2e4038f2/blueprints/data-solutions/vertex-mlops/outputs.tf,2023-02-02 19:13:13+01:00,2023-04-18 17:32:15+02:00,2,1,0,1,0,0,0,0,0,0
https://github.com/nasa/cumulus,32,tf-modules/cumulus/archive.tf,tf-modules/cumulus/archive.tf,0,todo,# TODO We need to figure out how to make this dynamic,# TODO We need to figure out how to make this dynamic,"module ""archive"" {
  source = ""../archive""

  prefix = var.prefix

  permissions_boundary_arn = var.permissions_boundary_arn

  ecs_cluster_name = aws_ecs_cluster.default.name

  elasticsearch_domain_arn        = var.elasticsearch_domain_arn
  elasticsearch_hostname          = var.elasticsearch_hostname
  elasticsearch_security_group_id = var.elasticsearch_security_group_id

  ems_host = ""change-ems-host""

  system_bucket     = var.system_bucket
  public_buckets    = var.public_buckets
  protected_buckets = var.protected_buckets
  private_buckets   = var.private_buckets

  vpc_id            = var.vpc_id
  lambda_subnet_ids = var.lambda_subnet_ids

  cmr_client_id   = var.cmr_client_id
  cmr_environment = var.cmr_environment
  cmr_provider    = var.cmr_provider
  cmr_username    = var.cmr_username
  cmr_password    = var.cmr_password

  urs_url             = ""https://uat.urs.earthdata.nasa.gov""
  urs_client_id       = var.urs_client_id
  urs_client_password = var.urs_client_password

  token_secret = var.token_secret

  dynamo_tables = var.dynamo_tables

  api_port = var.archive_api_port

  schedule_sf_function_arn      = data.aws_lambda_function.schedule_sf.arn
  message_consumer_function_arn = data.aws_lambda_function.message_consumer.arn
  # TODO This should eventually come from the ingest module
  kinesis_inbound_event_logger = var.kinesis_inbound_event_logger

  # TODO We need to figure out how to make this dynamic
  background_queue_name = ""backgroundProcessing""

  distribution_api_id = module.distribution.rest_api_id
  distribution_url    = module.distribution.distribution_url

  users = var.archive_api_users
}
",module,"module ""archive"" {
  source = ""../archive""

  prefix = var.prefix

  api_url = var.archive_api_url

  deploy_to_ngap = var.deploy_to_ngap

  permissions_boundary_arn = var.permissions_boundary_arn

  lambda_processing_role_arn = aws_iam_role.lambda_processing.arn

  ecs_cluster_name = aws_ecs_cluster.default.name

  elasticsearch_domain_arn        = var.elasticsearch_domain_arn
  elasticsearch_hostname          = var.elasticsearch_hostname
  elasticsearch_security_group_id = var.elasticsearch_security_group_id

  ems_host              = var.ems_host
  ems_port              = var.ems_port
  ems_path              = var.ems_path
  ems_datasource        = var.ems_datasource
  ems_private_key       = var.ems_private_key
  ems_provider          = var.ems_provider
  ems_retention_in_days = var.ems_retention_in_days
  ems_submit_report     = var.ems_submit_report
  ems_username          = var.ems_username

  es_index_shards        = var.es_index_shards
  es_request_concurrency = var.es_request_concurrency

  system_bucket     = var.system_bucket
  public_buckets    = local.public_bucket_names
  protected_buckets = local.protected_bucket_names
  private_buckets   = local.private_bucket_names

  vpc_id            = var.vpc_id
  lambda_subnet_ids = var.lambda_subnet_ids

  cmr_client_id      = var.cmr_client_id
  cmr_environment    = var.cmr_environment
  cmr_oauth_provider = var.cmr_oauth_provider
  cmr_provider       = var.cmr_provider
  cmr_username       = var.cmr_username
  cmr_password       = var.cmr_password

  launchpad_api         = var.launchpad_api
  launchpad_certificate = var.launchpad_certificate
  launchpad_passphrase  = var.launchpad_passphrase

  saml_entity_id                  = var.saml_entity_id
  saml_assertion_consumer_service = var.saml_assertion_consumer_service
  saml_idp_login                  = var.saml_idp_login
  saml_launchpad_metadata_url     = var.saml_launchpad_metadata_url

  urs_url             = var.urs_url
  urs_client_id       = var.urs_client_id
  urs_client_password = var.urs_client_password

  token_secret = var.token_secret

  dynamo_tables = var.dynamo_tables

  api_port = var.archive_api_port
  private_archive_api_gateway = var.private_archive_api_gateway
  api_gateway_stage = var.api_gateway_stage

  schedule_sf_function_arn                         = module.ingest.schedule_sf_lambda_function_arn
  manual_consumer_function_arn                     = module.ingest.manual_consumer_lambda_function_arn
  message_consumer_function_arn                    = module.ingest.message_consumer_lambda_function_arn
  kinesis_fallback_topic_arn                       = module.ingest.kinesis_fallback_topic_arn
  kinesis_inbound_event_logger_lambda_function_arn = module.ingest.kinesis_inbound_event_logger_lambda_function_arn

  metrics_es_host     = var.metrics_es_host
  metrics_es_password = var.metrics_es_password
  metrics_es_username = var.metrics_es_username

  daily_execution_payload_cleanup_schedule_expression = var.daily_execution_payload_cleanup_schedule_expression
  complete_execution_payload_timeout_disable = var.complete_execution_payload_timeout_disable
  complete_execution_payload_timeout = var.complete_execution_payload_timeout
  non_complete_execution_payload_timeout_disable = var.non_complete_execution_payload_timeout_disable
  non_complete_execution_payload_timeout = var.non_complete_execution_payload_timeout

  background_queue_url = module.ingest.background_queue_url

  distribution_api_id = module.distribution.rest_api_id
  distribution_url    = module.distribution.distribution_url

  users = var.archive_api_users

  oauth_provider   = var.oauth_provider
  oauth_user_group = var.oauth_user_group

  log_destination_arn = var.log_destination_arn

  tags = var.tags
}
",module,55,,ad90977e68ab8e08ed1dda6f0cc022f825b5c3b7,cb6ec4395fab63ae7c8cf3108aa4d80040810f5f,https://github.com/nasa/cumulus/blob/ad90977e68ab8e08ed1dda6f0cc022f825b5c3b7/tf-modules/cumulus/archive.tf#L55,https://github.com/nasa/cumulus/blob/cb6ec4395fab63ae7c8cf3108aa4d80040810f5f/tf-modules/cumulus/archive.tf,2019-08-14 14:23:38-04:00,2020-08-11 16:32:14-04:00,26,1,0,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,321,terraform/projects/infra-security-groups/publishing-api.tf,terraform/projects/infra-security-groups/publishing-api.tf,0,# todo,# TODO: application machines need access to publishing-api - create an application,"# TODO: application machines need access to publishing-api - create an application 
 # group that needs access?","resource ""aws_security_group_rule"" ""allow_management_to_publishing-api_https"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  # Which security group is the rule assigned to
  security_group_id = ""${aws_security_group.publishing-api_elb_external.id}""

  # Which security group can use this rule
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,84,,b212a5508ed19a405a50c07afee2d3d66c55a60b,7fd13330f8d6238e108f76ce76a76a28a99caaaf,https://github.com/alphagov/govuk-aws/blob/b212a5508ed19a405a50c07afee2d3d66c55a60b/terraform/projects/infra-security-groups/publishing-api.tf#L84,https://github.com/alphagov/govuk-aws/blob/7fd13330f8d6238e108f76ce76a76a28a99caaaf/terraform/projects/infra-security-groups/publishing-api.tf,2017-09-15 17:07:50+01:00,2018-01-02 17:41:32+00:00,4,1,1,1,0,1,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,972,examples/data-solutions/data-playground/main.tf,blueprints/data-solutions/data-playground/main.tf,1,# todo,# TODO: Add encryption_key to Vertex AI notebooks as well,"############################################################################### 
 #                         Vertex AI Notebook                                   # 
 ############################################################################### 
 # TODO: Add encryption_key to Vertex AI notebooks as well 
 # TODO: Add shared VPC support","resource ""google_notebooks_instance"" ""playground"" {
  name         = ""data-play-notebook""
  location     = format(""%s-%s"", var.region, ""b"")
  machine_type = ""e2-medium""
  project      = module.project.project_id

  container_image {
    repository = ""gcr.io/deeplearning-platform-release/base-cpu""
    tag        = ""latest""
  }

  install_gpu_driver = true
  boot_disk_type     = ""PD_SSD""
  boot_disk_size_gb  = 110

  no_public_ip    = false
  no_proxy_access = false

  network = module.vpc.network.id
  subnet  = module.vpc.subnets[format(""%s/%s"", var.region, var.vpc_config.subnet_name)].id
}
",resource,"resource ""google_notebooks_instance"" ""playground"" {
  name         = ""${var.prefix}-notebook""
  location     = format(""%s-%s"", var.region, ""b"")
  machine_type = ""e2-medium""
  project      = module.project.project_id

  container_image {
    repository = ""gcr.io/deeplearning-platform-release/base-cpu""
    tag        = ""latest""
  }

  install_gpu_driver = true
  boot_disk_type     = ""PD_SSD""
  boot_disk_size_gb  = 110
  disk_encryption    = try(local.service_encryption_keys.compute != null, false) ? ""CMEK"" : null
  kms_key            = try(local.service_encryption_keys.compute, null)

  no_public_ip    = true
  no_proxy_access = false

  network = local.vpc
  subnet  = local.subnet

  service_account = module.service-account-notebook.email

  #TODO Uncomment once terraform-provider-google/issues/9273 is fixed
  # tags = [""ssh""]
  depends_on = [
    google_project_iam_member.shared_vpc,
  ]
}
",resource,91,,54d805dac04ba4d43b189d22b0751e45ca69f366,07a7be29e3bd898dfdfb8ce39dadf7a663fa2fcf,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/54d805dac04ba4d43b189d22b0751e45ca69f366/examples/data-solutions/data-playground/main.tf#L91,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/07a7be29e3bd898dfdfb8ce39dadf7a663fa2fcf/blueprints/data-solutions/data-playground/main.tf,2022-07-10 09:27:18+02:00,2023-01-19 00:33:31+01:00,10,1,1,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,591,examples/data-solutions/dp-foundation/main.tf,examples/data-solutions/data-platform-foundations/main.tf,1,fix,#TODO Fix Network name logic,#TODO Fix Network name logic,"locals {
  _networks = {
    load = {
      #TODO Fix Network name logic
      network_name = element(split(""/"", var.network_config.network != null ? var.network_config.network : module.lod-vpc[0].self_link), length(split(""/"", var.network_config.network != null ? var.network_config.network : module.lod-vpc[0].self_link)) - 1)
      network      = var.network_config.network != null ? var.network_config.network : module.lod-vpc[0].self_link
      subnet       = var.network_config.network != null ? var.network_config.vpc_subnet_self_link.load : module.lod-vpc[0].subnet_self_links[""${var.composer_config.region}/${local.prefix_lod}-subnet""]
      subnet_range = var.network_config.vpc_subnet_range.load
    }
    orchestration = {
      #TODO Fix Network name logic
      network_name = element(split(""/"", var.network_config.network != null ? var.network_config.network : module.orc-vpc[0].self_link), length(split(""/"", var.network_config.network != null ? var.network_config.network : module.orc-vpc[0].self_link)) - 1)
      network      = var.network_config.network != null ? var.network_config.network : module.orc-vpc[0].self_link
      subnet       = var.network_config.network != null ? var.network_config.vpc_subnet_self_link.orchestration : module.orc-vpc[0].subnet_self_links[""${var.composer_config.region}/${local.prefix_orc}-subnet""]
      subnet_range = var.network_config.vpc_subnet_range.orchestration
    }
    transformation = {
      #TODO Fix Network name logic
      network_name = element(split(""/"", var.network_config.network != null ? var.network_config.network : module.trf-vpc[0].self_link), length(split(""/"", var.network_config.network != null ? var.network_config.network : module.trf-vpc[0].self_link)) - 1)
      network      = var.network_config.network != null ? var.network_config.network : module.trf-vpc[0].self_link
      subnet       = var.network_config.network != null ? var.network_config.vpc_subnet_self_link.transformation : module.trf-vpc[0].subnet_self_links[""${var.composer_config.region}/${local.prefix_trf}-subnet""]
      subnet_range = var.network_config.vpc_subnet_range.transformation
    }
  }

  _shared_vpc_service_config = var.network_config.network != null ? {
    attach       = true
    host_project = var.network_config.host_project
  } : null

  groups                  = { for k, v in var.groups : k => ""${v}@${var.organization.domain}"" }
  groups_iam              = { for k, v in local.groups : k => ""group:${v}"" }
  service_encryption_keys = var.service_encryption_keys

  # Uncomment this section and assigne comment the previous line

  # service_encryption_keys = {
  #   bq       = module.sec-kms-1.key_ids.bq
  #   composer = module.sec-kms-2.key_ids.composer
  #   dataflow = module.sec-kms-2.key_ids.dataflow
  #   storage  = module.sec-kms-1.key_ids.storage
  #   pubsub   = module.sec-kms-0.key_ids.pubsub
  # }
}
",locals,"locals {
  _networks = {
    load = {
      network_name = coalesce(local._shared_vpc_network, module.lod-vpc[0].name)
      network      = coalesce(var.network_config.network_self_link, module.lod-vpc[0].self_link)
      subnet       = try(var.network_config.subnet_self_links.load, module.lod-vpc[0].subnet_self_links[""${var.location_config.region}/${local.prefix_lod}-subnet""])
    }
    orchestration = {
      network_name = coalesce(local._shared_vpc_network, module.orc-vpc[0].name)
      network      = coalesce(var.network_config.network_self_link, module.orc-vpc[0].self_link)
      subnet       = try(var.network_config.subnet_self_links.orchestration, module.orc-vpc[0].subnet_self_links[""${var.location_config.region}/${local.prefix_orc}-subnet""])
    }
    transformation = {
      network_name = coalesce(local._shared_vpc_network, module.trf-vpc[0].name)
      network      = coalesce(var.network_config.network_self_link, module.trf-vpc[0].self_link)
      subnet       = try(var.network_config.subnet_self_links.transformation, module.trf-vpc[0].subnet_self_links[""${var.location_config.region}/${local.prefix_trf}-subnet""])
    }
  }
  _shared_vpc_network = try(regex(""[a-z]([-a-z0-9]*[a-z0-9])?$"", var.network_config.network_self_link), null)
  _shared_vpc_project = try(regex(""projects/([a-z0-9-]{6,30})"", var.network_config.network_self_link)[0], null)
  _shared_vpc_service_config = var.network_config.network_self_link != null ? {
    attach       = true
    host_project = local._shared_vpc_project
  } : null

  groups                  = { for k, v in var.groups : k => ""${v}@${var.organization.domain}"" }
  groups_iam              = { for k, v in local.groups : k => ""group:${v}"" }
  service_encryption_keys = var.service_encryption_keys

  # To create KMS keys in the common projet: uncomment assignement below and comment assignement above

  # service_encryption_keys = {
  #   bq       = module.sec-kms-1.key_ids.bq
  #   composer = module.sec-kms-2.key_ids.composer
  #   dataflow = module.sec-kms-2.key_ids.dataflow
  #   storage  = module.sec-kms-1.key_ids.storage
  #   pubsub   = module.sec-kms-0.key_ids.pubsub
  # }
}
",locals,27,,b3238969dfef485c4b1d1112242a06d1c3cca3c5,e270adf516d391a1c603b78002fcc931f902b001,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/b3238969dfef485c4b1d1112242a06d1c3cca3c5/examples/data-solutions/dp-foundation/main.tf#L27,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/e270adf516d391a1c603b78002fcc931f902b001/examples/data-solutions/data-platform-foundations/main.tf,2022-02-03 14:25:46+01:00,2022-02-08 17:46:34+01:00,6,1,0,1,0,0,1,0,0,0
https://github.com/alphagov/govuk-aws,312,terraform/projects/infra-security-groups/backend.tf,terraform/projects/infra-security-groups/backend.tf,0,# todo,# TODO: replace this with specific routes from application servers,# TODO: replace this with specific routes from application servers,"resource ""aws_security_group_rule"" ""allow_management_to_backend_elb_internal"" {
  type      = ""ingress""
  from_port = 443
  to_port   = 443
  protocol  = ""tcp""

  security_group_id        = ""${aws_security_group.backend_elb_internal.id}""
  source_security_group_id = ""${aws_security_group.management.id}""
}
",resource,the block associated got renamed or deleted,,61,,923e481addb08a4badef9a4ac1d531d4bbfea4b5,7fd13330f8d6238e108f76ce76a76a28a99caaaf,https://github.com/alphagov/govuk-aws/blob/923e481addb08a4badef9a4ac1d531d4bbfea4b5/terraform/projects/infra-security-groups/backend.tf#L61,https://github.com/alphagov/govuk-aws/blob/7fd13330f8d6238e108f76ce76a76a28a99caaaf/terraform/projects/infra-security-groups/backend.tf,2017-09-15 17:02:09+01:00,2018-01-02 17:41:32+00:00,2,1,0,1,0,1,1,0,0,0
https://github.com/kubernetes/k8s.io,276,infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf,infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf,0,# todo,# TODO(ameukam): adjust for production.,"container_concurrency = 5 # TODO(ameukam): adjust for production. 
 // 30 seconds less than cloud scheduler maximum.","resource ""google_cloud_run_service"" ""regions"" {
  project  = google_project.project.project_id
  for_each = toset(var.cloud_run_regions)
  name     = ""${local.project_id}-${each.key}""
  location = each.key

  template {
    metadata {
      annotations = {
        ""autoscaling.knative.dev/maxScale"" = ""3"" // Control costs.
        ""run.googleapis.com/launch-stage""  = ""BETA""
      }
    }
    spec {
      service_account_name = google_service_account.oci-proxy.email
      containers {
        image = local.image
      }
      container_concurrency = 5 # TODO(ameukam): adjust for production.
      // 30 seconds less than cloud scheduler maximum.
      timeout_seconds = 570
    }
  }

  traffic {
    percent         = 100
    latest_revision = true
  }

  depends_on = [
    google_project_service.project[""run.googleapis.com""]
  ]

  lifecycle {
    ignore_changes = [
      // This gets added by the Cloud Run API post deploy and causes diffs, can be ignored...
      template[0].metadata[0].annotations[""run.googleapis.com/sandbox""],
    ]
  }
}
",resource,"resource ""google_cloud_run_service"" ""regions"" {
  project  = google_project.project.project_id
  for_each = toset(var.cloud_run_regions)
  name     = ""${local.project_id}-${each.key}""
  location = each.key

  template {
    metadata {
      annotations = {
        ""autoscaling.knative.dev/maxScale"" = ""3"" // Control costs.
        ""run.googleapis.com/launch-stage""  = ""BETA""
      }
    }
    spec {
      service_account_name = google_service_account.oci-proxy.email
      containers {
        image = local.image
      }
      container_concurrency = 5
      // 30 seconds less than cloud scheduler maximum.
      timeout_seconds = 570
    }
  }

  traffic {
    percent         = 100
    latest_revision = true
  }

  depends_on = [
    google_project_service.project[""run.googleapis.com""]
  ]

  lifecycle {
    ignore_changes = [
      // This gets added by the Cloud Run API post deploy and causes diffs, can be ignored...
      template[0].metadata[0].annotations[""client.knative.dev/user-image""],
      template[0].metadata[0].annotations[""run.googleapis.com/sandbox""],
      template[0].metadata[0].annotations[""run.googleapis.com/client-name""],
      template[0].metadata[0].annotations[""run.googleapis.com/client-version""],
      // Ignore changes done on the container specification
      // since this cloud run service is handled by https://github.com/kubernetes-sigs/oci-proxy/blob/main/hack/make-rules/deploy.sh
      template[0].spec[0].containers[0],
    ]
  }
}
",resource,112,,6b67b4c61dcd8f7111cc8e608538ca87f108a105,8219f980d204345cc624987ba6022780fefb4db5,https://github.com/kubernetes/k8s.io/blob/6b67b4c61dcd8f7111cc8e608538ca87f108a105/infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf#L112,https://github.com/kubernetes/k8s.io/blob/8219f980d204345cc624987ba6022780fefb4db5/infra/gcp/terraform/k8s-infra-oci-proxy/oci-proxy-sandbox.tf,2022-02-07 22:14:33+01:00,2022-08-05 22:03:15+02:00,3,1,1,1,0,0,0,1,0,0
https://github.com/aws-ia/terraform-aws-eks-blueprints,332,examples/eks-cluster-with-new-vpc/main.tf,examples/eks-cluster-with-new-vpc/main.tf,0,todo,# TODO - requires dependency on `cert-manager` for namespace,"# TODO - requires dependency on `cert-manager` for namespace 
 # enable_cert_manager_csi_driver = true ","module ""eks_blueprints_kubernetes_addons"" {
  source = ""../../modules/kubernetes-addons""

  eks_cluster_id       = module.eks_blueprints.eks_cluster_id
  eks_cluster_endpoint = module.eks_blueprints.eks_cluster_endpoint
  eks_oidc_provider    = module.eks_blueprints.oidc_provider
  eks_cluster_version  = module.eks_blueprints.eks_cluster_version

  # EKS Managed Add-ons
  enable_amazon_eks_vpc_cni            = true
  enable_amazon_eks_coredns            = true
  enable_amazon_eks_kube_proxy         = true
  enable_amazon_eks_aws_ebs_csi_driver = true

  # Add-ons
  enable_aws_load_balancer_controller = true
  enable_metrics_server               = true
  enable_aws_cloudwatch_metrics       = true
  enable_kubecost                     = true
  enable_gatekeeper                   = true

  enable_cluster_autoscaler = true
  cluster_autoscaler_helm_config = {
    set = [
      {
        name  = ""podLabels.prometheus\\.io/scrape"",
        value = ""true"",
        type  = ""string"",
      }
    ]
  }

  enable_cert_manager = true
  cert_manager_helm_config = {
    set_values = [
      {
        name  = ""extraArgs[0]""
        value = ""--enable-certificate-owner-ref=false""
      },
    ]
  }
  # TODO - requires dependency on `cert-manager` for namespace
  # enable_cert_manager_csi_driver = true

  tags = local.tags
}
",module,,,108,0.0,37be09b5b05ec8588daf7b8e1eb8ef26a1a8507d,243ae23284c132753957508de3f724c0af73ebf0,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/37be09b5b05ec8588daf7b8e1eb8ef26a1a8507d/examples/eks-cluster-with-new-vpc/main.tf#L108,https://github.com/aws-ia/terraform-aws-eks-blueprints/blob/243ae23284c132753957508de3f724c0af73ebf0/examples/eks-cluster-with-new-vpc/main.tf#L0,2022-10-10 22:30:52-07:00,2023-02-14 16:25:25-05:00,4,2,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,616,examples/data-solutions/data-platform-foundations/variables.tf,examples/data-solutions/data-platform-foundations/variables.tf,0,#todo,#TODO hardcoded Cloud NAT,#TODO hardcoded Cloud NAT,"variable ""network_config"" {
  description = ""Network configurations to use. Specify a shared VPC to use, if null networks will be created in projects.""
  type = object({
    #TODO hardcoded Cloud NAT
    network_self_link = string
    #TODO hardcoded VPC ranges
    subnet_self_links = object({
      load           = string
      transformation = string
      orchestration  = string
    })
    composer_ip_ranges = object({
      cloudsql   = string
      gke_master = string
      web_server = string
    })
    composer_secondary_ranges = object({
      pods     = string
      services = string
    })
  })
  default = {
    enable_cloud_nat = false
    host_project     = null
    network          = null

    vpc_subnet = {
      load = {
        range           = ""10.10.0.0/24""
        secondary_range = null
      }
      transformation = {
        range           = ""10.10.0.0/24""
        secondary_range = null
      }
      orchestration = {
        range = ""10.10.0.0/24""
        secondary_range = {
          pods     = ""10.10.8.0/22""
          services = ""10.10.12.0/24""
        }
      }
    }
    vpc_subnet_self_link = null
  }
}
",variable,"variable ""network_config"" {
  description = ""Shared VPC network configurations to use. If null networks will be created in projects with preconfigured values.""
  type = object({
    network_self_link = string
    subnet_self_links = object({
      load           = string
      transformation = string
      orchestration  = string
    })
    composer_ip_ranges = object({
      cloudsql   = string
      gke_master = string
      web_server = string
    })
    composer_secondary_ranges = object({
      pods     = string
      services = string
    })
  })

  default = {
    network_self_link         = null
    subnet_self_links         = null
    composer_ip_ranges        = null
    composer_secondary_ranges = null
  }
}
",variable,81,,2e560407c118e7b7abc32f8ac1788a3f48563f21,d8bad5779036aa31639e4611e4935287fc79a4bc,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/2e560407c118e7b7abc32f8ac1788a3f48563f21/examples/data-solutions/data-platform-foundations/variables.tf#L81,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/d8bad5779036aa31639e4611e4935287fc79a4bc/examples/data-solutions/data-platform-foundations/variables.tf,2022-02-07 17:51:06+01:00,2022-02-07 21:28:54+01:00,2,1,0,1,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1862,modules/project-factory/factory-budgets.tf,modules/project-factory/factory-budgets.tf,0,implement,# reimplement the billing account factory here to interpolate projects,# reimplement the billing account factory here to interpolate projects,"locals {
  # reimplement the billing account factory here to interpolate projects
  _budget_path = try(pathexpand(var.factories_config.budgets.budgets_data_path), null)
  _budgets = (
    {
      for f in try(fileset(local._budget_path, ""**/*.yaml""), []) :
      trimsuffix(f, "".yaml"") => yamldecode(file(""${local._budget_path}/${f}""))
    }
  )
  budgets = {
    for k, v in local._budgets : k => merge(v, {
      amount = merge(
        {
          currency_code   = null
          nanos           = null
          units           = null
          use_last_period = null
        },
        try(v.amount, {})
      )
      display_name = try(v.display_name, null)
      filter = try(v.filter, null) == null ? null : {
        credit_types_treatment = (
          try(v.filter.credit_types_treatment, null) == null
          ? null
          : merge(
            { exclude_all = null, include_specified = null },
            v.filter.credit_types_treatment
          )
        )
        label = try(v.filter.label, null)
        projects = concat(
          try(v.projects, []),
          [
            for p in lookup(local.project_budgets, k, []) :
            ""projects/${module.projects[p].project_id}""
          ]
        )
        resource_ancestors = try(v.filter.resource_ancestors, null)
        services           = try(v.filter.services, null)
        subaccounts        = try(v.filter.subaccounts, null)
      }
      threshold_rules = [
        for vv in try(v.threshold_rules, []) : merge({
          percent          = null
          forecasted_spend = null
        }, vv)
      ]
      update_rules = {
        for kk, vv in try(v.update_rules, {}) : kk => merge({
          disable_default_iam_recipients   = null
          monitoring_notification_channels = null
          pubsub_topic                     = null
        }, vv)
      }
    })
  }
}
",locals,"locals {
  # reimplement the billing account factory here to interpolate projects
  _budget_path = try(pathexpand(var.factories_config.budgets.budgets_data_path), null)
  _budgets = (
    {
      for f in try(fileset(local._budget_path, ""**/*.yaml""), []) :
      trimsuffix(f, "".yaml"") => yamldecode(file(""${local._budget_path}/${f}""))
    }
  )
  budgets = {
    for k, v in local._budgets : k => merge(v, {
      amount = merge(
        {
          currency_code   = null
          nanos           = null
          units           = null
          use_last_period = null
        },
        try(v.amount, {})
      )
      display_name = try(v.display_name, null)
      filter = try(v.filter, null) == null ? null : {
        credit_types_treatment = (
          try(v.filter.credit_types_treatment, null) == null
          ? null
          : merge(
            { exclude_all = null, include_specified = null },
            v.filter.credit_types_treatment
          )
        )
        label = try(v.filter.label, null)
        projects = concat(
          try(v.projects, []),
          [
            for p in lookup(local.project_budgets, k, []) :
            ""projects/${module.projects[p].project_id}""
          ]
        )
        resource_ancestors = try(v.filter.resource_ancestors, null)
        services           = try(v.filter.services, null)
        subaccounts        = try(v.filter.subaccounts, null)
      }
      threshold_rules = [
        for vv in try(v.threshold_rules, []) : merge({
          percent          = null
          forecasted_spend = null
        }, vv)
      ]
      update_rules = {
        for kk, vv in try(v.update_rules, {}) : kk => merge({
          disable_default_iam_recipients   = null
          monitoring_notification_channels = null
          pubsub_topic                     = null
        }, vv)
      }
    })
  }
}
",locals,18,20.0,dbabfb9ae0c7fe7395ea51ae6fa50aaa6c652c32,7f8d2834b3e0fea6c56a6af1122534c41d12ee91,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/dbabfb9ae0c7fe7395ea51ae6fa50aaa6c652c32/modules/project-factory/factory-budgets.tf#L18,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/7f8d2834b3e0fea6c56a6af1122534c41d12ee91/modules/project-factory/factory-budgets.tf#L20,2024-02-27 18:13:49+00:00,2024-03-19 15:50:06+00:00,2,0,0,1,0,1,0,0,0,0
https://github.com/SUSE/ha-sap-terraform-deployments,354,azure/image.tf,azure/image.tf,0,// todo,// TODO: this is an hack: replace iscsi name later,// TODO: this is an hack: replace iscsi name later,"resource ""azurerm_image"" ""monitoring"" {
  count               = var.iscsi_srv_uri != """" ? 1 : 0
  name                = ""monitoringSrvImg""
  location            = var.az_region
  resource_group_name = azurerm_resource_group.myrg.name

  os_disk {
    os_type  = ""Linux""
    os_state = ""Generalized""
    blob_uri = var.iscsi_srv_uri
    size_gb  = ""32""
  }

  tags = {
    workspace = terraform.workspace
  }
}
",resource,"resource ""azurerm_image"" ""monitoring"" {
  count               = var.monitoring_uri != """" ? 1 : 0
  name                = ""monitoringSrvImg""
  location            = var.az_region
  resource_group_name = azurerm_resource_group.myrg.name

  os_disk {
    os_type  = ""Linux""
    os_state = ""Generalized""
    blob_uri = var.monitoring_uri
    size_gb  = ""32""
  }

  tags = {
    workspace = terraform.workspace
  }
}
",resource,93,,5c0d2ffe158dbf6db6c58414cdbc56fa872b4197,9adcf152486838f9f5b600ead5e4ef373918a786,https://github.com/SUSE/ha-sap-terraform-deployments/blob/5c0d2ffe158dbf6db6c58414cdbc56fa872b4197/azure/image.tf#L93,https://github.com/SUSE/ha-sap-terraform-deployments/blob/9adcf152486838f9f5b600ead5e4ef373918a786/azure/image.tf,2019-09-05 00:01:31+02:00,2019-09-05 18:08:13+02:00,3,1,1,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,58,terraform/projects/govuk-security-groups/logging.tf,terraform/projects/infra-security-groups/logging.tf,1,# todo,# TODO: add rule for kibana from backends once those are created.,# TODO: add rule for kibana from backends once those are created.,"resource ""aws_security_group"" ""logging_elb"" {
  name        = ""${var.stackname}_logging_elb_access""
  vpc_id      = ""${data.terraform_remote_state.govuk_vpc.vpc_id}""
  description = ""Access the logging ELB""

  tags {
    Name = ""${var.stackname}_logging_elb_access""
  }
}
",resource,,,38,0.0,00346bc2ba10d116f3e41951070ef0ebe0d9085d,0527d5b230dc008ee687667c45d1280de00b40bc,https://github.com/alphagov/govuk-aws/blob/00346bc2ba10d116f3e41951070ef0ebe0d9085d/terraform/projects/govuk-security-groups/logging.tf#L38,https://github.com/alphagov/govuk-aws/blob/0527d5b230dc008ee687667c45d1280de00b40bc/terraform/projects/infra-security-groups/logging.tf#L0,2017-07-13 14:53:36+01:00,2017-09-19 20:14:08+01:00,3,2,0,1,0,1,0,0,1,0
https://github.com/kubernetes/k8s.io,243,infra/gcp/terraform/k8s-infra-kubernetes-io/main.tf,infra/gcp/terraform/k8s-infra-kubernetes-io/main.tf,0,# todo,"# calendar_period = ""MONTH"" # TODO: terraform doesn't support this?","# calendar_period = ""MONTH"" # TODO: terraform doesn't support this? 
 # exclude promotions, which is where our credits come from, since that zeros out cost","resource ""google_billing_budget"" ""k8s_infra"" {
  billing_account = data.google_billing_account.account.billing_account
  display_name = ""k8s-infra-monthly""
  budget_filter {
    # calendar_period = ""MONTH"" # TODO: terraform doesn't support this?
    # exclude promotions, which is where our credits come from, since that zeros out cost
    credit_types_treatment = ""INCLUDE_SPECIFIED_CREDITS""
    credit_types           = [
        ""SUSTAINED_USAGE_DISCOUNT"",
        ""DISCOUNT"",
        ""COMMITTED_USAGE_DISCOUNT"",
        ""FREE_TIER"",
        ""COMMITTED_USAGE_DISCOUNT_DOLLAR_BASE"",
        ""SUBSCRIPTION_BENEFIT"",
    ]
  }
  amount {
    specified_amount {
      currency_code = ""USD""
      units = ""250000"" # 3M/yr / 12mo
    }
  }
  all_updates_rule {
    # Don't send to users with Billing Account Administrators and
    # Billing Account Users IAM roles for the billing account
    disable_default_iam_recipients = true
    monitoring_notification_channels = [
      data.google_monitoring_notification_channel.sig_k8s_infra_leads.name
    ]
  }
  dynamic ""threshold_rules"" {
    for_each = toset([0.9, 1.0])
    content {
      threshold_percent = threshold_rules.value
    }
  }
}
",resource,the block associated got renamed or deleted,,107,,3d4fe9a599e378fe1ba8518f0517b5ca4126b181,348b73a1f3749e3becf6bc2433e0bfea6fda807d,https://github.com/kubernetes/k8s.io/blob/3d4fe9a599e378fe1ba8518f0517b5ca4126b181/infra/gcp/terraform/k8s-infra-kubernetes-io/main.tf#L107,https://github.com/kubernetes/k8s.io/blob/348b73a1f3749e3becf6bc2433e0bfea6fda807d/infra/gcp/terraform/k8s-infra-kubernetes-io/main.tf,2021-10-14 12:00:26-07:00,2021-10-14 15:18:11-07:00,2,1,0,1,1,0,0,0,0,0
https://github.com/pingcap/tidb-operator,45,deploy/aws/tidb-operator/main.tf,deploy/modules/aws/tidb-operator/main.tf,1,hack,# we have the following hack,"# kubernetes and helm providers rely on EKS, but terraform provider doesn't support depends_on 
 # follow this link https://github.com/hashicorp/terraform/issues/2430#issuecomment-370685911 
 # we have the following hack","resource ""local_file"" ""kubeconfig"" {
  depends_on        = [module.eks]
  sensitive_content = module.eks.kubeconfig
  filename          = module.eks.kubeconfig_filename
}
",resource,"resource ""local_file"" ""kubeconfig"" {
  depends_on        = [module.eks]
  sensitive_content = module.eks.kubeconfig
  filename          = module.eks.kubeconfig_filename
}
",resource,28,33.0,58095783adeb0ca30ecdf094a7e8db7f17fb5919,1a6d49b25efccbb6fe03c3ec7caa6258f76f685a,https://github.com/pingcap/tidb-operator/blob/58095783adeb0ca30ecdf094a7e8db7f17fb5919/deploy/aws/tidb-operator/main.tf#L28,https://github.com/pingcap/tidb-operator/blob/1a6d49b25efccbb6fe03c3ec7caa6258f76f685a/deploy/modules/aws/tidb-operator/main.tf#L33,2019-07-03 11:55:46+08:00,2020-05-11 11:29:58+08:00,6,0,1,1,1,0,0,0,0,0
https://github.com/wireapp/wire-server-deploy,71,terraform/examples/wire-server-deploy-offline-hetzner/main.tf,terraform/examples/wire-server-deploy-offline-hetzner/main.tf,0,# todo,# TODO: IPv6,# TODO: IPv6,"locals {
  rfc1918_cidr        = ""10.0.0.0/8""
  kubenode_count      = 3
  minio_count         = 2
  elasticsearch_count = 2
  cassandra_count     = 3
  restund_count       = 2
  ssh_keys            = [hcloud_ssh_key.adminhost.name]

  # TODO: IPv6
  disable_network_cfg = <<-EOF
  #cloud-config
  runcmd:

    # Allow DNS
    - iptables -A OUTPUT -o eth0 -p udp --dport 53  -j ACCEPT
    - ip6tables -A OUTPUT -o eth0 -p udp --dport 53  -j ACCEPT

    # Allow NTP
    - iptables -A OUTPUT -o eth0 -p udp --dport 123 -j ACCEPT
    - ip6tables -A OUTPUT -o eth0 -p udp --dport 123 -j ACCEPT

    # Drop all other traffic
    - iptables -A OUTPUT -o eth0 -j DROP
    - ip6tables -A OUTPUT -o eth0 -j DROP

  EOF
}
",locals,"locals {
  rfc1918_cidr        = ""10.0.0.0/8""
  kubenode_count      = 3
  minio_count         = 2
  elasticsearch_count = 2
  cassandra_count     = 3
  restund_count       = 2
  ssh_keys            = [hcloud_ssh_key.adminhost.name]

  # TODO: IPv6
  disable_network_cfg = <<-EOF
  #cloud-config
  runcmd:

    # Allow DNS
    - iptables -A OUTPUT -o eth0 -p udp --dport 53  -j ACCEPT
    - ip6tables -A OUTPUT -o eth0 -p udp --dport 53  -j ACCEPT

    # Allow NTP
    - iptables -A OUTPUT -o eth0 -p udp --dport 123 -j ACCEPT
    - ip6tables -A OUTPUT -o eth0 -p udp --dport 123 -j ACCEPT

    # Drop all other traffic
    - iptables -A OUTPUT -o eth0 -j DROP
    - ip6tables -A OUTPUT -o eth0 -j DROP

  EOF
}
",locals,10,10.0,b7ab89140674e4ed5db56509e60b2b6c60d88900,ecea454794c466c81e910883a6a2cf67dda457ce,https://github.com/wireapp/wire-server-deploy/blob/b7ab89140674e4ed5db56509e60b2b6c60d88900/terraform/examples/wire-server-deploy-offline-hetzner/main.tf#L10,https://github.com/wireapp/wire-server-deploy/blob/ecea454794c466c81e910883a6a2cf67dda457ce/terraform/examples/wire-server-deploy-offline-hetzner/main.tf#L10,2021-04-20 13:14:17+02:00,2023-08-02 08:32:44+01:00,4,0,0,0,0,0,1,0,0,0
https://github.com/Worklytics/psoxy,121,infra/modules/aws-psoxy-instance/main.tf,infra/modules/aws-psoxy-instance/main.tf,0,# todo,# TODO: limit to SSM parameters in question,"# TODO: limit to SSM parameters in question 
 # ""Resource"": ""arn:aws:ssm:us-east-2:123456789012:parameter/prod-*""","resource ""aws_iam_policy"" ""policy"" {
  name        = ""${var.function_name}_ssmGetParameters""
  description = ""Allow lambda function role to read SSM parameters""

  policy = jsonencode(
{
  ""Version"": ""2012-10-17"",
  ""Statement"": [
    {
      ""Action"": [
        ""ssm:GetParameter*""
      ],
      ""Effect"": ""Allow"",
      ""Resource"": ""*""
      # TODO: limit to SSM parameters in question
      # ""Resource"": ""arn:aws:ssm:us-east-2:123456789012:parameter/prod-*""
    }
  ]
})

}
",resource,"resource ""aws_iam_policy"" ""policy"" {
  name        = ""${var.function_name}_ssmGetParameters""
  description = ""Allow lambda function role to read SSM parameters""

  policy = jsonencode(
    {
      ""Version"" : ""2012-10-17"",
      ""Statement"" : [
        {
          ""Action"" : [
            ""ssm:GetParameter*""
          ],
          ""Effect"" : ""Allow"",
          ""Resource"" : ""arn:aws:ssm:${var.region}:${var.aws_account_id}:parameter/*""
        }
      ]
  })
}
",resource,101,,3f3e920ccb3225be2ee885e6f3b9d10902ccc8a4,117af0cb45dab7c468732cc2219e354c4929e460,https://github.com/Worklytics/psoxy/blob/3f3e920ccb3225be2ee885e6f3b9d10902ccc8a4/infra/modules/aws-psoxy-instance/main.tf#L101,https://github.com/Worklytics/psoxy/blob/117af0cb45dab7c468732cc2219e354c4929e460/infra/modules/aws-psoxy-instance/main.tf,2022-01-11 16:22:58-08:00,2022-05-09 17:19:18-07:00,38,1,0,0,0,1,0,0,0,0
https://github.com/CDCgov/prime-simplereport,39,ops/services/postgres_db/main.tf,ops/services/postgres_db/main.tf,0,// todo,// TODO: replace with commented-out line below when removing old DB config,// TODO: replace with commented-out line below when removing old DB config,"resource ""azurerm_postgresql_flexible_server"" ""db"" {
  name                = ""simple-report-${var.env}-flexible-db""
  location            = var.rg_location
  resource_group_name = var.rg_name
  sku_name            = var.env == ""prod"" ? ""MO_Standard_E8ds_v4"" : ""MO_Standard_E4ds_v4""
  version             = ""13""
  delegated_subnet_id = var.subnet_id
  private_dns_zone_id = var.dns_zone_id

  // TODO: replace with commented-out line below when removing old DB config
  administrator_login = ""simple_report""
  //administrator_login    = var.administrator_login
  administrator_password = data.azurerm_key_vault_secret.db_password.value

  storage_mb                   = 524288 // 512 GB
  backup_retention_days        = 7
  geo_redundant_backup_enabled = false

  tags = var.tags

  // Time is Eastern
  maintenance_window {
    day_of_week  = 0
    start_hour   = 0
    start_minute = 0
  }

  # See note at https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/postgresql_flexible_server#high_availability
  lifecycle {
    ignore_changes = [
      zone,
      high_availability.0.standby_availability_zone
    ]
  }
}
",resource,"resource ""azurerm_postgresql_flexible_server"" ""db"" {
  name                = ""simple-report-${var.env}-flexible-db""
  location            = var.rg_location
  resource_group_name = var.rg_name
  sku_name            = var.env == ""prod"" ? ""MO_Standard_E8ds_v4"" : ""MO_Standard_E4ds_v4""
  version             = ""13""
  delegated_subnet_id = var.subnet_id


  administrator_login    = var.administrator_login
  administrator_password = data.azurerm_key_vault_secret.db_password.value

  storage_mb                   = 524288 // 512 GB
  backup_retention_days        = 7
  geo_redundant_backup_enabled = false

  tags = var.tags

  // Time is Eastern
  maintenance_window {
    day_of_week  = 0
    start_hour   = 0
    start_minute = 0
  }

  # See note at https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/postgresql_flexible_server#high_availability
  lifecycle {
    ignore_changes = [
      zone,
      high_availability.0.standby_availability_zone
    ]
  }
}
",resource,77,,3e4185fa549937cff9213c325bc0fee780e41eb0,fb9a18eb71f31044ca7a58958a25dea489263ca7,https://github.com/CDCgov/prime-simplereport/blob/3e4185fa549937cff9213c325bc0fee780e41eb0/ops/services/postgres_db/main.tf#L77,https://github.com/CDCgov/prime-simplereport/blob/fb9a18eb71f31044ca7a58958a25dea489263ca7/ops/services/postgres_db/main.tf,2022-02-16 12:59:39-05:00,2022-04-28 23:27:57-04:00,2,1,1,1,0,1,0,0,0,0
https://github.com/alphagov/govuk-aws,845,terraform/projects/app-elasticsearch6/main.tf,terraform/projects/app-elasticsearch6/main.tf,0,# todo,# TODO: change the default to 3 after the first deploy,# TODO: change the default to 3 after the first deploy,"variable ""elasticsearch6_master_instance_count"" {
  type        = ""string""
  description = ""Number of dedicated master nodes in the cluster""
  default     = ""2""
}
",variable,the block associated got renamed or deleted,,63,,cc6d4e4b85c01b2f75e322ff70b212c45ff29834,4357f2d981e7f59c9ba3dc7858196714b4851628,https://github.com/alphagov/govuk-aws/blob/cc6d4e4b85c01b2f75e322ff70b212c45ff29834/terraform/projects/app-elasticsearch6/main.tf#L63,https://github.com/alphagov/govuk-aws/blob/4357f2d981e7f59c9ba3dc7858196714b4851628/terraform/projects/app-elasticsearch6/main.tf,2019-05-31 12:49:39+01:00,2023-08-08 15:01:01+01:00,13,1,1,1,0,0,0,1,0,0
https://github.com/Worklytics/psoxy,827,infra/examples-dev/aws/variables.tf,infra/examples-dev/aws/variables.tf,0,# todo,# TODO: rethink this schema before we publish this,# TODO: rethink this schema before we publish this,"variable ""lookup_table_builders"" {
  type = map(object({
    input_connector_id            = string
    sanitized_accessor_role_names = list(string)
    rules = object({
      pseudonymFormat       = string
      columnsToRedact       = list(string)
      columnsToInclude      = list(string)
      columnsToPseudonymize = list(string)
      columnsToDuplicate    = map(string)
      columnsToRename       = map(string)
    })
  }))
  default = {
    #    ""hris-lookup"" = {
    #      input_connector_id = ""hris"",
    #      sanitized_accessor_role_names = [
    #        # ADD LIST OF NAMES OF YOUR AWS ROLES WHICH CAN READ LOOKUP TABLE
    #      ],
    #      rules       = {
    #        pseudonym_format = ""URL_SAFE_TOKEN""
    #        columnsToRedact       = [
    #          ""employee_email"",
    #          ""manager_id"",
    #          ""manager_email"",
    #        ]
    #        columnsToPseudonymize = [
    #          ""employee_id"", # primary key
    #        ]
    #        columnsToDuplicate   = {
    #          ""employee_id"" = ""employee_id_orig""
    #        }
    #        columnsToRename      = {}
    #        columnsToInclude     = null
    #      }
    #
    #    }
  }
}
",variable,"variable ""lookup_table_builders"" {
  type = map(object({
    input_connector_id            = string
    sanitized_accessor_role_names = list(string)
    rules = object({
      pseudonymFormat       = optional(string, ""URL_SAFE_TOKEN"")
      columnsToRedact       = optional(list(string))
      columnsToInclude      = optional(list(string))
      columnsToPseudonymize = optional(list(string))
      columnsToDuplicate    = optional(map(string))
      columnsToRename       = optional(map(string))
    })
  }))
  default = {
    #    ""hris-lookup"" = {
    #      input_connector_id = ""hris"",
    #      sanitized_accessor_role_names = [
    #        # ADD LIST OF NAMES OF YOUR AWS ROLES WHICH CAN READ LOOKUP TABLE
    #      ],
    #      rules       = {
    #        pseudonym_format = ""URL_SAFE_TOKEN""
    #        columnsToRedact       = [
    #          ""employee_email"",
    #          ""manager_id"",
    #          ""manager_email"",
    #        ]
    #        columnsToPseudonymize = [
    #          ""employee_id"", # primary key
    #        ]
    #        columnsToDuplicate   = {
    #          ""employee_id"" = ""employee_id_orig""
    #        }
    #        columnsToRename      = {}
    #        columnsToInclude     = null
    #      }
    #
    #    }
  }
}
",variable,186,256.0,674bb3cc40b9675953558a8fe9f432c2298ba3a0,338ff46f49075efb1124868a2e98d9b71dbcf03b,https://github.com/Worklytics/psoxy/blob/674bb3cc40b9675953558a8fe9f432c2298ba3a0/infra/examples-dev/aws/variables.tf#L186,https://github.com/Worklytics/psoxy/blob/338ff46f49075efb1124868a2e98d9b71dbcf03b/infra/examples-dev/aws/variables.tf#L256,2023-03-22 16:22:58-07:00,2023-12-29 21:19:18-08:00,15,0,1,1,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-vpc-service-controls,3,examples/simple_example/variables.tf,examples/simple_example/variables.tf,0,# todo,## TODO: remove after test,## TODO: remove after test,"variable ""policy_name"" {
  description = ""The policy's name.""

  ## TODO: remove after test
  default = """"
}
",variable,"variable ""policy_name"" {
  description = ""The policy's name.""
}
",variable,27,,07ef41e99d7389c0b4a31c4a67a12a7ab02627bd,79819996404c4ad171ea8759e10b83a6cfd36df0,https://github.com/terraform-google-modules/terraform-google-vpc-service-controls/blob/07ef41e99d7389c0b4a31c4a67a12a7ab02627bd/examples/simple_example/variables.tf#L27,https://github.com/terraform-google-modules/terraform-google-vpc-service-controls/blob/79819996404c4ad171ea8759e10b83a6cfd36df0/examples/simple_example/variables.tf,2019-04-26 00:29:28+00:00,2019-04-26 14:30:45+00:00,2,1,0,1,0,1,0,0,0,1
https://github.com/alphagov/govuk-aws,1050,terraform/projects/infra-security-groups/cache.tf,terraform/projects/infra-security-groups/cache.tf,0,crap,# Allow the prometheus instances to scrape router's metrics,# Allow the prometheus instances to scrape router's metrics,"resource ""aws_security_group_rule"" ""cache_ingress_prometheus_router"" {
  type      = ""ingress""
  from_port = 3055
  to_port   = 3055
  protocol  = ""tcp""

  # Which security group is the rule assigned to
  security_group_id = ""${aws_security_group.cache.id}""

  # Which security group can use this rule
  source_security_group_id = ""${aws_security_group.prometheus.id}""
}
",resource,,,177,0.0,2f98d8ddca4f860b5ffa0cd1fc2ec36cc35b7b9d,c56537748dc97bd5618840bb62b795aebd3bf4cf,https://github.com/alphagov/govuk-aws/blob/2f98d8ddca4f860b5ffa0cd1fc2ec36cc35b7b9d/terraform/projects/infra-security-groups/cache.tf#L177,https://github.com/alphagov/govuk-aws/blob/c56537748dc97bd5618840bb62b795aebd3bf4cf/terraform/projects/infra-security-groups/cache.tf#L0,2020-03-05 15:48:39+00:00,2023-05-12 17:01:25+01:00,5,2,0,0,0,1,0,0,1,0
https://github.com/ministryofjustice/aws-root-account,6,terraform/organizations-accounts.tf,terraform/organizations-accounts.tf,0,hack,# This is a slightly hacky way to get email addresses for already configured accounts.,"# This is a slightly hacky way to get email addresses for already configured accounts. 
 # We should store all (including new) account email addresses in AWS Secrets Manager, 
 # rather than rely on this in the future.","data ""aws_organizations_organization"" ""root"" {}
",data,the block associated got renamed or deleted,,1,,5e53a40e86403ec063a74b9f9bd68864ea3c195a,9d8fb3bcfae2288a98498d3cc34a310bf918a287,https://github.com/ministryofjustice/aws-root-account/blob/5e53a40e86403ec063a74b9f9bd68864ea3c195a/terraform/organizations-accounts.tf#L1,https://github.com/ministryofjustice/aws-root-account/blob/9d8fb3bcfae2288a98498d3cc34a310bf918a287/terraform/organizations-accounts.tf,2020-11-26 12:48:39+00:00,2020-12-18 12:46:23+00:00,9,1,0,1,0,1,0,0,0,0
https://github.com/nasa/cumulus,15,variables.tf,variables.tf,0,todo,# TODO Add descriptions,"# TODO Add descriptions  
 # Required variables ","variable ""prefix"" {
  type = string
}
",variable,"variable ""prefix"" {
  type        = string
  description = ""Resource prefix unique to this deployment""
}
",variable,1,,d02dddacfe2488210b9a79990db5bbd8d20c39f8,0ea14e208a63ef4bdf1033d09f547ba89d3cecbe,https://github.com/nasa/cumulus/blob/d02dddacfe2488210b9a79990db5bbd8d20c39f8/variables.tf#L1,https://github.com/nasa/cumulus/blob/0ea14e208a63ef4bdf1033d09f547ba89d3cecbe/variables.tf,2019-07-22 14:25:58-04:00,2019-07-25 10:55:47-04:00,3,1,0,1,0,0,0,0,0,0
https://github.com/alphagov/govuk-aws,854,terraform/modules/aws/lb_listener_rules/main.tf,terraform/modules/aws/lb_listener_rules/main.tf,0,implement,"/** * ## Modules: aws/lb_listener_rules * * This module creates Load Balancer listener rules based on Host header and target groups for * an existing listener resource. * * If the parameter `autoscaling_group_name` is non empty, the module also creates an attachment * from each target group to the ASG with the specified name. * * Limitations: *  - The target group deregistration_delay, health_check_interval and health_check_timeout * values can be configured with variables, but will be the same for all the target groups *  - With Terraform we can't provide a 'count' or list for listener_rule condition blocks, * so at the moment only one condition can be specified per rule *  - At the moment this module only implements Host Header based rules*/","/** 
 * ## Modules: aws/lb_listener_rules 
 * 
 * This module creates Load Balancer listener rules based on Host header and target groups for 
 * an existing listener resource. 
 * 
 * If the parameter `autoscaling_group_name` is non empty, the module also creates an attachment 
 * from each target group to the ASG with the specified name. 
 * 
 * Limitations: 
 *  - The target group deregistration_delay, health_check_interval and health_check_timeout 
 * values can be configured with variables, but will be the same for all the target groups 
 *  - With Terraform we can't provide a 'count' or list for listener_rule condition blocks, 
 * so at the moment only one condition can be specified per rule 
 *  - At the moment this module only implements Host Header based rules 
 */ ","variable ""default_tags"" {
  type        = ""map""
  description = ""Additional resource tags""
  default     = {}
}
",variable,"variable ""default_tags"" {
  type        = map(string)
  description = ""Additional resource tags""
  default     = {}
}
",variable,1,1.0,a272a6f68c811aa9bb956809fd9e2caec8fa8089,7a0cb9b14717825fe20ec66dde2591851d2de47b,https://github.com/alphagov/govuk-aws/blob/a272a6f68c811aa9bb956809fd9e2caec8fa8089/terraform/modules/aws/lb_listener_rules/main.tf#L1,https://github.com/alphagov/govuk-aws/blob/7a0cb9b14717825fe20ec66dde2591851d2de47b/terraform/modules/aws/lb_listener_rules/main.tf#L1,2019-06-12 17:18:39+01:00,2023-12-01 16:46:15+00:00,10,0,0,1,1,0,1,0,0,0
https://github.com/chanzuckerberg/cztack,94,aws-cloudfront-logs-bucket/outputs.tf,aws-cloudfront-logs-bucket/outputs.tf,0,hack,// HACK(el): we do this to hint TF dependency graph since modules can't depend_on,// HACK(el): we do this to hint TF dependency graph since modules can't depend_on,"output ""name"" {
  value = module.aws-cloudfront-logs-bucket.name
}
",output,"output ""name"" {
  value = module.aws-cloudfront-logs-bucket.name
}
",output,1,1.0,d87b0071e7729697680297d70284c649a0cf13cb,ec0aea5167b9ae64529cdac2441a59b67424f040,https://github.com/chanzuckerberg/cztack/blob/d87b0071e7729697680297d70284c649a0cf13cb/aws-cloudfront-logs-bucket/outputs.tf#L1,https://github.com/chanzuckerberg/cztack/blob/ec0aea5167b9ae64529cdac2441a59b67424f040/aws-cloudfront-logs-bucket/outputs.tf#L1,2020-07-08 10:19:24-07:00,2024-03-27 14:09:21-04:00,2,0,0,1,1,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1639,fast/stages/3-gke-multitenant/dev/variables.tf,fast/stages/3-gke-multitenant/dev/variables.tf,0,todo,# TODO add kube state metrics,"# TODO add kube state metrics  
 # Google Cloud Managed Service for Prometheus","variable ""clusters"" {
  description = ""Clusters configuration. Refer to the gke-cluster-standard module for type details.""
  type = map(object({
    cluster_autoscaling = optional(any)
    description         = optional(string)
    enable_addons = optional(any, {
      horizontal_pod_autoscaling = true, http_load_balancing = true
    })
    enable_features = optional(any, {
      workload_identity = true
    })
    issue_client_certificate = optional(bool, false)
    labels                   = optional(map(string))
    location                 = string
    logging_config = optional(object({
      enable_system_logs             = optional(bool, true)
      enable_workloads_logs          = optional(bool, true)
      enable_api_server_logs         = optional(bool, false)
      enable_scheduler_logs          = optional(bool, false)
      enable_controller_manager_logs = optional(bool, false)
    }), {})
    maintenance_config = optional(any, {
      daily_window_start_time = ""03:00""
      recurring_window        = null
      maintenance_exclusion   = []
    })
    max_pods_per_node  = optional(number, 110)
    min_master_version = optional(string)
    monitoring_config = optional(object({
      enable_system_metrics = optional(bool, true)

      # Control plane metrics
      enable_api_server_metrics         = optional(bool, false)
      enable_controller_manager_metrics = optional(bool, false)
      enable_scheduler_metrics          = optional(bool, false)

      # TODO add kube state metrics

      # Google Cloud Managed Service for Prometheus
      enable_managed_prometheus = optional(bool, true)
    }), {})
    node_locations         = optional(list(string))
    private_cluster_config = optional(any)
    release_channel        = optional(string)
    vpc_config = object({
      subnetwork = string
      network    = optional(string)
      secondary_range_blocks = optional(object({
        pods     = string
        services = string
      }))
      secondary_range_names = optional(object({
        pods     = optional(string, ""pods"")
        services = optional(string, ""services"")
      }))
      master_authorized_ranges = optional(map(string))
      master_ipv4_cidr_block   = optional(string)
    })
  }))
  default  = {}
  nullable = false
}
",variable,"variable ""clusters"" {
  description = ""Clusters configuration. Refer to the gke-cluster-standard module for type details.""
  type = map(object({
    cluster_autoscaling = optional(any)
    description         = optional(string)
    enable_addons = optional(any, {
      horizontal_pod_autoscaling = true, http_load_balancing = true
    })
    enable_features = optional(any, {
      workload_identity = true
    })
    issue_client_certificate = optional(bool, false)
    labels                   = optional(map(string))
    location                 = string
    logging_config = optional(object({
      enable_system_logs             = optional(bool, true)
      enable_workloads_logs          = optional(bool, true)
      enable_api_server_logs         = optional(bool, false)
      enable_scheduler_logs          = optional(bool, false)
      enable_controller_manager_logs = optional(bool, false)
    }), {})
    maintenance_config = optional(any, {
      daily_window_start_time = ""03:00""
      recurring_window        = null
      maintenance_exclusion   = []
    })
    max_pods_per_node  = optional(number, 110)
    min_master_version = optional(string)
    monitoring_config = optional(object({
      enable_system_metrics = optional(bool, true)

      # (Optional) control plane metrics
      enable_api_server_metrics         = optional(bool, false)
      enable_controller_manager_metrics = optional(bool, false)
      enable_scheduler_metrics          = optional(bool, false)

      # (Optional) kube state metrics
      enable_daemonset_metrics   = optional(bool, false)
      enable_deployment_metrics  = optional(bool, false)
      enable_hpa_metrics         = optional(bool, false)
      enable_pod_metrics         = optional(bool, false)
      enable_statefulset_metrics = optional(bool, false)
      enable_storage_metrics     = optional(bool, false)

      # Google Cloud Managed Service for Prometheus
      enable_managed_prometheus = optional(bool, true)
    }), {})
    node_locations         = optional(list(string))
    private_cluster_config = optional(any)
    release_channel        = optional(string)
    vpc_config = object({
      subnetwork = string
      network    = optional(string)
      secondary_range_blocks = optional(object({
        pods     = string
        services = string
      }))
      secondary_range_names = optional(object({
        pods     = optional(string, ""pods"")
        services = optional(string, ""services"")
      }))
      master_authorized_ranges = optional(map(string))
      master_ipv4_cidr_block   = optional(string)
    })
  }))
  default  = {}
  nullable = false
}
",variable,78,,b3dc91b5cd6375d9e589f149d98985a895fffbc2,6eb862a7754e9796cc26386227ea763c579edcdc,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/b3dc91b5cd6375d9e589f149d98985a895fffbc2/fast/stages/3-gke-multitenant/dev/variables.tf#L78,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/6eb862a7754e9796cc26386227ea763c579edcdc/fast/stages/3-gke-multitenant/dev/variables.tf,2023-09-14 23:25:57+01:00,2023-09-15 12:18:45+01:00,2,1,1,1,0,0,0,0,1,0
https://github.com/kubernetes/k8s.io,369,infra/aws/terraform/prow-build-cluster/variables.tf,infra/aws/terraform/prow-build-cluster/variables.tf,0,# todo,# TODO(xmudrii): This is a temporary variable. To be deleted after making canary cluster a build cluster.,"# TODO(xmudrii): This is a temporary variable. To be deleted after making canary cluster a build cluster. 
 # This variable defines if this cluster is used as a Prow build cluster.","variable ""prow_build_cluster"" {
  type        = bool
  description = ""Provision this cluster as a Prow build cluster.""
  default     = true
  nullable    = false
}
",variable,the block associated got renamed or deleted,,40,,77dd998553934196b4d573be7a2fb8bcf7d8b56f,3cf0ef275d51659e041a4663921016a73d4eb7b8,https://github.com/kubernetes/k8s.io/blob/77dd998553934196b4d573be7a2fb8bcf7d8b56f/infra/aws/terraform/prow-build-cluster/variables.tf#L40,https://github.com/kubernetes/k8s.io/blob/3cf0ef275d51659e041a4663921016a73d4eb7b8/infra/aws/terraform/prow-build-cluster/variables.tf,2023-04-25 13:38:58+02:00,2023-04-26 14:58:43+02:00,4,1,1,1,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-slo,14,modules/slo-pipeline/main.tf,modules/slo-pipeline/main.tf,0,todo,# TODO update version once event-function is released with new functionality,# TODO update version once event-function is released with new functionality,"module ""event_function"" {
  # TODO update version once event-function is released with new functionality
  source = ""github.com/taylorludwig/terraform-google-event-function?ref=feature%2F37-terraform-created-files-in-archive""
  # source  = ""terraform-google-modules/event-function/google""
  # version = ""~> 1.1""

  description            = ""SLO Exporter to BigQuery or Stackdriver Monitoring""
  name                   = var.function_name
  available_memory_mb    = var.function_memory
  project_id             = var.project_id
  region                 = var.region
  service_account_email  = local.service_account_email
  source_directory       = local.function_source_directory
  source_dependent_files = [local_file.exporters]
  bucket_name            = local.bucket_name
  runtime                = ""python37""
  timeout_s              = ""60""
  entry_point            = ""main""

  event_trigger = {
    event_type = ""providers/cloud.pubsub/eventTypes/topic.publish""
    resource   = ""projects/${var.project_id}/topics/${google_pubsub_topic.stream.name}""
  }
}
",module,"module ""event_function"" {
  source  = ""terraform-google-modules/event-function/google""
  version = ""~> 1.2""

  description            = ""SLO Exporter to BigQuery or Stackdriver Monitoring""
  name                   = var.function_name
  available_memory_mb    = var.function_memory
  project_id             = var.project_id
  region                 = var.region
  service_account_email  = local.service_account_email
  source_directory       = local.function_source_directory
  source_dependent_files = [local_file.exporters]
  bucket_name            = local.bucket_name
  runtime                = ""python37""
  timeout_s              = ""60""
  entry_point            = ""main""

  event_trigger = {
    event_type = ""providers/cloud.pubsub/eventTypes/topic.publish""
    resource   = ""projects/${var.project_id}/topics/${google_pubsub_topic.stream.name}""
  }
}
",module,49,,33d08bd605f74f3168020d48535152adda5dedd6,bc2231a36af0a89bf505e1da2fda8cc5210b8912,https://github.com/terraform-google-modules/terraform-google-slo/blob/33d08bd605f74f3168020d48535152adda5dedd6/modules/slo-pipeline/main.tf#L49,https://github.com/terraform-google-modules/terraform-google-slo/blob/bc2231a36af0a89bf505e1da2fda8cc5210b8912/modules/slo-pipeline/main.tf,2019-12-13 16:06:10-08:00,2019-12-18 10:43:18-08:00,2,1,1,1,1,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-kubernetes-engine,11,modules/safer-cluster/variables.tf,modules/safer-cluster/variables.tf,0,// todo,// TODO(mmontan): allow specifying which project to use,"// TODO(mmontan): allow specifying which project to use 
 // for reading images. ","variable ""service_account"" {
  type        = string
  description = ""The service account to run nodes as if not overridden in `node_pools`. The create_service_account variable default value (true) will cause a cluster-specific service account to be created.""
  default     = """"
}
",variable,"variable ""service_account"" {
  type        = string
  description = ""The service account to run nodes as if not overridden in `node_pools`. The create_service_account variable default value (true) will cause a cluster-specific service account to be created.""
  default     = """"
}
",variable,211,,e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5,5a194719faa144ad0a7ee578663d336358f5073c,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/e8688fce06b3a2aedb7f9df34b96d9f2eae4e7c5/modules/safer-cluster/variables.tf#L211,https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/5a194719faa144ad0a7ee578663d336358f5073c/modules/safer-cluster/variables.tf,2019-10-04 15:21:33-07:00,2019-11-13 15:10:12-06:00,6,1,1,0,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-bigquery,7,variables.tf,variables.tf,0,#todo,#TODO: update the descriptions and change the defaults if needed,"/** 
 * Copyright 2018 Google LLC 
 * 
 * Licensed under the Apache License, Version 2.0 (the ""License""); 
 * you may not use this file except in compliance with the License. 
 * You may obtain a copy of the License at 
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0 
 * 
 * Unless required by applicable law or agreed to in writing, software 
 * distributed under the License is distributed on an ""AS IS"" BASIS, 
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 * See the License for the specific language governing permissions and 
 * limitations under the License. 
 */  
 #TODO: update the descriptions and change the defaults if needed","variable ""dataset_id"" {
  description = ""update""
}
",variable,"variable ""dataset_id"" {
  description = ""Unique ID for the dataset being provisioned""
}
",variable,17,,d56aa2c9a80343d60eed3e1a7d24962be31ee0b6,a7966ae4afc7bb73842fb9fd6f0f708b359cf36e,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/d56aa2c9a80343d60eed3e1a7d24962be31ee0b6/variables.tf#L17,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/a7966ae4afc7bb73842fb9fd6f0f708b359cf36e/variables.tf,2018-11-20 10:30:15-05:00,2019-01-28 12:41:47-05:00,5,1,0,1,0,0,0,0,0,0
https://github.com/compiler-explorer/infra,161,terraform/security.tf,terraform/security.tf,0,# todo,# TODO! hardcoded from another,"    ""CI""          = ""sg-0b6cec49789cbf1a8""  # TODO! hardcoded from another","resource ""aws_security_group_rule"" ""efs_inbound"" {
  for_each                 = {
    ""Admin""       = aws_security_group.AdminNode.id,
    ""Compilation"" = aws_security_group.CompilerExplorer.id
    ""Builder""     = aws_security_group.Builder.id
    ""CI""          = ""sg-0b6cec49789cbf1a8""  # TODO! hardcoded from another
  }
  security_group_id        = aws_security_group.efs.id
  type                     = ""ingress""
  from_port                = 0
  to_port                  = 65535
  protocol                 = ""all""
  source_security_group_id = each.value
  description              = ""${each.key} node acccess""
}
",resource,"resource ""aws_security_group_rule"" ""efs_inbound"" {
  for_each                 = {
    ""Admin""       = aws_security_group.AdminNode.id,
    ""Compilation"" = aws_security_group.CompilerExplorer.id
    ""Builder""     = aws_security_group.Builder.id
  }
  security_group_id        = aws_security_group.efs.id
  type                     = ""ingress""
  from_port                = 0
  to_port                  = 65535
  protocol                 = ""all""
  source_security_group_id = each.value
  description              = ""${each.key} node acccess""
}
",resource,419,,31bbd3c4f99d686ec26a81b00435dcb6c7538f7f,f6a403d5c5294ac511990056b94a449e34f0fbdf,https://github.com/compiler-explorer/infra/blob/31bbd3c4f99d686ec26a81b00435dcb6c7538f7f/terraform/security.tf#L419,https://github.com/compiler-explorer/infra/blob/f6a403d5c5294ac511990056b94a449e34f0fbdf/terraform/security.tf,2021-10-27 08:34:58-05:00,2021-10-27 08:55:44-05:00,2,1,0,1,0,1,0,1,0,0
https://github.com/kubernetes/k8s.io,342,infra/gcp/terraform/modules/oci-proxy/oci-proxy.tf,infra/gcp/terraform/modules/oci-proxy/main.tf,1,// todo,// TODO: switch DEFAULT_AWS_BASE_URL to cloudfront or else refine the region mapping,"// TODO: switch DEFAULT_AWS_BASE_URL to cloudfront or else refine the region mapping 
 // GCP asia-east1 is Changhua County, Taiwan","locals {
  cloud_run_config = {
    asia-east1 = {
      // TODO: switch DEFAULT_AWS_BASE_URL to cloudfront or else refine the region mapping
      // GCP asia-east1 is Changhua County, Taiwan
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-southeast-1 is Singapore
          value = ""https://prod-registry-k8s-io-ap-southeast-1.s3.dualstack.ap-southeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-east1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-northeast1 is Tokyo, Japan
    asia-northeast1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-northeast-1 is Tokyo
          value = ""https://prod-registry-k8s-io-ap-northeast-1.s3.dualstack.ap-northeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-northeast1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-northeast2 is Osaka, Japan
    asia-northeast2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-northeast-1 is Tokyo
          value = ""https://prod-registry-k8s-io-ap-northeast-1.s3.dualstack.ap-northeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-northeast2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-south1 is Mumbai, India
    asia-south1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-south-1 is Mumbai
          value = ""https://prod-registry-k8s-io-ap-south-1.s3.dualstack.ap-south-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-south1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP australia-southeast1 is Sydney
    australia-southeast1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-southeast-1 is Singapore
          value = ""https://prod-registry-k8s-io-ap-southeast-1.s3.dualstack.ap-southeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://australia-southeast1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-north1 is Hamina, Finland
    europe-north1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-north1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-southwest1 is Madrid, Spain
    europe-southwest1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-southwest1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west1 is St. Ghislain, Belgium
    europe-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west2 is London, UK
    europe-west2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-west-2 is London
          value = ""https://prod-registry-k8s-io-eu-west-2.s3.dualstack.eu-west-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west4 is Eemshaven, Netherlands
    europe-west4 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west4-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west8 is Milan, Italy
    europe-west8 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west8-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west9 is Paris, France
    europe-west9 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-west-2 is London
          value = ""https://prod-registry-k8s-io-eu-west-2.s3.dualstack.eu-west-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west9-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP southamerica-west1 is Santiago, Chile
    southamerica-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          // See: https://github.com/kubernetes/k8s.io/pull/4739/files#r1100667255
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://southamerica-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-central1 is Iowa, USA
    us-central1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-central1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east1 is South Carolina, USA
    us-east1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east4 is Virginia, USA
    us-east4 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east4-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east5 is Ohio, USA
    us-east5 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east5-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-south1 is Texas, USA
    us-south1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-south1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-west1 is Oregon, USA
    us-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-west-2 is Oregon, USA
          value = ""https://prod-registry-k8s-io-us-west-2.s3.dualstack.us-west-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-west2 is California, USA
    us-west2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-west-1 is California, USA
          value = ""https://prod-registry-k8s-io-us-west-1.s3.dualstack.us-west-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-west2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
  }
}",locals,"locals {
  cloud_run_config = {
    asia-east1 = {
      // GCP asia-east1 is Changhua County, Taiwan
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS Cloudfront
          value = ""https://d39mqg4b1dx9z1.cloudfront.net"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-east1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-northeast1 is Tokyo, Japan
    asia-northeast1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-northeast-1 is Tokyo
          value = ""https://prod-registry-k8s-io-ap-northeast-1.s3.dualstack.ap-northeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-northeast1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-northeast2 is Osaka, Japan
    asia-northeast2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-northeast-1 is Tokyo
          value = ""https://prod-registry-k8s-io-ap-northeast-1.s3.dualstack.ap-northeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-northeast2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP asia-south1 is Mumbai, India
    asia-south1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-south-1 is Mumbai
          value = ""https://prod-registry-k8s-io-ap-south-1.s3.dualstack.ap-south-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://asia-south1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP australia-southeast1 is Sydney
    australia-southeast1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS ap-southeast-1 is Singapore
          value = ""https://prod-registry-k8s-io-ap-southeast-1.s3.dualstack.ap-southeast-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://australia-southeast1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-north1 is Hamina, Finland
    europe-north1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-north1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-southwest1 is Madrid, Spain
    europe-southwest1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-southwest1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west1 is St. Ghislain, Belgium
    europe-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS Cloudfront
          value = ""https://d39mqg4b1dx9z1.cloudfront.net"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west10 is Berlin, Germany
    europe-west10 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west10-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west2 is London, UK
    europe-west2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-west-1 is Ireland
          value = ""https://prod-registry-k8s-io-eu-west-1.s3.dualstack.eu-west-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west3 is Frankfurt, Germany
    europe-west3 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west3-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west4 is Eemshaven, Netherlands
    europe-west4 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS Cloudfront
          value = ""https://d39mqg4b1dx9z1.cloudfront.net"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west4-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west8 is Milan, Italy
    europe-west8 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-central-1 is Frankfurt
          value = ""https://prod-registry-k8s-io-eu-central-1.s3.dualstack.eu-central-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west8-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP europe-west9 is Paris, France
    europe-west9 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS eu-west-1 is in Ireland
          value = ""https://prod-registry-k8s-io-eu-west-1.s3.dualstack.eu-west-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://europe-west9-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP southamerica-west1 is Santiago, Chile
    southamerica-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          // See: https://github.com/kubernetes/k8s.io/pull/4739/files#r1100667255
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://southamerica-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-central1 is Iowa, USA
    us-central1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-central1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east1 is South Carolina, USA
    us-east1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east4 is Virginia, USA
    us-east4 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-1 is Virginia, USA
          value = ""https://prod-registry-k8s-io-us-east-1.s3.dualstack.us-east-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east4-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-east5 is Ohio, USA
    us-east5 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-east5-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-south1 is Texas, USA
    us-south1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-east-2 is Ohio, USA
          value = ""https://prod-registry-k8s-io-us-east-2.s3.dualstack.us-east-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-south1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-west1 is Oregon, USA
    us-west1 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-west-2 is Oregon, USA
          value = ""https://prod-registry-k8s-io-us-west-2.s3.dualstack.us-west-2.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-west1-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
    // GCP us-west2 is California, USA
    us-west2 = {
      environment_variables = [
        {
          name = ""DEFAULT_AWS_BASE_URL"",
          // AWS us-west-1 is California, USA
          value = ""https://prod-registry-k8s-io-us-west-1.s3.dualstack.us-west-1.amazonaws.com"",
        },
        {
          name  = ""UPSTREAM_REGISTRY_ENDPOINT"",
          value = ""https://us-west2-docker.pkg.dev""
        },
        {
          name  = ""UPSTREAM_REGISTRY_PATH"",
          value = ""k8s-artifacts-prod/images""
        }
      ]
    }
  }
}
",locals,20,,ffbaa4eb3b652a9cc7520593cae83a8004ef88a3,3ca41f506262aed659a3a76877db17f1232618ba,https://github.com/kubernetes/k8s.io/blob/ffbaa4eb3b652a9cc7520593cae83a8004ef88a3/infra/gcp/terraform/modules/oci-proxy/oci-proxy.tf#L20,https://github.com/kubernetes/k8s.io/blob/3ca41f506262aed659a3a76877db17f1232618ba/infra/gcp/terraform/modules/oci-proxy/main.tf,2023-04-02 19:38:59-07:00,2024-01-30 23:09:46+01:00,7,1,0,1,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1759,modules/net-lb-app-ext-regional/backend-service.tf,modules/net-lb-app-ext-regional/backend-service.tf,0,# todo,# TODO(jccb): add security_policy block,"# TODO(jccb): add security_policy block 
 # TODO(jccb): add connection_tracking_policy block ","resource ""google_compute_region_backend_service"" ""default"" {
  provider = google-beta
  for_each = var.backend_service_configs
  project = (
    each.value.project_id == null
    ? var.project_id
    : each.value.project_id
  )
  name                            = ""${var.name}-${each.key}""
  region                          = var.region
  description                     = var.description
  affinity_cookie_ttl_sec         = each.value.affinity_cookie_ttl_sec
  connection_draining_timeout_sec = each.value.connection_draining_timeout_sec
  enable_cdn                      = each.value.enable_cdn
  health_checks = length(each.value.health_checks) == 0 ? null : [
    for k in each.value.health_checks : lookup(local.hc_ids, k, k)
  ]
  # external regional load balancer is always EXTERNAL_MANAGER.
  # TODO(jccb): double check if this is true
  load_balancing_scheme = ""EXTERNAL_MANAGED""
  #TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL
  port_name = (
    each.value.port_name == null
    ? lower(each.value.protocol == null ? var.protocol : each.value.protocol)
    : each.value.port_name
  )
  protocol = (
    each.value.protocol == null ? var.protocol : each.value.protocol
  )
  session_affinity = each.value.session_affinity
  timeout_sec      = each.value.timeout_sec

  dynamic ""backend"" {
    for_each = { for b in coalesce(each.value.backends, []) : b.backend => b }
    content {
      group           = lookup(local.group_ids, backend.key, backend.key)
      balancing_mode  = backend.value.balancing_mode # UTILIZATION, RATE
      capacity_scaler = backend.value.capacity_scaler
      description     = backend.value.description
      max_connections = try(
        backend.value.max_connections.per_group, null
      )
      max_connections_per_endpoint = try(
        backend.value.max_connections.per_endpoint, null
      )
      max_connections_per_instance = try(
        backend.value.max_connections.per_instance, null
      )
      max_rate = try(
        backend.value.max_rate.per_group, null
      )
      max_rate_per_endpoint = try(
        backend.value.max_rate.per_endpoint, null
      )
      max_rate_per_instance = try(
        backend.value.max_rate.per_instance, null
      )
      max_utilization = backend.value.max_utilization
    }
  }

  dynamic ""cdn_policy"" {
    for_each = (
      each.value.cdn_policy == null ? [] : [each.value.cdn_policy]
    )
    iterator = cdn
    content {
      cache_mode                   = cdn.value.cache_mode
      client_ttl                   = cdn.value.client_ttl
      default_ttl                  = cdn.value.default_ttl
      max_ttl                      = cdn.value.max_ttl
      negative_caching             = cdn.value.negative_caching
      serve_while_stale            = cdn.value.serve_while_stale
      signed_url_cache_max_age_sec = cdn.value.signed_url_cache_max_age_sec
      dynamic ""cache_key_policy"" {
        for_each = (
          cdn.value.cache_key_policy == null
          ? []
          : [cdn.value.cache_key_policy]
        )
        iterator = ck
        content {
          include_host           = ck.value.include_host
          include_named_cookies  = ck.value.include_named_cookies
          include_protocol       = ck.value.include_protocol
          include_query_string   = ck.value.include_query_string
          query_string_blacklist = ck.value.query_string_blacklist
          query_string_whitelist = ck.value.query_string_whitelist
        }
      }
      dynamic ""negative_caching_policy"" {
        for_each = (
          cdn.value.negative_caching_policy == null
          ? []
          : [cdn.value.negative_caching_policy]
        )
        iterator = nc
        content {
          code = nc.value.code
          ttl  = nc.value.ttl
        }
      }
    }
  }

  dynamic ""circuit_breakers"" {
    for_each = (
      each.value.circuit_breakers == null ? [] : [each.value.circuit_breakers]
    )
    iterator = cb
    content {
      max_connections             = cb.value.max_connections
      max_pending_requests        = cb.value.max_pending_requests
      max_requests                = cb.value.max_requests
      max_requests_per_connection = cb.value.max_requests_per_connection
      max_retries                 = cb.value.max_retries
      dynamic ""connect_timeout"" {
        for_each = (
          cb.value.connect_timeout == null ? [] : [cb.value.connect_timeout]
        )
        content {
          seconds = connect_timeout.value.seconds
          nanos   = connect_timeout.value.nanos
        }
      }
    }
  }

  dynamic ""consistent_hash"" {
    for_each = (
      each.value.consistent_hash == null ? [] : [each.value.consistent_hash]
    )
    iterator = ch
    content {
      http_header_name  = ch.value.http_header_name
      minimum_ring_size = ch.value.minimum_ring_size
      dynamic ""http_cookie"" {
        for_each = ch.value.http_cookie == null ? [] : [ch.value.http_cookie]
        content {
          name = http_cookie.value.name
          path = http_cookie.value.path
          dynamic ""ttl"" {
            for_each = (
              http_cookie.value.ttl == null ? [] : [http_cookie.value.ttl]
            )
            content {
              seconds = ttl.value.seconds
              nanos   = ttl.value.nanos
            }
          }
        }
      }
    }
  }

  dynamic ""iap"" {
    for_each = each.value.iap_config == null ? [] : [each.value.iap_config]
    content {
      oauth2_client_id            = iap.value.oauth2_client_id
      oauth2_client_secret        = iap.value.oauth2_client_secret
      oauth2_client_secret_sha256 = iap.value.oauth2_client_secret_sha256
    }
  }

  dynamic ""log_config"" {
    for_each = each.value.log_sample_rate == null ? [] : [""""]
    content {
      enable      = true
      sample_rate = each.value.log_sample_rate
    }
  }

  dynamic ""outlier_detection"" {
    for_each = (
      each.value.outlier_detection == null ? [] : [each.value.outlier_detection]
    )
    iterator = od
    content {
      consecutive_errors                    = od.value.consecutive_errors
      consecutive_gateway_failure           = od.value.consecutive_gateway_failure
      enforcing_consecutive_errors          = od.value.enforcing_consecutive_errors
      enforcing_consecutive_gateway_failure = od.value.enforcing_consecutive_gateway_failure
      enforcing_success_rate                = od.value.enforcing_success_rate
      max_ejection_percent                  = od.value.max_ejection_percent
      success_rate_minimum_hosts            = od.value.success_rate_minimum_hosts
      success_rate_request_volume           = od.value.success_rate_request_volume
      success_rate_stdev_factor             = od.value.success_rate_stdev_factor
      dynamic ""base_ejection_time"" {
        for_each = (
          od.value.base_ejection_time == null ? [] : [od.value.base_ejection_time]
        )
        content {
          seconds = base_ejection_time.value.seconds
          nanos   = base_ejection_time.value.nanos
        }
      }
      dynamic ""interval"" {
        for_each = (
          od.value.interval == null ? [] : [od.value.interval]
        )
        content {
          seconds = interval.value.seconds
          nanos   = interval.value.nanos
        }
      }
    }
  }
}
",resource,"resource ""google_compute_region_backend_service"" ""default"" {
  provider = google-beta
  for_each = var.backend_service_configs
  project = (
    each.value.project_id == null
    ? var.project_id
    : each.value.project_id
  )
  name                            = ""${var.name}-${each.key}""
  region                          = var.region
  description                     = var.description
  affinity_cookie_ttl_sec         = each.value.affinity_cookie_ttl_sec
  connection_draining_timeout_sec = each.value.connection_draining_timeout_sec
  enable_cdn                      = each.value.enable_cdn
  health_checks = length(each.value.health_checks) == 0 ? null : [
    for k in each.value.health_checks : lookup(local.hc_ids, k, k)
  ]
  # external regional load balancer is always EXTERNAL_MANAGER.
  # TODO(jccb): double check if this is true
  load_balancing_scheme = ""EXTERNAL_MANAGED""
  #TODO(jccb): add locality_lb_policy with MAGLEV and WEIGHTED_MAGLEV when scheme EXTERNAL
  port_name = (
    each.value.port_name == null
    ? lower(each.value.protocol == null ? var.protocol : each.value.protocol)
    : each.value.port_name
  )
  protocol = (
    each.value.protocol == null ? var.protocol : each.value.protocol
  )
  session_affinity = each.value.session_affinity
  timeout_sec      = each.value.timeout_sec

  dynamic ""backend"" {
    for_each = { for b in coalesce(each.value.backends, []) : b.backend => b }
    content {
      group           = lookup(local.group_ids, backend.key, backend.key)
      balancing_mode  = backend.value.balancing_mode # UTILIZATION, RATE
      capacity_scaler = backend.value.capacity_scaler
      description     = backend.value.description
      max_connections = try(
        backend.value.max_connections.per_group, null
      )
      max_connections_per_endpoint = try(
        backend.value.max_connections.per_endpoint, null
      )
      max_connections_per_instance = try(
        backend.value.max_connections.per_instance, null
      )
      max_rate = try(
        backend.value.max_rate.per_group, null
      )
      max_rate_per_endpoint = try(
        backend.value.max_rate.per_endpoint, null
      )
      max_rate_per_instance = try(
        backend.value.max_rate.per_instance, null
      )
      max_utilization = backend.value.max_utilization
    }
  }

  dynamic ""cdn_policy"" {
    for_each = (
      each.value.cdn_policy == null ? [] : [each.value.cdn_policy]
    )
    iterator = cdn
    content {
      cache_mode                   = cdn.value.cache_mode
      client_ttl                   = cdn.value.client_ttl
      default_ttl                  = cdn.value.default_ttl
      max_ttl                      = cdn.value.max_ttl
      negative_caching             = cdn.value.negative_caching
      serve_while_stale            = cdn.value.serve_while_stale
      signed_url_cache_max_age_sec = cdn.value.signed_url_cache_max_age_sec
      dynamic ""cache_key_policy"" {
        for_each = (
          cdn.value.cache_key_policy == null
          ? []
          : [cdn.value.cache_key_policy]
        )
        iterator = ck
        content {
          include_host           = ck.value.include_host
          include_named_cookies  = ck.value.include_named_cookies
          include_protocol       = ck.value.include_protocol
          include_query_string   = ck.value.include_query_string
          query_string_blacklist = ck.value.query_string_blacklist
          query_string_whitelist = ck.value.query_string_whitelist
        }
      }
      dynamic ""negative_caching_policy"" {
        for_each = (
          cdn.value.negative_caching_policy == null
          ? []
          : [cdn.value.negative_caching_policy]
        )
        iterator = nc
        content {
          code = nc.value.code
          ttl  = nc.value.ttl
        }
      }
    }
  }

  dynamic ""circuit_breakers"" {
    for_each = (
      each.value.circuit_breakers == null ? [] : [each.value.circuit_breakers]
    )
    iterator = cb
    content {
      max_connections             = cb.value.max_connections
      max_pending_requests        = cb.value.max_pending_requests
      max_requests                = cb.value.max_requests
      max_requests_per_connection = cb.value.max_requests_per_connection
      max_retries                 = cb.value.max_retries
      dynamic ""connect_timeout"" {
        for_each = (
          cb.value.connect_timeout == null ? [] : [cb.value.connect_timeout]
        )
        content {
          seconds = connect_timeout.value.seconds
          nanos   = connect_timeout.value.nanos
        }
      }
    }
  }

  dynamic ""consistent_hash"" {
    for_each = (
      each.value.consistent_hash == null ? [] : [each.value.consistent_hash]
    )
    iterator = ch
    content {
      http_header_name  = ch.value.http_header_name
      minimum_ring_size = ch.value.minimum_ring_size
      dynamic ""http_cookie"" {
        for_each = ch.value.http_cookie == null ? [] : [ch.value.http_cookie]
        content {
          name = http_cookie.value.name
          path = http_cookie.value.path
          dynamic ""ttl"" {
            for_each = (
              http_cookie.value.ttl == null ? [] : [http_cookie.value.ttl]
            )
            content {
              seconds = ttl.value.seconds
              nanos   = ttl.value.nanos
            }
          }
        }
      }
    }
  }

  dynamic ""iap"" {
    for_each = each.value.iap_config == null ? [] : [each.value.iap_config]
    content {
      oauth2_client_id            = iap.value.oauth2_client_id
      oauth2_client_secret        = iap.value.oauth2_client_secret
      oauth2_client_secret_sha256 = iap.value.oauth2_client_secret_sha256
    }
  }

  dynamic ""log_config"" {
    for_each = each.value.log_sample_rate == null ? [] : [""""]
    content {
      enable      = true
      sample_rate = each.value.log_sample_rate
    }
  }

  dynamic ""outlier_detection"" {
    for_each = (
      each.value.outlier_detection == null ? [] : [each.value.outlier_detection]
    )
    iterator = od
    content {
      consecutive_errors                    = od.value.consecutive_errors
      consecutive_gateway_failure           = od.value.consecutive_gateway_failure
      enforcing_consecutive_errors          = od.value.enforcing_consecutive_errors
      enforcing_consecutive_gateway_failure = od.value.enforcing_consecutive_gateway_failure
      enforcing_success_rate                = od.value.enforcing_success_rate
      max_ejection_percent                  = od.value.max_ejection_percent
      success_rate_minimum_hosts            = od.value.success_rate_minimum_hosts
      success_rate_request_volume           = od.value.success_rate_request_volume
      success_rate_stdev_factor             = od.value.success_rate_stdev_factor
      dynamic ""base_ejection_time"" {
        for_each = (
          od.value.base_ejection_time == null ? [] : [od.value.base_ejection_time]
        )
        content {
          seconds = base_ejection_time.value.seconds
          nanos   = base_ejection_time.value.nanos
        }
      }
      dynamic ""interval"" {
        for_each = (
          od.value.interval == null ? [] : [od.value.interval]
        )
        content {
          seconds = interval.value.seconds
          nanos   = interval.value.nanos
        }
      }
    }
  }
}
",resource,39,39.0,8beb621e070226b7f11a82807a706170ae7040ea,8beb621e070226b7f11a82807a706170ae7040ea,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/8beb621e070226b7f11a82807a706170ae7040ea/modules/net-lb-app-ext-regional/backend-service.tf#L39,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/8beb621e070226b7f11a82807a706170ae7040ea/modules/net-lb-app-ext-regional/backend-service.tf#L39,2024-01-05 16:59:27+01:00,2024-01-05 16:59:27+01:00,1,0,0,1,0,1,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-rds,1,modules/db_parameter_group/main.tf,modules/db_parameter_group/main.tf,0,implement,// @todo: implement this,"// @todo: implement this 
 //  parameter = [""${var.parameters}""]  
 //  parameter = [ 
 //    { 
 //      name  = ""character_set_server"" 
 //      value = ""utf8"" 
 //    }, 
 //    { 
 //      name  = ""character_set_client"" 
 //      value = ""utf18"" 
 //    }, 
 //  ]","resource ""aws_db_parameter_group"" ""this"" {
  count = ""${var.count}""

  name_prefix = ""${var.name_prefix}""
  description = ""Database parameter group for ${var.identifier}""
  family      = ""${var.family}""

  // @todo: implement this
  //  parameter = [""${var.parameters}""]

  //  parameter = [
  //    {
  //      name  = ""character_set_server""
  //      value = ""utf8""
  //    },
  //    {
  //      name  = ""character_set_client""
  //      value = ""utf18""
  //    },
  //  ]
  parameter {
    name  = ""character_set_server""
    value = ""utf8""
  }
  parameter {
    name  = ""character_set_client""
    value = ""utf8""
  }
  tags = ""${merge(var.tags, map(""Name"", format(""%s"", var.identifier)))}""
}
",resource,"resource ""aws_db_parameter_group"" ""this"" {
  count = ""${var.count}""

  name_prefix = ""${var.name_prefix}""
  description = ""Database parameter group for ${var.identifier}""
  family      = ""${var.family}""

  parameter = [""${var.parameters}""]

  tags = ""${merge(var.tags, map(""Name"", format(""%s"", var.identifier)))}""
}
",resource,11,,3e6e7dd55518388b476de3f50202d9368e09b622,5cf5f93d63fe80488a68060ca207fbc6aefe77ee,https://github.com/terraform-aws-modules/terraform-aws-rds/blob/3e6e7dd55518388b476de3f50202d9368e09b622/modules/db_parameter_group/main.tf#L11,https://github.com/terraform-aws-modules/terraform-aws-rds/blob/5cf5f93d63fe80488a68060ca207fbc6aefe77ee/modules/db_parameter_group/main.tf,2017-09-13 22:43:28+02:00,2017-09-20 16:35:35-04:00,2,1,1,1,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-project-factory,110,modules/fabric-project/vars.tf,modules/fabric-project/variables.tf,1,fix,# TODO: revert to a single map once the following issue is fixed,"# TODO: revert to a single map once the following issue is fixed 
 # https://github.com/hashicorp/terraform/issues/12570 ","variable ""extra_bindings_roles"" {
  description = ""List of roles for additional IAM bindings, pair with members list below.""
  default     = []
}
",variable,"variable ""extra_bindings_roles"" {
  description = ""List of roles for additional IAM bindings, pair with members list below.""
  type        = list(string)
  default     = []
}
",variable,79,86.0,6a786a6d668df3a254ed64b83f3c5779cb6540f3,97eee8801f9c63456f814f90331d635dd8cea99a,https://github.com/terraform-google-modules/terraform-google-project-factory/blob/6a786a6d668df3a254ed64b83f3c5779cb6540f3/modules/fabric-project/vars.tf#L79,https://github.com/terraform-google-modules/terraform-google-project-factory/blob/97eee8801f9c63456f814f90331d635dd8cea99a/modules/fabric-project/variables.tf#L86,2019-05-15 01:35:34-05:00,2019-11-01 10:55:38+01:00,5,0,0,1,1,0,0,0,0,0
https://github.com/awslabs/data-on-eks,7,ai-ml/ray/terraform/examples/pytorch/main.tf,ai-ml/ray/terraform/examples/pytorch/main.tf,0,workaround,# workaround for protobuf protoc >= 3.19.0 issue,# workaround for protobuf protoc >= 3.19.0 issue,"module ""pytorch_cluster"" {
  source = ""../../modules/ray-cluster""

  namespace        = local.name
  ray_cluster_name = local.name
  eks_cluster_name = local.eks_cluster

  helm_values = [
    yamlencode({
      image = {
        repository = ""rayproject/ray-ml""
        # This is a different version than the xgboost version
        tag        = ""2.3.0""
        pullPolicy = ""IfNotPresent""
      }
      head = {
        enableInTreeAutoscaling = ""True""
        resources = {
          limits = {
            cpu    = ""4""
            memory = ""24G""
          }
          requests = {
            cpu    = ""4""
            memory = ""12G""
          }
        }
        tolerations = [
          {
            key      = local.name
            effect   = ""NoSchedule""
            operator = ""Exists""
          }
        ]
        containerEnv = [
          {
            name  = ""RAY_LOG_TO_STDERR""
            value = ""1""
          },
          {
            # workaround for protobuf protoc >= 3.19.0 issue
            name  = ""PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION""
            value = ""python""
          }
        ]
      }
      worker = {
        resources = {
          limits = {
            cpu    = ""8""
            memory = ""24G""
          }
          requests = {
            cpu    = ""4""
            memory = ""12G""
          }
        }
        tolerations = [
          {
            key      = local.name
            effect   = ""NoSchedule""
            operator = ""Exists""
          }
        ]
        replicas    = ""0""
        minReplicas = ""0""
        maxReplicas = ""30""
        containerEnv = [
          {
            name  = ""RAY_LOG_TO_STDERR""
            value = ""1""
          },
          {
            # workaround for protobuf protoc >= 3.19.0 issue
            name  = ""PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION""
            value = ""python""
          }
        ]
      }
    })
  ]
}
",module,"module ""pytorch_cluster"" {
  source = ""../../modules/ray-cluster""

  namespace        = local.name
  ray_cluster_name = local.name
  eks_cluster_name = local.eks_cluster

  helm_values = [
    yamlencode({
      image = {
        repository = ""rayproject/ray-ml""
        # This is a different version than the xgboost version
        tag        = ""2.3.0""
        pullPolicy = ""IfNotPresent""
      }
      head = {
        enableInTreeAutoscaling = ""True""
        resources = {
          limits = {
            cpu    = ""4""
            memory = ""24G""
          }
          requests = {
            cpu    = ""4""
            memory = ""12G""
          }
        }
        tolerations = [
          {
            key      = local.name
            effect   = ""NoSchedule""
            operator = ""Exists""
          }
        ]
        containerEnv = [
          {
            name  = ""RAY_LOG_TO_STDERR""
            value = ""1""
          },
          {
            # workaround for protobuf protoc >= 3.19.0 issue
            name  = ""PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION""
            value = ""python""
          }
        ]
      }
      worker = {
        resources = {
          limits = {
            cpu    = ""8""
            memory = ""24G""
          }
          requests = {
            cpu    = ""4""
            memory = ""12G""
          }
        }
        tolerations = [
          {
            key      = local.name
            effect   = ""NoSchedule""
            operator = ""Exists""
          }
        ]
        replicas    = ""0""
        minReplicas = ""0""
        maxReplicas = ""30""
        containerEnv = [
          {
            name  = ""RAY_LOG_TO_STDERR""
            value = ""1""
          },
          {
            # workaround for protobuf protoc >= 3.19.0 issue
            name  = ""PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION""
            value = ""python""
          }
        ]
      }
    })
  ]
}
",module,114,114.0,84d14e8fee669fb5db87dd5f4d0e40554ee3a0d3,e31667b33a449fcf25f3067a01445c2444b53349,https://github.com/awslabs/data-on-eks/blob/84d14e8fee669fb5db87dd5f4d0e40554ee3a0d3/ai-ml/ray/terraform/examples/pytorch/main.tf#L114,https://github.com/awslabs/data-on-eks/blob/e31667b33a449fcf25f3067a01445c2444b53349/ai-ml/ray/terraform/examples/pytorch/main.tf#L114,2023-03-21 08:33:37+00:00,2023-05-22 14:26:59-05:00,2,0,1,0,0,0,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-iam,1,test/fixtures/full/iam.tf,test/fixtures/helper/iam.tf,1,# todo,## TODO(jmccune): Disabled as per discussion with Aaron.  Re-enable post 0.12,"## TODO(jmccune): Disabled as per discussion with Aaron.  Re-enable post 0.12 
 # considering public pull requests. 
 # module ""iam_binding_organization"" { 
 #   source        = ""../../.."" 
 #   mode          = var.mode 
 #   organizations = [var.org_id] 
 #   bindings = local.org_bindings 
 # } ","module ""iam_binding_folder"" {
  source  = ""../../..""
  mode    = var.mode
  folders = module.base.folders

  bindings = local.basic_bindings
}
",module,"module ""iam_binding_folder"" {
  source   = ""../../../modules/folders_iam""
  mode     = var.mode
  folders  = module.base.folders
  bindings = local.folder_bindings
}
",module,32,33.0,2897ee8fd869ee2494933856414a8e584ae55e7b,91ff044511481248165cdfcb9cf5e1d5f9b48d77,https://github.com/terraform-google-modules/terraform-google-iam/blob/2897ee8fd869ee2494933856414a8e584ae55e7b/test/fixtures/full/iam.tf#L32,https://github.com/terraform-google-modules/terraform-google-iam/blob/91ff044511481248165cdfcb9cf5e1d5f9b48d77/test/fixtures/helper/iam.tf#L33,2019-07-12 15:16:02-07:00,2023-07-25 14:33:53-05:00,12,0,0,1,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,363,main.tf,main.tf,0,todo,# TODO - does cluster_encryption_config need to be a list?!,# TODO - does cluster_encryption_config need to be a list?!,"resource ""aws_iam_policy"" ""cluster_encryption"" {
  count = var.create && var.attach_cluster_encryption_policy && length(var.cluster_encryption_config) > 0 ? 1 : 0

  name_prefix = ""${local.iam_role_name}-ClusterEncryption-""
  description = ""Cluster encryption policy to allow cluster role to utilize CMK provided""

  policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = [
          ""kms:Encrypt"",
          ""kms:Decrypt"",
          ""kms:ListGrants"",
          ""kms:DescribeKey"",
        ]
        Effect = ""Allow""
        # TODO - does cluster_encryption_config need to be a list?!
        Resource = [for config in var.cluster_encryption_config : config.provider_key_arn]
      },
    ]
  })

  tags = var.tags
}
",resource,"resource ""aws_iam_policy"" ""cluster_encryption"" {
  count = local.create_iam_role && var.attach_cluster_encryption_policy && length(var.cluster_encryption_config) > 0 ? 1 : 0

  name        = var.cluster_encryption_policy_use_name_prefix ? null : local.cluster_encryption_policy_name
  name_prefix = var.cluster_encryption_policy_use_name_prefix ? local.cluster_encryption_policy_name : null
  description = var.cluster_encryption_policy_description
  path        = var.cluster_encryption_policy_path

  policy = jsonencode({
    Version = ""2012-10-17""
    Statement = [
      {
        Action = [
          ""kms:Encrypt"",
          ""kms:Decrypt"",
          ""kms:ListGrants"",
          ""kms:DescribeKey"",
        ]
        Effect   = ""Allow""
        Resource = [for config in var.cluster_encryption_config : config.provider_key_arn]
      },
    ]
  })

  tags = merge(var.tags, var.cluster_encryption_policy_tags)
}
",resource,246,,7644952131a466ca22ba5b3e62cd988e01eff716,2df1572b8a031fbd31a845cc5c61f015ec387f56,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/7644952131a466ca22ba5b3e62cd988e01eff716/main.tf#L246,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/2df1572b8a031fbd31a845cc5c61f015ec387f56/main.tf,2022-03-02 18:29:35+01:00,2022-03-09 15:13:18+01:00,3,1,1,1,0,1,0,0,0,0
https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules,35,modules/vmseries/variables.tf,modules/vmseries/variables.tf,0,fix,# FIXME maybe `subnet_id` instead of `subnet`,"variable ""interfaces"" { # FIXME maybe `subnet_id` instead of `subnet`","variable ""interfaces"" { # FIXME maybe `subnet_id` instead of `subnet`
  description = <<-EOF
  List of the network interface specifications.
  The first should be the Management network interface, which does not participate in data filtering.
  The remaining ones are the dataplane interfaces.

  - `subnet`: Subnet object to use.
  - `lb_backend_pool_id`: Identifier of the backend pool of the load balancer to associate.
  - `enable_backend_pool`: If false, ignore `lb_backend_pool_id`. Default it false.
  - `public_ip_address_id`: Identifier of the existing public IP to associate.

  Example:

  ```
  [
    {
      subnet              = { id = var.vmseries_subnet_id_public }
      lb_backend_pool_id  = module.inbound_lb.backend-pool-id
      enable_backend_pool = true
    },
    {
      subnet              = { id = var.vmseries_subnet_id_private }
      lb_backend_pool_id  = module.outbound_lb.backend-pool-id
      enable_backend_pool = true
    },
  ]
  ```

  EOF
}
",variable,"variable ""interfaces"" {
  description = <<-EOF
  List of the network interface specifications.
  The first should be the Management network interface, which does not participate in data filtering.
  The remaining ones are the dataplane interfaces.

  - `subnet_id`: Identifier of the existing subnet to use.
  - `lb_backend_pool_id`: Identifier of the existing backend pool of the load balancer to associate.
  - `enable_backend_pool`: If false, ignore `lb_backend_pool_id`. Default it false.
  - `public_ip_address_id`: Identifier of the existing public IP to associate.

  Example:

  ```
  [
    {
      subnet_id            = azurerm_subnet.my_mgmt_subnet.id
      public_ip_address_id = azurerm_public_ip.my_mgmt_ip.id
    },
    {
      subnet_id           = azurerm_subnet.my_pub_subnet.id
      lb_backend_pool_id  = module.inbound_lb.backend_pool_id
      enable_backend_pool = true
    },
  ]
  ```

  EOF
}
",variable,29,,75b886d45bb898f4c908b10951906d875e6cd4f3,96b36698922904be306a659b6cbe9d05f6afbd51,https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/75b886d45bb898f4c908b10951906d875e6cd4f3/modules/vmseries/variables.tf#L29,https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/96b36698922904be306a659b6cbe9d05f6afbd51/modules/vmseries/variables.tf,2021-03-22 12:11:14+01:00,2021-04-01 09:40:32+02:00,4,1,1,1,0,0,1,0,0,0
https://github.com/terraform-google-modules/terraform-google-slo,8,modules/slo/main.tf,modules/slo/main.tf,0,workaround,# Workaround for https://github.com/terraform-providers/terraform-provider-random/issues/95,"# Generate a random uuid that will regenerate when the SLO config or the Error 
 # Budget Policy is updated. 
 # Workaround for https://github.com/terraform-providers/terraform-provider-random/issues/95","resource ""random_uuid"" ""config_hash"" {
  keepers = {
    for content in [local_file.slo.content, local_file.error_budget_policy.content] :
    content => md5(content)
  }
}
",resource,the block associated got renamed or deleted,,77,,825194fc70002c5b310442faceccf313321768d0,7b2bb290a79dab58f9a7232441909c6949bfcab1,https://github.com/terraform-google-modules/terraform-google-slo/blob/825194fc70002c5b310442faceccf313321768d0/modules/slo/main.tf#L77,https://github.com/terraform-google-modules/terraform-google-slo/blob/7b2bb290a79dab58f9a7232441909c6949bfcab1/modules/slo/main.tf,2019-12-07 23:32:23+01:00,2019-12-13 16:05:15-08:00,2,1,0,0,1,0,0,0,0,0
https://github.com/ministryofjustice/modernisation-platform,200,terraform/environments/data-platform-apps-and-tools/opensearch.tf,terraform/environments/data-platform-apps-and-tools/opensearch.tf,0,// todo,// TODO: Find source for this policy @jacobwoffenden,"// TODO: Find source for this policy @jacobwoffenden 
 #checkov:skip=CKV_AWS_283:","data ""aws_iam_policy_document"" ""opensearch_domain"" {
  // TODO: Find source for this policy @jacobwoffenden
  #checkov:skip=CKV_AWS_283:
  statement {
    effect  = ""Allow""
    actions = [""es:ESHttp*""]
    principals {
      type        = ""AWS""
      identifiers = [""*""]
    }
    resources = [""${aws_opensearch_domain.openmetadata.arn}/*""]
  }
}
",data,,,74,0.0,90002b7667baf7c1eb23d0e49dcfa9d9eaee7567,951ffdb805c4255e3bb6d0a5febe5f1bb21407c9,https://github.com/ministryofjustice/modernisation-platform/blob/90002b7667baf7c1eb23d0e49dcfa9d9eaee7567/terraform/environments/data-platform-apps-and-tools/opensearch.tf#L74,https://github.com/ministryofjustice/modernisation-platform/blob/951ffdb805c4255e3bb6d0a5febe5f1bb21407c9/terraform/environments/data-platform-apps-and-tools/opensearch.tf#L0,2023-10-18 15:43:32+01:00,2023-12-19 15:49:47+00:00,3,2,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-slo,1,examples/simple_example/main.tf,examples/simple_example/main.tf,0,# todo,# TODO: Add project to Stackdriver host workspace here,# TODO: Add project to Stackdriver host workspace here,"module ""slo-pipeline"" {
  source                      = ""../../modules/slo-pipeline""
  function_name               = ""slo-export""
  region                      = var.region
  project_id                  = module.slo-project.project_id
  bigquery_project_id         = module.slo-project.project_id
  bigquery_dataset_name       = ""slo_reports""
  bucket_name                 = var.bucket_name
  stackdriver_host_project_id = var.stackdriver_host_project_id
}
",module,the block associated got renamed or deleted,,44,,4236fcdd363233b69a439c1755154c8082ba32dd,1da067573e522895223077bd116231200b15e9ce,https://github.com/terraform-google-modules/terraform-google-slo/blob/4236fcdd363233b69a439c1755154c8082ba32dd/examples/simple_example/main.tf#L44,https://github.com/terraform-google-modules/terraform-google-slo/blob/1da067573e522895223077bd116231200b15e9ce/examples/simple_example/main.tf,2019-09-04 09:54:21+02:00,2019-09-09 17:40:22+02:00,4,1,0,1,0,0,0,0,1,0
https://github.com/wireapp/wire-server-deploy,55,terraform/modules/sft/outputs.tf,terraform/modules/sft/outputs.tf,0,# todo,# TODO: It is absurd that srv-announcer requires this. All route53 resources are,"# TODO: It is absurd that srv-announcer requires this. All route53 resources are 
 # scoped globally, figure out if we really need to do this.","data ""aws_region"" ""current"" {}
",data,"data ""aws_region"" ""current"" {}
",data,1,1.0,ddf967a4a5d4f3e8f6ffbb9a93b47ee2089f60c0,d8e12109f7193074bb4c065a6e3c0580a24cbceb,https://github.com/wireapp/wire-server-deploy/blob/ddf967a4a5d4f3e8f6ffbb9a93b47ee2089f60c0/terraform/modules/sft/outputs.tf#L1,https://github.com/wireapp/wire-server-deploy/blob/d8e12109f7193074bb4c065a6e3c0580a24cbceb/terraform/modules/sft/outputs.tf#L1,2020-09-18 11:48:52+02:00,2020-10-15 12:30:35+02:00,4,0,0,1,0,0,0,0,0,0
https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules,45,examples/transit_vnet_common/main.tf,examples/transit_vnet_common/main.tf,0,fix,# FIXME automatize,backend_name        = var.inbound_lb_name # FIXME automatize,"module ""inbound_lb"" {
  source = ""../../modules/loadbalancer""

  name_lb             = var.inbound_lb_name
  location            = var.location
  resource_group_name = azurerm_resource_group.this.name
  backend_name        = var.inbound_lb_name # FIXME automatize
  frontend_ips        = var.frontend_ips
}
",module,"module ""inbound_lb"" {
  source = ""../../modules/loadbalancer""

  name                = var.inbound_lb_name
  location            = var.location
  resource_group_name = azurerm_resource_group.this.name
  frontend_ips        = var.frontend_ips
}
",module,46,,e69a3cf69a8139f84d2c072ec554184f739c8e8f,481fefe1044fde2f794407a5a1902791b4445ab1,https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/e69a3cf69a8139f84d2c072ec554184f739c8e8f/examples/transit_vnet_common/main.tf#L46,https://github.com/PaloAltoNetworks/terraform-azurerm-vmseries-modules/blob/481fefe1044fde2f794407a5a1902791b4445ab1/examples/transit_vnet_common/main.tf,2021-04-22 10:50:23+02:00,2021-04-22 10:50:23+02:00,2,1,0,1,0,0,1,0,0,0
https://github.com/rancherfederal/rke2-aws-tf,2,main.tf,main.tf,0,# todo,"# TODO: Ideally set this to `length(var.servers)`, but currently blocked by: https://github.com/rancher/rke2/issues/349","# TODO: Ideally set this to `length(var.servers)`, but currently blocked by: https://github.com/rancher/rke2/issues/349","module ""servers"" {
  source = ""./modules/nodepool""
  name   = ""${local.uname}-server""

  vpc_id                 = var.vpc_id
  subnets                = var.subnets
  ami                    = var.ami
  block_device_mappings  = var.block_device_mappings
  vpc_security_group_ids = [aws_security_group.server.id, aws_security_group.cluster.id]
  spot                   = var.spot
  target_group_arns = [
    module.cp_lb.server_tg_arn,
    module.cp_lb.server_supervisor_tg_arn,
  ]

  # Overrideable variables
  userdata             = data.template_cloudinit_config.this.rendered
  iam_instance_profile = var.iam_instance_profile == """" ? module.iam[0].iam_instance_profile : var.iam_instance_profile

  # Don't allow something not recommended within etcd scaling, set max deliberately and only control desired
  asg = { min : 1, max : 7, desired : var.servers }

  # TODO: Ideally set this to `length(var.servers)`, but currently blocked by: https://github.com/rancher/rke2/issues/349
  min_elb_capacity = 1

  tags = merge({
    ""Role"" = ""server"",
  }, local.ccm_tags, var.tags)
}
",module,"module ""servers"" {
  source = ""./modules/nodepool""
  name   = ""${local.uname}-server""

  vpc_id                      = var.vpc_id
  subnets                     = var.subnets
  ami                         = var.ami
  instance_type               = var.instance_type
  block_device_mappings       = var.block_device_mappings
  extra_block_device_mappings = var.extra_block_device_mappings
  vpc_security_group_ids = concat(
    [aws_security_group.cluster.id, aws_security_group.server.id],
  var.extra_security_group_ids)
  spot                        = var.spot
  target_group_arns           = local.target_group_arns
  wait_for_capacity_timeout   = var.wait_for_capacity_timeout
  metadata_options            = var.metadata_options
  associate_public_ip_address = var.associate_public_ip_address

  # Overrideable variables
  userdata             = data.cloudinit_config.this.rendered
  iam_instance_profile = var.iam_instance_profile == """" ? module.iam[0].iam_instance_profile : var.iam_instance_profile

  # Don't allow something not recommended within etcd scaling, set max deliberately and only control desired
  asg = {
    min                  = 1
    max                  = 7
    desired              = var.servers
    suspended_processes  = var.suspended_processes
    termination_policies = var.termination_policies
  }

  # TODO: Ideally set this to `length(var.servers)`, but currently blocked by: https://github.com/rancher/rke2/issues/349
  min_elb_capacity = 1

  tags = merge({
    ""Role"" = ""server"",
  }, local.ccm_tags, var.tags)
}
",module,193,224.0,e864f5bf26b72c24f35ffce486d801247e723582,26629708e56f3d961cfefaa19052e93d958f4469,https://github.com/rancherfederal/rke2-aws-tf/blob/e864f5bf26b72c24f35ffce486d801247e723582/main.tf#L193,https://github.com/rancherfederal/rke2-aws-tf/blob/26629708e56f3d961cfefaa19052e93d958f4469/main.tf#L224,2020-10-22 20:55:46-06:00,2023-12-18 14:11:04-06:00,26,0,1,1,1,0,1,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,476,modules/workers/instance.tf,modules/workers/instance.tf,0,todo,# TODO Not updateable remove when supported,"agent_config, # TODO Not updateable; remove when supported","resource ""oci_core_instance"" ""workers"" {
  for_each             = local.enabled_instances
  availability_domain  = element(each.value.availability_domains, 1)
  fault_domain         = try(each.value.placement_fds[0], null)
  compartment_id       = each.value.compartment_id
  display_name         = each.key
  preserve_boot_volume = false
  shape                = each.value.shape

  defined_tags            = each.value.defined_tags
  freeform_tags           = each.value.freeform_tags
  extended_metadata       = each.value.extended_metadata
  capacity_reservation_id = each.value.capacity_reservation_id

  dynamic ""shape_config"" {
    for_each = length(regexall(""Flex"", each.value.shape)) > 0 ? [1] : []
    content {
      ocpus = each.value.ocpus
      memory_in_gbs = ( # If > 64GB memory/core, correct input to exactly 64GB memory/core
        (each.value.memory / each.value.ocpus) > 64 ? each.value.ocpus * 64 : each.value.memory
      )
    }
  }

  dynamic ""platform_config"" {
    for_each = each.value.platform_config != null ? [1] : []
    content {
      type = lookup(
        # Attempt lookup against data source for the associated 'type' of configured worker shape
        lookup(local.platform_config_by_shape, each.value.shape, {}), ""type"",
        # Fall back to 'type' on pool with custom platform_config, or INTEL_VM default
        lookup(each.value.platform_config, ""type"", ""INTEL_VM"")
      )
      # Remaining parameters as configured, validated by instance/instance config resource
      are_virtual_instructions_enabled               = lookup(each.value.platform_config, ""are_virtual_instructions_enabled"", null)
      is_access_control_service_enabled              = lookup(each.value.platform_config, ""is_access_control_service_enabled"", null)
      is_input_output_memory_management_unit_enabled = lookup(each.value.platform_config, ""is_input_output_memory_management_unit_enabled"", null)
      is_measured_boot_enabled                       = lookup(each.value.platform_config, ""is_measured_boot_enabled"", null)
      is_memory_encryption_enabled                   = lookup(each.value.platform_config, ""is_memory_encryption_enabled"", null)
      is_secure_boot_enabled                         = lookup(each.value.platform_config, ""is_secure_boot_enabled"", null)
      is_symmetric_multi_threading_enabled           = lookup(each.value.platform_config, ""is_symmetric_multi_threading_enabled"", null)
      is_trusted_platform_module_enabled             = lookup(each.value.platform_config, ""is_trusted_platform_module_enabled"", null)
      numa_nodes_per_socket                          = lookup(each.value.platform_config, ""numa_nodes_per_socket"", null)
      percentage_of_cores_enabled                    = lookup(each.value.platform_config, ""percentage_of_cores_enabled"", null)
    }
  }

  agent_config {
    are_all_plugins_disabled = each.value.agent_config.are_all_plugins_disabled
    is_management_disabled   = each.value.agent_config.is_management_disabled
    is_monitoring_disabled   = each.value.agent_config.is_monitoring_disabled
    dynamic ""plugins_config"" {
      for_each = each.value.agent_config.plugins_config
      content {
        name          = each.key
        desired_state = each.value
      }
    }
  }

  create_vnic_details {
    assign_private_dns_record = var.assign_dns
    assign_public_ip          = each.value.assign_public_ip
    nsg_ids                   = each.value.nsg_ids
    subnet_id                 = each.value.subnet_id
    defined_tags              = each.value.defined_tags
    freeform_tags             = each.value.freeform_tags
  }

  instance_options {
    are_legacy_imds_endpoints_disabled = false
  }

  metadata = merge(
    {
      apiserver_host           = var.apiserver_private_host
      cluster_ca_cert          = var.cluster_ca_cert
      oke-k8version            = var.kubernetes_version
      oke-kubeproxy-proxy-mode = var.kubeproxy_mode
      oke-tenancy-id           = var.tenancy_id
      oke-initial-node-labels  = join("","", [for k, v in each.value.node_labels : format(""%v=%v"", k, v)])
      secondary_vnics          = jsonencode(lookup(each.value, ""secondary_vnics"", {}))
      ssh_authorized_keys      = var.ssh_public_key
      user_data                = lookup(lookup(data.cloudinit_config.workers, lookup(each.value, ""key"", """"), {}), ""rendered"", """")
    },

    # Only provide cluster DNS service address if set explicitly; determined automatically in practice.
    coalesce(var.cluster_dns, ""none"") == ""none"" ? {} : { kubedns_svc_ip = var.cluster_dns },

    # Extra user-defined fields merged last
    var.node_metadata,                       # global
    lookup(each.value, ""node_metadata"", {}), # pool-specific
  )

  source_details {
    boot_volume_size_in_gbs = each.value.boot_volume_size
    source_id               = each.value.image_id
    source_type             = ""image""
  }

  lifecycle {
    precondition {
      condition     = coalesce(each.value.image_id, ""none"") != ""none""
      error_message = <<-EOT
      Missing image_id; check provided value if image_type is 'custom', or image_os/image_os_version if image_type is 'oke' or 'platform'.
        pool: ${each.key}
        image_type: ${coalesce(each.value.image_type, ""none"")}
        image_id: ${coalesce(each.value.image_id, ""none"")}
      EOT
    }

    ignore_changes = [
      agent_config, # TODO Not updateable; remove when supported
      defined_tags, freeform_tags, display_name,
      metadata[""cluster_ca_cert""], metadata[""user_data""],
      create_vnic_details[0].defined_tags,
      create_vnic_details[0].freeform_tags,
    ]
  }
}
",resource,"resource ""oci_core_instance"" ""workers"" {
  for_each             = local.enabled_instances
  availability_domain  = element(each.value.availability_domains, 1)
  fault_domain         = try(each.value.placement_fds[0], null)
  compartment_id       = each.value.compartment_id
  display_name         = each.key
  preserve_boot_volume = false
  shape                = each.value.shape

  defined_tags            = each.value.defined_tags
  freeform_tags           = each.value.freeform_tags
  extended_metadata       = each.value.extended_metadata
  capacity_reservation_id = each.value.capacity_reservation_id

  dynamic ""shape_config"" {
    for_each = length(regexall(""Flex"", each.value.shape)) > 0 ? [1] : []
    content {
      ocpus = each.value.ocpus
      memory_in_gbs = ( # If > 64GB memory/core, correct input to exactly 64GB memory/core
        (each.value.memory / each.value.ocpus) > 64 ? each.value.ocpus * 64 : each.value.memory
      )
    }
  }

  dynamic ""platform_config"" {
    for_each = each.value.platform_config != null ? [1] : []
    content {
      type = lookup(
        # Attempt lookup against data source for the associated 'type' of configured worker shape
        lookup(local.platform_config_by_shape, each.value.shape, {}), ""type"",
        # Fall back to 'type' on pool with custom platform_config, or INTEL_VM default
        lookup(each.value.platform_config, ""type"", ""INTEL_VM"")
      )
      # Remaining parameters as configured, validated by instance/instance config resource
      are_virtual_instructions_enabled               = lookup(each.value.platform_config, ""are_virtual_instructions_enabled"", null)
      is_access_control_service_enabled              = lookup(each.value.platform_config, ""is_access_control_service_enabled"", null)
      is_input_output_memory_management_unit_enabled = lookup(each.value.platform_config, ""is_input_output_memory_management_unit_enabled"", null)
      is_measured_boot_enabled                       = lookup(each.value.platform_config, ""is_measured_boot_enabled"", null)
      is_memory_encryption_enabled                   = lookup(each.value.platform_config, ""is_memory_encryption_enabled"", null)
      is_secure_boot_enabled                         = lookup(each.value.platform_config, ""is_secure_boot_enabled"", null)
      is_symmetric_multi_threading_enabled           = lookup(each.value.platform_config, ""is_symmetric_multi_threading_enabled"", null)
      is_trusted_platform_module_enabled             = lookup(each.value.platform_config, ""is_trusted_platform_module_enabled"", null)
      numa_nodes_per_socket                          = lookup(each.value.platform_config, ""numa_nodes_per_socket"", null)
      percentage_of_cores_enabled                    = lookup(each.value.platform_config, ""percentage_of_cores_enabled"", null)
    }
  }

  agent_config {
    are_all_plugins_disabled = each.value.agent_config.are_all_plugins_disabled
    is_management_disabled   = each.value.agent_config.is_management_disabled
    is_monitoring_disabled   = each.value.agent_config.is_monitoring_disabled
    dynamic ""plugins_config"" {
      for_each = each.value.agent_config.plugins_config
      content {
        name          = plugins_config.key
        desired_state = plugins_config.value
      }
    }
  }

  create_vnic_details {
    assign_private_dns_record = var.assign_dns
    assign_public_ip          = each.value.assign_public_ip
    nsg_ids                   = each.value.nsg_ids
    subnet_id                 = each.value.subnet_id
    defined_tags              = each.value.defined_tags
    freeform_tags             = each.value.freeform_tags
  }

  instance_options {
    are_legacy_imds_endpoints_disabled = false
  }

  metadata = merge(
    {
      apiserver_host           = var.apiserver_private_host
      cluster_ca_cert          = var.cluster_ca_cert
      oke-k8version            = var.kubernetes_version
      oke-kubeproxy-proxy-mode = var.kubeproxy_mode
      oke-tenancy-id           = var.tenancy_id
      oke-initial-node-labels  = join("","", [for k, v in each.value.node_labels : format(""%v=%v"", k, v)])
      secondary_vnics          = jsonencode(lookup(each.value, ""secondary_vnics"", {}))
      ssh_authorized_keys      = var.ssh_public_key
      user_data                = lookup(lookup(data.cloudinit_config.workers, lookup(each.value, ""key"", """"), {}), ""rendered"", """")
    },

    # Only provide cluster DNS service address if set explicitly; determined automatically in practice.
    coalesce(var.cluster_dns, ""none"") == ""none"" ? {} : { kubedns_svc_ip = var.cluster_dns },

    # Extra user-defined fields merged last
    var.node_metadata,                       # global
    lookup(each.value, ""node_metadata"", {}), # pool-specific
  )

  source_details {
    boot_volume_size_in_gbs = each.value.boot_volume_size
    boot_volume_vpus_per_gb = each.value.boot_volume_vpus_per_gb
    source_id               = each.value.image_id
    source_type             = ""image""
  }

  lifecycle {
    precondition {
      condition     = coalesce(each.value.image_id, ""none"") != ""none""
      error_message = <<-EOT
      Missing image_id; check provided value if image_type is 'custom', or image_os/image_os_version if image_type is 'oke' or 'platform'.
        pool: ${each.key}
        image_type: ${coalesce(each.value.image_type, ""none"")}
        image_id: ${coalesce(each.value.image_id, ""none"")}
      EOT
    }

    ignore_changes = [
      agent_config, # TODO Not updateable; remove when supported
      defined_tags, freeform_tags, display_name,
      metadata[""cluster_ca_cert""], metadata[""user_data""],
      create_vnic_details[0].defined_tags,
      create_vnic_details[0].freeform_tags,
    ]
  }
}
",resource,113,114.0,9cc7db89975e38e16fc4ca25ad55bedc3117c2a9,a1fdfcb7de5e777f0191a43940ef276175a20ba9,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/9cc7db89975e38e16fc4ca25ad55bedc3117c2a9/modules/workers/instance.tf#L113,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/a1fdfcb7de5e777f0191a43940ef276175a20ba9/modules/workers/instance.tf#L114,2023-11-03 18:43:09-06:00,2024-02-12 09:53:40+11:00,3,0,1,1,0,0,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,393,modules/organization/firewall-policy.tf,modules/organization/firewall-policy.tf,0,fix,# TODO: remove once provider issues is fixed,"# TODO: remove once provider issues is fixed 
 # https://github.com/hashicorp/terraform-provider-google/issues/7790","resource ""google_compute_organization_security_policy_rule"" ""rule"" {
  provider                = google-beta
  for_each                = local.firewall_rules
  policy_id               = google_compute_organization_security_policy.policy[each.value.policy].id
  action                  = each.value.action
  direction               = each.value.direction
  priority                = try(each.value.priority, null)
  target_resources        = try(each.value.target_resources, null)
  target_service_accounts = try(each.value.target_service_accounts, null)
  enable_logging          = try(each.value.logging, null)
  # preview                 = each.value.preview
  match {
    description = each.value.description
    config {
      src_ip_ranges  = each.value.direction == ""INGRESS"" ? each.value.ranges : null
      dest_ip_ranges = each.value.direction == ""EGRESS"" ? each.value.ranges : null
      dynamic ""layer4_config"" {
        for_each = each.value.ports
        iterator = port
        content {
          ip_protocol = port.key
          ports       = port.value
        }
      }
    }
  }
  # TODO: remove once provider issues is fixed
  # https://github.com/hashicorp/terraform-provider-google/issues/7790
  lifecycle {
    ignore_changes = [description]
  }
}
",resource,the block associated got renamed or deleted,,95,,e2f5b96f4aecf420c3949f4685f0e5cab5d66799,f78902aee85d1ab10f1acf3b9727d188c349cdb9,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/e2f5b96f4aecf420c3949f4685f0e5cab5d66799/modules/organization/firewall-policy.tf#L95,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/f78902aee85d1ab10f1acf3b9727d188c349cdb9/modules/organization/firewall-policy.tf,2021-12-22 10:46:27+01:00,2021-12-31 13:06:35+01:00,3,1,0,1,1,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1308,blueprints/data-solutions/shielded-folder/variables.tf,blueprints/data-solutions/shielded-folder/variables.tf,0,#todo,"#TODO data-security  = ""gcp-data-security""","#TODO data-security  = ""gcp-data-security""","variable ""groups"" {
  description = ""User groups.""
  type        = map(string)
  default = {
    #TODO data-analysts  = ""gcp-data-analysts""
    data-engineers = ""gcp-data-engineers""
    #TODO data-security  = ""gcp-data-security""
  }
}
",variable,"variable ""groups"" {
  description = ""User groups.""
  type        = map(string)
  default = {
    #TODO data-analysts  = ""gcp-data-analysts""
    data-engineers = ""gcp-data-engineers""
    data-security  = ""gcp-data-security""
  }
}
",variable,59,,84be665172b21220938ee702c4654e1a0cd0a584,4007d42705a930e9e526a8da3616712ad0e646f6,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/84be665172b21220938ee702c4654e1a0cd0a584/blueprints/data-solutions/shielded-folder/variables.tf#L59,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/4007d42705a930e9e526a8da3616712ad0e646f6/blueprints/data-solutions/shielded-folder/variables.tf,2023-01-17 08:49:04+01:00,2023-01-21 01:08:51+01:00,3,1,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-lb-http,4,main.tf,main.tf,0,# todo,# TODO: Infer type of health check to use from backends.protocol,# TODO: Infer type of health check to use from backends.protocol,"resource ""google_compute_health_check"" ""default"" {
  for_each = var.backends
  project  = var.project
  name     = ""${var.name}-backend-${each.key}""

  check_interval_sec  = lookup(each.value[""health_check""], ""check_interval_sec"", 5)
  timeout_sec         = lookup(each.value[""health_check""], ""timeout_sec"", 5)
  healthy_threshold   = lookup(each.value[""health_check""], ""healthy_threshold"", 2)
  unhealthy_threshold = lookup(each.value[""health_check""], ""unhealthy_threshold"", 2)

  # TODO: Infer type of health check to use from backends.protocol
  dynamic ""http_health_check"" {
    for_each = lookup(each.value[""health_check""], ""http_health_check"", {}) == {} ? [] : [each.value[""health_check""][""http_health_check""]]
    content {
      host         = lookup(http_health_check.value, ""host"", null)
      request_path = lookup(http_health_check.value, ""request_path"", null)
      response     = lookup(http_health_check.value, ""response"", null)

      port               = lookup(http_health_check.value, ""port"", null)
      port_name          = lookup(http_health_check.value, ""port_name"", null)
      port_specification = lookup(http_health_check.value, ""port_specification"", null)
    }
  }

  dynamic ""https_health_check"" {
    for_each = lookup(each.value[""health_check""], ""https_health_check"", {}) == {} ? [] : [each.value[""health_check""][""https_health_check""]]

    content {
      host         = lookup(https_health_check.value, ""host"", null)
      request_path = lookup(https_health_check.value, ""request_path"", null)
      response     = lookup(https_health_check.value, ""response"", null)

      port               = lookup(https_health_check.value, ""port"", null)
      port_name          = lookup(https_health_check.value, ""port_name"", null)
      port_specification = lookup(https_health_check.value, ""port_specification"", null)
    }
  }

  dynamic ""http2_health_check"" {
    for_each = lookup(each.value[""health_check""], ""http2_health_check"", {}) == {} ? [] : [each.value[""health_check""][""http2_health_check""]]

    content {
      host         = lookup(http2_health_check.value, ""host"", null)
      request_path = lookup(http2_health_check.value, ""request_path"", null)
      response     = lookup(http2_health_check.value, ""response"", null)

      port               = lookup(http2_health_check.value, ""port"", null)
      port_name          = lookup(http2_health_check.value, ""port_name"", null)
      port_specification = lookup(http2_health_check.value, ""port_specification"", null)
    }
  }

}
",resource,"resource ""google_compute_health_check"" ""default"" {
  for_each = var.backends
  project  = var.project
  name     = ""${var.name}-backend-${each.key}""

  check_interval_sec  = lookup(each.value[""health_check""], ""check_interval_sec"", 5)
  timeout_sec         = lookup(each.value[""health_check""], ""timeout_sec"", 5)
  healthy_threshold   = lookup(each.value[""health_check""], ""healthy_threshold"", 2)
  unhealthy_threshold = lookup(each.value[""health_check""], ""unhealthy_threshold"", 2)

  dynamic ""http_health_check"" {
    for_each = each.value[""protocol""] == ""HTTP"" ? [
      {
        host               = lookup(each.value[""health_check""], ""host"", null)
        request_path       = lookup(each.value[""health_check""], ""request_path"", null)
        response           = lookup(each.value[""health_check""], ""response"", null)
        port               = lookup(each.value[""health_check""], ""port"", null)
        port_name          = lookup(each.value[""health_check""], ""port_name"", null)
        port_specification = lookup(each.value[""health_check""], ""port_specification"", null)
      }
    ] : []

    content {
      host         = lookup(http_health_check.value, ""host"", null)
      request_path = lookup(http_health_check.value, ""request_path"", null)
      response     = lookup(http_health_check.value, ""response"", null)

      port               = lookup(http_health_check.value, ""port"", null)
      port_name          = lookup(http_health_check.value, ""port_name"", null)
      port_specification = lookup(http_health_check.value, ""port_specification"", null)
    }
  }

  dynamic ""https_health_check"" {
    for_each = each.value[""protocol""] == ""HTTPS"" ? [
      {
        host               = lookup(each.value[""health_check""], ""host"", null)
        request_path       = lookup(each.value[""health_check""], ""request_path"", null)
        response           = lookup(each.value[""health_check""], ""response"", null)
        port               = lookup(each.value[""health_check""], ""port"", null)
        port_name          = lookup(each.value[""health_check""], ""port_name"", null)
        port_specification = lookup(each.value[""health_check""], ""port_specification"", null)
      }
    ] : []

    content {
      host         = lookup(https_health_check.value, ""host"", null)
      request_path = lookup(https_health_check.value, ""request_path"", null)
      response     = lookup(https_health_check.value, ""response"", null)

      port               = lookup(https_health_check.value, ""port"", null)
      port_name          = lookup(https_health_check.value, ""port_name"", null)
      port_specification = lookup(https_health_check.value, ""port_specification"", null)
    }
  }

  dynamic ""http2_health_check"" {
    for_each = each.value[""protocol""] == ""HTTP2"" ? [
      {
        host               = lookup(each.value[""health_check""], ""host"", null)
        request_path       = lookup(each.value[""health_check""], ""request_path"", null)
        response           = lookup(each.value[""health_check""], ""response"", null)
        port               = lookup(each.value[""health_check""], ""port"", null)
        port_name          = lookup(each.value[""health_check""], ""port_name"", null)
        port_specification = lookup(each.value[""health_check""], ""port_specification"", null)
      }
    ] : []

    content {
      host         = lookup(http2_health_check.value, ""host"", null)
      request_path = lookup(http2_health_check.value, ""request_path"", null)
      response     = lookup(http2_health_check.value, ""response"", null)

      port               = lookup(http2_health_check.value, ""port"", null)
      port_name          = lookup(http2_health_check.value, ""port_name"", null)
      port_specification = lookup(http2_health_check.value, ""port_specification"", null)
    }
  }

}
",resource,149,,9e9fc7746c7b1dfeaa1506f09e0410e0e70d18d7,67ae7540846611edb3311d7e668158e98a7c8135,https://github.com/terraform-google-modules/terraform-google-lb-http/blob/9e9fc7746c7b1dfeaa1506f09e0410e0e70d18d7/main.tf#L149,https://github.com/terraform-google-modules/terraform-google-lb-http/blob/67ae7540846611edb3311d7e668158e98a7c8135/main.tf,2019-10-23 18:15:14+01:00,2019-10-23 18:15:14+01:00,2,1,0,0,0,0,1,0,1,0
https://github.com/alphagov/govuk-aws,699,terraform/projects/app-draft-cache/main.tf,terraform/projects/app-draft-cache/main.tf,0,todo,# TODO publicapi is a special set of nginx config that routes /api requests to,"# TODO publicapi is a special set of nginx config that routes /api requests to 
 # their relevant apps upstream.","resource ""aws_route53_record"" ""draft-cache_publicapi_service_record"" {
  zone_id = ""${data.terraform_remote_state.infra_stack_dns_zones.internal_zone_id}""
  name    = ""draft-publicapi.${data.terraform_remote_state.infra_stack_dns_zones.internal_domain_name}""
  type    = ""CNAME""
  records = [""draft-cache.${data.terraform_remote_state.infra_stack_dns_zones.internal_domain_name}""]
  ttl     = 300
}
",resource,,,134,0.0,9f011edb46f4934d57ca530017aba313d337ba20,241558af7d6786415e64eea48e193f23518625c2,https://github.com/alphagov/govuk-aws/blob/9f011edb46f4934d57ca530017aba313d337ba20/terraform/projects/app-draft-cache/main.tf#L134,https://github.com/alphagov/govuk-aws/blob/241558af7d6786415e64eea48e193f23518625c2/terraform/projects/app-draft-cache/main.tf#L0,2018-10-26 13:18:26+01:00,2023-05-10 15:30:22+01:00,23,2,0,0,0,0,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,981,fast/stages/03-gke-multitenant/module/gke-hub.tf,fast/stages/03-gke-multitenant/module/gke-hub.tf,0,# todo,# TODO: service account,"/** 
 * Copyright 2022 Google LLC 
 * 
 * Licensed under the Apache License, Version 2.0 (the ""License""); 
 * you may not use this file except in compliance with the License. 
 * You may obtain a copy of the License at 
 * 
 *      http://www.apache.org/licenses/LICENSE-2.0 
 * 
 * Unless required by applicable law or agreed to in writing, software 
 * distributed under the License is distributed on an ""AS IS"" BASIS, 
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
 * See the License for the specific language governing permissions and 
 * limitations under the License. 
 */  
 # TODO: service account 
 # https://cloud.google.com/kubernetes-engine/docs/how-to/msc-setup-with-shared-vpc-networks#shared-service-project-iam 
 # TODO: add roles/multiclusterservicediscovery.serviceAgent and 
 #       roles/compute.networkViewer to IAM condition for GKE stage SA ","locals {
  fleet_enabled = (
    var.fleet_features != null || var.fleet_workload_identity
  )
  # TODO: add condition
  fleet_mcs_enabled = false
}
",locals,"locals {
  fleet_enabled = (
    var.fleet_features != null || var.fleet_workload_identity
  )
  fleet_mcs_enabled = local.fleet_enabled && lookup(
    coalesce(var.fleet_features, {}), ""multiclusterservicediscovery"", false
  ) == true
}
",locals,17,,133fd078232ef202140450d921bb8018b60e700f,c24e66138339bb5c599e52cd88236267acac4611,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/133fd078232ef202140450d921bb8018b60e700f/fast/stages/03-gke-multitenant/module/gke-hub.tf#L17,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/c24e66138339bb5c599e52cd88236267acac4611/fast/stages/03-gke-multitenant/module/gke-hub.tf,2022-07-29 11:31:34+02:00,2022-07-29 14:01:35+02:00,2,1,0,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/hpc-toolkit,292,modules/network/multivpc/main.tf,modules/network/multivpc/main.tf,0,implementation,# consider changing to explicit var.subnetworks implementation,"# the value 0 creates a single subnetwork that spans the entire range above 
 # consider changing to explicit var.subnetworks implementation","module ""vpcs"" {
  source = ""github.com/GoogleCloudPlatform/hpc-toolkit//modules/network/vpc?ref=v1.31.1&depth=1""

  count = var.network_count

  project_id            = var.project_id
  deployment_name       = var.deployment_name
  region                = var.region
  network_address_range = cidrsubnet(local.global_ip_cidr_valid, local.subnetwork_new_bits, count.index)
  # the value 0 creates a single subnetwork that spans the entire range above
  # consider changing to explicit var.subnetworks implementation
  default_primary_subnetwork_size = 0

  network_name                           = ""${local.network_name}-${count.index}""
  subnetwork_name                        = ""${local.network_name}-${count.index}-subnet""
  allowed_ssh_ip_ranges                  = var.allowed_ssh_ip_ranges
  delete_default_internet_gateway_routes = var.delete_default_internet_gateway_routes
  enable_iap_rdp_ingress                 = var.enable_iap_rdp_ingress
  enable_iap_ssh_ingress                 = var.enable_iap_ssh_ingress
  enable_iap_winrm_ingress               = var.enable_iap_winrm_ingress
  enable_internal_traffic                = var.enable_internal_traffic
  extra_iap_ports                        = var.extra_iap_ports
  firewall_rules                         = var.firewall_rules
  ips_per_nat                            = var.ips_per_nat
  mtu                                    = var.mtu
  network_description                    = var.network_description
  network_routing_mode                   = var.network_routing_mode
}
",module,"module ""vpcs"" {
  source = ""github.com/GoogleCloudPlatform/hpc-toolkit//modules/network/vpc?ref=v1.32.1&depth=1""

  count = var.network_count

  project_id            = var.project_id
  deployment_name       = var.deployment_name
  region                = var.region
  network_address_range = cidrsubnet(local.global_ip_cidr_valid, local.subnetwork_new_bits, count.index)
  # the value 0 creates a single subnetwork that spans the entire range above
  # consider changing to explicit var.subnetworks implementation
  default_primary_subnetwork_size = 0

  network_name                           = ""${local.network_name}-${count.index}""
  subnetwork_name                        = ""${local.network_name}-${count.index}-subnet""
  allowed_ssh_ip_ranges                  = var.allowed_ssh_ip_ranges
  delete_default_internet_gateway_routes = var.delete_default_internet_gateway_routes
  enable_iap_rdp_ingress                 = var.enable_iap_rdp_ingress
  enable_iap_ssh_ingress                 = var.enable_iap_ssh_ingress
  enable_iap_winrm_ingress               = var.enable_iap_winrm_ingress
  enable_internal_traffic                = var.enable_internal_traffic
  extra_iap_ports                        = var.extra_iap_ports
  firewall_rules                         = var.firewall_rules
  ips_per_nat                            = var.ips_per_nat
  mtu                                    = var.mtu
  network_description                    = var.network_description
  network_routing_mode                   = var.network_routing_mode
}
",module,56,56.0,da5237a68099dd5ae7c69020609272a6b64e531a,0aec7fb77c813bd747de536bc927542877d69de6,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/da5237a68099dd5ae7c69020609272a6b64e531a/modules/network/multivpc/main.tf#L56,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/0aec7fb77c813bd747de536bc927542877d69de6/modules/network/multivpc/main.tf#L56,2024-04-12 17:18:10+00:00,2024-04-19 19:04:24+00:00,2,0,0,1,0,0,1,0,0,0
https://github.com/Worklytics/psoxy,391,infra/modules/hashicorp-vault-secrets/main.tf,infra/modules/hashicorp-vault-secrets/main.tf,0,implementation,# q: is to ALSO pass in some notion of access? except very different per implementation,"# for use in explicit IAM policy grants? 
 # q: good idea? breaks notion of AWS SSM parameters secrets being an implementation of a generic 
 # secrets-store interface 
 # q: is to ALSO pass in some notion of access? except very different per implementation","output ""secret_ids"" {
  value = { for k, v in var.secrets : k => aws_ssm_parameter.secret[k].path }
}
",output,,,18,0.0,e8f084f7a3cb3950efeaf655a06bcbc8dcbaa137,31311227708efa985f4963b3b9c47bf2547ef506,https://github.com/Worklytics/psoxy/blob/e8f084f7a3cb3950efeaf655a06bcbc8dcbaa137/infra/modules/hashicorp-vault-secrets/main.tf#L18,https://github.com/Worklytics/psoxy/blob/31311227708efa985f4963b3b9c47bf2547ef506/infra/modules/hashicorp-vault-secrets/main.tf#L0,2022-10-04 10:51:26-07:00,2022-10-17 12:58:48-07:00,2,2,0,1,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,596,examples/data-solutions/data-platform-foundations/03-orchestration.tf,examples/data-solutions/data-platform-foundations/03-orchestration.tf,0,#todo,#TODO Check with Simo/Ludo,#TODO Check with Simo/Ludo,"resource ""google_project_iam_binding"" ""composer_shared_vpc_agent"" {
  count   = var.network_config.network != null ? 1 : 0
  project = var.network_config.host_project
  role    = ""roles/composer.sharedVpcAgent""
  members = [
    ""serviceAccount:${module.orc-prj.service_accounts.robots.composer}""
  ]
}
",resource,"resource ""google_project_iam_binding"" ""composer_shared_vpc_agent"" {
  count   = var.network_config.network_self_link != null ? 1 : 0
  project = local._shared_vpc_project
  role    = ""roles/composer.sharedVpcAgent""
  members = [
    ""serviceAccount:${module.orc-prj.service_accounts.robots.composer}""
  ]
}
",resource,128,,74b850b4b8edb1acfb80958f665c2aad10945fd0,d8bad5779036aa31639e4611e4935287fc79a4bc,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/74b850b4b8edb1acfb80958f665c2aad10945fd0/examples/data-solutions/data-platform-foundations/03-orchestration.tf#L128,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/d8bad5779036aa31639e4611e4935287fc79a4bc/examples/data-solutions/data-platform-foundations/03-orchestration.tf,2022-02-05 09:04:18+01:00,2022-02-07 21:28:54+01:00,4,1,0,0,0,0,0,0,0,1
https://github.com/Azure/Avere,20,src/terraform/modules/hammerspace/anvil/main.tf,src/terraform/modules/hammerspace/anvil/main.tf,0,todo,// TODO - create the associations https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/network_interface_backend_address_pool_association,// TODO - create the associations https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/network_interface_backend_address_pool_association,"resource ""azurerm_lb_backend_address_pool"" ""anvilloadbalancerbepool"" {
  count               = local.is_high_availability ? 1 : 0
  resource_group_name = var.resource_group_name
  loadbalancer_id     = azurerm_lb.anvilloadbalancer[0].id
  name                = ""${var.unique_name}LoadBalancerBEPool""
}
",resource,"resource ""azurerm_lb_backend_address_pool"" ""anvilloadbalancerbepool"" {
  count           = local.is_high_availability ? 1 : 0
  loadbalancer_id = azurerm_lb.anvilloadbalancer[0].id
  name            = ""${var.unique_name}LoadBalancerBEPool""
}
",resource,48,,47847b35c4a7b8d24584e2c9690ea7a41d5bc3f1,a64c98d189a8f44b087f399cfa0864ecef7b3eeb,https://github.com/Azure/Avere/blob/47847b35c4a7b8d24584e2c9690ea7a41d5bc3f1/src/terraform/modules/hammerspace/anvil/main.tf#L48,https://github.com/Azure/Avere/blob/a64c98d189a8f44b087f399cfa0864ecef7b3eeb/src/terraform/modules/hammerspace/anvil/main.tf,2021-03-02 06:48:40-05:00,2021-05-02 10:11:01-04:00,7,1,0,1,0,0,1,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,640,modules/_user_data/main.tf,modules/_user_data/main.tf,0,todo,# TODO - will be removed in v21.0,"# Try to use `ami_type` first, but fall back to current, default behavior 
 # TODO - will be removed in v21.0","locals {
  # Converts AMI type into user data type that represents the underlying format (bash, toml, PS1, nodeadm)
  # TODO - platform will be removed in v21.0 and only `ami_type` will be valid
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  template_path = {
    al2023       = ""${path.module}/../../templates/al2023_user_data.tpl""
    bottlerocket = ""${path.module}/../../templates/bottlerocket_user_data.tpl""
    linux        = ""${path.module}/../../templates/linux_user_data.tpl""
    windows      = ""${path.module}/../../templates/windows_user_data.tpl""
  }

  cluster_service_cidr = try(coalesce(var.cluster_service_ipv4_cidr, var.cluster_service_cidr), """")

  user_data = base64encode(templatefile(
    coalesce(var.user_data_template_path, local.template_path[local.user_data_type]),
    {
      # https://docs.aws.amazon.com/eks/latest/userguide/launch-templates.html#launch-template-custom-ami
      enable_bootstrap_user_data = var.enable_bootstrap_user_data

      # Required to bootstrap node
      cluster_name        = var.cluster_name
      cluster_endpoint    = var.cluster_endpoint
      cluster_auth_base64 = var.cluster_auth_base64

      cluster_service_cidr = local.cluster_service_cidr
      cluster_ip_family    = var.cluster_ip_family
      # Bottlerocket
      cluster_dns_ip = try(cidrhost(local.cluster_service_cidr, 10), """")

      # Optional
      bootstrap_extra_args     = var.bootstrap_extra_args
      pre_bootstrap_user_data  = var.pre_bootstrap_user_data
      post_bootstrap_user_data = var.post_bootstrap_user_data
    }
  ))

  user_data_type_to_rendered = {
    al2023 = {
      user_data = var.create ? try(data.cloudinit_config.al2023_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    bottlerocket = {
      user_data = var.create && local.user_data_type == ""bottlerocket"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.bootstrap_extra_args != """") ? local.user_data : """"
    }
    linux = {
      user_data = var.create ? try(data.cloudinit_config.linux_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    windows = {
      user_data = var.create && local.user_data_type == ""windows"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.pre_bootstrap_user_data != """") ? local.user_data : """"
    }
  }
}
",locals,"locals {
  # Converts AMI type into user data type that represents the underlying format (bash, toml, PS1, nodeadm)
  # TODO - platform will be removed in v21.0 and only `ami_type` will be valid
  ami_type_to_user_data_type = {
    AL2_x86_64                 = ""linux""
    AL2_x86_64_GPU             = ""linux""
    AL2_ARM_64                 = ""linux""
    BOTTLEROCKET_ARM_64        = ""bottlerocket""
    BOTTLEROCKET_x86_64        = ""bottlerocket""
    BOTTLEROCKET_ARM_64_NVIDIA = ""bottlerocket""
    BOTTLEROCKET_x86_64_NVIDIA = ""bottlerocket""
    WINDOWS_CORE_2019_x86_64   = ""windows""
    WINDOWS_FULL_2019_x86_64   = ""windows""
    WINDOWS_CORE_2022_x86_64   = ""windows""
    WINDOWS_FULL_2022_x86_64   = ""windows""
    AL2023_x86_64_STANDARD     = ""al2023""
    AL2023_ARM_64_STANDARD     = ""al2023""
  }
  # Try to use `ami_type` first, but fall back to current, default behavior
  # TODO - will be removed in v21.0
  user_data_type = try(local.ami_type_to_user_data_type[var.ami_type], var.platform)

  template_path = {
    al2023       = ""${path.module}/../../templates/al2023_user_data.tpl""
    bottlerocket = ""${path.module}/../../templates/bottlerocket_user_data.tpl""
    linux        = ""${path.module}/../../templates/linux_user_data.tpl""
    windows      = ""${path.module}/../../templates/windows_user_data.tpl""
  }

  cluster_service_cidr = try(coalesce(var.cluster_service_ipv4_cidr, var.cluster_service_cidr), """")

  user_data = base64encode(templatefile(
    coalesce(var.user_data_template_path, local.template_path[local.user_data_type]),
    {
      # https://docs.aws.amazon.com/eks/latest/userguide/launch-templates.html#launch-template-custom-ami
      enable_bootstrap_user_data = var.enable_bootstrap_user_data

      # Required to bootstrap node
      cluster_name        = var.cluster_name
      cluster_endpoint    = var.cluster_endpoint
      cluster_auth_base64 = var.cluster_auth_base64

      cluster_service_cidr = local.cluster_service_cidr
      cluster_ip_family    = var.cluster_ip_family
      # Bottlerocket
      cluster_dns_ip = try(cidrhost(local.cluster_service_cidr, 10), """")

      # Optional
      bootstrap_extra_args     = var.bootstrap_extra_args
      pre_bootstrap_user_data  = var.pre_bootstrap_user_data
      post_bootstrap_user_data = var.post_bootstrap_user_data
    }
  ))

  user_data_type_to_rendered = {
    al2023 = {
      user_data = var.create ? try(data.cloudinit_config.al2023_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    bottlerocket = {
      user_data = var.create && local.user_data_type == ""bottlerocket"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.bootstrap_extra_args != """") ? local.user_data : """"
    }
    linux = {
      user_data = var.create ? try(data.cloudinit_config.linux_eks_managed_node_group[0].rendered, local.user_data) : """"
    }
    windows = {
      user_data = var.create && local.user_data_type == ""windows"" && (var.enable_bootstrap_user_data || var.user_data_template_path != """" || var.pre_bootstrap_user_data != """") ? local.user_data : """"
    }
  }
}
",locals,35,35.0,74d39187d855932dd976da6180eda42dcfe09873,74d39187d855932dd976da6180eda42dcfe09873,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/_user_data/main.tf#L35,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/74d39187d855932dd976da6180eda42dcfe09873/modules/_user_data/main.tf#L35,2024-05-08 08:04:19-04:00,2024-05-08 08:04:19-04:00,1,0,0,1,0,0,0,0,0,0
https://github.com/Azure/az-hop,1,tf/keyvault.tf,tf/keyvault.tf,0,todo,# TODO => Add the option to enable VMs to keep secrets in KV,# TODO => Add the option to enable VMs to keep secrets in KV,"resource ""azurerm_key_vault"" ""deployhpc"" {
  name                        = format(""%s%s"", ""kv"", random_string.random.result)
  location                    = azurerm_resource_group.rg.location
  resource_group_name         = azurerm_resource_group.rg.name
  enabled_for_disk_encryption = true
  tenant_id                   = data.azurerm_client_config.current.tenant_id
  soft_delete_enabled         = true
  soft_delete_retention_days  = 7
  purge_protection_enabled    = false
  # TODO => Add the option to enable VMs to keep secrets in KV
  sku_name = ""standard""

  access_policy {
    tenant_id = data.azurerm_client_config.current.tenant_id
    object_id = data.azurerm_client_config.current.object_id

    # QUESTION => Do we need this ?
    certificate_permissions = [
      ""get"",
      ""managecontacts"", 
    ]

    # QUESTION => Do we need this ?
    key_permissions = [
      ""get"",
    ]

    secret_permissions = [
      ""get"",
      ""set"",
      ""list"",
      ""delete"",
      ""purge"",
      ""recover"",
      ""restore""
    ]

    # QUESTION => Do we need this ?
    storage_permissions = [
      ""get"",
    ]
  }

  network_acls {
    default_action = ""Allow""
    bypass         = ""AzureServices""
  }
}
",resource,"resource ""azurerm_key_vault"" ""azhop"" {
  name                        = local.key_vault_name
  location                    = local.create_rg ? azurerm_resource_group.rg[0].location : data.azurerm_resource_group.rg[0].location
  resource_group_name         = local.create_rg ? azurerm_resource_group.rg[0].name : data.azurerm_resource_group.rg[0].name
  enabled_for_disk_encryption = true
  enabled_for_deployment      = true
  enabled_for_template_deployment = true
  tenant_id                   = local.tenant_id
  # soft delete is enabled by default now (2021-8-25), with 90 days retention
  # soft_delete_enabled         = true
  soft_delete_retention_days  = 7
  purge_protection_enabled    = true
  # TODO => Add the option to enable VMs to keep secrets in KV
  sku_name = ""standard""

  network_acls {
    default_action             = local.locked_down_network ? ""Deny"" : ""Allow""
    bypass                     = ""AzureServices""
    ip_rules                   = local.grant_access_from
    virtual_network_subnet_ids = [local.create_admin_subnet ? azurerm_subnet.admin[0].id : data.azurerm_subnet.admin[0].id]
  }
}
",resource,12,18.0,3401eed51efc83ffe43e672c0b863a41fed82427,c692256260053a8f543cc99411274f57d6d7a4b4,https://github.com/Azure/az-hop/blob/3401eed51efc83ffe43e672c0b863a41fed82427/tf/keyvault.tf#L12,https://github.com/Azure/az-hop/blob/c692256260053a8f543cc99411274f57d6d7a4b4/tf/keyvault.tf#L18,2020-12-04 10:09:00+00:00,2024-03-29 14:45:48+01:00,31,0,0,1,0,1,0,0,0,0
https://github.com/wireapp/wire-server-deploy,66,terraform/modules/hetzner-kubernetes/machines.variables.tf,terraform/modules/hetzner-kubernetes/machines.variables.tf,0,implement,# FUTUREWORK: replace 'any' by implementing https://www.terraform.io/docs/language/functions/defaults.html,"# FUTUREWORK: replace 'any' by implementing https://www.terraform.io/docs/language/functions/defaults.html 
 #","variable ""machines"" {
  description = ""list of machines""
  # type = list(object({
  #   group_name = string
  #   machine_id = string
  #   machine_type = string
  #   component_classes = list(string)
  #   volume = optional(object({
  #     size = number
  #     format = optional(string)
  #   }))
  # }))
  type = any
  default = []

  validation {
    condition = length(var.machines) > 0
    error_message = ""At least one machine must be defined.""
  }
}
",variable,"variable ""machines"" {
  description = ""list of machines""
  # type = list(object({
  #   group_name = string
  #   machine_id = string
  #   machine_type = string
  #   component_classes = list(string)
  #   volume = optional(object({
  #     size = number
  #     format = optional(string)
  #   }))
  # }))
  type = any
  default = []

  validation {
    condition = length(var.machines) > 0
    error_message = ""At least one machine must be defined.""
  }
}
",variable,14,14.0,3920e9276b86d927a007fd2d763caf4048b13f81,4982bdbd431d0a752e74556ec3d8b87d7257e576,https://github.com/wireapp/wire-server-deploy/blob/3920e9276b86d927a007fd2d763caf4048b13f81/terraform/modules/hetzner-kubernetes/machines.variables.tf#L14,https://github.com/wireapp/wire-server-deploy/blob/4982bdbd431d0a752e74556ec3d8b87d7257e576/terraform/modules/hetzner-kubernetes/machines.variables.tf#L14,2021-02-22 21:10:04+01:00,2023-07-27 17:19:32+02:00,2,0,1,1,0,0,0,0,0,0
https://github.com/nasa/cumulus,5,packages/s3-credentials-endpoint/main.tf,packages/s3-credentials-endpoint/main.tf,0,todo,# TODO Remove this stub value,"DISTRIBUTION_REDIRECT_ENDPOINT = ""https://${var.rest_api.id}.execute-api.${var.region}.amazonaws.com/${var.stage_name}/${var.redirect_path}"" 
 # TODO Remove this stub value 
 # public_buckets            = """"","resource ""aws_lambda_function"" ""s3_credentials"" {
  function_name = ""${var.prefix}-s3-credentials-endpoint""
  # TODO Fetch this from ... somewhere. Or package it with the module zip file? Probably the better option
  filename         = ""${path.module}/dist/src.zip""
  source_code_hash = filebase64sha256(""${path.module}/dist/src.zip"")
  handler          = ""index.handler""
  role             = aws_iam_role.s3_credentials_lambda.arn
  runtime          = ""nodejs8.10""
  timeout          = 10
  memory_size      = 320
  environment {
    variables = {
      DISTRIBUTION_REDIRECT_ENDPOINT = ""https://${var.rest_api.id}.execute-api.${var.region}.amazonaws.com/${var.stage_name}/${var.redirect_path}""
      # TODO Remove this stub value
      # public_buckets            = """"
      EARTHDATA_BASE_URL        = var.urs_url
      EARTHDATA_CLIENT_ID       = var.urs_client_id
      EARTHDATA_CLIENT_PASSWORD = var.urs_client_password
      AccessTokensTable         = aws_dynamodb_table.access_tokens.id
      STSCredentialsLambda      = var.sts_credentials_lambda_arn
    }
  }
}
",resource,"resource ""aws_lambda_function"" ""s3_credentials"" {
  function_name    = ""${var.prefix}-s3-credentials-endpoint""
  filename         = ""${local.dist_dir}/index.js""
  source_code_hash = data.archive_file.s3_credentials_endpoint_package.output_base64sha256
  handler          = ""index.handler""
  role             = aws_iam_role.s3_credentials_lambda.arn
  runtime          = ""nodejs8.10""
  timeout          = 10
  memory_size      = 320
  vpc_config {
    subnet_ids = var.subnet_ids
    security_group_ids = var.ngap_sgs
  }
  environment {
    variables = {
      DISTRIBUTION_REDIRECT_ENDPOINT = ""https://${var.rest_api.id}.execute-api.${var.region}.amazonaws.com/${var.stage_name}/${var.redirect_path}""
      public_buckets            = var.public_buckets
      EARTHDATA_BASE_URL        = var.urs_url
      EARTHDATA_CLIENT_ID       = var.urs_client_id
      EARTHDATA_CLIENT_PASSWORD = var.urs_client_password
      AccessTokensTable         = aws_dynamodb_table.access_tokens.id
      STSCredentialsLambda      = var.sts_credentials_lambda_arn
    }
  }
}
",resource,64,,b37630397418a4cb61e428974577b0e21a636fae,6af6a727f927229cc2c252726bf45b1ab093c4be,https://github.com/nasa/cumulus/blob/b37630397418a4cb61e428974577b0e21a636fae/packages/s3-credentials-endpoint/main.tf#L64,https://github.com/nasa/cumulus/blob/6af6a727f927229cc2c252726bf45b1ab093c4be/packages/s3-credentials-endpoint/main.tf,2019-07-02 10:24:14-04:00,2019-07-17 18:01:16-05:00,3,1,1,1,0,0,0,0,0,0
https://github.com/cattle-ops/terraform-aws-gitlab-runner,1,main.tf,main.tf,0,workaround,"# workaround for ""conditional operator cannot be used with list values""","# workaround for ""conditional operator cannot be used with list values""","locals {
  # workaround for ""conditional operator cannot be used with list values""
  runner_ssh_config = {
    enabled  = ""${var.gitlab_runner_ssh_cidr_blocks}""
    disabled = ""${list()}""
  }
}
",locals,"locals {
  // Convert list to a string separated and prepend by a comma
  docker_machine_options_string           = ""${format("",%s"", join("","", formatlist(""%q"", var.docker_machine_options)))}""
  runners_off_peak_periods_string         = ""${var.runners_off_peak_periods == """" ? """" : format(""OffPeakPeriods = %s"", var.runners_off_peak_periods)}""
  secure_parameter_store_runner_token_key = ""${var.environment}-${var.secure_parameter_store_runner_token_key}""
}
",locals,7,,55e74cc467c2d39b7e458496c24eb5d6ca924609,f42a055f92d05224c26848049123e24b89161c16,https://github.com/cattle-ops/terraform-aws-gitlab-runner/blob/55e74cc467c2d39b7e458496c24eb5d6ca924609/main.tf#L7,https://github.com/cattle-ops/terraform-aws-gitlab-runner/blob/f42a055f92d05224c26848049123e24b89161c16/main.tf,2019-04-12 18:06:36-07:00,2019-04-12 22:18:20-07:00,2,1,0,1,0,0,0,0,0,0
https://github.com/uyuni-project/sumaform,1354,modules/pts/main.tf,modules/pts/main.tf,0,fix,// FIXME,// FIXME,"module ""locust"" {
  source               = ""../locust""
  name                 = var.locust_name
  base_configuration   = var.base_configuration
  server_configuration = module.server.configuration
  locust_file          = ""modules/libvirt/pts/locustfile.py""
  slave_quantity       = 5


  memory = 1024
  // FIXME
  mac    = var.locust_mac
}
",module,"module ""locust"" {
  source               = ""../locust""
  name                 = var.locust_name
  base_configuration   = var.base_configuration
  server_configuration = module.server.configuration
  locust_file          = ""${path.module}/locustfile.py""
  slave_quantity       = 5
  provider_settings    = var.locust_provider_settings
}
",module,59,,e929516f1e746ca6b74abf40d71b026a56e09d0c,284b756e4cf20114fb5a8919c36fdb838b2ab269,https://github.com/uyuni-project/sumaform/blob/e929516f1e746ca6b74abf40d71b026a56e09d0c/modules/pts/main.tf#L59,https://github.com/uyuni-project/sumaform/blob/284b756e4cf20114fb5a8919c36fdb838b2ab269/modules/pts/main.tf,2020-01-28 10:22:11+00:00,2020-01-28 10:22:11+00:00,2,1,0,1,0,0,1,0,0,0
https://github.com/nasa/cumulus,265,tf-modules/ingest/sqs-message-remover.tf,tf-modules/ingest/sqs-message-remover.tf,0,# todo,# TODO: Create a local variable for security groups to use,"# TODO: Create a local variable for security groups to use 
 # throughout the ingest modiule","module ""sqs_message_remover_lambda"" {
  source = ""../../lambdas/sqs-message-remover""

  prefix = var.prefix

  cmr_environment = var.cmr_environment

  system_bucket = var.system_bucket

  lambda_subnet_ids = var.lambda_subnet_ids
  # TODO: Create a local variable for security groups to use
  # throughout the ingest modiule
  security_group_ids = [
    aws_security_group.no_ingress_all_egress[0].id
  ]

  tags = var.tags

  # is this necessary or should we move towards least privileges
  # for the lambda?
  lambda_processing_role_arn = var.lambda_processing_role_arn
}
",module,"module ""sqs_message_remover_lambda"" {
  source = ""../../lambdas/sqs-message-remover""

  prefix = var.prefix

  system_bucket = var.system_bucket

  lambda_subnet_ids = var.lambda_subnet_ids
  # TODO: Create a local variable for security groups to use
  # throughout the ingest modiule
  security_group_ids = [
    aws_security_group.no_ingress_all_egress[0].id
  ]

  tags = var.tags

  # is this necessary or should we move towards least privileges
  # for the lambda?
  lambda_processing_role_arn = var.lambda_processing_role_arn
  lambda_timeouts       = var.lambda_timeouts
  lambda_memory_sizes   = var.lambda_memory_sizes
}
",module,11,9.0,4ddf0e2f969ae00b52c0cf63fbaf74be80401915,b3166bf3a9969a4cbff452ab7f6568874f94d06e,https://github.com/nasa/cumulus/blob/4ddf0e2f969ae00b52c0cf63fbaf74be80401915/tf-modules/ingest/sqs-message-remover.tf#L11,https://github.com/nasa/cumulus/blob/b3166bf3a9969a4cbff452ab7f6568874f94d06e/tf-modules/ingest/sqs-message-remover.tf#L9,2020-08-04 11:28:42-04:00,2023-10-13 14:43:14-04:00,4,0,1,1,0,1,0,0,0,0
https://github.com/kubernetes/k8s.io,115,infra/gcp/clusters/modules/gke-project/main.tf,infra/gcp/terraform/modules/gke-project/main.tf,1,// todo,// TODO(spiffxp): explicitly not using a data source for this until,"// TODO(spiffxp): explicitly not using a data source for this until 
 // I have a better sense of whether this requires more permissions 
 // than (are / should be) available for k8s-infra-prow-oncall and 
 // k8s-infra-cluster-admins 
 // data google_billing_account { 
 // billing_account = locals.billing_account 
 // }  
 // Create the project in which we're creating the cluster","resource ""google_project"" ""project"" {
  name            = var.project_name
  project_id      = var.project_name
  org_id          = data.google_organization.org.org_id
  billing_account = local.billing_account
}
",resource,"resource ""google_project"" ""project"" {
  name            = var.project_name
  project_id      = var.project_name
  org_id          = data.google_organization.org.org_id
  billing_account = local.billing_account
}
",resource,28,55.0,d09eae6759b7f46c3c63dd96593d4a5d8b7c10a1,84bb4180c27c027b4391af1b3c3afa427935d1b9,https://github.com/kubernetes/k8s.io/blob/d09eae6759b7f46c3c63dd96593d4a5d8b7c10a1/infra/gcp/clusters/modules/gke-project/main.tf#L28,https://github.com/kubernetes/k8s.io/blob/84bb4180c27c027b4391af1b3c3afa427935d1b9/infra/gcp/terraform/modules/gke-project/main.tf#L55,2021-03-03 16:40:35-05:00,2024-02-08 15:43:16-08:00,9,0,0,1,0,1,0,0,0,0
https://github.com/wireapp/wire-server-deploy,61,terraform/modules/sft/variables.tf,terraform/modules/sft/variables.tf,0,#todo,#TODO: Make this better,#TODO: Make this better,"variable ""server_names_stale"" {
  #TODO: Make this better
  description = ""List of names of stale sft servers. The server will be availables at sft<name>.<environment>.<root_domain>, ideally these shouldn't be touched by terraform""
  type = set(string)
}
",variable,the block associated got renamed or deleted,,15,,8d9b7151e0d68df4553b84e43b905305f02c39ba,d8e12109f7193074bb4c065a6e3c0580a24cbceb,https://github.com/wireapp/wire-server-deploy/blob/8d9b7151e0d68df4553b84e43b905305f02c39ba/terraform/modules/sft/variables.tf#L15,https://github.com/wireapp/wire-server-deploy/blob/d8e12109f7193074bb4c065a6e3c0580a24cbceb/terraform/modules/sft/variables.tf,2020-10-06 18:36:03+02:00,2020-10-15 12:30:35+02:00,2,1,0,1,0,0,0,0,0,0
https://github.com/aws-observability/terraform-aws-observability-accelerator,5,examples/workloads.tf,examples/workloads.tf,0,# todo,"# TODO: create also a cluster, VPC -- check if enough VPCs","# TODO: create also a cluster, VPC -- check if enough VPCs  
 # deploys AWS Distro for OpenTelemetry operator into the cluster","module ""eks_observability_accelerator"" {
  #source = ""aws-ia/terrarom-aws-observability-accelerator""
  source = ""../""

  aws_region     = var.aws_region
  eks_cluster_id = var.eks_cluster_id

  # TODO: create also a cluster, VPC -- check if enough VPCs

  # deploys AWS Distro for OpenTelemetry operator into the cluster
  enable_amazon_eks_adot = false

  # reusing existing certificate manager? defaults to true
  enable_cert_manager = false

  # # -- or enable opentelemetry operator
  enable_opentelemetry_operator = false #-- true doesn't work for me, needs fix
  #open_telemetry_operator_config = map() // custom config

  # creates a new AMP workspace, defaults to true
  enable_managed_prometheus = false

  # reusing existing AMP -- needs data source for alerting rules
  managed_prometheus_id     = var.managed_prometheus_workspace_id
  managed_prometheus_region = null # defaults to the current region, useful for cross region scenarios (same account)

  # sets up the AMP alert manager at the workspace level
  enable_alertmanager = true

  # create a new Grafana workspace
  enable_managed_grafana = true
  #managed_grafana_workspace_id = ""g-9790a4306b""



  enable_java                 = true
  enable_java_recording_rules = true


  # enable_haproxy = true
  # haproxy_config = {
  #   amp_endpoint     = module / amp.endpoint
  #   grafana_endpoint = module.grafana.endpoint
  # }


  # java_config = {
  #   amp_endpoint     = """"
  #   grafana_endpoint = """"
  # }

  # # -- or provide custom alerts definition
  # prometheus_custom_alert_rule = var.prometheus_custom_alert_rule


  # # create grafana workspace, and customer to deal with authentication later
  # create_managed_grafana_workspace = true
  # grafana_auth_provider            = var.grafana_auth_provider       //SAML or AWS_SSO
  # grafana_account_access_type      = var.grafana_account_access_type // CURRENT_ACCOUNT or ORGANIZATION
  # grafana_permission_type          = var.grafana_permission_type     // SERVICE_MANAGED or CUSTOMER_MANAGED
  # grafana_permission_role_arn      = var.grafana_permission_role_arn // if CUSTOMER_MANAGED

  # # -- or using existing amg workspace. so we can use API for keys


  tags = local.tags


}
",module,"module ""eks_observability_accelerator"" {
  #source = ""aws-ia/terrarom-aws-observability-accelerator""
  source = ""../""

  aws_region     = var.aws_region
  eks_cluster_id = var.eks_cluster_id

  # deploys AWS Distro for OpenTelemetry operator into the cluster
  enable_amazon_eks_adot = true

  # reusing existing certificate manager? defaults to true
  enable_cert_manager = true

  # # -- or enable opentelemetry operator
  enable_opentelemetry_operator = false
  #open_telemetry_operator_config = map() // custom config

  # creates a new AMP workspace, defaults to true
  enable_managed_prometheus = false

  # reusing existing AMP -- needs data source for alerting rules
  managed_prometheus_id     = var.managed_prometheus_workspace_id
  managed_prometheus_region = null # defaults to the current region, useful for cross region scenarios (same account)

  # sets up the AMP alert manager at the workspace level
  enable_alertmanager = true

  # create a new Grafana workspace - TODO review design
  enable_managed_grafana       = false
  managed_grafana_workspace_id = var.managed_grafana_workspace_id
  grafana_api_key              = var.grafana_api_key

  # enable workload-specific collector, metrics, alerts and dashboards
  enable_java                 = false
  enable_java_recording_rules = false

  # enable_haproxy = true
  # haproxy_config = {
  #   amp_endpoint     = module / amp.endpoint
  #   grafana_endpoint = module.grafana.endpoint
  # }

  enable_infra_metrics = true
  #infra_metrics_config = {}

  tags = local.tags
}
",module,10,,2a5564607491389ad1a87c16add9542d44d9ac20,a8fc12f7b7d7f4ed814d48061cf3e0eb4a646c9e,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/2a5564607491389ad1a87c16add9542d44d9ac20/examples/workloads.tf#L10,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/a8fc12f7b7d7f4ed814d48061cf3e0eb4a646c9e/examples/workloads.tf,2022-08-26 17:30:03+02:00,2022-08-26 17:30:03+02:00,3,1,1,1,0,0,1,0,0,0
https://github.com/oracle-terraform-modules/terraform-oci-oke,291,variables-network.tf,variables-network.tf,0,todo,"// TODO Align with subnets declaration, never/auto/always","variable ""create_nsgs_always"" { // TODO Align with subnets declaration, never/auto/always","variable ""create_nsgs_always"" { // TODO Align with subnets declaration, never/auto/always
  default     = false
  description = ""Whether to create standard network security groups when associated components will not be.""
  type        = bool
}
",variable,the block associated got renamed or deleted,,16,,cf7f4da8a0c56d0350bd86c2ef1011e3f6c2f3b2,32cf3b275cc82bf2119d9d27231c8bc86b6e0ed1,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/cf7f4da8a0c56d0350bd86c2ef1011e3f6c2f3b2/variables-network.tf#L16,https://github.com/oracle-terraform-modules/terraform-oci-oke/blob/32cf3b275cc82bf2119d9d27231c8bc86b6e0ed1/variables-network.tf,2023-10-25 16:40:02+11:00,2023-10-25 16:40:02+11:00,5,1,0,1,0,1,1,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,1699,fast/stages/1-resman/branch-teams.tf,fast/stages/1-resman/branch-teams.tf,0,# todo,# TODO: move into team's own IaC project,# TODO: move into team's own IaC project,"module ""branch-teams-team-sa"" {
  source       = ""../../../modules/iam-service-account""
  for_each     = var.fast_features.teams ? coalesce(var.team_folders, {}) : {}
  project_id   = var.automation.project_id
  name         = ""prod-teams-${each.key}-0""
  display_name = ""Terraform team ${each.key} service account.""
  prefix       = var.prefix
  iam = {
    ""roles/iam.serviceAccountTokenCreator"" = concat(
      compact([try(module.branch-teams-team-sa-cicd[each.key].iam_email, null)]),
      (
        each.value.impersonation_groups == null
        ? []
        : [for g in each.value.impersonation_groups : ""group:${g}""]
      )
    )
  }
}
",module,,,88,0.0,e7e188818a633c1b6a47ec318eb3513b50b7437a,7a5dd4e6db197daa52da8a8d877ce86b5c93182e,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/e7e188818a633c1b6a47ec318eb3513b50b7437a/fast/stages/1-resman/branch-teams.tf#L88,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/7a5dd4e6db197daa52da8a8d877ce86b5c93182e/fast/stages/1-resman/branch-teams.tf#L0,2023-10-18 12:18:31+00:00,2024-05-15 09:17:13+00:00,8,2,0,1,0,1,0,0,0,0
https://github.com/terraform-google-modules/terraform-google-bigquery,68,modules/data_warehouse/outputs.tf,modules/data_warehouse/outputs.tf,0,#todo,#TODO Create new Looker Studio Template,#TODO Create new Looker Studio Template,"output ""lookerstudio_report_url"" {
  value       = ""https://lookerstudio.google.com/reporting/create?c.reportId=8a6517b8-8fcd-47a2-a953-9d4fb9ae4794&ds.ds_profit.datasourceName=lookerstudio_report_profit&ds.ds_profit.projectId=${module.project-services.project_id}&ds.ds_profit.type=TABLE&ds.ds_profit.datasetId=${google_bigquery_dataset.ds_edw.dataset_id}&ds.ds_profit.tableId=lookerstudio_report_profit&ds.ds_dc.datasourceName=lookerstudio_report_distribution_centers&ds.ds_dc.projectId=${module.project-services.project_id}&ds.ds_dc.type=TABLE&ds.ds_dc.datasetId=${google_bigquery_dataset.ds_edw.dataset_id}&ds.ds_dc.tableId=lookerstudio_report_distribution_centers""
  description = ""The URL to create a new Looker Studio report displays a sample dashboard for the e-commerce data analysis""
}
",output,"output ""lookerstudio_report_url"" {
  value       = ""https://lookerstudio.google.com/reporting/create?c.reportId=8a6517b8-8fcd-47a2-a953-9d4fb9ae4794&ds.ds_profit.datasourceName=lookerstudio_report_profit&ds.ds_profit.projectId=${module.project-services.project_id}&ds.ds_profit.type=TABLE&ds.ds_profit.datasetId=${google_bigquery_dataset.ds_edw.dataset_id}&ds.ds_profit.tableId=lookerstudio_report_profit&ds.ds_dc.datasourceName=lookerstudio_report_distribution_centers&ds.ds_dc.projectId=${module.project-services.project_id}&ds.ds_dc.type=TABLE&ds.ds_dc.datasetId=${google_bigquery_dataset.ds_edw.dataset_id}&ds.ds_dc.tableId=lookerstudio_report_distribution_centers""
  description = ""The URL to create a new Looker Studio report displays a sample dashboard for the e-commerce data analysis""
}
",output,27,,e97adfb1984592a6f9e4eea8f8bdc3d2969e3d2d,f88f4b53ea5ed8416ed01e7285fa6018ddb8bd0b,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/e97adfb1984592a6f9e4eea8f8bdc3d2969e3d2d/modules/data_warehouse/outputs.tf#L27,https://github.com/terraform-google-modules/terraform-google-bigquery/blob/f88f4b53ea5ed8416ed01e7285fa6018ddb8bd0b/modules/data_warehouse/outputs.tf,2023-10-09 13:27:46-06:00,2023-10-23 13:10:22-06:00,2,1,0,1,0,0,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,613,modules/karpenter/main.tf,modules/karpenter/main.tf,0,todo,# TODO - this will be replaced in v20.0 with the scoped policy provided by Karpenter,"  # TODO - this will be replaced in v20.0 with the scoped policy provided by Karpenter
  # https://github.com/aws/karpenter/blob/main/website/content/en/docs/upgrading/v1beta1-controller-policy.json","data ""aws_iam_policy_document"" ""irsa"" {
  count = local.create_irsa ? 1 : 0

  statement {
    actions = [
      ""ec2:CreateLaunchTemplate"",
      ""ec2:CreateFleet"",
      ""ec2:CreateTags"",
      ""ec2:DescribeLaunchTemplates"",
      ""ec2:DescribeImages"",
      ""ec2:DescribeInstances"",
      ""ec2:DescribeSecurityGroups"",
      ""ec2:DescribeSubnets"",
      ""ec2:DescribeInstanceTypes"",
      ""ec2:DescribeInstanceTypeOfferings"",
      ""ec2:DescribeAvailabilityZones"",
      ""ec2:DescribeSpotPriceHistory"",
      ""pricing:GetProducts"",
    ]

    resources = [""*""]
  }

  statement {
    actions = [
      ""ec2:TerminateInstances"",
      ""ec2:DeleteLaunchTemplate"",
    ]

    resources = [""*""]

    condition {
      test     = ""StringEquals""
      variable = ""ec2:ResourceTag/${var.irsa_tag_key}""
      values   = local.irsa_tag_values
    }
  }

  statement {
    actions = [""ec2:RunInstances""]
    resources = [
      ""arn:${local.partition}:ec2:*:${local.account_id}:launch-template/*"",
    ]

    condition {
      test     = ""StringEquals""
      variable = ""ec2:ResourceTag/${var.irsa_tag_key}""
      values   = local.irsa_tag_values
    }
  }

  statement {
    actions = [""ec2:RunInstances""]
    resources = [
      ""arn:${local.partition}:ec2:*::image/*"",
      ""arn:${local.partition}:ec2:*::snapshot/*"",
      ""arn:${local.partition}:ec2:*:${local.account_id}:instance/*"",
      ""arn:${local.partition}:ec2:*:${local.account_id}:spot-instances-request/*"",
      ""arn:${local.partition}:ec2:*:${local.account_id}:security-group/*"",
      ""arn:${local.partition}:ec2:*:${local.account_id}:volume/*"",
      ""arn:${local.partition}:ec2:*:${local.account_id}:network-interface/*"",
      ""arn:${local.partition}:ec2:*:${coalesce(var.irsa_subnet_account_id, local.account_id)}:subnet/*"",
    ]
  }

  statement {
    actions   = [""ssm:GetParameter""]
    resources = var.irsa_ssm_parameter_arns
  }

  statement {
    actions   = [""eks:DescribeCluster""]
    resources = [""arn:${local.partition}:eks:*:${local.account_id}:cluster/${var.cluster_name}""]
  }

  statement {
    actions   = [""iam:PassRole""]
    resources = [var.create_iam_role ? aws_iam_role.this[0].arn : var.iam_role_arn]
  }

  dynamic ""statement"" {
    for_each = local.enable_spot_termination ? [1] : []

    content {
      actions = [
        ""sqs:DeleteMessage"",
        ""sqs:GetQueueUrl"",
        ""sqs:GetQueueAttributes"",
        ""sqs:ReceiveMessage"",
      ]
      resources = [aws_sqs_queue.this[0].arn]
    }
  }

  # TODO - this will be replaced in v20.0 with the scoped policy provided by Karpenter
  # https://github.com/aws/karpenter/blob/main/website/content/en/docs/upgrading/v1beta1-controller-policy.json
  dynamic ""statement"" {
    for_each = var.enable_karpenter_instance_profile_creation ? [1] : []

    content {
      actions = [
        ""iam:AddRoleToInstanceProfile"",
        ""iam:CreateInstanceProfile"",
        ""iam:DeleteInstanceProfile"",
        ""iam:GetInstanceProfile"",
        ""iam:RemoveRoleFromInstanceProfile"",
        ""iam:TagInstanceProfile"",
      ]
      resources = [""*""]
    }
  }
}
",data,the block associated got renamed or deleted,,164,,aec2bab1d8da89b65b84d11fef77cbc969fccc91,6b40bdbb1d283d9259f43b03d24dca99cc1eceff,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/aec2bab1d8da89b65b84d11fef77cbc969fccc91/modules/karpenter/main.tf#L164,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/6b40bdbb1d283d9259f43b03d24dca99cc1eceff/modules/karpenter/main.tf,2023-11-01 11:33:07-04:00,2024-02-02 09:36:25-05:00,4,1,1,1,0,1,0,0,0,0
https://github.com/chanzuckerberg/cztack,128,aws-iam-role/main.tf,aws-iam-role/main.tf,0,hack,# Slight hack so Terraform can get the size statically during the plan.,"# Slight hack so Terraform can get the size statically during the plan. 
 # Simply passing the list to `for_each` throws an Invalid for_each argument","locals {
  # Slight hack so Terraform can get the size statically during the plan. 
  # Simply passing the list to `for_each` throws an Invalid for_each argument
  attached_policies_names_arns = zipmap(var.attached_policies_arns, var.attached_policies_arns)

  tags = {
    project   = var.project
    env       = var.env
    service   = var.service
    owner     = var.owner
    managedBy = ""terraform""
  }
}
",locals,"locals {
  tags = {
    project   = var.project
    env       = var.env
    service   = var.service
    owner     = var.owner
    managedBy = ""terraform""
  }
}
",locals,2,,4008493ab394e50f6def8dc22d9297f29556e638,216fe141b5aebe1d4eb594f10016eed34716d6fc,https://github.com/chanzuckerberg/cztack/blob/4008493ab394e50f6def8dc22d9297f29556e638/aws-iam-role/main.tf#L2,https://github.com/chanzuckerberg/cztack/blob/216fe141b5aebe1d4eb594f10016eed34716d6fc/aws-iam-role/main.tf,2020-12-16 10:47:02+08:00,2020-12-16 23:03:48+08:00,2,1,0,1,1,0,0,0,0,0
https://github.com/Worklytics/psoxy,203,infra/modules/psoxy-package/main.tf,infra/modules/psoxy-package/main.tf,0,# todo,# TODO: solve weirdness with AWS case: AWS lambda is deployed directly by Terraform from a code,"# packages psoxy for deployment  
 # TODO: solve weirdness with AWS case: AWS lambda is deployed directly by Terraform from a code 
 # package built by terraform, but terraform doesn't understand this dependency in its plan. we make 
 # it work via explicit 'depends_on', but Terraform still gives 'error inconsistent plan' as its 
 # original plan presumed the sha-256 of the package","locals {
  path_to_core_module    = ""${var.path_to_psoxy_java}/core""
  path_to_impl_module    = ""${var.path_to_psoxy_java}/impl/${var.implementation}""
  path_to_deployment_jar = ""${local.path_to_impl_module}/target/psoxy-${var.implementation}-1.0-SNAPSHOT.jar""
}
",locals,"data ""external"" ""deployment_package"" {
  count = var.deployment_bundle == null ? 1 : 0

  program = [
    ""${path.module}/build.sh"",
    var.path_to_psoxy_java,
    var.implementation,
    var.force_bundle ? ""--force_bundle"" : """"
  ]
}
",data,3,3.0,450629d23c2f1ec4eb34e057d6d2c3ae5215abf2,02ae30df5ec3b392705780a5f58ae90ca40f01d7,https://github.com/Worklytics/psoxy/blob/450629d23c2f1ec4eb34e057d6d2c3ae5215abf2/infra/modules/psoxy-package/main.tf#L3,https://github.com/Worklytics/psoxy/blob/02ae30df5ec3b392705780a5f58ae90ca40f01d7/infra/modules/psoxy-package/main.tf#L3,2022-01-19 08:22:58-08:00,2023-06-21 21:02:46+00:00,16,0,1,1,1,0,0,0,0,0
https://github.com/Worklytics/psoxy,52,infra/modules/gcp-oauth-refresh-strategy/main.tf,infra/modules/gcp-oauth-refresh-strategy/main.tf,0,implementation,"# composing them is complex and exposes implementation details (eg, that refresh token strategy","# not 'proper' terraform style to invoke modules hierarchically rather than via composition; but 
 # composing them is complex and exposes implementation details (eg, that refresh token strategy 
 # requires two secrets)""","module ""client_secret_grant"" {
  source = ""../gcp-secret-user-version-adder""

  project_id     = var.project_id
  secret_id      = google_secret_manager_secret.client_secret.secret_id
  grant_duration = var.token_adder_grant_duration
  user_emails    = var.token_adder_user_emails
}
",module,,,29,0.0,1fd1678613e7c2ef7cf06efe921c58ec6e0e4a9a,f6f2f7e067e314e015df718052bc6b672925bfd4,https://github.com/Worklytics/psoxy/blob/1fd1678613e7c2ef7cf06efe921c58ec6e0e4a9a/infra/modules/gcp-oauth-refresh-strategy/main.tf#L29,https://github.com/Worklytics/psoxy/blob/f6f2f7e067e314e015df718052bc6b672925bfd4/infra/modules/gcp-oauth-refresh-strategy/main.tf#L0,2021-10-26 11:04:53-07:00,2022-11-10 23:38:02+01:00,3,2,0,1,0,1,0,0,0,0
https://github.com/nasa/cumulus,22,tf-modules/cumulus/ecs_cluster.tf,tf-modules/cumulus/ecs_cluster.tf,0,todo,# TODO I don't like the fact that we're making an assumption here about the names of our tables,# TODO I don't like the fact that we're making an assumption here about the names of our tables,"data ""aws_iam_policy_document"" ""ecs_cluster_instance_policy"" {
  statement {
    actions   = [""dynamodb:UpdateItem""]
    resources = [data.aws_dynamodb_table.async_operations.arn]
  }

  statement {
    actions = [
      ""autoscaling:CompleteLifecycleAction"",
      ""autoscaling:DescribeAutoScalingInstances"",
      ""autoscaling:DescribeLifecycleHooks"",
      ""autoscaling:RecordLifecycleActionHeartbeat"",
      ""cloudwatch:GetMetricStatistics"",
      ""ec2:DescribeInstances"",
      ""ecr:BatchCheckLayerAvailability"",
      ""ecr:BatchGetImage"",
      ""ecr:GetAuthorizationToken"",
      ""ecr:GetDownloadUrlForLayer"",
      ""ecs:DeregisterContainerInstance"",
      ""ecs:DescribeClusters"",
      ""ecs:DescribeContainerInstances"",
      ""ecs:DescribeServices"",
      ""ecs:DiscoverPollEndpoint"",
      ""ecs:ListContainerInstances"",
      ""ecs:ListServices"",
      ""ecs:ListTaskDefinitions"",
      ""ecs:ListTasks"",
      ""ecs:Poll"",
      ""ecs:RegisterContainerInstance"",
      ""ecs:RunTask"",
      ""ecs:StartTelemetrySession"",
      ""ecs:Submit*"",
      ""ecs:UpdateContainerInstancesState"",
      ""lambda:GetFunction"",
      ""lambda:invokeFunction"",
      ""logs:CreateLogGroup"",
      ""logs:CreateLogStream"",
      ""logs:DescribeLogStreams"",
      ""logs:PutLogEvents"",
      ""ssm:GetParameter""
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""states:DescribeActivity"",
      ""states:GetActivityTask"",
      ""states:GetExecutionHistory"",
      ""states:SendTaskFailure"",
      ""states:SendTaskSuccess""
    ]
    resources = [""arn:aws:states:*:*:*""]
  }

  statement {
    actions = [
      ""s3:GetAccelerateConfiguration"",
      ""s3:GetBucket*"",
      ""s3:GetLifecycleConfiguration"",
      ""s3:GetReplicationConfiguration"",
      ""s3:ListBucket*"",
      ""s3:PutAccelerateConfiguration"",
      ""s3:PutBucket*"",
      ""s3:PutLifecycleConfiguration"",
      ""s3:PutReplicationConfiguration""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}""]
  }

  statement {
    actions = [
      ""s3:AbortMultipartUpload"",
      ""s3:DeleteObject"",
      ""s3:DeleteObjectVersion"",
      ""s3:GetObject*"",
      ""s3:ListMultipartUploadParts"",
      ""s3:PutObject*""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}/*""]
  }

  statement {
    actions = [""dynamodb:Scan""]
    # TODO I don't like the fact that we're making an assumption here about the names of our tables
    resources = [""arn:aws:dynamodb:${data.aws_region.current.name}:${data.aws_caller_identity.current.account_id}:table/${var.prefix}-*""]
  }

  statement {
    actions = [
      ""es:ESHttpDelete"",
      ""es:ESHttpGet"",
      ""es:ESHttpHead"",
      ""es:ESHttpPost"",
      ""es:ESHttpPut""
    ]
    # TODO Get this value dynamically instead of from a variable
    resources = [var.elasticsearch_arn]
  }
}
",data,"data ""aws_iam_policy_document"" ""ecs_cluster_instance_policy"" {
  statement {
    actions   = [""dynamodb:UpdateItem""]
    resources = [var.dynamo_tables.async_operations.arn]
  }

  statement {
    actions = [
      ""autoscaling:CompleteLifecycleAction"",
      ""autoscaling:DescribeAutoScalingInstances"",
      ""autoscaling:DescribeLifecycleHooks"",
      ""autoscaling:RecordLifecycleActionHeartbeat"",
      ""cloudwatch:GetMetricStatistics"",
      ""ec2:DescribeInstances"",
      ""ecr:BatchCheckLayerAvailability"",
      ""ecr:BatchGetImage"",
      ""ecr:GetAuthorizationToken"",
      ""ecr:GetDownloadUrlForLayer"",
      ""ecs:DeregisterContainerInstance"",
      ""ecs:DescribeClusters"",
      ""ecs:DescribeContainerInstances"",
      ""ecs:DescribeServices"",
      ""ecs:DiscoverPollEndpoint"",
      ""ecs:ListContainerInstances"",
      ""ecs:ListServices"",
      ""ecs:ListTaskDefinitions"",
      ""ecs:ListTasks"",
      ""ecs:Poll"",
      ""ecs:RegisterContainerInstance"",
      ""ecs:RunTask"",
      ""ecs:StartTelemetrySession"",
      ""ecs:Submit*"",
      ""ecs:UpdateContainerInstancesState"",
      ""lambda:GetFunction"",
      ""lambda:invokeFunction"",
      ""logs:CreateLogGroup"",
      ""logs:CreateLogStream"",
      ""logs:DescribeLogStreams"",
      ""logs:PutLogEvents"",
      ""ssm:GetParameter""
    ]
    resources = [""*""]
  }

  statement {
    actions = [
      ""states:DescribeActivity"",
      ""states:GetActivityTask"",
      ""states:GetExecutionHistory"",
      ""states:SendTaskFailure"",
      ""states:SendTaskSuccess""
    ]
    resources = [""arn:aws:states:*:*:*""]
  }

  statement {
    actions = [
      ""s3:GetAccelerateConfiguration"",
      ""s3:GetBucket*"",
      ""s3:GetLifecycleConfiguration"",
      ""s3:GetReplicationConfiguration"",
      ""s3:ListBucket*"",
      ""s3:PutAccelerateConfiguration"",
      ""s3:PutBucket*"",
      ""s3:PutLifecycleConfiguration"",
      ""s3:PutReplicationConfiguration""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}""]
  }

  statement {
    actions = [
      ""s3:AbortMultipartUpload"",
      ""s3:DeleteObject"",
      ""s3:DeleteObjectVersion"",
      ""s3:GetObject*"",
      ""s3:ListMultipartUploadParts"",
      ""s3:PutObject*""
    ]
    resources = [for b in flatten([var.public_buckets, var.protected_buckets, var.private_buckets, var.system_bucket]) : ""arn:aws:s3:::${b}/*""]
  }

  statement {
    actions   = [""dynamodb:Scan""]
    resources = [for k, v in var.dynamo_tables : v.arn]
  }

  statement {
    actions = [
      ""es:ESHttpDelete"",
      ""es:ESHttpGet"",
      ""es:ESHttpHead"",
      ""es:ESHttpPost"",
      ""es:ESHttpPut""
    ]
    resources = [var.elasticsearch_domain_arn]
  }
}
",data,90,,1da53282470313085da6e713a94458500df71f6c,ff8e3e11f6c76726b63759d970e3289c743980ad,https://github.com/nasa/cumulus/blob/1da53282470313085da6e713a94458500df71f6c/tf-modules/cumulus/ecs_cluster.tf#L90,https://github.com/nasa/cumulus/blob/ff8e3e11f6c76726b63759d970e3289c743980ad/tf-modules/cumulus/ecs_cluster.tf,2019-08-02 16:32:51-04:00,2019-09-06 13:28:48-04:00,6,1,1,1,0,1,0,0,0,0
https://github.com/terraform-aws-modules/terraform-aws-eks,126,node_groups.tf,node_groups.tf,0,hack,# Hack to ensure ordering of resource creation. Do not create node_groups,"# Hack to ensure ordering of resource creation. Do not create node_groups 
 # before other resources are ready. Removes race conditions","data ""null_data_source"" ""node_groups"" {
  count = var.create_eks ? 1 : 0

  inputs = {
    cluster_name = var.cluster_name

    # Ensure these resources are created before ""unlocking"" the data source.
    # `depends_on` causes a refresh on every run so is useless here.
    # [Re]creating or removing these resources will trigger recreation of Node Group resources
    aws_auth         = coalescelist(kubernetes_config_map.aws_auth[*].id, [""""])[0]
    role_NodePolicy  = coalescelist(aws_iam_role_policy_attachment.workers_AmazonEKSWorkerNodePolicy[*].id, [""""])[0]
    role_CNI_Policy  = coalescelist(aws_iam_role_policy_attachment.workers_AmazonEKS_CNI_Policy[*].id, [""""])[0]
    role_Container   = coalescelist(aws_iam_role_policy_attachment.workers_AmazonEC2ContainerRegistryReadOnly[*].id, [""""])[0]
    role_autoscaling = coalescelist(aws_iam_role_policy_attachment.workers_autoscaling[*].id, [""""])[0]
  }
}
",data,the block associated got renamed or deleted,,1,,11147e9af34054c4c4576aa00938a2c65198ca5f,616d30ec674ff1d125710755f5073b1665bbd1af,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/11147e9af34054c4c4576aa00938a2c65198ca5f/node_groups.tf#L1,https://github.com/terraform-aws-modules/terraform-aws-eks/blob/616d30ec674ff1d125710755f5073b1665bbd1af/node_groups.tf,2020-01-09 12:53:08+01:00,2020-06-28 02:31:23+02:00,5,1,1,1,0,0,0,0,0,0
https://github.com/pingcap/tidb-operator,8,deploy/alicloud/main.tf,deploy/aliyun/main.tf,1,fix,// TODO: use STS when upstream get this fixed,"// Workaround: ACK does not support customize node RAM role, access key is the only way get local volume provisioner working 
 // TODO: use STS when upstream get this fixed","resource ""local_file"" ""local-volume-provisioner"" {
  depends_on = [""data.template_file.local-volume-provisioner""]
  filename   = ""${local.local_volume_provisioner_path}""
  content    = ""${data.template_file.local-volume-provisioner.rendered}""
}
",resource,the block associated got renamed or deleted,,86,,eebd686956c0b2adf67a10e1a376659c95c571a3,042b1a97fbbdf342297002990564828e6644a3f0,https://github.com/pingcap/tidb-operator/blob/eebd686956c0b2adf67a10e1a376659c95c571a3/deploy/alicloud/main.tf#L86,https://github.com/pingcap/tidb-operator/blob/042b1a97fbbdf342297002990564828e6644a3f0/deploy/aliyun/main.tf,2019-05-06 19:59:43+08:00,2019-07-23 19:44:58+08:00,4,1,0,1,1,1,0,0,0,0
https://github.com/GoogleCloudPlatform/hpc-toolkit,52,modules/compute/vm-instance/variables.tf,modules/compute/vm-instance/variables.tf,0,workaround,# It's a workaround of lack of `optional` in Terraform 1.2,type    = any # It's a workaround of lack of `optional` in Terraform 1.2,"variable ""placement_policy"" {
  description = <<-EOT
  Control where your VM instances are physically located relative to each other within a zone.
  See https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_resource_policy#nested_group_placement_policy
  EOT

  type    = any # It's a workaround of lack of `optional` in Terraform 1.2
  default = null
  validation {
    condition     = var.placement_policy == null ? true : try(keys(var.placement_policy), null) != null
    error_message = <<-EOT
    The var.placement_policy should be either unset/null or be a map/object with 
    fields: vm_count (number), availability_domain_count (number), collocation (string), max_distance (number).
    EOT
  }

  validation {
    condition = alltrue([
      for k in try(keys(var.placement_policy), []) : contains([
      ""vm_count"", ""availability_domain_count"", ""collocation"", ""max_distance""], k)
    ])
    error_message = <<-EOT
    The supported fields for var.placement_policy are:
    vm_count (number), availability_domain_count (number), collocation (string), max_distance (number).
    EOT
  }
}
",variable,"variable ""placement_policy"" {
  description = <<-EOT
  Control where your VM instances are physically located relative to each other within a zone.
  See https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_resource_policy#nested_group_placement_policy
  EOT

  type    = any # It's a workaround of lack of `optional` in Terraform 1.2
  default = null
  validation {
    condition     = var.placement_policy == null ? true : try(keys(var.placement_policy), null) != null
    error_message = <<-EOT
    The var.placement_policy should be either unset/null or be a map/object with 
    fields: vm_count (number), availability_domain_count (number), collocation (string), max_distance (number).
    EOT
  }

  validation {
    condition = alltrue([
      for k in try(keys(var.placement_policy), []) : contains([
      ""vm_count"", ""availability_domain_count"", ""collocation"", ""max_distance""], k)
    ])
    error_message = <<-EOT
    The supported fields for var.placement_policy are:
    vm_count (number), availability_domain_count (number), collocation (string), max_distance (number).
    EOT
  }
}
",variable,286,308.0,99573023b3653e2d7aca52c3f41de5c788b9a342,99abb3b2a16d20128fe85ba43c8c1356ebd9858f,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/99573023b3653e2d7aca52c3f41de5c788b9a342/modules/compute/vm-instance/variables.tf#L286,https://github.com/GoogleCloudPlatform/hpc-toolkit/blob/99abb3b2a16d20128fe85ba43c8c1356ebd9858f/modules/compute/vm-instance/variables.tf#L308,2023-07-12 12:33:12-07:00,2024-03-07 14:31:49-06:00,8,0,0,0,1,0,0,0,0,0
https://github.com/ministryofjustice/aws-root-account,9,terraform/organizations-accounts-hmpps-delius.tf,terraform/organizations-accounts-hmpps-delius.tf,0,# todo,# TODO: Move this into AWS Secrets Manager,"email     = local.account_emails[""Alfresco non-prod""][0] # TODO: Move this into AWS Secrets Manager","resource ""aws_organizations_account"" ""alfresco-non-prod"" {
  name      = ""Alfresco non-prod""
  email     = local.account_emails[""Alfresco non-prod""][0] # TODO: Move this into AWS Secrets Manager
  parent_id = aws_organizations_organizational_unit.hmpps-delius.id

  lifecycle {
    # If any of these attributes are changed, it attempts to destroy and recreate the account,
    # so we should ignore the changes to prevent this from happening.
    ignore_changes = [
      name,
      email,
      iam_user_access_to_billing,
      role_name
    ]
  }
}
",resource,,,4,0.0,b2b66fbf2222c0f21bb889002f2aa294eb1fe375,d7b325af5b38460b9d14f63e6bdc9716285854f3,https://github.com/ministryofjustice/aws-root-account/blob/b2b66fbf2222c0f21bb889002f2aa294eb1fe375/terraform/organizations-accounts-hmpps-delius.tf#L4,https://github.com/ministryofjustice/aws-root-account/blob/d7b325af5b38460b9d14f63e6bdc9716285854f3/terraform/organizations-accounts-hmpps-delius.tf#L0,2020-11-26 14:00:11+00:00,2022-03-01 19:30:50+00:00,5,2,0,1,0,1,0,0,0,0
https://github.com/wireapp/wire-server-deploy,3,terraform/modules/aws_vpc_security_groups/main.tf,terraform/modules/aws-vpc-security-groups/main.tf,1,fix,# FIXME: tighten this up. need UDP for flannel.,# FIXME: tighten this up. need UDP for flannel.,"resource ""aws_security_group"" ""k8s_node"" {
  name        = ""k8s_node""
  description = ""hosts that have kubernetes.""
  vpc_id      = var.vpc_id

  # incoming from the admin node (kubectl)
  ingress {
    from_port   = 6443
    to_port     = 6443
    protocol    = ""tcp""
    security_groups = [""${aws_security_group.talk_to_k8s.id}""]
  }

  # FIXME: tighten this up.
  ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = ""tcp""
    security_groups = [""${aws_security_group.k8s_private.id}""]
  }

  # FIXME: tighten this up. need UDP for flannel.
  ingress {
    from_port   = 0
    to_port     = 65535
    protocol    = ""udp""
    security_groups = [""${aws_security_group.k8s_private.id}""]
  }

  tags = {
    Name = ""k8s_node""
  }
}
",resource,"resource ""aws_security_group"" ""k8s_node"" {
  name        = ""k8s_node""
  description = ""hosts that have kubernetes.""
  vpc_id      = var.vpc_id

  # incoming from the admin node (kubectl)
  ingress {
    description     = """"
    from_port       = 6443
    to_port         = 6443
    protocol        = ""tcp""
    security_groups = [""${aws_security_group.talk_to_k8s.id}""]
  }

  # FIXME: tighten this up.
  ingress {
    description     = """"
    from_port       = 0
    to_port         = 65535
    protocol        = ""tcp""
    security_groups = [""${aws_security_group.k8s_private.id}""]
  }

  # FIXME: tighten this up. need UDP for flannel.
  ingress {
    description     = """"
    from_port       = 0
    to_port         = 65535
    protocol        = ""udp""
    security_groups = [""${aws_security_group.k8s_private.id}""]
  }

  # incoming traffic to the application.
  ingress {
    from_port   = 31772
    to_port     = 31773
    protocol    = ""tcp""
    # NOTE: NLBs dont allow security groups to be set on them, which is why
    # we go with the CIDR for now, which is hard-coded and needs fixing
    cidr_blocks = [""172.17.0.0/20""]
  }

  tags = {
    Name = ""k8s_node""
  }
}
",resource,221,234.0,cb61b733457d5a1ccdb5c9dcb5fde4cab9e5d7e0,e7f081ca744de60bf9d10cb037828b995883d2aa,https://github.com/wireapp/wire-server-deploy/blob/cb61b733457d5a1ccdb5c9dcb5fde4cab9e5d7e0/terraform/modules/aws_vpc_security_groups/main.tf#L221,https://github.com/wireapp/wire-server-deploy/blob/e7f081ca744de60bf9d10cb037828b995883d2aa/terraform/modules/aws-vpc-security-groups/main.tf#L234,2020-04-23 17:54:17+01:00,2020-08-26 16:29:39+02:00,5,0,0,0,0,1,0,0,0,0
https://github.com/aws-observability/terraform-aws-observability-accelerator,33,examples/existing-cluster-with-base-and-infra/main.tf,examples/existing-cluster-with-base-and-infra/main.tf,0,todo,# TODO remove when Kevin's PR is live,# TODO remove when Kevin's PR is live,"module ""workloads_infra"" {
  source = ""../../workloads/infra""
  # source = ""aws-ia/terrarom-aws-observability-accelerator/workloads/infra""

  eks_cluster_id = module.eks_observability_accelerator.eks_cluster_id

  dashboards_folder_id            = module.eks_observability_accelerator.grafana_dashboards_folder_id
  managed_prometheus_workspace_id = module.eks_observability_accelerator.managed_prometheus_workspace_id

  # TODO remove when Kevin's PR is live
  managed_prometheus_workspace_endpoint = module.eks_observability_accelerator.managed_prometheus_workspace_endpoint
  managed_prometheus_workspace_region   = module.eks_observability_accelerator.managed_prometheus_workspace_region


  managed_grafana_workspace_endpoint = module.eks_observability_accelerator.managed_grafana_workspace_endpoint

  # TODO: manage with Secrets manager
  grafana_api_key = var.grafana_api_key

  # module custom configuration, check module Documentation
  # config               = {}

  # depends_on = [
  #   module.eks_observability_accelerator
  # ]
}
",module,"module ""workloads_infra"" {
  source = ""../../modules/workloads/infra""
  # source = ""aws-observability/terrarom-aws-observability-accelerator/workloads/infra""

  eks_cluster_id = module.eks_observability_accelerator.eks_cluster_id

  dashboards_folder_id            = module.eks_observability_accelerator.grafana_dashboards_folder_id
  managed_prometheus_workspace_id = module.eks_observability_accelerator.managed_prometheus_workspace_id

  managed_prometheus_workspace_endpoint = module.eks_observability_accelerator.managed_prometheus_workspace_endpoint
  managed_prometheus_workspace_region   = module.eks_observability_accelerator.managed_prometheus_workspace_region

  enable_alerting_rules = false

  tags = local.tags

  depends_on = [
    module.eks_observability_accelerator
  ]
}
",module,90,,6dca51b135de9dae7aa62a61e7eebc9895c27412,05511992e9cc5b9fdd5c3ba59e30704d78fadda3,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/6dca51b135de9dae7aa62a61e7eebc9895c27412/examples/existing-cluster-with-base-and-infra/main.tf#L90,https://github.com/aws-observability/terraform-aws-observability-accelerator/blob/05511992e9cc5b9fdd5c3ba59e30704d78fadda3/examples/existing-cluster-with-base-and-infra/main.tf,2022-08-26 17:30:03+02:00,2022-08-30 19:59:34+02:00,7,1,0,1,0,0,0,0,1,0
https://github.com/uyuni-project/sumaform,1593,modules/server_containerized/main.tf,modules/server_containerized/main.tf,0,// todo,"// TODO: This module is a copy/paste of the server module and some variables are not yet implemented, some could also be dropped, work in-progress.","// TODO: This module is a copy/paste of the server module and some variables are not yet implemented, some could also be dropped, work in-progress. ","variable ""images"" {
  default = {
    ""head""           = ""sles15sp4o""
    ""uyuni-master""   = ""opensuse154o""
    ""uyuni-released"" = ""opensuse154o""
    ""uyuni-pr""       = ""opensuse154o""
  }
}
",variable,"variable ""images"" {
  default = {
    ""head""           = ""slemicro55o""
    ""uyuni-master""   = ""leapmicro55o""
    ""uyuni-released"" = ""leapmicro55o""
    ""uyuni-pr""       = ""leapmicro55o""
  }
}
",variable,1,1.0,d102072b9d7d2bdbb735f2ab16d98fef44f031dd,951f2ff6b900c938712001c5ce9daf9a1119209b,https://github.com/uyuni-project/sumaform/blob/d102072b9d7d2bdbb735f2ab16d98fef44f031dd/modules/server_containerized/main.tf#L1,https://github.com/uyuni-project/sumaform/blob/951f2ff6b900c938712001c5ce9daf9a1119209b/modules/server_containerized/main.tf#L1,2023-07-31 09:35:18+02:00,2024-04-10 13:06:55+02:00,19,0,0,1,0,0,0,0,0,0
https://github.com/kubernetes/k8s.io,226,infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf,infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf,0,// todo,// TODO: this role belongs in k8s-infra-prow-build,// TODO: this role belongs in k8s-infra-prow-build,"resource ""google_project_iam_member"" ""prow_deployer_for_prow_build"" {
  project = ""k8s-infra-prow-build""
  role    = ""roles/container.admin""
  member  = ""serviceAccount:prow-deployer@k8s-infra-prow-build-trusted.iam.gserviceaccount.com""
}
",resource,the block associated got renamed or deleted,,101,,a3ad1141d5391ea466f6e15dce112d7d2be2c89b,e48cc4ae5c901edac148bb40e05077612b80ac64,https://github.com/kubernetes/k8s.io/blob/a3ad1141d5391ea466f6e15dce112d7d2be2c89b/infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf#L101,https://github.com/kubernetes/k8s.io/blob/e48cc4ae5c901edac148bb40e05077612b80ac64/infra/gcp/terraform/k8s-infra-prow-build-trusted/main.tf,2021-09-28 20:31:14-07:00,2021-09-29 06:31:05-07:00,3,1,0,0,0,1,0,0,0,0
https://github.com/GoogleCloudPlatform/cloud-foundation-fabric,852,fast/stages/03-gke-multitenant/prod/gke-nodepools.tf,fast/stages/03-gke-multitenant/_module/gke-nodepools.tf,1,# todo,# TODO(jccb): can we use spot instances here?,# TODO(jccb): can we use spot instances here?,"module ""gke_1_nodepool"" {
  source             = ""../../../../modules/gke-nodepool""
  for_each           = local.nodepools
  name               = each.value.name
  project_id         = module.gke-project-0.project_id
  cluster_name       = module.gke-cluster[each.value.cluster].name
  location           = module.gke-cluster[each.value.cluster].location
  initial_node_count = each.value.node_count
  node_machine_type  = each.value.node_type
  # TODO(jccb): can we use spot instances here?
  node_preemptible = each.value.preemptible

  node_count = each.value.node_count
  # node_count = (
  #   each.value.autoscaling_config == null ? each.value.node_count : null
  # )
  # dynamic ""autoscaling_config"" {
  #   for_each = each.value.autoscaling_config == null ? {} : { 1 = 1 }
  #   content {
  #     min_node_count = each.value.autoscaling_config.min_node_count
  #     max_node_count = each.value.autoscaling_config.max_node_count
  #   }
  # }

  # overrides
  node_locations    = each.value.overrides.node_locations
  max_pods_per_node = each.value.overrides.max_pods_per_node
  node_image_type   = each.value.overrides.image_type
  node_tags         = each.value.overrides.node_tags
  node_taints       = each.value.overrides.node_taints

  management_config = {
    auto_repair  = true
    auto_upgrade = true
  }

  node_service_account_create = true
}
",module,the block associated got renamed or deleted,,39,,f3f9a4a88cedd64f6fc91b64666046aa6726a2f3,3745b2885ef1a43b46c663221e77aba0f2eee817,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/f3f9a4a88cedd64f6fc91b64666046aa6726a2f3/fast/stages/03-gke-multitenant/prod/gke-nodepools.tf#L39,https://github.com/GoogleCloudPlatform/cloud-foundation-fabric/blob/3745b2885ef1a43b46c663221e77aba0f2eee817/fast/stages/03-gke-multitenant/_module/gke-nodepools.tf,2022-06-08 11:41:50+02:00,2022-08-06 11:00:46+02:00,4,1,1,1,0,0,0,0,0,1
https://github.com/chanzuckerberg/cztack,9,aws-s3-private-bucket/main.tf,aws-s3-private-bucket/main.tf,0,# todo,# TODO,"# TODO 
 #   logging { 
 #   target_bucket = """" 
 #   target_prefix = """" 
 # } ","resource ""aws_s3_bucket"" ""bucket"" {
  bucket = ""${var.bucket_name}""
  acl    = ""private""

  policy = ""${data.aws_iam_policy_document.bucket_policy.json}""

  versioning {
    enabled = true
  }

  # TODO
  #   logging {
  #   target_bucket = """"
  #   target_prefix = """"
  # }

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = ""AES256""
      }
    }
  }
  tags = ""${local.tags}""
}
",resource,"resource ""aws_s3_bucket"" ""bucket"" {
  bucket = var.bucket_name
  # `grant` and `acl` conflict with each other - https://www.terraform.io/docs/providers/aws/r/s3_bucket.html#acl

  # Using canned ACL will conflict with using grant ACL
  acl = local.acl

  dynamic ""grant"" {
    for_each = local.valid_grants

    content {
      id          = lookup(grant.value, ""canonical_user_id"", null)
      uri         = lookup(grant.value, ""uri"", null)
      permissions = grant.value.permissions
      type        = lookup(grant.value, ""canonical_user_id"", null) == null ? ""Group"" : ""CanonicalUser""
    }
  }

  versioning {
    enabled = var.enable_versioning
  }

  dynamic ""cors_rule"" {
    for_each = var.cors_rules

    content {
      allowed_headers = lookup(cors_rule.value, ""allowed_headers"", null)
      allowed_methods = lookup(cors_rule.value, ""allowed_methods"", null)
      allowed_origins = lookup(cors_rule.value, ""allowed_origins"", null)
      expose_headers  = lookup(cors_rule.value, ""expose_headers"", null)
      max_age_seconds = lookup(cors_rule.value, ""max_age_seconds"", null)
    }
  }

  acceleration_status = var.transfer_acceleration ? ""Enabled"" : ""Suspended""

  # dynamic block used instead of simply assigning a variable b/c lifecycle_rule is configuration block
  dynamic ""lifecycle_rule"" {
    for_each = var.lifecycle_rules

    content {
      id      = lookup(lifecycle_rule.value, ""id"", null) #lookup() provides default value in case it does not exist in var.lifecycle_rules input
      prefix  = lookup(lifecycle_rule.value, ""prefix"", null)
      tags    = lookup(lifecycle_rule.value, ""tags"", null)
      enabled = lookup(lifecycle_rule.value, ""enabled"", false)
      # var.abort_incomplete_multipart_upload_days is 14 by default
      abort_incomplete_multipart_upload_days = lookup(lifecycle_rule.value, ""abort_incomplete_multipart_upload_days"", var.abort_incomplete_multipart_upload_days)

      dynamic ""expiration"" {
        for_each = length(keys(lookup(lifecycle_rule.value, ""expiration"", {}))) == 0 ? [] : [lookup(lifecycle_rule.value, ""expiration"", {})]

        content {
          date                         = lookup(expiration.value, ""date"", null)
          days                         = lookup(expiration.value, ""days"", null)
          expired_object_delete_marker = lookup(expiration.value, ""expired_object_delete_marker"", null)
        }
      }

      dynamic ""transition"" {
        for_each = length(keys(lookup(lifecycle_rule.value, ""transition"", {}))) == 0 ? [] : [lookup(lifecycle_rule.value, ""transition"", {})]

        content {
          date          = lookup(transition.value, ""date"", null)
          days          = lookup(transition.value, ""days"", null)
          storage_class = lookup(transition.value, ""storage_class"", null)
        }
      }

      dynamic ""noncurrent_version_expiration"" {
        for_each = length(keys(lookup(lifecycle_rule.value, ""noncurrent_version_expiration"", {}))) == 0 ? [] : [lookup(lifecycle_rule.value, ""noncurrent_version_expiration"", {})]

        content {
          days = lookup(noncurrent_version_expiration.value, ""days"", null)
        }
      }

      dynamic ""noncurrent_version_transition"" {
        for_each = length(keys(lookup(lifecycle_rule.value, ""noncurrent_version_transition"", {}))) == 0 ? [] : [lookup(lifecycle_rule.value, ""noncurrent_version_transition"", {})]

        content {
          days          = lookup(lifecycle_rule.value.noncurrent_version_transition, ""days"", null)
          storage_class = lookup(lifecycle_rule.value.noncurrent_version_transition, ""storage_class"", null)
        }
      }
    }
  }

  dynamic ""logging"" {
    for_each = var.logging_bucket == null ? [] : [var.logging_bucket]
    content {
      target_bucket = var.logging_bucket.name
      target_prefix = var.logging_bucket.prefix
    }
  }

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm = ""AES256""
      }
    }
  }
  tags = local.tags
}
",resource,21,,22e21f1ad3ed47710fa56060efc74a5c531c574f,c0c5731e3901a2e1bb1fde5c2b3a5337afdb8ac1,https://github.com/chanzuckerberg/cztack/blob/22e21f1ad3ed47710fa56060efc74a5c531c574f/aws-s3-private-bucket/main.tf#L21,https://github.com/chanzuckerberg/cztack/blob/c0c5731e3901a2e1bb1fde5c2b3a5337afdb8ac1/aws-s3-private-bucket/main.tf,2019-08-20 10:49:00-07:00,2021-04-15 16:45:51-07:00,17,1,1,1,0,0,0,0,1,0
